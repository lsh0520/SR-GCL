nohup: ignoring input
[08:20:16] WARNING: not removing hydrogen atom without neighbors
[08:20:16] WARNING: not removing hydrogen atom without neighbors
[08:20:17] WARNING: not removing hydrogen atom without neighbors
[08:20:17] WARNING: not removing hydrogen atom without neighbors
[08:20:17] WARNING: not removing hydrogen atom without neighbors
[08:20:17] WARNING: not removing hydrogen atom without neighbors
[08:20:17] WARNING: not removing hydrogen atom without neighbors
[08:20:17] WARNING: not removing hydrogen atom without neighbors
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.4.
[08:20:17] WARNING: not removing hydrogen atom without neighbors
[08:20:17] WARNING: not removing hydrogen atom without neighbors
[08:20:17] WARNING: not removing hydrogen atom without neighbors
[08:20:18] WARNING: not removing hydrogen atom without neighbors
[08:20:18] WARNING: not removing hydrogen atom without neighbors
2022-09-13 08:20:19.114 | INFO     | modules.masked_transformer_encoder:__init__:122 - number of parameters: 0.000000e+00
=========================================
batch_size = 32
d_model = 128
dataset = sider
decay = 0
device = 0
dim_feedforward = 512
eval_train = 0
filename =
gnn_JK = cat
gnn_dropout = 0.3
gnn_emb_dim = 300
gnn_num_layer = 5
gnn_residual = False
gnn_type = gin
gnn_virtual_node = False
graph_pooling = cls
input_model_file = models_graphtrans/graphtrans-sr-gcl.pth
lr = 0.0001
lr_scale = 1
max_input_len = 1000
nhead = 4
num_encoder_layers = 4
num_encoder_layers_masked = 0
num_workers = 0
pos_encoder = False
runseed = 0
seed = 12344
split = scaffold
transformer_activation = relu
transformer_dropout = 0.3
transformer_norm_input = True
transformer_prenorm = False
=========================================
sider
scaffold
Loaded GraphTrans from models_graphtrans/graphtrans-sr-gcl.pth
====epoch 1
Train Loss 23.644715948266473
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.4866 test: 0.5106 | best val epoch -- val: 0.4866 test: 0.5106

====epoch 2
Train Loss 20.556616771525043
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.5015 test: 0.5077 | best val epoch -- val: 0.5015 test: 0.5077

====epoch 3
Train Loss 19.586620989944134
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.5029 test: 0.5082 | best val epoch -- val: 0.5029 test: 0.5082

====epoch 4
Train Loss 19.19761611484311
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.5215 test: 0.5131 | best val epoch -- val: 0.5215 test: 0.5131

====epoch 5
Train Loss 19.16041564326333
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.5169 test: 0.5152 | best val epoch -- val: 0.5215 test: 0.5131

====epoch 6
Train Loss 19.08955047757368
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.5132 test: 0.5187 | best val epoch -- val: 0.5215 test: 0.5131

====epoch 7
Train Loss 19.036279402963235
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.5173 test: 0.5169 | best val epoch -- val: 0.5215 test: 0.5131

====epoch 8
Train Loss 18.99395912980375
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.5116 test: 0.5197 | best val epoch -- val: 0.5215 test: 0.5131

====epoch 9
Train Loss 18.926411711289028
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.5177 test: 0.5267 | best val epoch -- val: 0.5215 test: 0.5131

====epoch 10
Train Loss 18.82571659450953
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.5213 test: 0.5395 | best val epoch -- val: 0.5215 test: 0.5131

====epoch 11
Train Loss 18.733073261652677
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.5251 test: 0.5457 | best val epoch -- val: 0.5251 test: 0.5457

====epoch 12
Train Loss 18.680075896724713
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.5415 test: 0.5478 | best val epoch -- val: 0.5415 test: 0.5478

====epoch 13
Train Loss 18.45970062244806
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.5371 test: 0.5587 | best val epoch -- val: 0.5415 test: 0.5478

====epoch 14
Train Loss 18.33361826548345
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.5341 test: 0.5624 | best val epoch -- val: 0.5415 test: 0.5478

====epoch 15
Train Loss 18.14179319944102
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.5359 test: 0.5700 | best val epoch -- val: 0.5415 test: 0.5478

====epoch 16
Train Loss 17.999835992448038
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.5510 test: 0.5800 | best val epoch -- val: 0.5510 test: 0.5800

====epoch 17
Train Loss 17.979616100336568
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.5628 test: 0.5966 | best val epoch -- val: 0.5628 test: 0.5966

====epoch 18
Train Loss 17.787210253073564
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.5688 test: 0.5887 | best val epoch -- val: 0.5688 test: 0.5887

====epoch 19
Train Loss 17.6934004189474
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.5731 test: 0.5989 | best val epoch -- val: 0.5731 test: 0.5989

====epoch 20
Train Loss 17.677002723330546
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.5825 test: 0.6162 | best val epoch -- val: 0.5825 test: 0.6162

====epoch 21
Train Loss 17.563391399101107
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.5852 test: 0.5957 | best val epoch -- val: 0.5852 test: 0.5957

====epoch 22
Train Loss 17.500378996875167
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.5987 test: 0.6093 | best val epoch -- val: 0.5987 test: 0.6093

====epoch 23
Train Loss 17.33067837824143
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.5982 test: 0.6040 | best val epoch -- val: 0.5987 test: 0.6093

====epoch 24
Train Loss 17.2893643053335
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.5966 test: 0.6102 | best val epoch -- val: 0.5987 test: 0.6093

====epoch 25
Train Loss 17.255525949875018
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6063 test: 0.6113 | best val epoch -- val: 0.6063 test: 0.6113

====epoch 26
Train Loss 17.284181620904864
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6047 test: 0.6238 | best val epoch -- val: 0.6063 test: 0.6113

====epoch 27
Train Loss 17.143267233383558
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6046 test: 0.6230 | best val epoch -- val: 0.6063 test: 0.6113

====epoch 28
Train Loss 16.960690603385327
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6018 test: 0.6111 | best val epoch -- val: 0.6063 test: 0.6113

====epoch 29
Train Loss 17.032030898248927
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6122 test: 0.6127 | best val epoch -- val: 0.6122 test: 0.6127

====epoch 30
Train Loss 17.040627379384322
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6146 test: 0.6297 | best val epoch -- val: 0.6146 test: 0.6297

====epoch 31
Train Loss 16.940687086676306
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6270 test: 0.6258 | best val epoch -- val: 0.6270 test: 0.6258

====epoch 32
Train Loss 16.625193961341637
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6225 test: 0.6128 | best val epoch -- val: 0.6270 test: 0.6258

====epoch 33
Train Loss 16.59935625480257
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6198 test: 0.6147 | best val epoch -- val: 0.6270 test: 0.6258

====epoch 34
Train Loss 16.65532426713044
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6255 test: 0.6132 | best val epoch -- val: 0.6270 test: 0.6258

====epoch 35
Train Loss 16.6483991169846
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6194 test: 0.6154 | best val epoch -- val: 0.6270 test: 0.6258

====epoch 36
Train Loss 16.495503163405473
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6280 test: 0.6238 | best val epoch -- val: 0.6280 test: 0.6238

====epoch 37
Train Loss 16.475535189597014
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6271 test: 0.6167 | best val epoch -- val: 0.6280 test: 0.6238

====epoch 38
Train Loss 16.37353653006124
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6268 test: 0.6244 | best val epoch -- val: 0.6280 test: 0.6238

====epoch 39
Train Loss 16.429635504339902
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6241 test: 0.6246 | best val epoch -- val: 0.6280 test: 0.6238

====epoch 40
Train Loss 16.397403148930888
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6358 test: 0.6190 | best val epoch -- val: 0.6358 test: 0.6190

====epoch 41
Train Loss 16.25399223089162
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6305 test: 0.6270 | best val epoch -- val: 0.6358 test: 0.6190

====epoch 42
Train Loss 16.17452909223598
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6268 test: 0.6181 | best val epoch -- val: 0.6358 test: 0.6190

====epoch 43
Train Loss 15.970869150093439
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6312 test: 0.6244 | best val epoch -- val: 0.6358 test: 0.6190

====epoch 44
Train Loss 16.127674609793434
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6290 test: 0.6240 | best val epoch -- val: 0.6358 test: 0.6190

====epoch 45
Train Loss 15.992965733184242
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6314 test: 0.6147 | best val epoch -- val: 0.6358 test: 0.6190

====epoch 46
Train Loss 15.9466833985229
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6372 test: 0.6212 | best val epoch -- val: 0.6372 test: 0.6212

====epoch 47
Train Loss 15.878447626242645
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6309 test: 0.6130 | best val epoch -- val: 0.6372 test: 0.6212

====epoch 48
Train Loss 15.964915817763547
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6340 test: 0.6240 | best val epoch -- val: 0.6372 test: 0.6212

====epoch 49
Train Loss 15.724014683105498
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6322 test: 0.6179 | best val epoch -- val: 0.6372 test: 0.6212

====epoch 50
Train Loss 15.751913189494783
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6379 test: 0.6195 | best val epoch -- val: 0.6379 test: 0.6195

====epoch 51
Train Loss 15.784193782806632
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6299 test: 0.6180 | best val epoch -- val: 0.6379 test: 0.6195

====epoch 52
Train Loss 15.741099570897651
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6377 test: 0.6148 | best val epoch -- val: 0.6379 test: 0.6195

====epoch 53
Train Loss 15.79950230384833
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6371 test: 0.6251 | best val epoch -- val: 0.6379 test: 0.6195

====epoch 54
Train Loss 15.577958377086619
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6291 test: 0.6241 | best val epoch -- val: 0.6379 test: 0.6195

====epoch 55
Train Loss 15.50483057965388
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6309 test: 0.6320 | best val epoch -- val: 0.6379 test: 0.6195

====epoch 56
Train Loss 15.430223057449352
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6435 test: 0.6408 | best val epoch -- val: 0.6435 test: 0.6408

====epoch 57
Train Loss 15.559268463394746
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6376 test: 0.6308 | best val epoch -- val: 0.6435 test: 0.6408

====epoch 58
Train Loss 15.389718231004775
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6405 test: 0.6318 | best val epoch -- val: 0.6435 test: 0.6408

====epoch 59
Train Loss 15.466662399470211
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6338 test: 0.6281 | best val epoch -- val: 0.6435 test: 0.6408

====epoch 60
Train Loss 15.326394253764827
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6344 test: 0.6311 | best val epoch -- val: 0.6435 test: 0.6408

====epoch 61
Train Loss 15.327346707419755
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6373 test: 0.6213 | best val epoch -- val: 0.6435 test: 0.6408

====epoch 62
Train Loss 15.404405689415812
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6444 test: 0.6145 | best val epoch -- val: 0.6444 test: 0.6145

====epoch 63
Train Loss 15.256640882836942
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6432 test: 0.6216 | best val epoch -- val: 0.6444 test: 0.6145

====epoch 64
Train Loss 15.225419439257903
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6466 test: 0.6201 | best val epoch -- val: 0.6466 test: 0.6201

====epoch 65
Train Loss 15.127736320926765
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6419 test: 0.6301 | best val epoch -- val: 0.6466 test: 0.6201

====epoch 66
Train Loss 15.13325919048272
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6409 test: 0.6285 | best val epoch -- val: 0.6466 test: 0.6201

====epoch 67
Train Loss 15.01721386735865
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6408 test: 0.6202 | best val epoch -- val: 0.6466 test: 0.6201

====epoch 68
Train Loss 14.972714340969878
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6389 test: 0.6243 | best val epoch -- val: 0.6466 test: 0.6201

====epoch 69
Train Loss 14.914983831967847
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6387 test: 0.6201 | best val epoch -- val: 0.6466 test: 0.6201

====epoch 70
Train Loss 15.023845105596468
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6377 test: 0.6157 | best val epoch -- val: 0.6466 test: 0.6201

====epoch 71
Train Loss 14.905426708914701
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6297 test: 0.6093 | best val epoch -- val: 0.6466 test: 0.6201

====epoch 72
Train Loss 14.831852054756588
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6282 test: 0.6222 | best val epoch -- val: 0.6466 test: 0.6201

====epoch 73
Train Loss 14.755294729152338
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6284 test: 0.6297 | best val epoch -- val: 0.6466 test: 0.6201

====epoch 74
Train Loss 14.795100955544125
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6321 test: 0.6245 | best val epoch -- val: 0.6466 test: 0.6201

====epoch 75
Train Loss 14.58343860913282
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6316 test: 0.6166 | best val epoch -- val: 0.6466 test: 0.6201

====epoch 76
Train Loss 14.746970930112695
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6290 test: 0.6224 | best val epoch -- val: 0.6466 test: 0.6201

====epoch 77
Train Loss 14.797157871812992
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6336 test: 0.6250 | best val epoch -- val: 0.6466 test: 0.6201

====epoch 78
Train Loss 14.800280697602842
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6378 test: 0.6269 | best val epoch -- val: 0.6466 test: 0.6201

====epoch 79
Train Loss 14.658067407269979
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6346 test: 0.6250 | best val epoch -- val: 0.6466 test: 0.6201

====epoch 80
Train Loss 14.608134491523424
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6330 test: 0.6281 | best val epoch -- val: 0.6466 test: 0.6201

====epoch 81
Train Loss 14.68679911174693
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6361 test: 0.6236 | best val epoch -- val: 0.6466 test: 0.6201

====epoch 82
Train Loss 14.560145450800224
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6394 test: 0.6270 | best val epoch -- val: 0.6466 test: 0.6201

====epoch 83
Train Loss 14.63395151321439
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6412 test: 0.6269 | best val epoch -- val: 0.6466 test: 0.6201

====epoch 84
Train Loss 14.457047116405747
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6396 test: 0.6318 | best val epoch -- val: 0.6466 test: 0.6201

====epoch 85
Train Loss 14.564905404542198
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6419 test: 0.6251 | best val epoch -- val: 0.6466 test: 0.6201

====epoch 86
Train Loss 14.399285612545052
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6302 test: 0.6243 | best val epoch -- val: 0.6466 test: 0.6201

====epoch 87
Train Loss 14.537618948763832
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6338 test: 0.6241 | best val epoch -- val: 0.6466 test: 0.6201

====epoch 88
Train Loss 14.454675608813647
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6408 test: 0.6330 | best val epoch -- val: 0.6466 test: 0.6201

====epoch 89
Train Loss 14.350765410301374
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6351 test: 0.6306 | best val epoch -- val: 0.6466 test: 0.6201

====epoch 90
Train Loss 14.217433597008077
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6381 test: 0.6200 | best val epoch -- val: 0.6466 test: 0.6201

====epoch 91
Train Loss 14.206263227356612
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6335 test: 0.6287 | best val epoch -- val: 0.6466 test: 0.6201

====epoch 92
Train Loss 14.213357867999884
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6437 test: 0.6238 | best val epoch -- val: 0.6466 test: 0.6201

====epoch 93
Train Loss 14.190726316038564
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6341 test: 0.6286 | best val epoch -- val: 0.6466 test: 0.6201

====epoch 94
Train Loss 14.17169292068571
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6367 test: 0.6269 | best val epoch -- val: 0.6466 test: 0.6201

====epoch 95
Train Loss 14.083143023943029
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6443 test: 0.6326 | best val epoch -- val: 0.6466 test: 0.6201

====epoch 96
Train Loss 14.003147589657924
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6393 test: 0.6313 | best val epoch -- val: 0.6466 test: 0.6201

====epoch 97
Train Loss 14.223681874453417
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6420 test: 0.6313 | best val epoch -- val: 0.6466 test: 0.6201

====epoch 98
Train Loss 14.065863595810555
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6465 test: 0.6292 | best val epoch -- val: 0.6466 test: 0.6201

====epoch 99
Train Loss 14.0411902966421
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6484 test: 0.6366 | best val epoch -- val: 0.6484 test: 0.6366

====epoch 100
Train Loss 13.993897033005947
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6412 test: 0.6308 | best val epoch -- val: 0.6484 test: 0.6366

[08:23:53] WARNING: not removing hydrogen atom without neighbors
[08:23:53] WARNING: not removing hydrogen atom without neighbors
[08:23:53] WARNING: not removing hydrogen atom without neighbors
[08:23:53] WARNING: not removing hydrogen atom without neighbors
[08:23:53] WARNING: not removing hydrogen atom without neighbors
[08:23:53] WARNING: not removing hydrogen atom without neighbors
[08:23:53] WARNING: not removing hydrogen atom without neighbors
[08:23:53] WARNING: not removing hydrogen atom without neighbors
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.4.
[08:23:54] WARNING: not removing hydrogen atom without neighbors
[08:23:54] WARNING: not removing hydrogen atom without neighbors
[08:23:54] WARNING: not removing hydrogen atom without neighbors
[08:23:54] WARNING: not removing hydrogen atom without neighbors
[08:23:54] WARNING: not removing hydrogen atom without neighbors
2022-09-13 08:23:55.516 | INFO     | modules.masked_transformer_encoder:__init__:122 - number of parameters: 0.000000e+00
=========================================
batch_size = 32
d_model = 128
dataset = sider
decay = 0
device = 0
dim_feedforward = 512
eval_train = 0
filename =
gnn_JK = cat
gnn_dropout = 0.3
gnn_emb_dim = 300
gnn_num_layer = 5
gnn_residual = False
gnn_type = gin
gnn_virtual_node = False
graph_pooling = cls
input_model_file = models_graphtrans/graphtrans-sr-gcl.pth
lr = 0.0001
lr_scale = 1
max_input_len = 1000
nhead = 4
num_encoder_layers = 4
num_encoder_layers_masked = 0
num_workers = 0
pos_encoder = False
runseed = 1
seed = 12344
split = scaffold
transformer_activation = relu
transformer_dropout = 0.3
transformer_norm_input = True
transformer_prenorm = False
=========================================
sider
scaffold
Loaded GraphTrans from models_graphtrans/graphtrans-sr-gcl.pth
====epoch 1
Train Loss 24.16460060785766
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.5101 test: 0.4913 | best val epoch -- val: 0.5101 test: 0.4913

====epoch 2
Train Loss 20.9220749961996
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.5222 test: 0.4986 | best val epoch -- val: 0.5222 test: 0.4986

====epoch 3
Train Loss 19.62952948121024
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.5283 test: 0.4979 | best val epoch -- val: 0.5283 test: 0.4979

====epoch 4
Train Loss 19.342233434554643
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.5326 test: 0.4963 | best val epoch -- val: 0.5326 test: 0.4963

====epoch 5
Train Loss 19.24359560470229
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.5310 test: 0.4945 | best val epoch -- val: 0.5326 test: 0.4963

====epoch 6
Train Loss 19.140569546013463
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.5327 test: 0.5020 | best val epoch -- val: 0.5327 test: 0.5020

====epoch 7
Train Loss 19.135827811680766
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.5369 test: 0.5047 | best val epoch -- val: 0.5369 test: 0.5047

====epoch 8
Train Loss 19.115221067776886
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.5349 test: 0.5109 | best val epoch -- val: 0.5369 test: 0.5047

====epoch 9
Train Loss 19.025084692041776
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.5401 test: 0.5133 | best val epoch -- val: 0.5401 test: 0.5133

====epoch 10
Train Loss 19.044157517353067
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.5482 test: 0.5234 | best val epoch -- val: 0.5482 test: 0.5234

====epoch 11
Train Loss 19.000243314512097
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.5550 test: 0.5268 | best val epoch -- val: 0.5550 test: 0.5268

====epoch 12
Train Loss 19.011629201302977
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.5474 test: 0.5329 | best val epoch -- val: 0.5550 test: 0.5268

====epoch 13
Train Loss 18.879066785119797
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.5445 test: 0.5393 | best val epoch -- val: 0.5550 test: 0.5268

====epoch 14
Train Loss 18.765269551389352
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.5445 test: 0.5597 | best val epoch -- val: 0.5550 test: 0.5268

====epoch 15
Train Loss 18.704997946751842
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.5562 test: 0.5637 | best val epoch -- val: 0.5562 test: 0.5637

====epoch 16
Train Loss 18.501451992112294
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.5824 test: 0.5709 | best val epoch -- val: 0.5824 test: 0.5709

====epoch 17
Train Loss 18.33247114129243
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.5813 test: 0.5699 | best val epoch -- val: 0.5824 test: 0.5709

====epoch 18
Train Loss 18.20603965291085
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.5807 test: 0.5666 | best val epoch -- val: 0.5824 test: 0.5709

====epoch 19
Train Loss 18.082161838066174
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.5865 test: 0.5867 | best val epoch -- val: 0.5865 test: 0.5867

====epoch 20
Train Loss 17.962258156098276
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.5880 test: 0.5773 | best val epoch -- val: 0.5880 test: 0.5773

====epoch 21
Train Loss 17.938826842938045
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.5753 test: 0.5762 | best val epoch -- val: 0.5880 test: 0.5773

====epoch 22
Train Loss 17.933868065282038
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.5966 test: 0.6001 | best val epoch -- val: 0.5966 test: 0.6001

====epoch 23
Train Loss 17.685098745926272
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.5943 test: 0.5945 | best val epoch -- val: 0.5966 test: 0.6001

====epoch 24
Train Loss 17.621906828347523
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.5892 test: 0.5926 | best val epoch -- val: 0.5966 test: 0.6001

====epoch 25
Train Loss 17.520057387714388
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.5981 test: 0.6006 | best val epoch -- val: 0.5981 test: 0.6006

====epoch 26
Train Loss 17.446086726033194
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6088 test: 0.5938 | best val epoch -- val: 0.6088 test: 0.5938

====epoch 27
Train Loss 17.292154762908815
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6029 test: 0.6021 | best val epoch -- val: 0.6088 test: 0.5938

====epoch 28
Train Loss 17.263471787874245
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6016 test: 0.6051 | best val epoch -- val: 0.6088 test: 0.5938

====epoch 29
Train Loss 17.25262270119261
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.5978 test: 0.6114 | best val epoch -- val: 0.6088 test: 0.5938

====epoch 30
Train Loss 17.23830532648653
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.5980 test: 0.6022 | best val epoch -- val: 0.6088 test: 0.5938

====epoch 31
Train Loss 17.130847059673993
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6131 test: 0.6010 | best val epoch -- val: 0.6131 test: 0.6010

====epoch 32
Train Loss 17.145625472997885
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6091 test: 0.6033 | best val epoch -- val: 0.6131 test: 0.6010

====epoch 33
Train Loss 16.992059162625555
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6078 test: 0.5849 | best val epoch -- val: 0.6131 test: 0.6010

====epoch 34
Train Loss 16.92227072776788
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6194 test: 0.5882 | best val epoch -- val: 0.6194 test: 0.5882

====epoch 35
Train Loss 16.721484191755053
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6209 test: 0.5958 | best val epoch -- val: 0.6209 test: 0.5958

====epoch 36
Train Loss 16.96752402809833
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6205 test: 0.5949 | best val epoch -- val: 0.6209 test: 0.5958

====epoch 37
Train Loss 16.711180736563968
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6153 test: 0.6033 | best val epoch -- val: 0.6209 test: 0.5958

====epoch 38
Train Loss 16.63844683732672
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6225 test: 0.6050 | best val epoch -- val: 0.6225 test: 0.6050

====epoch 39
Train Loss 16.670266699372768
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6263 test: 0.5987 | best val epoch -- val: 0.6263 test: 0.5987

====epoch 40
Train Loss 16.457504592195082
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6290 test: 0.6031 | best val epoch -- val: 0.6290 test: 0.6031

====epoch 41
Train Loss 16.44676712236388
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6207 test: 0.6048 | best val epoch -- val: 0.6290 test: 0.6031

====epoch 42
Train Loss 16.554284066044353
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6312 test: 0.6010 | best val epoch -- val: 0.6312 test: 0.6010

====epoch 43
Train Loss 16.310723841195088
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6209 test: 0.5975 | best val epoch -- val: 0.6312 test: 0.6010

====epoch 44
Train Loss 16.37864165551966
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6253 test: 0.5958 | best val epoch -- val: 0.6312 test: 0.6010

====epoch 45
Train Loss 16.294981828987186
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6338 test: 0.6108 | best val epoch -- val: 0.6338 test: 0.6108

====epoch 46
Train Loss 16.215199297758474
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6318 test: 0.6052 | best val epoch -- val: 0.6338 test: 0.6108

====epoch 47
Train Loss 16.19478347109599
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6381 test: 0.5990 | best val epoch -- val: 0.6381 test: 0.5990

====epoch 48
Train Loss 16.040648190860935
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6390 test: 0.6138 | best val epoch -- val: 0.6390 test: 0.6138

====epoch 49
Train Loss 16.044749293187387
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6357 test: 0.6038 | best val epoch -- val: 0.6390 test: 0.6138

====epoch 50
Train Loss 15.959920136020946
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6362 test: 0.6049 | best val epoch -- val: 0.6390 test: 0.6138

====epoch 51
Train Loss 15.929718377388829
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6391 test: 0.6011 | best val epoch -- val: 0.6391 test: 0.6011

====epoch 52
Train Loss 15.935581091551725
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6439 test: 0.6039 | best val epoch -- val: 0.6439 test: 0.6039

====epoch 53
Train Loss 15.923376762576005
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6360 test: 0.6047 | best val epoch -- val: 0.6439 test: 0.6039

====epoch 54
Train Loss 15.711372259032462
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6473 test: 0.5988 | best val epoch -- val: 0.6473 test: 0.5988

====epoch 55
Train Loss 15.642895253225046
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6487 test: 0.6084 | best val epoch -- val: 0.6487 test: 0.6084

====epoch 56
Train Loss 15.845774230268276
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6522 test: 0.6093 | best val epoch -- val: 0.6522 test: 0.6093

====epoch 57
Train Loss 15.664976006830026
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6536 test: 0.6029 | best val epoch -- val: 0.6536 test: 0.6029

====epoch 58
Train Loss 15.657186885433493
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6442 test: 0.6079 | best val epoch -- val: 0.6536 test: 0.6029

====epoch 59
Train Loss 15.593634445140648
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6551 test: 0.6097 | best val epoch -- val: 0.6551 test: 0.6097

====epoch 60
Train Loss 15.348758742735955
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6552 test: 0.6024 | best val epoch -- val: 0.6552 test: 0.6024

====epoch 61
Train Loss 15.498449421221759
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6488 test: 0.5910 | best val epoch -- val: 0.6552 test: 0.6024

====epoch 62
Train Loss 15.290669058960399
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6507 test: 0.6021 | best val epoch -- val: 0.6552 test: 0.6024

====epoch 63
Train Loss 15.540212525682973
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6566 test: 0.6065 | best val epoch -- val: 0.6566 test: 0.6065

====epoch 64
Train Loss 15.287875667955996
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6589 test: 0.5955 | best val epoch -- val: 0.6589 test: 0.5955

====epoch 65
Train Loss 15.237990400793226
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6521 test: 0.5942 | best val epoch -- val: 0.6589 test: 0.5955

====epoch 66
Train Loss 15.401239203844243
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6545 test: 0.5991 | best val epoch -- val: 0.6589 test: 0.5955

====epoch 67
Train Loss 15.132508780845628
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6599 test: 0.6068 | best val epoch -- val: 0.6599 test: 0.6068

====epoch 68
Train Loss 15.171056850721556
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6471 test: 0.6034 | best val epoch -- val: 0.6599 test: 0.6068

====epoch 69
Train Loss 15.236656221657753
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6620 test: 0.6099 | best val epoch -- val: 0.6620 test: 0.6099

====epoch 70
Train Loss 15.103635297596755
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6553 test: 0.5981 | best val epoch -- val: 0.6620 test: 0.6099

====epoch 71
Train Loss 15.276033252467501
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6572 test: 0.6021 | best val epoch -- val: 0.6620 test: 0.6099

====epoch 72
Train Loss 14.998707438619839
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6618 test: 0.6070 | best val epoch -- val: 0.6620 test: 0.6099

====epoch 73
Train Loss 15.014522409121362
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6590 test: 0.6047 | best val epoch -- val: 0.6620 test: 0.6099

====epoch 74
Train Loss 14.973495492407908
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6636 test: 0.5990 | best val epoch -- val: 0.6636 test: 0.5990

====epoch 75
Train Loss 14.936991983166227
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6635 test: 0.5981 | best val epoch -- val: 0.6636 test: 0.5990

====epoch 76
Train Loss 14.89350977341738
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6598 test: 0.6006 | best val epoch -- val: 0.6636 test: 0.5990

====epoch 77
Train Loss 14.913515277170692
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6559 test: 0.6046 | best val epoch -- val: 0.6636 test: 0.5990

====epoch 78
Train Loss 14.767559710896814
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6570 test: 0.6003 | best val epoch -- val: 0.6636 test: 0.5990

====epoch 79
Train Loss 14.828605417615544
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6565 test: 0.6056 | best val epoch -- val: 0.6636 test: 0.5990

====epoch 80
Train Loss 14.804493723649674
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6511 test: 0.6038 | best val epoch -- val: 0.6636 test: 0.5990

====epoch 81
Train Loss 14.78596847086967
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6477 test: 0.6040 | best val epoch -- val: 0.6636 test: 0.5990

====epoch 82
Train Loss 14.629357819075649
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6443 test: 0.6051 | best val epoch -- val: 0.6636 test: 0.5990

====epoch 83
Train Loss 14.68885650156114
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6451 test: 0.6091 | best val epoch -- val: 0.6636 test: 0.5990

====epoch 84
Train Loss 14.592863120142907
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6528 test: 0.5991 | best val epoch -- val: 0.6636 test: 0.5990

====epoch 85
Train Loss 14.695243644936932
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6628 test: 0.6059 | best val epoch -- val: 0.6636 test: 0.5990

====epoch 86
Train Loss 14.574513568252446
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6549 test: 0.6049 | best val epoch -- val: 0.6636 test: 0.5990

====epoch 87
Train Loss 14.58989805797179
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6665 test: 0.6005 | best val epoch -- val: 0.6665 test: 0.6005

====epoch 88
Train Loss 14.52173177417782
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6588 test: 0.6105 | best val epoch -- val: 0.6665 test: 0.6005

====epoch 89
Train Loss 14.497076645005528
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6684 test: 0.6119 | best val epoch -- val: 0.6684 test: 0.6119

====epoch 90
Train Loss 14.4945948478767
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6591 test: 0.6166 | best val epoch -- val: 0.6684 test: 0.6119

====epoch 91
Train Loss 14.640734419552501
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6621 test: 0.6085 | best val epoch -- val: 0.6684 test: 0.6119

====epoch 92
Train Loss 14.361396749080672
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6612 test: 0.6044 | best val epoch -- val: 0.6684 test: 0.6119

====epoch 93
Train Loss 14.302571308090457
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6598 test: 0.6033 | best val epoch -- val: 0.6684 test: 0.6119

====epoch 94
Train Loss 14.262034418897702
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6577 test: 0.6000 | best val epoch -- val: 0.6684 test: 0.6119

====epoch 95
Train Loss 14.353735045612343
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6579 test: 0.5985 | best val epoch -- val: 0.6684 test: 0.6119

====epoch 96
Train Loss 14.298040448797847
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6521 test: 0.6035 | best val epoch -- val: 0.6684 test: 0.6119

====epoch 97
Train Loss 14.187750808005951
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6536 test: 0.6072 | best val epoch -- val: 0.6684 test: 0.6119

====epoch 98
Train Loss 14.258476583645685
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6506 test: 0.6161 | best val epoch -- val: 0.6684 test: 0.6119

====epoch 99
Train Loss 14.287310482390298
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6578 test: 0.6127 | best val epoch -- val: 0.6684 test: 0.6119

====epoch 100
Train Loss 14.21485085449069
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6590 test: 0.6109 | best val epoch -- val: 0.6684 test: 0.6119

[08:27:43] WARNING: not removing hydrogen atom without neighbors
[08:27:43] WARNING: not removing hydrogen atom without neighbors
[08:27:43] WARNING: not removing hydrogen atom without neighbors
[08:27:43] WARNING: not removing hydrogen atom without neighbors
[08:27:43] WARNING: not removing hydrogen atom without neighbors
[08:27:43] WARNING: not removing hydrogen atom without neighbors
[08:27:43] WARNING: not removing hydrogen atom without neighbors
[08:27:43] WARNING: not removing hydrogen atom without neighbors
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.4.
[08:27:44] WARNING: not removing hydrogen atom without neighbors
[08:27:44] WARNING: not removing hydrogen atom without neighbors
[08:27:44] WARNING: not removing hydrogen atom without neighbors
[08:27:45] WARNING: not removing hydrogen atom without neighbors
[08:27:45] WARNING: not removing hydrogen atom without neighbors
2022-09-13 08:27:45.986 | INFO     | modules.masked_transformer_encoder:__init__:122 - number of parameters: 0.000000e+00
=========================================
batch_size = 32
d_model = 128
dataset = sider
decay = 0
device = 0
dim_feedforward = 512
eval_train = 0
filename =
gnn_JK = cat
gnn_dropout = 0.3
gnn_emb_dim = 300
gnn_num_layer = 5
gnn_residual = False
gnn_type = gin
gnn_virtual_node = False
graph_pooling = cls
input_model_file = models_graphtrans/graphtrans-sr-gcl.pth
lr = 0.0001
lr_scale = 1
max_input_len = 1000
nhead = 4
num_encoder_layers = 4
num_encoder_layers_masked = 0
num_workers = 0
pos_encoder = False
runseed = 2
seed = 12344
split = scaffold
transformer_activation = relu
transformer_dropout = 0.3
transformer_norm_input = True
transformer_prenorm = False
=========================================
sider
scaffold
Loaded GraphTrans from models_graphtrans/graphtrans-sr-gcl.pth
====epoch 1
Train Loss 23.873089795989458
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.5024 test: 0.4733 | best val epoch -- val: 0.5024 test: 0.4733

====epoch 2
Train Loss 20.77261954480029
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.5149 test: 0.4965 | best val epoch -- val: 0.5149 test: 0.4965

====epoch 3
Train Loss 19.65466671692472
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.5265 test: 0.5113 | best val epoch -- val: 0.5265 test: 0.5113

====epoch 4
Train Loss 19.367326808308345
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.5253 test: 0.5174 | best val epoch -- val: 0.5265 test: 0.5113

====epoch 5
Train Loss 19.264785140272526
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.5283 test: 0.5166 | best val epoch -- val: 0.5283 test: 0.5166

====epoch 6
Train Loss 19.235243163153168
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.5384 test: 0.5184 | best val epoch -- val: 0.5384 test: 0.5184

====epoch 7
Train Loss 19.13812335777553
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.5442 test: 0.5238 | best val epoch -- val: 0.5442 test: 0.5238

====epoch 8
Train Loss 19.16555940827521
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.5407 test: 0.5326 | best val epoch -- val: 0.5442 test: 0.5238

====epoch 9
Train Loss 19.086114096142154
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.5373 test: 0.5392 | best val epoch -- val: 0.5442 test: 0.5238

====epoch 10
Train Loss 18.99187838166947
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.5345 test: 0.5486 | best val epoch -- val: 0.5442 test: 0.5238

====epoch 11
Train Loss 18.908200781134596
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.5310 test: 0.5562 | best val epoch -- val: 0.5442 test: 0.5238

====epoch 12
Train Loss 18.744059904252982
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.5382 test: 0.5625 | best val epoch -- val: 0.5442 test: 0.5238

====epoch 13
Train Loss 18.610823738064127
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.5417 test: 0.5698 | best val epoch -- val: 0.5442 test: 0.5238

====epoch 14
Train Loss 18.468280592575127
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.5505 test: 0.5832 | best val epoch -- val: 0.5505 test: 0.5832

====epoch 15
Train Loss 18.34685605215551
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.5552 test: 0.5839 | best val epoch -- val: 0.5552 test: 0.5839

====epoch 16
Train Loss 18.38276434546434
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.5424 test: 0.5940 | best val epoch -- val: 0.5552 test: 0.5839

====epoch 17
Train Loss 18.188398516102385
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.5576 test: 0.6033 | best val epoch -- val: 0.5576 test: 0.6033

====epoch 18
Train Loss 18.081808341117764
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.5613 test: 0.5982 | best val epoch -- val: 0.5613 test: 0.5982

====epoch 19
Train Loss 17.926215006804675
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.5817 test: 0.6072 | best val epoch -- val: 0.5817 test: 0.6072

====epoch 20
Train Loss 17.807732981700823
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.5964 test: 0.6053 | best val epoch -- val: 0.5964 test: 0.6053

====epoch 21
Train Loss 17.765408439772123
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.5996 test: 0.6126 | best val epoch -- val: 0.5996 test: 0.6126

====epoch 22
Train Loss 17.66171016141136
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.5839 test: 0.6126 | best val epoch -- val: 0.5996 test: 0.6126

====epoch 23
Train Loss 17.62209832846734
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.5802 test: 0.6046 | best val epoch -- val: 0.5996 test: 0.6126

====epoch 24
Train Loss 17.506887711948902
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.5828 test: 0.5921 | best val epoch -- val: 0.5996 test: 0.6126

====epoch 25
Train Loss 17.496786455555
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6015 test: 0.6104 | best val epoch -- val: 0.6015 test: 0.6104

====epoch 26
Train Loss 17.362949948021523
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6094 test: 0.6072 | best val epoch -- val: 0.6094 test: 0.6072

====epoch 27
Train Loss 17.29848706537769
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6062 test: 0.6011 | best val epoch -- val: 0.6094 test: 0.6072

====epoch 28
Train Loss 17.345161956486127
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.5949 test: 0.6040 | best val epoch -- val: 0.6094 test: 0.6072

====epoch 29
Train Loss 17.0801375011573
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6065 test: 0.6080 | best val epoch -- val: 0.6094 test: 0.6072

====epoch 30
Train Loss 17.039792129024857
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6044 test: 0.5884 | best val epoch -- val: 0.6094 test: 0.6072

====epoch 31
Train Loss 17.118061981788728
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6109 test: 0.5988 | best val epoch -- val: 0.6109 test: 0.5988

====epoch 32
Train Loss 17.116448270470325
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6003 test: 0.5937 | best val epoch -- val: 0.6109 test: 0.5988

====epoch 33
Train Loss 16.92575510660081
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6185 test: 0.6048 | best val epoch -- val: 0.6185 test: 0.6048

====epoch 34
Train Loss 16.8193407227833
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6191 test: 0.5977 | best val epoch -- val: 0.6191 test: 0.5977

====epoch 35
Train Loss 16.678502327444903
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6190 test: 0.5828 | best val epoch -- val: 0.6191 test: 0.5977

====epoch 36
Train Loss 16.58145011178793
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6225 test: 0.5857 | best val epoch -- val: 0.6225 test: 0.5857

====epoch 37
Train Loss 16.644468223246648
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6265 test: 0.5971 | best val epoch -- val: 0.6265 test: 0.5971

====epoch 38
Train Loss 16.702015318884186
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6146 test: 0.6002 | best val epoch -- val: 0.6265 test: 0.5971

====epoch 39
Train Loss 16.541637956542978
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6176 test: 0.5900 | best val epoch -- val: 0.6265 test: 0.5971

====epoch 40
Train Loss 16.44100170597444
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6153 test: 0.5913 | best val epoch -- val: 0.6265 test: 0.5971

====epoch 41
Train Loss 16.38840995511392
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6215 test: 0.6047 | best val epoch -- val: 0.6265 test: 0.5971

====epoch 42
Train Loss 16.31701606825375
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6289 test: 0.5905 | best val epoch -- val: 0.6289 test: 0.5905

====epoch 43
Train Loss 16.12827510711376
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6231 test: 0.5961 | best val epoch -- val: 0.6289 test: 0.5905

====epoch 44
Train Loss 16.298258202191576
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6217 test: 0.5964 | best val epoch -- val: 0.6289 test: 0.5905

====epoch 45
Train Loss 15.999139414016986
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6219 test: 0.6086 | best val epoch -- val: 0.6289 test: 0.5905

====epoch 46
Train Loss 16.180966400207577
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6230 test: 0.6080 | best val epoch -- val: 0.6289 test: 0.5905

====epoch 47
Train Loss 16.064565271694
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6340 test: 0.5967 | best val epoch -- val: 0.6340 test: 0.5967

====epoch 48
Train Loss 16.170379341503082
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6245 test: 0.6094 | best val epoch -- val: 0.6340 test: 0.5967

====epoch 49
Train Loss 15.972931607652832
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6285 test: 0.5962 | best val epoch -- val: 0.6340 test: 0.5967

====epoch 50
Train Loss 15.777067872151681
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6296 test: 0.6079 | best val epoch -- val: 0.6340 test: 0.5967

====epoch 51
Train Loss 15.932900584129916
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6258 test: 0.6010 | best val epoch -- val: 0.6340 test: 0.5967

====epoch 52
Train Loss 15.946633008400795
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6187 test: 0.6102 | best val epoch -- val: 0.6340 test: 0.5967

====epoch 53
Train Loss 15.780331075484494
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6275 test: 0.6079 | best val epoch -- val: 0.6340 test: 0.5967

====epoch 54
Train Loss 15.648068566680854
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6264 test: 0.6040 | best val epoch -- val: 0.6340 test: 0.5967

====epoch 55
Train Loss 15.683308169269079
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6370 test: 0.5999 | best val epoch -- val: 0.6370 test: 0.5999

====epoch 56
Train Loss 15.727501228345801
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6242 test: 0.6153 | best val epoch -- val: 0.6370 test: 0.5999

====epoch 57
Train Loss 15.540276303643074
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6287 test: 0.6198 | best val epoch -- val: 0.6370 test: 0.5999

====epoch 58
Train Loss 15.571243389948535
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6219 test: 0.6057 | best val epoch -- val: 0.6370 test: 0.5999

====epoch 59
Train Loss 15.591410907116424
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6356 test: 0.5966 | best val epoch -- val: 0.6370 test: 0.5999

====epoch 60
Train Loss 15.512010848556466
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6406 test: 0.6091 | best val epoch -- val: 0.6406 test: 0.6091

====epoch 61
Train Loss 15.389735114264962
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6434 test: 0.6127 | best val epoch -- val: 0.6434 test: 0.6127

====epoch 62
Train Loss 15.324244265226586
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6399 test: 0.6085 | best val epoch -- val: 0.6434 test: 0.6127

====epoch 63
Train Loss 15.29526541695397
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6403 test: 0.6150 | best val epoch -- val: 0.6434 test: 0.6127

====epoch 64
Train Loss 15.366783781523512
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6318 test: 0.6099 | best val epoch -- val: 0.6434 test: 0.6127

====epoch 65
Train Loss 15.315094889965774
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6282 test: 0.6136 | best val epoch -- val: 0.6434 test: 0.6127

====epoch 66
Train Loss 15.173421765309167
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6407 test: 0.6078 | best val epoch -- val: 0.6434 test: 0.6127

====epoch 67
Train Loss 15.263997160985635
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6375 test: 0.6055 | best val epoch -- val: 0.6434 test: 0.6127

====epoch 68
Train Loss 15.139355888947973
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6388 test: 0.6103 | best val epoch -- val: 0.6434 test: 0.6127

====epoch 69
Train Loss 15.173350349017252
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6275 test: 0.6063 | best val epoch -- val: 0.6434 test: 0.6127

====epoch 70
Train Loss 15.194592727121279
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6333 test: 0.6029 | best val epoch -- val: 0.6434 test: 0.6127

====epoch 71
Train Loss 14.965771529866412
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6322 test: 0.6063 | best val epoch -- val: 0.6434 test: 0.6127

====epoch 72
Train Loss 15.119875613585721
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6396 test: 0.6015 | best val epoch -- val: 0.6434 test: 0.6127

====epoch 73
Train Loss 14.988265695925215
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6347 test: 0.6080 | best val epoch -- val: 0.6434 test: 0.6127

====epoch 74
Train Loss 15.09585096151969
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6382 test: 0.6009 | best val epoch -- val: 0.6434 test: 0.6127

====epoch 75
Train Loss 14.895084115677934
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6331 test: 0.6004 | best val epoch -- val: 0.6434 test: 0.6127

====epoch 76
Train Loss 14.855066197337026
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6389 test: 0.6122 | best val epoch -- val: 0.6434 test: 0.6127

====epoch 77
Train Loss 14.789740359387125
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6307 test: 0.6017 | best val epoch -- val: 0.6434 test: 0.6127

====epoch 78
Train Loss 14.834102942312937
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6336 test: 0.5997 | best val epoch -- val: 0.6434 test: 0.6127

====epoch 79
Train Loss 14.688047201992065
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6328 test: 0.6122 | best val epoch -- val: 0.6434 test: 0.6127

====epoch 80
Train Loss 14.887975947240008
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6275 test: 0.6053 | best val epoch -- val: 0.6434 test: 0.6127

====epoch 81
Train Loss 14.735038613746903
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6209 test: 0.6113 | best val epoch -- val: 0.6434 test: 0.6127

====epoch 82
Train Loss 14.583592723778423
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6189 test: 0.5979 | best val epoch -- val: 0.6434 test: 0.6127

====epoch 83
Train Loss 14.540194515266277
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6265 test: 0.5994 | best val epoch -- val: 0.6434 test: 0.6127

====epoch 84
Train Loss 14.53071308121454
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6159 test: 0.6018 | best val epoch -- val: 0.6434 test: 0.6127

====epoch 85
Train Loss 14.652718803338532
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6208 test: 0.5952 | best val epoch -- val: 0.6434 test: 0.6127

====epoch 86
Train Loss 14.375113816451837
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6190 test: 0.6002 | best val epoch -- val: 0.6434 test: 0.6127

====epoch 87
Train Loss 14.367747249371805
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6269 test: 0.6107 | best val epoch -- val: 0.6434 test: 0.6127

====epoch 88
Train Loss 14.360193173659399
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6212 test: 0.6112 | best val epoch -- val: 0.6434 test: 0.6127

====epoch 89
Train Loss 14.585981113401306
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6256 test: 0.6061 | best val epoch -- val: 0.6434 test: 0.6127

====epoch 90
Train Loss 14.370888931158062
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6260 test: 0.6015 | best val epoch -- val: 0.6434 test: 0.6127

====epoch 91
Train Loss 14.378937201881703
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6240 test: 0.5977 | best val epoch -- val: 0.6434 test: 0.6127

====epoch 92
Train Loss 14.417533047865696
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6249 test: 0.5974 | best val epoch -- val: 0.6434 test: 0.6127

====epoch 93
Train Loss 14.358008413158746
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6300 test: 0.6038 | best val epoch -- val: 0.6434 test: 0.6127

====epoch 94
Train Loss 14.28767504158707
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6252 test: 0.6072 | best val epoch -- val: 0.6434 test: 0.6127

====epoch 95
Train Loss 14.315691525769394
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6183 test: 0.6100 | best val epoch -- val: 0.6434 test: 0.6127

====epoch 96
Train Loss 14.102546626394718
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6297 test: 0.6007 | best val epoch -- val: 0.6434 test: 0.6127

====epoch 97
Train Loss 14.156587890050211
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6255 test: 0.6055 | best val epoch -- val: 0.6434 test: 0.6127

====epoch 98
Train Loss 14.100190462909323
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6213 test: 0.6012 | best val epoch -- val: 0.6434 test: 0.6127

====epoch 99
Train Loss 14.087062744239022
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6320 test: 0.6000 | best val epoch -- val: 0.6434 test: 0.6127

====epoch 100
Train Loss 14.076042741993088
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6309 test: 0.6005 | best val epoch -- val: 0.6434 test: 0.6127

[08:31:44] WARNING: not removing hydrogen atom without neighbors
[08:31:44] WARNING: not removing hydrogen atom without neighbors
[08:31:44] WARNING: not removing hydrogen atom without neighbors
[08:31:44] WARNING: not removing hydrogen atom without neighbors
[08:31:44] WARNING: not removing hydrogen atom without neighbors
[08:31:44] WARNING: not removing hydrogen atom without neighbors
[08:31:44] WARNING: not removing hydrogen atom without neighbors
[08:31:44] WARNING: not removing hydrogen atom without neighbors
[08:31:45] WARNING: not removing hydrogen atom without neighbors
[08:31:45] WARNING: not removing hydrogen atom without neighbors
[08:31:45] WARNING: not removing hydrogen atom without neighbors
[08:31:45] WARNING: not removing hydrogen atom without neighbors
[08:31:45] WARNING: not removing hydrogen atom without neighbors
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.4.
2022-09-13 08:31:46.270 | INFO     | modules.masked_transformer_encoder:__init__:122 - number of parameters: 0.000000e+00
=========================================
batch_size = 32
d_model = 128
dataset = sider
decay = 0
device = 0
dim_feedforward = 512
eval_train = 0
filename =
gnn_JK = cat
gnn_dropout = 0.3
gnn_emb_dim = 300
gnn_num_layer = 5
gnn_residual = False
gnn_type = gin
gnn_virtual_node = False
graph_pooling = cls
input_model_file = models_graphtrans/graphtrans-sr-gcl.pth
lr = 0.0001
lr_scale = 1
max_input_len = 1000
nhead = 4
num_encoder_layers = 4
num_encoder_layers_masked = 0
num_workers = 0
pos_encoder = False
runseed = 3
seed = 12344
split = scaffold
transformer_activation = relu
transformer_dropout = 0.3
transformer_norm_input = True
transformer_prenorm = False
=========================================
sider
scaffold
Loaded GraphTrans from models_graphtrans/graphtrans-sr-gcl.pth
====epoch 1
Train Loss 23.75397192207327
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.4982 test: 0.5090 | best val epoch -- val: 0.4982 test: 0.5090

====epoch 2
Train Loss 20.44899502318289
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.5059 test: 0.5179 | best val epoch -- val: 0.5059 test: 0.5179

====epoch 3
Train Loss 19.500701691650374
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.5065 test: 0.5186 | best val epoch -- val: 0.5065 test: 0.5186

====epoch 4
Train Loss 19.230724562313124
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.5119 test: 0.5133 | best val epoch -- val: 0.5119 test: 0.5133

====epoch 5
Train Loss 19.124484046695617
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.5066 test: 0.5125 | best val epoch -- val: 0.5119 test: 0.5133

====epoch 6
Train Loss 19.16990200815813
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.5093 test: 0.5162 | best val epoch -- val: 0.5119 test: 0.5133

====epoch 7
Train Loss 19.058376117881508
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.5036 test: 0.5194 | best val epoch -- val: 0.5119 test: 0.5133

====epoch 8
Train Loss 19.092650940528323
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.5030 test: 0.5201 | best val epoch -- val: 0.5119 test: 0.5133

====epoch 9
Train Loss 18.98826725777225
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.5018 test: 0.5274 | best val epoch -- val: 0.5119 test: 0.5133

====epoch 10
Train Loss 18.93739941540243
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.5013 test: 0.5313 | best val epoch -- val: 0.5119 test: 0.5133

====epoch 11
Train Loss 18.921305215540894
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.5008 test: 0.5329 | best val epoch -- val: 0.5119 test: 0.5133

====epoch 12
Train Loss 18.744341665650317
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.4989 test: 0.5440 | best val epoch -- val: 0.5119 test: 0.5133

====epoch 13
Train Loss 18.580142352347213
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.5147 test: 0.5612 | best val epoch -- val: 0.5147 test: 0.5612

====epoch 14
Train Loss 18.313503275473906
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.5224 test: 0.5726 | best val epoch -- val: 0.5224 test: 0.5726

====epoch 15
Train Loss 18.249622401827963
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.5322 test: 0.5880 | best val epoch -- val: 0.5322 test: 0.5880

====epoch 16
Train Loss 18.239571255294514
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.5182 test: 0.5933 | best val epoch -- val: 0.5322 test: 0.5880

====epoch 17
Train Loss 18.09390078040632
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.5322 test: 0.5866 | best val epoch -- val: 0.5322 test: 0.5866

====epoch 18
Train Loss 17.922703506374635
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.5309 test: 0.5912 | best val epoch -- val: 0.5322 test: 0.5866

====epoch 19
Train Loss 17.81913950275794
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.5428 test: 0.5833 | best val epoch -- val: 0.5428 test: 0.5833

====epoch 20
Train Loss 17.79821851929749
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.5426 test: 0.5862 | best val epoch -- val: 0.5428 test: 0.5833

====epoch 21
Train Loss 17.784963187466335
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.5594 test: 0.5970 | best val epoch -- val: 0.5594 test: 0.5970

====epoch 22
Train Loss 17.60475846091716
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.5525 test: 0.5914 | best val epoch -- val: 0.5594 test: 0.5970

====epoch 23
Train Loss 17.52080790110409
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.5766 test: 0.5971 | best val epoch -- val: 0.5766 test: 0.5971

====epoch 24
Train Loss 17.523636411463038
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.5802 test: 0.6016 | best val epoch -- val: 0.5802 test: 0.6016

====epoch 25
Train Loss 17.4444136521387
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.5823 test: 0.6007 | best val epoch -- val: 0.5823 test: 0.6007

====epoch 26
Train Loss 17.249737838195838
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6000 test: 0.6031 | best val epoch -- val: 0.6000 test: 0.6031

====epoch 27
Train Loss 17.309755982622764
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.5991 test: 0.6046 | best val epoch -- val: 0.6000 test: 0.6031

====epoch 28
Train Loss 17.289268665086176
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6046 test: 0.6003 | best val epoch -- val: 0.6046 test: 0.6003

====epoch 29
Train Loss 17.17469895140825
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6041 test: 0.6020 | best val epoch -- val: 0.6046 test: 0.6003

====epoch 30
Train Loss 17.104039740613672
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.5983 test: 0.5998 | best val epoch -- val: 0.6046 test: 0.6003

====epoch 31
Train Loss 16.936555450055394
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6016 test: 0.5937 | best val epoch -- val: 0.6046 test: 0.6003

====epoch 32
Train Loss 16.838496528193346
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6091 test: 0.5934 | best val epoch -- val: 0.6091 test: 0.5934

====epoch 33
Train Loss 16.836547329251452
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6097 test: 0.6105 | best val epoch -- val: 0.6097 test: 0.6105

====epoch 34
Train Loss 16.73935813612975
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.5946 test: 0.5967 | best val epoch -- val: 0.6097 test: 0.6105

====epoch 35
Train Loss 16.81282287944809
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6068 test: 0.5979 | best val epoch -- val: 0.6097 test: 0.6105

====epoch 36
Train Loss 16.72764485676012
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6093 test: 0.5976 | best val epoch -- val: 0.6097 test: 0.6105

====epoch 37
Train Loss 16.603170519956734
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.5996 test: 0.5944 | best val epoch -- val: 0.6097 test: 0.6105

====epoch 38
Train Loss 16.389005741942658
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6066 test: 0.6069 | best val epoch -- val: 0.6097 test: 0.6105

====epoch 39
Train Loss 16.447200056183778
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.5982 test: 0.6002 | best val epoch -- val: 0.6097 test: 0.6105

====epoch 40
Train Loss 16.275608628196363
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.5989 test: 0.6081 | best val epoch -- val: 0.6097 test: 0.6105

====epoch 41
Train Loss 16.474641089670747
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6130 test: 0.6035 | best val epoch -- val: 0.6130 test: 0.6035

====epoch 42
Train Loss 16.182018907215813
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6156 test: 0.5993 | best val epoch -- val: 0.6156 test: 0.5993

====epoch 43
Train Loss 16.11642287030672
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6129 test: 0.6026 | best val epoch -- val: 0.6156 test: 0.5993

====epoch 44
Train Loss 16.124233287129968
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6118 test: 0.5954 | best val epoch -- val: 0.6156 test: 0.5993

====epoch 45
Train Loss 16.112309180663452
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6161 test: 0.6071 | best val epoch -- val: 0.6161 test: 0.6071

====epoch 46
Train Loss 16.16642919156275
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6158 test: 0.6048 | best val epoch -- val: 0.6161 test: 0.6071

====epoch 47
Train Loss 16.030216051769692
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6131 test: 0.5994 | best val epoch -- val: 0.6161 test: 0.6071

====epoch 48
Train Loss 16.06261883327692
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6148 test: 0.6085 | best val epoch -- val: 0.6161 test: 0.6071

====epoch 49
Train Loss 16.039629250299704
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6200 test: 0.6166 | best val epoch -- val: 0.6200 test: 0.6166

====epoch 50
Train Loss 16.02052019444404
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6139 test: 0.6049 | best val epoch -- val: 0.6200 test: 0.6166

====epoch 51
Train Loss 15.794247771065546
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6222 test: 0.6197 | best val epoch -- val: 0.6222 test: 0.6197

====epoch 52
Train Loss 15.67540415875143
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6205 test: 0.6189 | best val epoch -- val: 0.6222 test: 0.6197

====epoch 53
Train Loss 15.675491771443813
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6205 test: 0.6187 | best val epoch -- val: 0.6222 test: 0.6197

====epoch 54
Train Loss 15.68412688957885
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6239 test: 0.6160 | best val epoch -- val: 0.6239 test: 0.6160

====epoch 55
Train Loss 15.742515930099328
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6235 test: 0.6241 | best val epoch -- val: 0.6239 test: 0.6160

====epoch 56
Train Loss 15.467696604279595
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6322 test: 0.6212 | best val epoch -- val: 0.6322 test: 0.6212

====epoch 57
Train Loss 15.50231346863439
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6348 test: 0.6312 | best val epoch -- val: 0.6348 test: 0.6312

====epoch 58
Train Loss 15.402592214610952
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6281 test: 0.6275 | best val epoch -- val: 0.6348 test: 0.6312

====epoch 59
Train Loss 15.675523278916701
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6215 test: 0.6227 | best val epoch -- val: 0.6348 test: 0.6312

====epoch 60
Train Loss 15.53889890423488
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6213 test: 0.6154 | best val epoch -- val: 0.6348 test: 0.6312

====epoch 61
Train Loss 15.315381214574755
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6324 test: 0.6192 | best val epoch -- val: 0.6348 test: 0.6312

====epoch 62
Train Loss 15.278957958019037
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6355 test: 0.6266 | best val epoch -- val: 0.6355 test: 0.6266

====epoch 63
Train Loss 15.10177898534651
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6233 test: 0.6255 | best val epoch -- val: 0.6355 test: 0.6266

====epoch 64
Train Loss 15.301090622676105
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6302 test: 0.6286 | best val epoch -- val: 0.6355 test: 0.6266

====epoch 65
Train Loss 15.014919193315775
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6306 test: 0.6178 | best val epoch -- val: 0.6355 test: 0.6266

====epoch 66
Train Loss 15.032408172515341
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6325 test: 0.6264 | best val epoch -- val: 0.6355 test: 0.6266

====epoch 67
Train Loss 15.140123931509232
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6341 test: 0.6240 | best val epoch -- val: 0.6355 test: 0.6266

====epoch 68
Train Loss 15.01956313037927
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6337 test: 0.6200 | best val epoch -- val: 0.6355 test: 0.6266

====epoch 69
Train Loss 15.012304305349016
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6317 test: 0.6254 | best val epoch -- val: 0.6355 test: 0.6266

====epoch 70
Train Loss 15.040511071620529
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6355 test: 0.6203 | best val epoch -- val: 0.6355 test: 0.6266

====epoch 71
Train Loss 14.899032931403696
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6249 test: 0.6180 | best val epoch -- val: 0.6355 test: 0.6266

====epoch 72
Train Loss 14.99088220616599
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6231 test: 0.6307 | best val epoch -- val: 0.6355 test: 0.6266

====epoch 73
Train Loss 14.98131793331649
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6230 test: 0.6298 | best val epoch -- val: 0.6355 test: 0.6266

====epoch 74
Train Loss 14.802129941079645
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6288 test: 0.6252 | best val epoch -- val: 0.6355 test: 0.6266

====epoch 75
Train Loss 14.917740266129156
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6253 test: 0.6195 | best val epoch -- val: 0.6355 test: 0.6266

====epoch 76
Train Loss 14.82971494445878
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6302 test: 0.6216 | best val epoch -- val: 0.6355 test: 0.6266

====epoch 77
Train Loss 14.77429713519849
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6305 test: 0.6247 | best val epoch -- val: 0.6355 test: 0.6266

====epoch 78
Train Loss 14.615362124052343
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6256 test: 0.6219 | best val epoch -- val: 0.6355 test: 0.6266

====epoch 79
Train Loss 14.745634672106391
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6384 test: 0.6222 | best val epoch -- val: 0.6384 test: 0.6222

====epoch 80
Train Loss 14.574768841877459
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6287 test: 0.6219 | best val epoch -- val: 0.6384 test: 0.6222

====epoch 81
Train Loss 14.631297026884393
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6322 test: 0.6208 | best val epoch -- val: 0.6384 test: 0.6222

====epoch 82
Train Loss 14.517814445175425
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6351 test: 0.6125 | best val epoch -- val: 0.6384 test: 0.6222

====epoch 83
Train Loss 14.41266890334683
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6359 test: 0.6174 | best val epoch -- val: 0.6384 test: 0.6222

====epoch 84
Train Loss 14.308248843571125
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6338 test: 0.6141 | best val epoch -- val: 0.6384 test: 0.6222

====epoch 85
Train Loss 14.498901186843328
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6323 test: 0.6234 | best val epoch -- val: 0.6384 test: 0.6222

====epoch 86
Train Loss 14.549366069107585
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6430 test: 0.6337 | best val epoch -- val: 0.6430 test: 0.6337

====epoch 87
Train Loss 14.464783276959118
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6296 test: 0.6263 | best val epoch -- val: 0.6430 test: 0.6337

====epoch 88
Train Loss 14.654158991642056
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6243 test: 0.6225 | best val epoch -- val: 0.6430 test: 0.6337

====epoch 89
Train Loss 14.46700700154779
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6298 test: 0.6210 | best val epoch -- val: 0.6430 test: 0.6337

====epoch 90
Train Loss 14.290117574740039
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6259 test: 0.6235 | best val epoch -- val: 0.6430 test: 0.6337

====epoch 91
Train Loss 14.200649145055184
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6327 test: 0.6229 | best val epoch -- val: 0.6430 test: 0.6337

====epoch 92
Train Loss 14.236847771068863
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6372 test: 0.6254 | best val epoch -- val: 0.6430 test: 0.6337

====epoch 93
Train Loss 14.271179018366112
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6308 test: 0.6307 | best val epoch -- val: 0.6430 test: 0.6337

====epoch 94
Train Loss 14.173468246472424
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6305 test: 0.6232 | best val epoch -- val: 0.6430 test: 0.6337

====epoch 95
Train Loss 14.060393221725127
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6354 test: 0.6233 | best val epoch -- val: 0.6430 test: 0.6337

====epoch 96
Train Loss 14.140258596581978
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6336 test: 0.6236 | best val epoch -- val: 0.6430 test: 0.6337

====epoch 97
Train Loss 14.216705715036989
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6347 test: 0.6272 | best val epoch -- val: 0.6430 test: 0.6337

====epoch 98
Train Loss 14.144391682044738
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6331 test: 0.6276 | best val epoch -- val: 0.6430 test: 0.6337

====epoch 99
Train Loss 14.039218713697478
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6378 test: 0.6280 | best val epoch -- val: 0.6430 test: 0.6337

====epoch 100
Train Loss 14.14747217426554
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6304 test: 0.6207 | best val epoch -- val: 0.6430 test: 0.6337

[08:35:45] WARNING: not removing hydrogen atom without neighbors
[08:35:45] WARNING: not removing hydrogen atom without neighbors
[08:35:45] WARNING: not removing hydrogen atom without neighbors
[08:35:45] WARNING: not removing hydrogen atom without neighbors
[08:35:45] WARNING: not removing hydrogen atom without neighbors
[08:35:45] WARNING: not removing hydrogen atom without neighbors
[08:35:45] WARNING: not removing hydrogen atom without neighbors
[08:35:45] WARNING: not removing hydrogen atom without neighbors
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.4.
[08:35:46] WARNING: not removing hydrogen atom without neighbors
[08:35:46] WARNING: not removing hydrogen atom without neighbors
[08:35:46] WARNING: not removing hydrogen atom without neighbors
[08:35:46] WARNING: not removing hydrogen atom without neighbors
[08:35:46] WARNING: not removing hydrogen atom without neighbors
2022-09-13 08:35:47.588 | INFO     | modules.masked_transformer_encoder:__init__:122 - number of parameters: 0.000000e+00
=========================================
batch_size = 32
d_model = 128
dataset = sider
decay = 0
device = 0
dim_feedforward = 512
eval_train = 0
filename =
gnn_JK = cat
gnn_dropout = 0.3
gnn_emb_dim = 300
gnn_num_layer = 5
gnn_residual = False
gnn_type = gin
gnn_virtual_node = False
graph_pooling = cls
input_model_file = models_graphtrans/graphtrans-sr-gcl.pth
lr = 0.0001
lr_scale = 1
max_input_len = 1000
nhead = 4
num_encoder_layers = 4
num_encoder_layers_masked = 0
num_workers = 0
pos_encoder = False
runseed = 4
seed = 12344
split = scaffold
transformer_activation = relu
transformer_dropout = 0.3
transformer_norm_input = True
transformer_prenorm = False
=========================================
sider
scaffold
Loaded GraphTrans from models_graphtrans/graphtrans-sr-gcl.pth
====epoch 1
Train Loss 23.574332829657713
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.5401 test: 0.5265 | best val epoch -- val: 0.5401 test: 0.5265

====epoch 2
Train Loss 20.573531917153936
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.5515 test: 0.5298 | best val epoch -- val: 0.5515 test: 0.5298

====epoch 3
Train Loss 19.514310121004286
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.5550 test: 0.5265 | best val epoch -- val: 0.5550 test: 0.5265

====epoch 4
Train Loss 19.30656262153398
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.5514 test: 0.5258 | best val epoch -- val: 0.5550 test: 0.5265

====epoch 5
Train Loss 19.24770260529968
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.5441 test: 0.5355 | best val epoch -- val: 0.5550 test: 0.5265

====epoch 6
Train Loss 19.16401412055652
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.5421 test: 0.5396 | best val epoch -- val: 0.5550 test: 0.5265

====epoch 7
Train Loss 19.135831373171644
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.5433 test: 0.5451 | best val epoch -- val: 0.5550 test: 0.5265

====epoch 8
Train Loss 19.096014898716106
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.5495 test: 0.5472 | best val epoch -- val: 0.5550 test: 0.5265

====epoch 9
Train Loss 19.03503825705326
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.5454 test: 0.5541 | best val epoch -- val: 0.5550 test: 0.5265

====epoch 10
Train Loss 18.924770717010887
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.5423 test: 0.5590 | best val epoch -- val: 0.5550 test: 0.5265

====epoch 11
Train Loss 18.816401306262126
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.5458 test: 0.5623 | best val epoch -- val: 0.5550 test: 0.5265

====epoch 12
Train Loss 18.635682709151137
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.5545 test: 0.5582 | best val epoch -- val: 0.5550 test: 0.5265

====epoch 13
Train Loss 18.4194463465587
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.5559 test: 0.5721 | best val epoch -- val: 0.5559 test: 0.5721

====epoch 14
Train Loss 18.45902370086254
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.5493 test: 0.5657 | best val epoch -- val: 0.5559 test: 0.5721

====epoch 15
Train Loss 18.177878056114167
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.5533 test: 0.5900 | best val epoch -- val: 0.5559 test: 0.5721

====epoch 16
Train Loss 18.159842900397027
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.5668 test: 0.5732 | best val epoch -- val: 0.5668 test: 0.5732

====epoch 17
Train Loss 17.988278983979157
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.5811 test: 0.5846 | best val epoch -- val: 0.5811 test: 0.5846

====epoch 18
Train Loss 17.84362282526279
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.5848 test: 0.5959 | best val epoch -- val: 0.5848 test: 0.5959

====epoch 19
Train Loss 17.985798473483136
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.5797 test: 0.5965 | best val epoch -- val: 0.5848 test: 0.5959

====epoch 20
Train Loss 17.65203196575338
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.5845 test: 0.5952 | best val epoch -- val: 0.5848 test: 0.5959

====epoch 21
Train Loss 17.76741405812515
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.5938 test: 0.5931 | best val epoch -- val: 0.5938 test: 0.5931

====epoch 22
Train Loss 17.654053295751446
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.5990 test: 0.5916 | best val epoch -- val: 0.5990 test: 0.5916

====epoch 23
Train Loss 17.50828882583427
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6045 test: 0.6065 | best val epoch -- val: 0.6045 test: 0.6065

====epoch 24
Train Loss 17.538719972766526
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6036 test: 0.6020 | best val epoch -- val: 0.6045 test: 0.6065

====epoch 25
Train Loss 17.323410588418138
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.5962 test: 0.6035 | best val epoch -- val: 0.6045 test: 0.6065

====epoch 26
Train Loss 17.284310550741868
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.5989 test: 0.5937 | best val epoch -- val: 0.6045 test: 0.6065

====epoch 27
Train Loss 17.22785592704325
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.5969 test: 0.5906 | best val epoch -- val: 0.6045 test: 0.6065

====epoch 28
Train Loss 17.165722748498588
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6034 test: 0.5959 | best val epoch -- val: 0.6045 test: 0.6065

====epoch 29
Train Loss 17.194023067308276
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6065 test: 0.6119 | best val epoch -- val: 0.6065 test: 0.6119

====epoch 30
Train Loss 17.087645145276426
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6069 test: 0.5861 | best val epoch -- val: 0.6069 test: 0.5861

====epoch 31
Train Loss 17.026999803057898
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6126 test: 0.6008 | best val epoch -- val: 0.6126 test: 0.6008

====epoch 32
Train Loss 16.807867856003718
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6196 test: 0.5969 | best val epoch -- val: 0.6196 test: 0.5969

====epoch 33
Train Loss 16.86186673343538
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6190 test: 0.5846 | best val epoch -- val: 0.6196 test: 0.5969

====epoch 34
Train Loss 16.702286499139372
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6258 test: 0.5877 | best val epoch -- val: 0.6258 test: 0.5877

====epoch 35
Train Loss 16.702328556731302
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6257 test: 0.5949 | best val epoch -- val: 0.6258 test: 0.5877

====epoch 36
Train Loss 16.917422555840652
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6230 test: 0.5829 | best val epoch -- val: 0.6258 test: 0.5877

====epoch 37
Train Loss 16.61094420140401
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6263 test: 0.5933 | best val epoch -- val: 0.6263 test: 0.5933

====epoch 38
Train Loss 16.53259612234863
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6299 test: 0.5833 | best val epoch -- val: 0.6299 test: 0.5833

====epoch 39
Train Loss 16.377442733121622
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6370 test: 0.5865 | best val epoch -- val: 0.6370 test: 0.5865

====epoch 40
Train Loss 16.394958039028584
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6343 test: 0.5842 | best val epoch -- val: 0.6370 test: 0.5865

====epoch 41
Train Loss 16.60635963418331
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6337 test: 0.5949 | best val epoch -- val: 0.6370 test: 0.5865

====epoch 42
Train Loss 16.220265882772587
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6374 test: 0.5780 | best val epoch -- val: 0.6374 test: 0.5780

====epoch 43
Train Loss 16.242554407998934
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6308 test: 0.5825 | best val epoch -- val: 0.6374 test: 0.5780

====epoch 44
Train Loss 16.124493286816477
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6343 test: 0.5903 | best val epoch -- val: 0.6374 test: 0.5780

====epoch 45
Train Loss 16.063676783100902
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6394 test: 0.5905 | best val epoch -- val: 0.6394 test: 0.5905

====epoch 46
Train Loss 16.074020969886462
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6287 test: 0.5852 | best val epoch -- val: 0.6394 test: 0.5905

====epoch 47
Train Loss 16.20225151541749
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6230 test: 0.5917 | best val epoch -- val: 0.6394 test: 0.5905

====epoch 48
Train Loss 15.989790887447441
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6320 test: 0.5946 | best val epoch -- val: 0.6394 test: 0.5905

====epoch 49
Train Loss 16.063552062724415
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6391 test: 0.5875 | best val epoch -- val: 0.6394 test: 0.5905

====epoch 50
Train Loss 15.791944258805248
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6340 test: 0.5845 | best val epoch -- val: 0.6394 test: 0.5905

====epoch 51
Train Loss 15.889624586557881
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6376 test: 0.5873 | best val epoch -- val: 0.6394 test: 0.5905

====epoch 52
Train Loss 15.710823079061505
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6403 test: 0.5842 | best val epoch -- val: 0.6403 test: 0.5842

====epoch 53
Train Loss 15.734545355897819
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6362 test: 0.5916 | best val epoch -- val: 0.6403 test: 0.5842

====epoch 54
Train Loss 15.617351186648568
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6347 test: 0.5918 | best val epoch -- val: 0.6403 test: 0.5842

====epoch 55
Train Loss 15.56462260094917
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6358 test: 0.6040 | best val epoch -- val: 0.6403 test: 0.5842

====epoch 56
Train Loss 15.500341715239195
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6400 test: 0.6021 | best val epoch -- val: 0.6403 test: 0.5842

====epoch 57
Train Loss 15.481484434041382
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6417 test: 0.5971 | best val epoch -- val: 0.6417 test: 0.5971

====epoch 58
Train Loss 15.561011829534918
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6412 test: 0.5971 | best val epoch -- val: 0.6417 test: 0.5971

====epoch 59
Train Loss 15.524903497298094
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6335 test: 0.5980 | best val epoch -- val: 0.6417 test: 0.5971

====epoch 60
Train Loss 15.541241130485695
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6459 test: 0.5966 | best val epoch -- val: 0.6459 test: 0.5966

====epoch 61
Train Loss 15.364148430909388
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6503 test: 0.5918 | best val epoch -- val: 0.6503 test: 0.5918

====epoch 62
Train Loss 15.426214503114556
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6507 test: 0.6029 | best val epoch -- val: 0.6507 test: 0.6029

====epoch 63
Train Loss 15.35880264584168
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6544 test: 0.5999 | best val epoch -- val: 0.6544 test: 0.5999

====epoch 64
Train Loss 15.20273293618261
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6413 test: 0.6107 | best val epoch -- val: 0.6544 test: 0.5999

====epoch 65
Train Loss 15.254422902357717
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6361 test: 0.6048 | best val epoch -- val: 0.6544 test: 0.5999

====epoch 66
Train Loss 15.214579635586169
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6345 test: 0.6014 | best val epoch -- val: 0.6544 test: 0.5999

====epoch 67
Train Loss 15.089596991173783
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6329 test: 0.5974 | best val epoch -- val: 0.6544 test: 0.5999

====epoch 68
Train Loss 15.076628618511478
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6344 test: 0.6063 | best val epoch -- val: 0.6544 test: 0.5999

====epoch 69
Train Loss 14.878633823662405
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6287 test: 0.6052 | best val epoch -- val: 0.6544 test: 0.5999

====epoch 70
Train Loss 15.030831545694952
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6321 test: 0.6076 | best val epoch -- val: 0.6544 test: 0.5999

====epoch 71
Train Loss 15.184850379423875
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6336 test: 0.5973 | best val epoch -- val: 0.6544 test: 0.5999

====epoch 72
Train Loss 14.890519405334272
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6328 test: 0.6022 | best val epoch -- val: 0.6544 test: 0.5999

====epoch 73
Train Loss 14.874480854302101
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6441 test: 0.6041 | best val epoch -- val: 0.6544 test: 0.5999

====epoch 74
Train Loss 14.85446192161541
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6479 test: 0.6052 | best val epoch -- val: 0.6544 test: 0.5999

====epoch 75
Train Loss 14.92260761391407
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6542 test: 0.5987 | best val epoch -- val: 0.6544 test: 0.5999

====epoch 76
Train Loss 15.002712503009644
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6419 test: 0.6010 | best val epoch -- val: 0.6544 test: 0.5999

====epoch 77
Train Loss 14.723598834894753
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6487 test: 0.5972 | best val epoch -- val: 0.6544 test: 0.5999

====epoch 78
Train Loss 14.848203994191262
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6505 test: 0.5977 | best val epoch -- val: 0.6544 test: 0.5999

====epoch 79
Train Loss 14.905349018186591
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6488 test: 0.5927 | best val epoch -- val: 0.6544 test: 0.5999

====epoch 80
Train Loss 14.644408400564798
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6474 test: 0.5965 | best val epoch -- val: 0.6544 test: 0.5999

====epoch 81
Train Loss 14.836827563103213
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6470 test: 0.6015 | best val epoch -- val: 0.6544 test: 0.5999

====epoch 82
Train Loss 14.68315492971017
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6501 test: 0.5938 | best val epoch -- val: 0.6544 test: 0.5999

====epoch 83
Train Loss 14.608826563343696
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6484 test: 0.5930 | best val epoch -- val: 0.6544 test: 0.5999

====epoch 84
Train Loss 14.559928953331328
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6555 test: 0.5983 | best val epoch -- val: 0.6555 test: 0.5983

====epoch 85
Train Loss 14.500861958578607
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6552 test: 0.5946 | best val epoch -- val: 0.6555 test: 0.5983

====epoch 86
Train Loss 14.691715458123019
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6485 test: 0.6062 | best val epoch -- val: 0.6555 test: 0.5983

====epoch 87
Train Loss 14.369424004333341
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6453 test: 0.6032 | best val epoch -- val: 0.6555 test: 0.5983

====epoch 88
Train Loss 14.303492376585773
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6481 test: 0.6045 | best val epoch -- val: 0.6555 test: 0.5983

====epoch 89
Train Loss 14.39877159058662
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6348 test: 0.6014 | best val epoch -- val: 0.6555 test: 0.5983

====epoch 90
Train Loss 14.482456784351994
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6350 test: 0.6034 | best val epoch -- val: 0.6555 test: 0.5983

====epoch 91
Train Loss 14.37731987352429
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6332 test: 0.6044 | best val epoch -- val: 0.6555 test: 0.5983

====epoch 92
Train Loss 14.22363535787263
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6404 test: 0.5959 | best val epoch -- val: 0.6555 test: 0.5983

====epoch 93
Train Loss 14.241577703459328
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6338 test: 0.6041 | best val epoch -- val: 0.6555 test: 0.5983

====epoch 94
Train Loss 14.463787125839382
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6387 test: 0.6074 | best val epoch -- val: 0.6555 test: 0.5983

====epoch 95
Train Loss 14.156639316648542
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6474 test: 0.6114 | best val epoch -- val: 0.6555 test: 0.5983

====epoch 96
Train Loss 14.011579993466295
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6455 test: 0.6003 | best val epoch -- val: 0.6555 test: 0.5983

====epoch 97
Train Loss 13.983877767858672
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6466 test: 0.6065 | best val epoch -- val: 0.6555 test: 0.5983

====epoch 98
Train Loss 14.097992135548983
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6331 test: 0.6096 | best val epoch -- val: 0.6555 test: 0.5983

====epoch 99
Train Loss 14.255600445938486
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6402 test: 0.6049 | best val epoch -- val: 0.6555 test: 0.5983

====epoch 100
Train Loss 13.869137758102685
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6392 test: 0.6023 | best val epoch -- val: 0.6555 test: 0.5983

[08:39:37] WARNING: not removing hydrogen atom without neighbors
[08:39:37] WARNING: not removing hydrogen atom without neighbors
[08:39:38] WARNING: not removing hydrogen atom without neighbors
[08:39:38] WARNING: not removing hydrogen atom without neighbors
[08:39:38] WARNING: not removing hydrogen atom without neighbors
[08:39:38] WARNING: not removing hydrogen atom without neighbors
[08:39:38] WARNING: not removing hydrogen atom without neighbors
[08:39:38] WARNING: not removing hydrogen atom without neighbors
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.4.
[08:39:38] WARNING: not removing hydrogen atom without neighbors
[08:39:38] WARNING: not removing hydrogen atom without neighbors
[08:39:38] WARNING: not removing hydrogen atom without neighbors
[08:39:39] WARNING: not removing hydrogen atom without neighbors
[08:39:39] WARNING: not removing hydrogen atom without neighbors
2022-09-13 08:39:40.054 | INFO     | modules.masked_transformer_encoder:__init__:122 - number of parameters: 0.000000e+00
=========================================
batch_size = 32
d_model = 128
dataset = sider
decay = 0
device = 0
dim_feedforward = 512
eval_train = 0
filename =
gnn_JK = cat
gnn_dropout = 0.3
gnn_emb_dim = 300
gnn_num_layer = 5
gnn_residual = False
gnn_type = gin
gnn_virtual_node = False
graph_pooling = cls
input_model_file = models_graphtrans/graphtrans-sr-gcl.pth
lr = 0.0001
lr_scale = 1
max_input_len = 1000
nhead = 4
num_encoder_layers = 4
num_encoder_layers_masked = 0
num_workers = 0
pos_encoder = False
runseed = 5
seed = 12344
split = scaffold
transformer_activation = relu
transformer_dropout = 0.3
transformer_norm_input = True
transformer_prenorm = False
=========================================
sider
scaffold
Loaded GraphTrans from models_graphtrans/graphtrans-sr-gcl.pth
====epoch 1
Train Loss 24.33989015846383
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.5003 test: 0.5168 | best val epoch -- val: 0.5003 test: 0.5168

====epoch 2
Train Loss 21.322928684434473
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.5084 test: 0.5209 | best val epoch -- val: 0.5084 test: 0.5209

====epoch 3
Train Loss 19.77838404067664
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.5058 test: 0.5142 | best val epoch -- val: 0.5084 test: 0.5209

====epoch 4
Train Loss 19.39727136845106
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.5020 test: 0.5235 | best val epoch -- val: 0.5084 test: 0.5209

====epoch 5
Train Loss 19.206335315056148
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.5002 test: 0.5295 | best val epoch -- val: 0.5084 test: 0.5209

====epoch 6
Train Loss 19.149729556345935
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.5034 test: 0.5329 | best val epoch -- val: 0.5084 test: 0.5209

====epoch 7
Train Loss 19.088078220729585
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.5029 test: 0.5263 | best val epoch -- val: 0.5084 test: 0.5209

====epoch 8
Train Loss 18.99136561416544
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.5112 test: 0.5428 | best val epoch -- val: 0.5112 test: 0.5428

====epoch 9
Train Loss 19.035011005011057
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.5226 test: 0.5503 | best val epoch -- val: 0.5226 test: 0.5503

====epoch 10
Train Loss 18.879227488636054
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.5258 test: 0.5655 | best val epoch -- val: 0.5258 test: 0.5655

====epoch 11
Train Loss 18.74907681321039
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.5266 test: 0.5610 | best val epoch -- val: 0.5266 test: 0.5610

====epoch 12
Train Loss 18.65783134491579
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.5323 test: 0.5631 | best val epoch -- val: 0.5323 test: 0.5631

====epoch 13
Train Loss 18.397563745709625
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.5334 test: 0.5721 | best val epoch -- val: 0.5334 test: 0.5721

====epoch 14
Train Loss 18.37482733222597
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.5338 test: 0.5765 | best val epoch -- val: 0.5338 test: 0.5765

====epoch 15
Train Loss 18.253611203416373
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.5400 test: 0.5860 | best val epoch -- val: 0.5400 test: 0.5860

====epoch 16
Train Loss 18.06222416316088
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.5609 test: 0.5927 | best val epoch -- val: 0.5609 test: 0.5927

====epoch 17
Train Loss 18.013368739030504
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.5592 test: 0.5779 | best val epoch -- val: 0.5609 test: 0.5927

====epoch 18
Train Loss 17.812168281935147
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.5664 test: 0.5989 | best val epoch -- val: 0.5664 test: 0.5989

====epoch 19
Train Loss 17.833021435434052
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.5692 test: 0.5955 | best val epoch -- val: 0.5692 test: 0.5955

====epoch 20
Train Loss 17.79424486534855
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.5783 test: 0.5880 | best val epoch -- val: 0.5783 test: 0.5880

====epoch 21
Train Loss 17.64585486973882
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.5794 test: 0.6045 | best val epoch -- val: 0.5794 test: 0.6045

====epoch 22
Train Loss 17.477816505668944
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.5724 test: 0.6054 | best val epoch -- val: 0.5794 test: 0.6045

====epoch 23
Train Loss 17.379291208789844
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.5844 test: 0.6071 | best val epoch -- val: 0.5844 test: 0.6071

====epoch 24
Train Loss 17.42005162695502
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.5910 test: 0.6056 | best val epoch -- val: 0.5910 test: 0.6056

====epoch 25
Train Loss 17.200385076079478
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6116 test: 0.6257 | best val epoch -- val: 0.6116 test: 0.6257

====epoch 26
Train Loss 17.19579222927786
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6037 test: 0.6236 | best val epoch -- val: 0.6116 test: 0.6257

====epoch 27
Train Loss 17.163231923201394
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.5972 test: 0.6166 | best val epoch -- val: 0.6116 test: 0.6257

====epoch 28
Train Loss 16.983265989492576
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6052 test: 0.6111 | best val epoch -- val: 0.6116 test: 0.6257

====epoch 29
Train Loss 17.056281189761727
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6135 test: 0.6056 | best val epoch -- val: 0.6135 test: 0.6056

====epoch 30
Train Loss 16.761856939340337
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6052 test: 0.6136 | best val epoch -- val: 0.6135 test: 0.6056

====epoch 31
Train Loss 16.937601087873595
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6176 test: 0.6121 | best val epoch -- val: 0.6176 test: 0.6121

====epoch 32
Train Loss 16.67991274634334
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6140 test: 0.6089 | best val epoch -- val: 0.6176 test: 0.6121

====epoch 33
Train Loss 16.684052302670224
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6167 test: 0.6166 | best val epoch -- val: 0.6176 test: 0.6121

====epoch 34
Train Loss 16.759577955599816
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6128 test: 0.6203 | best val epoch -- val: 0.6176 test: 0.6121

====epoch 35
Train Loss 16.500169846592158
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6172 test: 0.6166 | best val epoch -- val: 0.6176 test: 0.6121

====epoch 36
Train Loss 16.43113565326878
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6205 test: 0.6132 | best val epoch -- val: 0.6205 test: 0.6132

====epoch 37
Train Loss 16.398584813407
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6220 test: 0.6277 | best val epoch -- val: 0.6220 test: 0.6277

====epoch 38
Train Loss 16.324138961020317
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6251 test: 0.6100 | best val epoch -- val: 0.6251 test: 0.6100

====epoch 39
Train Loss 16.178930402532856
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6270 test: 0.6179 | best val epoch -- val: 0.6270 test: 0.6179

====epoch 40
Train Loss 16.312229040528177
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6287 test: 0.6177 | best val epoch -- val: 0.6287 test: 0.6177

====epoch 41
Train Loss 16.306441107952807
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6239 test: 0.6252 | best val epoch -- val: 0.6287 test: 0.6177

====epoch 42
Train Loss 16.118730904741476
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6299 test: 0.6128 | best val epoch -- val: 0.6299 test: 0.6128

====epoch 43
Train Loss 16.144755437773895
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6270 test: 0.6124 | best val epoch -- val: 0.6299 test: 0.6128

====epoch 44
Train Loss 16.1107430153266
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6324 test: 0.6231 | best val epoch -- val: 0.6324 test: 0.6231

====epoch 45
Train Loss 15.901901655314365
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6235 test: 0.6238 | best val epoch -- val: 0.6324 test: 0.6231

====epoch 46
Train Loss 15.94869248204178
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6323 test: 0.6160 | best val epoch -- val: 0.6324 test: 0.6231

====epoch 47
Train Loss 15.965691848365369
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6272 test: 0.6205 | best val epoch -- val: 0.6324 test: 0.6231

====epoch 48
Train Loss 15.731774678549224
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6228 test: 0.6220 | best val epoch -- val: 0.6324 test: 0.6231

====epoch 49
Train Loss 15.59957529673727
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6294 test: 0.6239 | best val epoch -- val: 0.6324 test: 0.6231

====epoch 50
Train Loss 15.790809914037016
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6361 test: 0.6055 | best val epoch -- val: 0.6361 test: 0.6055

====epoch 51
Train Loss 15.687540893622268
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6305 test: 0.6146 | best val epoch -- val: 0.6361 test: 0.6055

====epoch 52
Train Loss 15.74497007074254
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6316 test: 0.6144 | best val epoch -- val: 0.6361 test: 0.6055

====epoch 53
Train Loss 15.70401116230879
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6347 test: 0.6059 | best val epoch -- val: 0.6361 test: 0.6055

====epoch 54
Train Loss 15.539777691922781
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6327 test: 0.6102 | best val epoch -- val: 0.6361 test: 0.6055

====epoch 55
Train Loss 15.3938080981211
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6320 test: 0.6159 | best val epoch -- val: 0.6361 test: 0.6055

====epoch 56
Train Loss 15.423427890165181
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6324 test: 0.6129 | best val epoch -- val: 0.6361 test: 0.6055

====epoch 57
Train Loss 15.429586224950047
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6287 test: 0.6211 | best val epoch -- val: 0.6361 test: 0.6055

====epoch 58
Train Loss 15.279426673084306
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6317 test: 0.6211 | best val epoch -- val: 0.6361 test: 0.6055

====epoch 59
Train Loss 15.282311516992776
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6358 test: 0.6119 | best val epoch -- val: 0.6361 test: 0.6055

====epoch 60
Train Loss 15.432489785574658
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6344 test: 0.6145 | best val epoch -- val: 0.6361 test: 0.6055

====epoch 61
Train Loss 15.24123225303142
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6390 test: 0.6110 | best val epoch -- val: 0.6390 test: 0.6110

====epoch 62
Train Loss 15.151108493793892
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6423 test: 0.6151 | best val epoch -- val: 0.6423 test: 0.6151

====epoch 63
Train Loss 15.103292631531108
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6357 test: 0.6173 | best val epoch -- val: 0.6423 test: 0.6151

====epoch 64
Train Loss 15.231845442080209
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6430 test: 0.6033 | best val epoch -- val: 0.6430 test: 0.6033

====epoch 65
Train Loss 14.926321154641768
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6274 test: 0.6140 | best val epoch -- val: 0.6430 test: 0.6033

====epoch 66
Train Loss 14.898856347350907
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6313 test: 0.6129 | best val epoch -- val: 0.6430 test: 0.6033

====epoch 67
Train Loss 14.895912220638145
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6181 test: 0.6129 | best val epoch -- val: 0.6430 test: 0.6033

====epoch 68
Train Loss 14.963600476807219
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6216 test: 0.6255 | best val epoch -- val: 0.6430 test: 0.6033

====epoch 69
Train Loss 14.886046032958525
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6283 test: 0.6124 | best val epoch -- val: 0.6430 test: 0.6033

====epoch 70
Train Loss 15.00348445009189
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6315 test: 0.6214 | best val epoch -- val: 0.6430 test: 0.6033

====epoch 71
Train Loss 14.91183520781058
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6322 test: 0.6138 | best val epoch -- val: 0.6430 test: 0.6033

====epoch 72
Train Loss 14.701000101254387
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6259 test: 0.6091 | best val epoch -- val: 0.6430 test: 0.6033

====epoch 73
Train Loss 14.735772311024403
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6203 test: 0.6014 | best val epoch -- val: 0.6430 test: 0.6033

====epoch 74
Train Loss 14.856750625369875
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6307 test: 0.6072 | best val epoch -- val: 0.6430 test: 0.6033

====epoch 75
Train Loss 14.501141814087593
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6268 test: 0.6049 | best val epoch -- val: 0.6430 test: 0.6033

====epoch 76
Train Loss 14.651683021189344
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6298 test: 0.6082 | best val epoch -- val: 0.6430 test: 0.6033

====epoch 77
Train Loss 14.796832411241214
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6306 test: 0.6019 | best val epoch -- val: 0.6430 test: 0.6033

====epoch 78
Train Loss 14.83492288558151
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6304 test: 0.6110 | best val epoch -- val: 0.6430 test: 0.6033

====epoch 79
Train Loss 14.581859217728198
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6294 test: 0.6008 | best val epoch -- val: 0.6430 test: 0.6033

====epoch 80
Train Loss 14.66159263972411
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6443 test: 0.6073 | best val epoch -- val: 0.6443 test: 0.6073

====epoch 81
Train Loss 14.458269256005508
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6391 test: 0.5947 | best val epoch -- val: 0.6443 test: 0.6073

====epoch 82
Train Loss 14.528093815159666
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6380 test: 0.5943 | best val epoch -- val: 0.6443 test: 0.6073

====epoch 83
Train Loss 14.398419436666389
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6386 test: 0.6067 | best val epoch -- val: 0.6443 test: 0.6073

====epoch 84
Train Loss 14.260601324219058
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6299 test: 0.5956 | best val epoch -- val: 0.6443 test: 0.6073

====epoch 85
Train Loss 14.124966078200654
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6314 test: 0.6044 | best val epoch -- val: 0.6443 test: 0.6073

====epoch 86
Train Loss 14.353751368622202
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6320 test: 0.5974 | best val epoch -- val: 0.6443 test: 0.6073

====epoch 87
Train Loss 14.422035787718107
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6306 test: 0.5927 | best val epoch -- val: 0.6443 test: 0.6073

====epoch 88
Train Loss 14.283580403527816
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6248 test: 0.5843 | best val epoch -- val: 0.6443 test: 0.6073

====epoch 89
Train Loss 14.301904440055898
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6273 test: 0.5792 | best val epoch -- val: 0.6443 test: 0.6073

====epoch 90
Train Loss 14.225828891418349
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6208 test: 0.5763 | best val epoch -- val: 0.6443 test: 0.6073

====epoch 91
Train Loss 14.294898031311867
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6182 test: 0.5853 | best val epoch -- val: 0.6443 test: 0.6073

====epoch 92
Train Loss 14.154074675108957
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6199 test: 0.5916 | best val epoch -- val: 0.6443 test: 0.6073

====epoch 93
Train Loss 14.263942207596168
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6177 test: 0.5766 | best val epoch -- val: 0.6443 test: 0.6073

====epoch 94
Train Loss 14.104082326043068
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6178 test: 0.5890 | best val epoch -- val: 0.6443 test: 0.6073

====epoch 95
Train Loss 14.051351430517638
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6179 test: 0.5831 | best val epoch -- val: 0.6443 test: 0.6073

====epoch 96
Train Loss 14.028129557319842
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6258 test: 0.5943 | best val epoch -- val: 0.6443 test: 0.6073

====epoch 97
Train Loss 14.049263518552976
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6287 test: 0.5954 | best val epoch -- val: 0.6443 test: 0.6073

====epoch 98
Train Loss 13.972958198353949
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6280 test: 0.6035 | best val epoch -- val: 0.6443 test: 0.6073

====epoch 99
Train Loss 13.840081363766858
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6208 test: 0.5992 | best val epoch -- val: 0.6443 test: 0.6073

====epoch 100
Train Loss 13.999424337291343
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6207 test: 0.6019 | best val epoch -- val: 0.6443 test: 0.6073

[08:43:33] WARNING: not removing hydrogen atom without neighbors
[08:43:33] WARNING: not removing hydrogen atom without neighbors
[08:43:33] WARNING: not removing hydrogen atom without neighbors
[08:43:33] WARNING: not removing hydrogen atom without neighbors
[08:43:33] WARNING: not removing hydrogen atom without neighbors
[08:43:33] WARNING: not removing hydrogen atom without neighbors
[08:43:33] WARNING: not removing hydrogen atom without neighbors
[08:43:33] WARNING: not removing hydrogen atom without neighbors
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.4.
[08:43:34] WARNING: not removing hydrogen atom without neighbors
[08:43:34] WARNING: not removing hydrogen atom without neighbors
[08:43:34] WARNING: not removing hydrogen atom without neighbors
[08:43:34] WARNING: not removing hydrogen atom without neighbors
[08:43:34] WARNING: not removing hydrogen atom without neighbors
2022-09-13 08:43:35.844 | INFO     | modules.masked_transformer_encoder:__init__:122 - number of parameters: 0.000000e+00
=========================================
batch_size = 32
d_model = 128
dataset = sider
decay = 0
device = 0
dim_feedforward = 512
eval_train = 0
filename =
gnn_JK = cat
gnn_dropout = 0.3
gnn_emb_dim = 300
gnn_num_layer = 5
gnn_residual = False
gnn_type = gin
gnn_virtual_node = False
graph_pooling = cls
input_model_file = models_graphtrans/graphtrans-sr-gcl.pth
lr = 0.0001
lr_scale = 1
max_input_len = 1000
nhead = 4
num_encoder_layers = 4
num_encoder_layers_masked = 0
num_workers = 0
pos_encoder = False
runseed = 6
seed = 12344
split = scaffold
transformer_activation = relu
transformer_dropout = 0.3
transformer_norm_input = True
transformer_prenorm = False
=========================================
sider
scaffold
Loaded GraphTrans from models_graphtrans/graphtrans-sr-gcl.pth
====epoch 1
Train Loss 24.09204877676071
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.4987 test: 0.5206 | best val epoch -- val: 0.4987 test: 0.5206

====epoch 2
Train Loss 20.63007467090713
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.5084 test: 0.5251 | best val epoch -- val: 0.5084 test: 0.5251

====epoch 3
Train Loss 19.561037786226713
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.5051 test: 0.5221 | best val epoch -- val: 0.5084 test: 0.5251

====epoch 4
Train Loss 19.262341121305152
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.5014 test: 0.5236 | best val epoch -- val: 0.5084 test: 0.5251

====epoch 5
Train Loss 19.208735855075332
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.5048 test: 0.5313 | best val epoch -- val: 0.5084 test: 0.5251

====epoch 6
Train Loss 19.07540412225712
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.5100 test: 0.5354 | best val epoch -- val: 0.5100 test: 0.5354

====epoch 7
Train Loss 19.033551614032362
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.5121 test: 0.5423 | best val epoch -- val: 0.5121 test: 0.5423

====epoch 8
Train Loss 19.005253350841542
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.5154 test: 0.5518 | best val epoch -- val: 0.5154 test: 0.5518

====epoch 9
Train Loss 18.929465601261224
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.5204 test: 0.5605 | best val epoch -- val: 0.5204 test: 0.5605

====epoch 10
Train Loss 18.84593783989953
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.5217 test: 0.5729 | best val epoch -- val: 0.5217 test: 0.5729

====epoch 11
Train Loss 18.82062958342348
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.5273 test: 0.5837 | best val epoch -- val: 0.5273 test: 0.5837

====epoch 12
Train Loss 18.624819784952145
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.5310 test: 0.5907 | best val epoch -- val: 0.5310 test: 0.5907

====epoch 13
Train Loss 18.45516276037486
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.5455 test: 0.5891 | best val epoch -- val: 0.5455 test: 0.5891

====epoch 14
Train Loss 18.38316131410498
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.5495 test: 0.5907 | best val epoch -- val: 0.5495 test: 0.5907

====epoch 15
Train Loss 18.22597552842684
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.5602 test: 0.5948 | best val epoch -- val: 0.5602 test: 0.5948

====epoch 16
Train Loss 18.088100160593587
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.5533 test: 0.5886 | best val epoch -- val: 0.5602 test: 0.5948

====epoch 17
Train Loss 17.952456383740987
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.5558 test: 0.5882 | best val epoch -- val: 0.5602 test: 0.5948

====epoch 18
Train Loss 17.948905543421418
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.5813 test: 0.5932 | best val epoch -- val: 0.5813 test: 0.5932

====epoch 19
Train Loss 17.87862708654112
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.5721 test: 0.5913 | best val epoch -- val: 0.5813 test: 0.5932

====epoch 20
Train Loss 17.658799010864627
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6014 test: 0.5921 | best val epoch -- val: 0.6014 test: 0.5921

====epoch 21
Train Loss 17.59070684409683
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.5920 test: 0.6029 | best val epoch -- val: 0.6014 test: 0.5921

====epoch 22
Train Loss 17.65680478892349
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6148 test: 0.5977 | best val epoch -- val: 0.6148 test: 0.5977

====epoch 23
Train Loss 17.40600319025896
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.5952 test: 0.5995 | best val epoch -- val: 0.6148 test: 0.5977

====epoch 24
Train Loss 17.265057788218357
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6030 test: 0.6000 | best val epoch -- val: 0.6148 test: 0.5977

====epoch 25
Train Loss 17.40360343246532
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.5996 test: 0.5953 | best val epoch -- val: 0.6148 test: 0.5977

====epoch 26
Train Loss 17.40474811508807
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6050 test: 0.6017 | best val epoch -- val: 0.6148 test: 0.5977

====epoch 27
Train Loss 17.20121177510509
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6055 test: 0.5957 | best val epoch -- val: 0.6148 test: 0.5977

====epoch 28
Train Loss 17.155903666588465
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6129 test: 0.6000 | best val epoch -- val: 0.6148 test: 0.5977

====epoch 29
Train Loss 17.037306297760956
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6165 test: 0.6012 | best val epoch -- val: 0.6165 test: 0.6012

====epoch 30
Train Loss 17.01545103427538
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6240 test: 0.5931 | best val epoch -- val: 0.6240 test: 0.5931

====epoch 31
Train Loss 16.85333210105851
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6287 test: 0.5886 | best val epoch -- val: 0.6287 test: 0.5886

====epoch 32
Train Loss 16.839674084463628
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6238 test: 0.5944 | best val epoch -- val: 0.6287 test: 0.5886

====epoch 33
Train Loss 16.796303036413295
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6238 test: 0.5939 | best val epoch -- val: 0.6287 test: 0.5886

====epoch 34
Train Loss 16.66343351766482
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6154 test: 0.6046 | best val epoch -- val: 0.6287 test: 0.5886

====epoch 35
Train Loss 16.624130355009555
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6152 test: 0.6066 | best val epoch -- val: 0.6287 test: 0.5886

====epoch 36
Train Loss 16.539776585509387
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6212 test: 0.6041 | best val epoch -- val: 0.6287 test: 0.5886

====epoch 37
Train Loss 16.543311751841134
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6249 test: 0.6044 | best val epoch -- val: 0.6287 test: 0.5886

====epoch 38
Train Loss 16.51735419835592
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6231 test: 0.6060 | best val epoch -- val: 0.6287 test: 0.5886

====epoch 39
Train Loss 16.43954905640286
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6281 test: 0.6084 | best val epoch -- val: 0.6287 test: 0.5886

====epoch 40
Train Loss 16.417025983391802
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6404 test: 0.6039 | best val epoch -- val: 0.6404 test: 0.6039

====epoch 41
Train Loss 16.384537684440872
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6323 test: 0.6073 | best val epoch -- val: 0.6404 test: 0.6039

====epoch 42
Train Loss 16.37883211029857
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6221 test: 0.6172 | best val epoch -- val: 0.6404 test: 0.6039

====epoch 43
Train Loss 16.24276683888434
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6318 test: 0.6172 | best val epoch -- val: 0.6404 test: 0.6039

====epoch 44
Train Loss 16.21281859368285
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6278 test: 0.6215 | best val epoch -- val: 0.6404 test: 0.6039

====epoch 45
Train Loss 16.05406893687005
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6227 test: 0.6234 | best val epoch -- val: 0.6404 test: 0.6039

====epoch 46
Train Loss 16.060426958531973
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6308 test: 0.6305 | best val epoch -- val: 0.6404 test: 0.6039

====epoch 47
Train Loss 16.178096329043203
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6298 test: 0.6382 | best val epoch -- val: 0.6404 test: 0.6039

====epoch 48
Train Loss 15.899616256807901
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6244 test: 0.6219 | best val epoch -- val: 0.6404 test: 0.6039

====epoch 49
Train Loss 15.98673856953192
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6307 test: 0.6306 | best val epoch -- val: 0.6404 test: 0.6039

====epoch 50
Train Loss 15.902389932731486
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6310 test: 0.6324 | best val epoch -- val: 0.6404 test: 0.6039

====epoch 51
Train Loss 15.935020102822463
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6289 test: 0.6345 | best val epoch -- val: 0.6404 test: 0.6039

====epoch 52
Train Loss 15.855751248776553
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6162 test: 0.6264 | best val epoch -- val: 0.6404 test: 0.6039

====epoch 53
Train Loss 15.703067259555326
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6219 test: 0.6330 | best val epoch -- val: 0.6404 test: 0.6039

====epoch 54
Train Loss 15.663041178268132
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6276 test: 0.6394 | best val epoch -- val: 0.6404 test: 0.6039

====epoch 55
Train Loss 15.699422562015405
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6289 test: 0.6327 | best val epoch -- val: 0.6404 test: 0.6039

====epoch 56
Train Loss 15.603490765329994
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6294 test: 0.6383 | best val epoch -- val: 0.6404 test: 0.6039

====epoch 57
Train Loss 15.54331275500287
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6378 test: 0.6390 | best val epoch -- val: 0.6404 test: 0.6039

====epoch 58
Train Loss 15.534156000351171
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6329 test: 0.6446 | best val epoch -- val: 0.6404 test: 0.6039

====epoch 59
Train Loss 15.524768007775952
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6310 test: 0.6398 | best val epoch -- val: 0.6404 test: 0.6039

====epoch 60
Train Loss 15.4940064624807
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6366 test: 0.6417 | best val epoch -- val: 0.6404 test: 0.6039

====epoch 61
Train Loss 15.268547346221359
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6395 test: 0.6389 | best val epoch -- val: 0.6404 test: 0.6039

====epoch 62
Train Loss 15.329894531257874
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6316 test: 0.6335 | best val epoch -- val: 0.6404 test: 0.6039

====epoch 63
Train Loss 15.277087983905009
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6370 test: 0.6444 | best val epoch -- val: 0.6404 test: 0.6039

====epoch 64
Train Loss 15.380975761091575
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6395 test: 0.6425 | best val epoch -- val: 0.6404 test: 0.6039

====epoch 65
Train Loss 15.142198510506773
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6393 test: 0.6430 | best val epoch -- val: 0.6404 test: 0.6039

====epoch 66
Train Loss 15.287768295312292
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6342 test: 0.6457 | best val epoch -- val: 0.6404 test: 0.6039

====epoch 67
Train Loss 14.95955593121308
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6292 test: 0.6453 | best val epoch -- val: 0.6404 test: 0.6039

====epoch 68
Train Loss 15.18872258213545
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6335 test: 0.6471 | best val epoch -- val: 0.6404 test: 0.6039

====epoch 69
Train Loss 15.04573808684606
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6457 test: 0.6484 | best val epoch -- val: 0.6457 test: 0.6484

====epoch 70
Train Loss 15.017432143148413
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6428 test: 0.6459 | best val epoch -- val: 0.6457 test: 0.6484

====epoch 71
Train Loss 14.979057426137906
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6445 test: 0.6453 | best val epoch -- val: 0.6457 test: 0.6484

====epoch 72
Train Loss 15.07915907130483
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6395 test: 0.6456 | best val epoch -- val: 0.6457 test: 0.6484

====epoch 73
Train Loss 14.866601608421869
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6492 test: 0.6498 | best val epoch -- val: 0.6492 test: 0.6498

====epoch 74
Train Loss 14.919408501194434
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6423 test: 0.6495 | best val epoch -- val: 0.6492 test: 0.6498

====epoch 75
Train Loss 14.923619544534493
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6413 test: 0.6517 | best val epoch -- val: 0.6492 test: 0.6498

====epoch 76
Train Loss 14.791435655060127
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6428 test: 0.6458 | best val epoch -- val: 0.6492 test: 0.6498

====epoch 77
Train Loss 14.735958775253032
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6475 test: 0.6438 | best val epoch -- val: 0.6492 test: 0.6498

====epoch 78
Train Loss 14.762839398870515
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6476 test: 0.6414 | best val epoch -- val: 0.6492 test: 0.6498

====epoch 79
Train Loss 14.644287304980288
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6498 test: 0.6438 | best val epoch -- val: 0.6498 test: 0.6438

====epoch 80
Train Loss 14.512359521280489
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6488 test: 0.6396 | best val epoch -- val: 0.6498 test: 0.6438

====epoch 81
Train Loss 14.58346186080477
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6563 test: 0.6410 | best val epoch -- val: 0.6563 test: 0.6410

====epoch 82
Train Loss 14.570212981336015
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6505 test: 0.6439 | best val epoch -- val: 0.6563 test: 0.6410

====epoch 83
Train Loss 14.7839973197678
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6550 test: 0.6383 | best val epoch -- val: 0.6563 test: 0.6410

====epoch 84
Train Loss 14.684599628885216
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6609 test: 0.6424 | best val epoch -- val: 0.6609 test: 0.6424

====epoch 85
Train Loss 14.515746874564437
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6621 test: 0.6414 | best val epoch -- val: 0.6621 test: 0.6414

====epoch 86
Train Loss 14.514660259906666
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6617 test: 0.6428 | best val epoch -- val: 0.6621 test: 0.6414

====epoch 87
Train Loss 14.398515038014972
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6591 test: 0.6412 | best val epoch -- val: 0.6621 test: 0.6414

====epoch 88
Train Loss 14.330459407349908
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6557 test: 0.6446 | best val epoch -- val: 0.6621 test: 0.6414

====epoch 89
Train Loss 14.348788606542662
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6593 test: 0.6450 | best val epoch -- val: 0.6621 test: 0.6414

====epoch 90
Train Loss 14.353837933192128
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6592 test: 0.6479 | best val epoch -- val: 0.6621 test: 0.6414

====epoch 91
Train Loss 14.263231402496407
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6599 test: 0.6462 | best val epoch -- val: 0.6621 test: 0.6414

====epoch 92
Train Loss 14.205191612748822
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6505 test: 0.6391 | best val epoch -- val: 0.6621 test: 0.6414

====epoch 93
Train Loss 14.148792150124416
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6520 test: 0.6451 | best val epoch -- val: 0.6621 test: 0.6414

====epoch 94
Train Loss 14.295526969765495
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6555 test: 0.6414 | best val epoch -- val: 0.6621 test: 0.6414

====epoch 95
Train Loss 14.250156954685062
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6522 test: 0.6500 | best val epoch -- val: 0.6621 test: 0.6414

====epoch 96
Train Loss 14.058691704755862
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6506 test: 0.6419 | best val epoch -- val: 0.6621 test: 0.6414

====epoch 97
Train Loss 14.102422972063561
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6450 test: 0.6418 | best val epoch -- val: 0.6621 test: 0.6414

====epoch 98
Train Loss 14.200045205198736
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6459 test: 0.6408 | best val epoch -- val: 0.6621 test: 0.6414

====epoch 99
Train Loss 14.041805586794283
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6536 test: 0.6392 | best val epoch -- val: 0.6621 test: 0.6414

====epoch 100
Train Loss 14.00802918317954
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6525 test: 0.6428 | best val epoch -- val: 0.6621 test: 0.6414

[08:47:31] WARNING: not removing hydrogen atom without neighbors
[08:47:31] WARNING: not removing hydrogen atom without neighbors
[08:47:31] WARNING: not removing hydrogen atom without neighbors
[08:47:31] WARNING: not removing hydrogen atom without neighbors
[08:47:31] WARNING: not removing hydrogen atom without neighbors
[08:47:31] WARNING: not removing hydrogen atom without neighbors
[08:47:31] WARNING: not removing hydrogen atom without neighbors
[08:47:31] WARNING: not removing hydrogen atom without neighbors
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.4.
[08:47:32] WARNING: not removing hydrogen atom without neighbors
[08:47:32] WARNING: not removing hydrogen atom without neighbors
[08:47:32] WARNING: not removing hydrogen atom without neighbors
[08:47:32] WARNING: not removing hydrogen atom without neighbors
[08:47:32] WARNING: not removing hydrogen atom without neighbors
2022-09-13 08:47:33.526 | INFO     | modules.masked_transformer_encoder:__init__:122 - number of parameters: 0.000000e+00
=========================================
batch_size = 32
d_model = 128
dataset = sider
decay = 0
device = 0
dim_feedforward = 512
eval_train = 0
filename =
gnn_JK = cat
gnn_dropout = 0.3
gnn_emb_dim = 300
gnn_num_layer = 5
gnn_residual = False
gnn_type = gin
gnn_virtual_node = False
graph_pooling = cls
input_model_file = models_graphtrans/graphtrans-sr-gcl.pth
lr = 0.0001
lr_scale = 1
max_input_len = 1000
nhead = 4
num_encoder_layers = 4
num_encoder_layers_masked = 0
num_workers = 0
pos_encoder = False
runseed = 7
seed = 12344
split = scaffold
transformer_activation = relu
transformer_dropout = 0.3
transformer_norm_input = True
transformer_prenorm = False
=========================================
sider
scaffold
Loaded GraphTrans from models_graphtrans/graphtrans-sr-gcl.pth
====epoch 1
Train Loss 24.610309492754197
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.5127 test: 0.5139 | best val epoch -- val: 0.5127 test: 0.5139

====epoch 2
Train Loss 21.129889955286373
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.4879 test: 0.5199 | best val epoch -- val: 0.5127 test: 0.5139

====epoch 3
Train Loss 19.738620614044695
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.4873 test: 0.5178 | best val epoch -- val: 0.5127 test: 0.5139

====epoch 4
Train Loss 19.405997557362607
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.4891 test: 0.5217 | best val epoch -- val: 0.5127 test: 0.5139

====epoch 5
Train Loss 19.204816252816304
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.4850 test: 0.5129 | best val epoch -- val: 0.5127 test: 0.5139

====epoch 6
Train Loss 19.180547220928148
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.4879 test: 0.5163 | best val epoch -- val: 0.5127 test: 0.5139

====epoch 7
Train Loss 19.125392347715696
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.4909 test: 0.5179 | best val epoch -- val: 0.5127 test: 0.5139

====epoch 8
Train Loss 19.12814964594539
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.4913 test: 0.5244 | best val epoch -- val: 0.5127 test: 0.5139

====epoch 9
Train Loss 19.070783647964678
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.5064 test: 0.5252 | best val epoch -- val: 0.5127 test: 0.5139

====epoch 10
Train Loss 19.06423170311531
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.5120 test: 0.5301 | best val epoch -- val: 0.5127 test: 0.5139

====epoch 11
Train Loss 19.01175557558643
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.5131 test: 0.5366 | best val epoch -- val: 0.5131 test: 0.5366

====epoch 12
Train Loss 18.898973833686274
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.5114 test: 0.5502 | best val epoch -- val: 0.5131 test: 0.5366

====epoch 13
Train Loss 18.788287760073977
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.5133 test: 0.5548 | best val epoch -- val: 0.5133 test: 0.5548

====epoch 14
Train Loss 18.725047146338426
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.5243 test: 0.5517 | best val epoch -- val: 0.5243 test: 0.5517

====epoch 15
Train Loss 18.460482179039712
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.5062 test: 0.5672 | best val epoch -- val: 0.5243 test: 0.5517

====epoch 16
Train Loss 18.39555045523093
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.5035 test: 0.5735 | best val epoch -- val: 0.5243 test: 0.5517

====epoch 17
Train Loss 18.188422597838777
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.5179 test: 0.5665 | best val epoch -- val: 0.5243 test: 0.5517

====epoch 18
Train Loss 18.20026302145638
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.5244 test: 0.5860 | best val epoch -- val: 0.5244 test: 0.5860

====epoch 19
Train Loss 18.036108752348042
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.5390 test: 0.5608 | best val epoch -- val: 0.5390 test: 0.5608

====epoch 20
Train Loss 17.960182196561043
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.5552 test: 0.5862 | best val epoch -- val: 0.5552 test: 0.5862

====epoch 21
Train Loss 17.869913512511847
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.5566 test: 0.5898 | best val epoch -- val: 0.5566 test: 0.5898

====epoch 22
Train Loss 17.773658791505472
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.5646 test: 0.5933 | best val epoch -- val: 0.5646 test: 0.5933

====epoch 23
Train Loss 17.70826518180398
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.5607 test: 0.5885 | best val epoch -- val: 0.5646 test: 0.5933

====epoch 24
Train Loss 17.67451794614876
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.5709 test: 0.5789 | best val epoch -- val: 0.5709 test: 0.5789

====epoch 25
Train Loss 17.576225155481616
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.5673 test: 0.6036 | best val epoch -- val: 0.5709 test: 0.5789

====epoch 26
Train Loss 17.42278350101682
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.5780 test: 0.5980 | best val epoch -- val: 0.5780 test: 0.5980

====epoch 27
Train Loss 17.530265272585165
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.5826 test: 0.5923 | best val epoch -- val: 0.5826 test: 0.5923

====epoch 28
Train Loss 17.381151663426447
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.5887 test: 0.5776 | best val epoch -- val: 0.5887 test: 0.5776

====epoch 29
Train Loss 17.3254636205944
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6017 test: 0.6000 | best val epoch -- val: 0.6017 test: 0.6000

====epoch 30
Train Loss 17.129138006666604
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.5976 test: 0.5989 | best val epoch -- val: 0.6017 test: 0.6000

====epoch 31
Train Loss 17.15797481295952
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6129 test: 0.6041 | best val epoch -- val: 0.6129 test: 0.6041

====epoch 32
Train Loss 17.03872415670353
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6176 test: 0.6068 | best val epoch -- val: 0.6176 test: 0.6068

====epoch 33
Train Loss 16.952895909965267
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6215 test: 0.6057 | best val epoch -- val: 0.6215 test: 0.6057

====epoch 34
Train Loss 17.007134817116523
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6177 test: 0.6009 | best val epoch -- val: 0.6215 test: 0.6057

====epoch 35
Train Loss 17.014775414901425
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6127 test: 0.5917 | best val epoch -- val: 0.6215 test: 0.6057

====epoch 36
Train Loss 16.718377075380417
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6123 test: 0.5992 | best val epoch -- val: 0.6215 test: 0.6057

====epoch 37
Train Loss 16.78155796351245
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6181 test: 0.5965 | best val epoch -- val: 0.6215 test: 0.6057

====epoch 38
Train Loss 16.58563603965399
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6191 test: 0.5943 | best val epoch -- val: 0.6215 test: 0.6057

====epoch 39
Train Loss 16.68421608215541
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6154 test: 0.6008 | best val epoch -- val: 0.6215 test: 0.6057

====epoch 40
Train Loss 16.535622239908705
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6188 test: 0.6052 | best val epoch -- val: 0.6215 test: 0.6057

====epoch 41
Train Loss 16.452639340949197
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6229 test: 0.5983 | best val epoch -- val: 0.6229 test: 0.5983

====epoch 42
Train Loss 16.555022443269856
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6256 test: 0.5909 | best val epoch -- val: 0.6256 test: 0.5909

====epoch 43
Train Loss 16.49744335407269
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6131 test: 0.6089 | best val epoch -- val: 0.6256 test: 0.5909

====epoch 44
Train Loss 16.41621376823925
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6203 test: 0.6130 | best val epoch -- val: 0.6256 test: 0.5909

====epoch 45
Train Loss 16.229827571590967
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6228 test: 0.6018 | best val epoch -- val: 0.6256 test: 0.5909

====epoch 46
Train Loss 16.20430938298598
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6144 test: 0.5925 | best val epoch -- val: 0.6256 test: 0.5909

====epoch 47
Train Loss 16.272833545547343
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6175 test: 0.6041 | best val epoch -- val: 0.6256 test: 0.5909

====epoch 48
Train Loss 16.126425447517907
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6173 test: 0.5990 | best val epoch -- val: 0.6256 test: 0.5909

====epoch 49
Train Loss 16.11576113964359
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6137 test: 0.6024 | best val epoch -- val: 0.6256 test: 0.5909

====epoch 50
Train Loss 15.978194580669282
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6130 test: 0.6031 | best val epoch -- val: 0.6256 test: 0.5909

====epoch 51
Train Loss 16.20499117757323
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6289 test: 0.6138 | best val epoch -- val: 0.6289 test: 0.6138

====epoch 52
Train Loss 15.912995844521578
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6226 test: 0.6033 | best val epoch -- val: 0.6289 test: 0.6138

====epoch 53
Train Loss 15.88152804239522
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6183 test: 0.5982 | best val epoch -- val: 0.6289 test: 0.6138

====epoch 54
Train Loss 15.829313563335193
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6301 test: 0.6136 | best val epoch -- val: 0.6301 test: 0.6136

====epoch 55
Train Loss 15.747113706617338
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6273 test: 0.6102 | best val epoch -- val: 0.6301 test: 0.6136

====epoch 56
Train Loss 15.726158374772666
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6281 test: 0.6200 | best val epoch -- val: 0.6301 test: 0.6136

====epoch 57
Train Loss 15.865493576012685
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6223 test: 0.6195 | best val epoch -- val: 0.6301 test: 0.6136

====epoch 58
Train Loss 15.559256167490439
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6238 test: 0.6137 | best val epoch -- val: 0.6301 test: 0.6136

====epoch 59
Train Loss 15.638515434286903
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6240 test: 0.6135 | best val epoch -- val: 0.6301 test: 0.6136

====epoch 60
Train Loss 15.759300000305783
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6253 test: 0.6181 | best val epoch -- val: 0.6301 test: 0.6136

====epoch 61
Train Loss 15.43870474211112
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6288 test: 0.6105 | best val epoch -- val: 0.6301 test: 0.6136

====epoch 62
Train Loss 15.522376226470692
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6298 test: 0.6089 | best val epoch -- val: 0.6301 test: 0.6136

====epoch 63
Train Loss 15.329459088149878
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6269 test: 0.6094 | best val epoch -- val: 0.6301 test: 0.6136

====epoch 64
Train Loss 15.337205392398985
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6275 test: 0.6186 | best val epoch -- val: 0.6301 test: 0.6136

====epoch 65
Train Loss 15.359184979014131
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6168 test: 0.6108 | best val epoch -- val: 0.6301 test: 0.6136

====epoch 66
Train Loss 15.196661972775543
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6248 test: 0.6191 | best val epoch -- val: 0.6301 test: 0.6136

====epoch 67
Train Loss 15.231254565672193
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6209 test: 0.6136 | best val epoch -- val: 0.6301 test: 0.6136

====epoch 68
Train Loss 15.211355289508955
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6253 test: 0.6158 | best val epoch -- val: 0.6301 test: 0.6136

====epoch 69
Train Loss 15.063602968562233
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6234 test: 0.6187 | best val epoch -- val: 0.6301 test: 0.6136

====epoch 70
Train Loss 15.048188403176145
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6258 test: 0.6243 | best val epoch -- val: 0.6301 test: 0.6136

====epoch 71
Train Loss 15.004254903405469
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6196 test: 0.6015 | best val epoch -- val: 0.6301 test: 0.6136

====epoch 72
Train Loss 15.058829788957288
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6164 test: 0.6228 | best val epoch -- val: 0.6301 test: 0.6136

====epoch 73
Train Loss 15.147398899466818
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6278 test: 0.6098 | best val epoch -- val: 0.6301 test: 0.6136

====epoch 74
Train Loss 14.811405092239582
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6277 test: 0.6193 | best val epoch -- val: 0.6301 test: 0.6136

====epoch 75
Train Loss 15.086633941353917
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6214 test: 0.6157 | best val epoch -- val: 0.6301 test: 0.6136

====epoch 76
Train Loss 15.06002988252638
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6265 test: 0.6131 | best val epoch -- val: 0.6301 test: 0.6136

====epoch 77
Train Loss 14.656608185738618
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6319 test: 0.6157 | best val epoch -- val: 0.6319 test: 0.6157

====epoch 78
Train Loss 14.766920089171816
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6231 test: 0.6102 | best val epoch -- val: 0.6319 test: 0.6157

====epoch 79
Train Loss 14.692397492016243
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6259 test: 0.6087 | best val epoch -- val: 0.6319 test: 0.6157

====epoch 80
Train Loss 14.811397449345987
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6194 test: 0.6082 | best val epoch -- val: 0.6319 test: 0.6157

====epoch 81
Train Loss 14.784656890920592
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6245 test: 0.6118 | best val epoch -- val: 0.6319 test: 0.6157

====epoch 82
Train Loss 14.701622819302651
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6230 test: 0.6141 | best val epoch -- val: 0.6319 test: 0.6157

====epoch 83
Train Loss 14.582493429236221
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6263 test: 0.6052 | best val epoch -- val: 0.6319 test: 0.6157

====epoch 84
Train Loss 14.524628328144626
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6213 test: 0.6157 | best val epoch -- val: 0.6319 test: 0.6157

====epoch 85
Train Loss 14.52166701761998
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6205 test: 0.6141 | best val epoch -- val: 0.6319 test: 0.6157

====epoch 86
Train Loss 14.543249832986236
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6171 test: 0.6101 | best val epoch -- val: 0.6319 test: 0.6157

====epoch 87
Train Loss 14.546229006617153
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6212 test: 0.6115 | best val epoch -- val: 0.6319 test: 0.6157

====epoch 88
Train Loss 14.337837413759416
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6251 test: 0.6146 | best val epoch -- val: 0.6319 test: 0.6157

====epoch 89
Train Loss 14.59435660098442
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6146 test: 0.6067 | best val epoch -- val: 0.6319 test: 0.6157

====epoch 90
Train Loss 14.356923129905299
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6146 test: 0.6046 | best val epoch -- val: 0.6319 test: 0.6157

====epoch 91
Train Loss 14.326664891816014
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6091 test: 0.6157 | best val epoch -- val: 0.6319 test: 0.6157

====epoch 92
Train Loss 14.278954962170612
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6163 test: 0.6098 | best val epoch -- val: 0.6319 test: 0.6157

====epoch 93
Train Loss 14.417301553395586
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6169 test: 0.6068 | best val epoch -- val: 0.6319 test: 0.6157

====epoch 94
Train Loss 14.228533215101148
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6147 test: 0.5980 | best val epoch -- val: 0.6319 test: 0.6157

====epoch 95
Train Loss 14.248890273023118
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6145 test: 0.5987 | best val epoch -- val: 0.6319 test: 0.6157

====epoch 96
Train Loss 14.244769438683223
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6195 test: 0.6101 | best val epoch -- val: 0.6319 test: 0.6157

====epoch 97
Train Loss 14.1351149430756
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6236 test: 0.5995 | best val epoch -- val: 0.6319 test: 0.6157

====epoch 98
Train Loss 14.175374286555812
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6221 test: 0.6103 | best val epoch -- val: 0.6319 test: 0.6157

====epoch 99
Train Loss 14.072562544283569
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6213 test: 0.6111 | best val epoch -- val: 0.6319 test: 0.6157

====epoch 100
Train Loss 14.021741829439941
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6252 test: 0.6069 | best val epoch -- val: 0.6319 test: 0.6157

[08:51:26] WARNING: not removing hydrogen atom without neighbors
[08:51:26] WARNING: not removing hydrogen atom without neighbors
[08:51:27] WARNING: not removing hydrogen atom without neighbors
[08:51:27] WARNING: not removing hydrogen atom without neighbors
[08:51:27] WARNING: not removing hydrogen atom without neighbors
[08:51:27] WARNING: not removing hydrogen atom without neighbors
[08:51:27] WARNING: not removing hydrogen atom without neighbors
[08:51:27] WARNING: not removing hydrogen atom without neighbors
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.4.
[08:51:28] WARNING: not removing hydrogen atom without neighbors
[08:51:28] WARNING: not removing hydrogen atom without neighbors
[08:51:28] WARNING: not removing hydrogen atom without neighbors
[08:51:28] WARNING: not removing hydrogen atom without neighbors
[08:51:28] WARNING: not removing hydrogen atom without neighbors
2022-09-13 08:51:29.143 | INFO     | modules.masked_transformer_encoder:__init__:122 - number of parameters: 0.000000e+00
=========================================
batch_size = 32
d_model = 128
dataset = sider
decay = 0
device = 0
dim_feedforward = 512
eval_train = 0
filename =
gnn_JK = cat
gnn_dropout = 0.3
gnn_emb_dim = 300
gnn_num_layer = 5
gnn_residual = False
gnn_type = gin
gnn_virtual_node = False
graph_pooling = cls
input_model_file = models_graphtrans/graphtrans-sr-gcl.pth
lr = 0.0001
lr_scale = 1
max_input_len = 1000
nhead = 4
num_encoder_layers = 4
num_encoder_layers_masked = 0
num_workers = 0
pos_encoder = False
runseed = 8
seed = 12344
split = scaffold
transformer_activation = relu
transformer_dropout = 0.3
transformer_norm_input = True
transformer_prenorm = False
=========================================
sider
scaffold
Loaded GraphTrans from models_graphtrans/graphtrans-sr-gcl.pth
====epoch 1
Train Loss 24.633514667773085
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.5139 test: 0.4830 | best val epoch -- val: 0.5139 test: 0.4830

====epoch 2
Train Loss 21.083863427689728
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.5107 test: 0.4960 | best val epoch -- val: 0.5139 test: 0.4830

====epoch 3
Train Loss 19.714640958177355
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.5142 test: 0.5192 | best val epoch -- val: 0.5142 test: 0.5192

====epoch 4
Train Loss 19.35975723468543
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.5172 test: 0.5254 | best val epoch -- val: 0.5172 test: 0.5254

====epoch 5
Train Loss 19.211663727115827
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.5206 test: 0.5192 | best val epoch -- val: 0.5206 test: 0.5192

====epoch 6
Train Loss 19.136929456921273
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.5254 test: 0.5321 | best val epoch -- val: 0.5254 test: 0.5321

====epoch 7
Train Loss 19.09316515500861
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.5333 test: 0.5335 | best val epoch -- val: 0.5333 test: 0.5335

====epoch 8
Train Loss 19.05761235430902
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.5288 test: 0.5330 | best val epoch -- val: 0.5333 test: 0.5335

====epoch 9
Train Loss 19.023918994064115
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.5375 test: 0.5360 | best val epoch -- val: 0.5375 test: 0.5360

====epoch 10
Train Loss 19.013864716901097
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.5319 test: 0.5325 | best val epoch -- val: 0.5375 test: 0.5360

====epoch 11
Train Loss 18.958302393223818
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.5338 test: 0.5341 | best val epoch -- val: 0.5375 test: 0.5360

====epoch 12
Train Loss 18.91875152362766
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.5328 test: 0.5394 | best val epoch -- val: 0.5375 test: 0.5360

====epoch 13
Train Loss 18.803723440372107
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.5416 test: 0.5490 | best val epoch -- val: 0.5416 test: 0.5490

====epoch 14
Train Loss 18.684631574748394
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.5472 test: 0.5593 | best val epoch -- val: 0.5472 test: 0.5593

====epoch 15
Train Loss 18.617835341914184
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.5462 test: 0.5697 | best val epoch -- val: 0.5472 test: 0.5593

====epoch 16
Train Loss 18.45730357725903
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.5580 test: 0.5768 | best val epoch -- val: 0.5580 test: 0.5768

====epoch 17
Train Loss 18.298773368701447
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.5619 test: 0.5896 | best val epoch -- val: 0.5619 test: 0.5896

====epoch 18
Train Loss 18.11237148455252
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.5761 test: 0.5865 | best val epoch -- val: 0.5761 test: 0.5865

====epoch 19
Train Loss 17.92768762780897
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.5639 test: 0.5921 | best val epoch -- val: 0.5761 test: 0.5865

====epoch 20
Train Loss 17.886669804030184
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.5667 test: 0.5959 | best val epoch -- val: 0.5761 test: 0.5865

====epoch 21
Train Loss 17.851486578555203
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.5805 test: 0.5998 | best val epoch -- val: 0.5805 test: 0.5998

====epoch 22
Train Loss 17.621484669007398
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.5891 test: 0.5933 | best val epoch -- val: 0.5891 test: 0.5933

====epoch 23
Train Loss 17.689526786008482
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.5847 test: 0.5859 | best val epoch -- val: 0.5891 test: 0.5933

====epoch 24
Train Loss 17.720292292487176
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.5834 test: 0.5904 | best val epoch -- val: 0.5891 test: 0.5933

====epoch 25
Train Loss 17.39729203741779
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.5818 test: 0.5891 | best val epoch -- val: 0.5891 test: 0.5933

====epoch 26
Train Loss 17.460716664569546
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.5823 test: 0.5924 | best val epoch -- val: 0.5891 test: 0.5933

====epoch 27
Train Loss 17.23867065041096
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.5779 test: 0.6016 | best val epoch -- val: 0.5891 test: 0.5933

====epoch 28
Train Loss 17.336276528038898
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.5841 test: 0.6085 | best val epoch -- val: 0.5891 test: 0.5933

====epoch 29
Train Loss 17.073457922888696
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.5903 test: 0.6035 | best val epoch -- val: 0.5903 test: 0.6035

====epoch 30
Train Loss 16.966189968015552
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.5989 test: 0.6006 | best val epoch -- val: 0.5989 test: 0.6006

====epoch 31
Train Loss 16.95957996433253
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6151 test: 0.6063 | best val epoch -- val: 0.6151 test: 0.6063

====epoch 32
Train Loss 16.87950715412281
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.5973 test: 0.6039 | best val epoch -- val: 0.6151 test: 0.6063

====epoch 33
Train Loss 16.958955942801143
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6019 test: 0.6003 | best val epoch -- val: 0.6151 test: 0.6063

====epoch 34
Train Loss 16.82253617091405
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.5887 test: 0.6066 | best val epoch -- val: 0.6151 test: 0.6063

====epoch 35
Train Loss 16.841268518999474
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6036 test: 0.6033 | best val epoch -- val: 0.6151 test: 0.6063

====epoch 36
Train Loss 16.746618972459828
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6113 test: 0.6164 | best val epoch -- val: 0.6151 test: 0.6063

====epoch 37
Train Loss 16.60887529335206
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6066 test: 0.6135 | best val epoch -- val: 0.6151 test: 0.6063

====epoch 38
Train Loss 16.60795125360165
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6131 test: 0.6135 | best val epoch -- val: 0.6151 test: 0.6063

====epoch 39
Train Loss 16.297097433669283
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6093 test: 0.6148 | best val epoch -- val: 0.6151 test: 0.6063

====epoch 40
Train Loss 16.512828500812766
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6125 test: 0.6080 | best val epoch -- val: 0.6151 test: 0.6063

====epoch 41
Train Loss 16.5250769682266
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6184 test: 0.6095 | best val epoch -- val: 0.6184 test: 0.6095

====epoch 42
Train Loss 16.271579874537792
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6204 test: 0.6028 | best val epoch -- val: 0.6204 test: 0.6028

====epoch 43
Train Loss 16.302022714503124
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6262 test: 0.6095 | best val epoch -- val: 0.6262 test: 0.6095

====epoch 44
Train Loss 16.039092531383226
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6226 test: 0.6075 | best val epoch -- val: 0.6262 test: 0.6095

====epoch 45
Train Loss 16.077654258419244
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6182 test: 0.6124 | best val epoch -- val: 0.6262 test: 0.6095

====epoch 46
Train Loss 16.192632941701792
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6320 test: 0.6229 | best val epoch -- val: 0.6320 test: 0.6229

====epoch 47
Train Loss 16.11234219815578
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6294 test: 0.6237 | best val epoch -- val: 0.6320 test: 0.6229

====epoch 48
Train Loss 15.859506383713043
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6346 test: 0.6167 | best val epoch -- val: 0.6346 test: 0.6167

====epoch 49
Train Loss 15.994362110212176
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6452 test: 0.6126 | best val epoch -- val: 0.6452 test: 0.6126

====epoch 50
Train Loss 15.944371632933443
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6310 test: 0.6255 | best val epoch -- val: 0.6452 test: 0.6126

====epoch 51
Train Loss 15.901448715652897
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6410 test: 0.6183 | best val epoch -- val: 0.6452 test: 0.6126

====epoch 52
Train Loss 15.822584164285058
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6428 test: 0.6231 | best val epoch -- val: 0.6452 test: 0.6126

====epoch 53
Train Loss 15.757400994640275
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6327 test: 0.6156 | best val epoch -- val: 0.6452 test: 0.6126

====epoch 54
Train Loss 15.61745970306791
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6386 test: 0.6157 | best val epoch -- val: 0.6452 test: 0.6126

====epoch 55
Train Loss 15.67961767957101
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6360 test: 0.6192 | best val epoch -- val: 0.6452 test: 0.6126

====epoch 56
Train Loss 15.649397652289247
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6473 test: 0.6214 | best val epoch -- val: 0.6473 test: 0.6214

====epoch 57
Train Loss 15.472733660588085
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6457 test: 0.6163 | best val epoch -- val: 0.6473 test: 0.6214

====epoch 58
Train Loss 15.472127737110503
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6475 test: 0.6079 | best val epoch -- val: 0.6475 test: 0.6079

====epoch 59
Train Loss 15.422543965100187
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6371 test: 0.6166 | best val epoch -- val: 0.6475 test: 0.6079

====epoch 60
Train Loss 15.3577314402734
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6363 test: 0.6190 | best val epoch -- val: 0.6475 test: 0.6079

====epoch 61
Train Loss 15.352413658452518
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6425 test: 0.6164 | best val epoch -- val: 0.6475 test: 0.6079

====epoch 62
Train Loss 15.410760411003517
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6383 test: 0.6192 | best val epoch -- val: 0.6475 test: 0.6079

====epoch 63
Train Loss 15.173935896547478
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6334 test: 0.6101 | best val epoch -- val: 0.6475 test: 0.6079

====epoch 64
Train Loss 15.353681266407397
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6393 test: 0.6233 | best val epoch -- val: 0.6475 test: 0.6079

====epoch 65
Train Loss 15.28892473540047
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6530 test: 0.6280 | best val epoch -- val: 0.6530 test: 0.6280

====epoch 66
Train Loss 15.075972231128961
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6438 test: 0.6231 | best val epoch -- val: 0.6530 test: 0.6280

====epoch 67
Train Loss 15.08919647339325
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6489 test: 0.6311 | best val epoch -- val: 0.6530 test: 0.6280

====epoch 68
Train Loss 15.117088512509655
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6517 test: 0.6207 | best val epoch -- val: 0.6530 test: 0.6280

====epoch 69
Train Loss 15.072672384667722
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6508 test: 0.6214 | best val epoch -- val: 0.6530 test: 0.6280

====epoch 70
Train Loss 14.934602054505282
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6481 test: 0.6203 | best val epoch -- val: 0.6530 test: 0.6280

====epoch 71
Train Loss 14.837039609825096
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6507 test: 0.6257 | best val epoch -- val: 0.6530 test: 0.6280

====epoch 72
Train Loss 14.80279774936136
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6486 test: 0.6278 | best val epoch -- val: 0.6530 test: 0.6280

====epoch 73
Train Loss 14.870198276286153
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6525 test: 0.6209 | best val epoch -- val: 0.6530 test: 0.6280

====epoch 74
Train Loss 14.566816599751535
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6517 test: 0.6193 | best val epoch -- val: 0.6530 test: 0.6280

====epoch 75
Train Loss 14.854488711243707
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6487 test: 0.6109 | best val epoch -- val: 0.6530 test: 0.6280

====epoch 76
Train Loss 14.760821318411995
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6465 test: 0.6095 | best val epoch -- val: 0.6530 test: 0.6280

====epoch 77
Train Loss 14.729429507993247
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6443 test: 0.6134 | best val epoch -- val: 0.6530 test: 0.6280

====epoch 78
Train Loss 14.705596794531965
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6383 test: 0.6121 | best val epoch -- val: 0.6530 test: 0.6280

====epoch 79
Train Loss 14.734906537529412
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6503 test: 0.6283 | best val epoch -- val: 0.6530 test: 0.6280

====epoch 80
Train Loss 14.617846449395392
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6382 test: 0.6214 | best val epoch -- val: 0.6530 test: 0.6280

====epoch 81
Train Loss 14.458932608723277
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6428 test: 0.6120 | best val epoch -- val: 0.6530 test: 0.6280

====epoch 82
Train Loss 14.554260079404314
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6360 test: 0.6189 | best val epoch -- val: 0.6530 test: 0.6280

====epoch 83
Train Loss 14.372609158690791
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6462 test: 0.5997 | best val epoch -- val: 0.6530 test: 0.6280

====epoch 84
Train Loss 14.325803538657507
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6452 test: 0.5956 | best val epoch -- val: 0.6530 test: 0.6280

====epoch 85
Train Loss 14.476103584979914
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6412 test: 0.6088 | best val epoch -- val: 0.6530 test: 0.6280

====epoch 86
Train Loss 14.539191374439628
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6487 test: 0.6063 | best val epoch -- val: 0.6530 test: 0.6280

====epoch 87
Train Loss 14.469847607923207
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6389 test: 0.6185 | best val epoch -- val: 0.6530 test: 0.6280

====epoch 88
Train Loss 14.400139964366032
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6349 test: 0.6055 | best val epoch -- val: 0.6530 test: 0.6280

====epoch 89
Train Loss 14.242129253518002
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6458 test: 0.6068 | best val epoch -- val: 0.6530 test: 0.6280

====epoch 90
Train Loss 14.485961399855864
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6447 test: 0.5980 | best val epoch -- val: 0.6530 test: 0.6280

====epoch 91
Train Loss 14.263928236987912
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6396 test: 0.6018 | best val epoch -- val: 0.6530 test: 0.6280

====epoch 92
Train Loss 14.271887944052853
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6350 test: 0.6169 | best val epoch -- val: 0.6530 test: 0.6280

====epoch 93
Train Loss 14.09029058196328
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6524 test: 0.6065 | best val epoch -- val: 0.6530 test: 0.6280

====epoch 94
Train Loss 14.086429267472935
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6437 test: 0.6087 | best val epoch -- val: 0.6530 test: 0.6280

====epoch 95
Train Loss 14.02053838320895
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6387 test: 0.6097 | best val epoch -- val: 0.6530 test: 0.6280

====epoch 96
Train Loss 14.135880977412034
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6390 test: 0.6088 | best val epoch -- val: 0.6530 test: 0.6280

====epoch 97
Train Loss 14.015975521213878
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6363 test: 0.6114 | best val epoch -- val: 0.6530 test: 0.6280

====epoch 98
Train Loss 13.98193148792903
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6385 test: 0.6055 | best val epoch -- val: 0.6530 test: 0.6280

====epoch 99
Train Loss 13.910463901452653
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6343 test: 0.6099 | best val epoch -- val: 0.6530 test: 0.6280

====epoch 100
Train Loss 14.026524073903218
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6304 test: 0.5977 | best val epoch -- val: 0.6530 test: 0.6280

[08:55:01] WARNING: not removing hydrogen atom without neighbors
[08:55:01] WARNING: not removing hydrogen atom without neighbors
[08:55:01] WARNING: not removing hydrogen atom without neighbors
[08:55:01] WARNING: not removing hydrogen atom without neighbors
[08:55:01] WARNING: not removing hydrogen atom without neighbors
[08:55:01] WARNING: not removing hydrogen atom without neighbors
[08:55:02] WARNING: not removing hydrogen atom without neighbors
[08:55:02] WARNING: not removing hydrogen atom without neighbors
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.4.
[08:55:02] WARNING: not removing hydrogen atom without neighbors
[08:55:02] WARNING: not removing hydrogen atom without neighbors
[08:55:02] WARNING: not removing hydrogen atom without neighbors
[08:55:03] WARNING: not removing hydrogen atom without neighbors
[08:55:03] WARNING: not removing hydrogen atom without neighbors
2022-09-13 08:55:04.091 | INFO     | modules.masked_transformer_encoder:__init__:122 - number of parameters: 0.000000e+00
=========================================
batch_size = 32
d_model = 128
dataset = sider
decay = 0
device = 0
dim_feedforward = 512
eval_train = 0
filename =
gnn_JK = cat
gnn_dropout = 0.3
gnn_emb_dim = 300
gnn_num_layer = 5
gnn_residual = False
gnn_type = gin
gnn_virtual_node = False
graph_pooling = cls
input_model_file = models_graphtrans/graphtrans-sr-gcl.pth
lr = 0.0001
lr_scale = 1
max_input_len = 1000
nhead = 4
num_encoder_layers = 4
num_encoder_layers_masked = 0
num_workers = 0
pos_encoder = False
runseed = 9
seed = 12344
split = scaffold
transformer_activation = relu
transformer_dropout = 0.3
transformer_norm_input = True
transformer_prenorm = False
=========================================
sider
scaffold
Loaded GraphTrans from models_graphtrans/graphtrans-sr-gcl.pth
====epoch 1
Train Loss 23.520250991597223
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.4949 test: 0.5024 | best val epoch -- val: 0.4949 test: 0.5024

====epoch 2
Train Loss 20.55545881145231
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.5351 test: 0.5040 | best val epoch -- val: 0.5351 test: 0.5040

====epoch 3
Train Loss 19.489444143318043
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.5344 test: 0.5065 | best val epoch -- val: 0.5351 test: 0.5040

====epoch 4
Train Loss 19.303227105517195
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.5336 test: 0.5165 | best val epoch -- val: 0.5351 test: 0.5040

====epoch 5
Train Loss 19.20438316711235
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.5335 test: 0.5184 | best val epoch -- val: 0.5351 test: 0.5040

====epoch 6
Train Loss 19.123558486530662
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.5289 test: 0.5200 | best val epoch -- val: 0.5351 test: 0.5040

====epoch 7
Train Loss 19.1808698601277
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.5309 test: 0.5226 | best val epoch -- val: 0.5351 test: 0.5040

====epoch 8
Train Loss 19.047335939320106
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.5335 test: 0.5294 | best val epoch -- val: 0.5351 test: 0.5040

====epoch 9
Train Loss 19.065054242192744
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.5301 test: 0.5333 | best val epoch -- val: 0.5351 test: 0.5040

====epoch 10
Train Loss 19.038434566641783
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.5362 test: 0.5425 | best val epoch -- val: 0.5362 test: 0.5425

====epoch 11
Train Loss 18.93766680391021
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.5369 test: 0.5483 | best val epoch -- val: 0.5369 test: 0.5483

====epoch 12
Train Loss 18.804150112327903
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.5458 test: 0.5544 | best val epoch -- val: 0.5458 test: 0.5544

====epoch 13
Train Loss 18.613948435809295
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.5641 test: 0.5685 | best val epoch -- val: 0.5641 test: 0.5685

====epoch 14
Train Loss 18.54115604822716
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.5637 test: 0.5588 | best val epoch -- val: 0.5641 test: 0.5685

====epoch 15
Train Loss 18.427311438540205
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.5639 test: 0.5647 | best val epoch -- val: 0.5641 test: 0.5685

====epoch 16
Train Loss 18.260396686598945
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.5628 test: 0.5711 | best val epoch -- val: 0.5641 test: 0.5685

====epoch 17
Train Loss 18.251573878169285
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.5760 test: 0.5826 | best val epoch -- val: 0.5760 test: 0.5826

====epoch 18
Train Loss 18.11209943738801
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.5903 test: 0.5886 | best val epoch -- val: 0.5903 test: 0.5886

====epoch 19
Train Loss 17.87420102996318
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.5985 test: 0.5919 | best val epoch -- val: 0.5985 test: 0.5919

====epoch 20
Train Loss 17.778108203824722
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6016 test: 0.5955 | best val epoch -- val: 0.6016 test: 0.5955

====epoch 21
Train Loss 17.763334972225906
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.5976 test: 0.6050 | best val epoch -- val: 0.6016 test: 0.5955

====epoch 22
Train Loss 17.655784735582326
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.5923 test: 0.6030 | best val epoch -- val: 0.6016 test: 0.5955

====epoch 23
Train Loss 17.522989449589453
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6065 test: 0.6104 | best val epoch -- val: 0.6065 test: 0.6104

====epoch 24
Train Loss 17.47221573061455
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.5988 test: 0.6107 | best val epoch -- val: 0.6065 test: 0.6104

====epoch 25
Train Loss 17.561170878736345
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6127 test: 0.6052 | best val epoch -- val: 0.6127 test: 0.6052

====epoch 26
Train Loss 17.320683964339
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6140 test: 0.6066 | best val epoch -- val: 0.6140 test: 0.6066

====epoch 27
Train Loss 17.14985903152079
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6167 test: 0.6070 | best val epoch -- val: 0.6167 test: 0.6070

====epoch 28
Train Loss 17.13112173224597
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6200 test: 0.6086 | best val epoch -- val: 0.6200 test: 0.6086

====epoch 29
Train Loss 17.07415643945169
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6156 test: 0.6018 | best val epoch -- val: 0.6200 test: 0.6086

====epoch 30
Train Loss 16.99440383115267
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6282 test: 0.5966 | best val epoch -- val: 0.6282 test: 0.5966

====epoch 31
Train Loss 17.12015842183662
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6145 test: 0.5927 | best val epoch -- val: 0.6282 test: 0.5966

====epoch 32
Train Loss 16.93244557173227
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6148 test: 0.5987 | best val epoch -- val: 0.6282 test: 0.5966

====epoch 33
Train Loss 16.92911446015527
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6172 test: 0.6019 | best val epoch -- val: 0.6282 test: 0.5966

====epoch 34
Train Loss 16.80686401482507
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6191 test: 0.5975 | best val epoch -- val: 0.6282 test: 0.5966

====epoch 35
Train Loss 16.655775616047837
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6198 test: 0.5953 | best val epoch -- val: 0.6282 test: 0.5966

====epoch 36
Train Loss 16.603995725837244
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6305 test: 0.5965 | best val epoch -- val: 0.6305 test: 0.5965

====epoch 37
Train Loss 16.571494148684017
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6312 test: 0.5977 | best val epoch -- val: 0.6312 test: 0.5977

====epoch 38
Train Loss 16.516285630814636
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6371 test: 0.5880 | best val epoch -- val: 0.6371 test: 0.5880

====epoch 39
Train Loss 16.58651122171509
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6341 test: 0.5981 | best val epoch -- val: 0.6371 test: 0.5880

====epoch 40
Train Loss 16.4088377022474
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6361 test: 0.5887 | best val epoch -- val: 0.6371 test: 0.5880

====epoch 41
Train Loss 16.421217303585273
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6334 test: 0.6008 | best val epoch -- val: 0.6371 test: 0.5880

====epoch 42
Train Loss 16.32003151707435
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6503 test: 0.5909 | best val epoch -- val: 0.6503 test: 0.5909

====epoch 43
Train Loss 16.230604139005717
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6398 test: 0.6028 | best val epoch -- val: 0.6503 test: 0.5909

====epoch 44
Train Loss 16.20695675151062
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6420 test: 0.5931 | best val epoch -- val: 0.6503 test: 0.5909

====epoch 45
Train Loss 16.058377097921273
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6476 test: 0.6066 | best val epoch -- val: 0.6503 test: 0.5909

====epoch 46
Train Loss 16.160806287922124
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6404 test: 0.6047 | best val epoch -- val: 0.6503 test: 0.5909

====epoch 47
Train Loss 16.019207193204757
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6426 test: 0.6129 | best val epoch -- val: 0.6503 test: 0.5909

====epoch 48
Train Loss 15.954876803981456
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6430 test: 0.6148 | best val epoch -- val: 0.6503 test: 0.5909

====epoch 49
Train Loss 15.908359753186838
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6404 test: 0.6137 | best val epoch -- val: 0.6503 test: 0.5909

====epoch 50
Train Loss 16.06484045228847
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6498 test: 0.6042 | best val epoch -- val: 0.6503 test: 0.5909

====epoch 51
Train Loss 15.700778288588822
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6466 test: 0.6034 | best val epoch -- val: 0.6503 test: 0.5909

====epoch 52
Train Loss 15.808423442811222
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6472 test: 0.6150 | best val epoch -- val: 0.6503 test: 0.5909

====epoch 53
Train Loss 15.655178894178825
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6482 test: 0.6099 | best val epoch -- val: 0.6503 test: 0.5909

====epoch 54
Train Loss 15.776176007105475
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6487 test: 0.6100 | best val epoch -- val: 0.6503 test: 0.5909

====epoch 55
Train Loss 15.428057184253225
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6468 test: 0.6116 | best val epoch -- val: 0.6503 test: 0.5909

====epoch 56
Train Loss 15.476394052871946
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6369 test: 0.6129 | best val epoch -- val: 0.6503 test: 0.5909

====epoch 57
Train Loss 15.555243283680008
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6475 test: 0.6192 | best val epoch -- val: 0.6503 test: 0.5909

====epoch 58
Train Loss 15.591520261989446
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6381 test: 0.6193 | best val epoch -- val: 0.6503 test: 0.5909

====epoch 59
Train Loss 15.414144739829906
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6340 test: 0.6167 | best val epoch -- val: 0.6503 test: 0.5909

====epoch 60
Train Loss 15.432142721925956
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6441 test: 0.6223 | best val epoch -- val: 0.6503 test: 0.5909

====epoch 61
Train Loss 15.290030490522685
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6415 test: 0.6160 | best val epoch -- val: 0.6503 test: 0.5909

====epoch 62
Train Loss 15.382933830609927
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6382 test: 0.6231 | best val epoch -- val: 0.6503 test: 0.5909

====epoch 63
Train Loss 15.317689681061518
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6379 test: 0.6192 | best val epoch -- val: 0.6503 test: 0.5909

====epoch 64
Train Loss 15.10325167057028
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6295 test: 0.6225 | best val epoch -- val: 0.6503 test: 0.5909

====epoch 65
Train Loss 15.264118930953892
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6284 test: 0.6172 | best val epoch -- val: 0.6503 test: 0.5909

====epoch 66
Train Loss 15.032017991807543
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6399 test: 0.6154 | best val epoch -- val: 0.6503 test: 0.5909

====epoch 67
Train Loss 15.093822051701226
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6445 test: 0.6173 | best val epoch -- val: 0.6503 test: 0.5909

====epoch 68
Train Loss 15.15326083540895
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6446 test: 0.6107 | best val epoch -- val: 0.6503 test: 0.5909

====epoch 69
Train Loss 14.911641165063779
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6473 test: 0.6248 | best val epoch -- val: 0.6503 test: 0.5909

====epoch 70
Train Loss 14.999056766554897
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6472 test: 0.6228 | best val epoch -- val: 0.6503 test: 0.5909

====epoch 71
Train Loss 15.18953479284178
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6456 test: 0.6169 | best val epoch -- val: 0.6503 test: 0.5909

====epoch 72
Train Loss 14.969734255504147
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6426 test: 0.6181 | best val epoch -- val: 0.6503 test: 0.5909

====epoch 73
Train Loss 14.868307373502159
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6413 test: 0.6250 | best val epoch -- val: 0.6503 test: 0.5909

====epoch 74
Train Loss 14.915953880670562
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6454 test: 0.6193 | best val epoch -- val: 0.6503 test: 0.5909

====epoch 75
Train Loss 14.885784410887664
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6419 test: 0.6240 | best val epoch -- val: 0.6503 test: 0.5909

====epoch 76
Train Loss 14.909481594046538
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6474 test: 0.6269 | best val epoch -- val: 0.6503 test: 0.5909

====epoch 77
Train Loss 14.849231098389795
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6425 test: 0.6108 | best val epoch -- val: 0.6503 test: 0.5909

====epoch 78
Train Loss 14.739616753502062
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6447 test: 0.6168 | best val epoch -- val: 0.6503 test: 0.5909

====epoch 79
Train Loss 14.630950126474593
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6496 test: 0.6246 | best val epoch -- val: 0.6503 test: 0.5909

====epoch 80
Train Loss 14.794819013725002
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6508 test: 0.6132 | best val epoch -- val: 0.6508 test: 0.6132

====epoch 81
Train Loss 14.657102425850598
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6518 test: 0.6265 | best val epoch -- val: 0.6518 test: 0.6265

====epoch 82
Train Loss 14.587035960178348
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6492 test: 0.6215 | best val epoch -- val: 0.6518 test: 0.6265

====epoch 83
Train Loss 14.518388536749262
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6449 test: 0.6171 | best val epoch -- val: 0.6518 test: 0.6265

====epoch 84
Train Loss 14.634912337068178
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6378 test: 0.6141 | best val epoch -- val: 0.6518 test: 0.6265

====epoch 85
Train Loss 14.39645999363404
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6447 test: 0.6124 | best val epoch -- val: 0.6518 test: 0.6265

====epoch 86
Train Loss 14.446151488818609
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6386 test: 0.6137 | best val epoch -- val: 0.6518 test: 0.6265

====epoch 87
Train Loss 14.330831280456533
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6403 test: 0.6167 | best val epoch -- val: 0.6518 test: 0.6265

====epoch 88
Train Loss 14.34529088024427
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6442 test: 0.6200 | best val epoch -- val: 0.6518 test: 0.6265

====epoch 89
Train Loss 14.330214879747151
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6443 test: 0.6131 | best val epoch -- val: 0.6518 test: 0.6265

====epoch 90
Train Loss 14.450503625445453
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6513 test: 0.6104 | best val epoch -- val: 0.6518 test: 0.6265

====epoch 91
Train Loss 14.300546786419341
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6520 test: 0.6154 | best val epoch -- val: 0.6520 test: 0.6154

====epoch 92
Train Loss 14.277993489562904
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6523 test: 0.6130 | best val epoch -- val: 0.6523 test: 0.6130

====epoch 93
Train Loss 14.310224490106286
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6546 test: 0.6056 | best val epoch -- val: 0.6546 test: 0.6056

====epoch 94
Train Loss 14.275348873127742
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6485 test: 0.6080 | best val epoch -- val: 0.6546 test: 0.6056

====epoch 95
Train Loss 14.09821531358314
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6526 test: 0.6076 | best val epoch -- val: 0.6546 test: 0.6056

====epoch 96
Train Loss 14.306197286467574
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6614 test: 0.6105 | best val epoch -- val: 0.6614 test: 0.6105

====epoch 97
Train Loss 14.117729091807933
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6546 test: 0.5972 | best val epoch -- val: 0.6614 test: 0.6105

====epoch 98
Train Loss 14.042989088363587
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6516 test: 0.5993 | best val epoch -- val: 0.6614 test: 0.6105

====epoch 99
Train Loss 13.991570027186526
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6457 test: 0.5987 | best val epoch -- val: 0.6614 test: 0.6105

====epoch 100
Train Loss 14.083103244623118
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6434 test: 0.6045 | best val epoch -- val: 0.6614 test: 0.6105

WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.4.
[08:58:32] WARNING: not removing hydrogen atom without neighbors
[08:58:32] WARNING: not removing hydrogen atom without neighbors
2022-09-13 08:58:34.439 | INFO     | modules.masked_transformer_encoder:__init__:122 - number of parameters: 0.000000e+00
=========================================
batch_size = 32
d_model = 128
dataset = hiv
decay = 0
device = 0
dim_feedforward = 512
eval_train = 0
filename =
gnn_JK = cat
gnn_dropout = 0.3
gnn_emb_dim = 300
gnn_num_layer = 5
gnn_residual = False
gnn_type = gin
gnn_virtual_node = False
graph_pooling = cls
input_model_file = models_graphtrans/graphtrans-sr-gcl.pth
lr = 0.0001
lr_scale = 1
max_input_len = 1000
nhead = 4
num_encoder_layers = 4
num_encoder_layers_masked = 0
num_workers = 0
pos_encoder = False
runseed = 0
seed = 12344
split = scaffold
transformer_activation = relu
transformer_dropout = 0.3
transformer_norm_input = True
transformer_prenorm = False
=========================================
hiv
scaffold
Loaded GraphTrans from models_graphtrans/graphtrans-sr-gcl.pth
====epoch 1
Train Loss 164.66407359809236
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7512 test: 0.7377 | best val epoch -- val: 0.7512 test: 0.7377

====epoch 2
Train Loss 135.49713301896878
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7589 test: 0.7518 | best val epoch -- val: 0.7589 test: 0.7518

====epoch 3
Train Loss 128.4235018909147
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7618 test: 0.7523 | best val epoch -- val: 0.7618 test: 0.7523

====epoch 4
Train Loss 123.74283861300232
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7737 test: 0.7743 | best val epoch -- val: 0.7737 test: 0.7743

====epoch 5
Train Loss 120.50752088229676
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7696 test: 0.7781 | best val epoch -- val: 0.7737 test: 0.7743

====epoch 6
Train Loss 118.873071903921
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7788 test: 0.7841 | best val epoch -- val: 0.7788 test: 0.7841

====epoch 7
Train Loss 115.69481398106934
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7803 test: 0.8004 | best val epoch -- val: 0.7803 test: 0.8004

====epoch 8
Train Loss 114.33838918951425
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7801 test: 0.7912 | best val epoch -- val: 0.7803 test: 0.8004

====epoch 9
Train Loss 112.53648410614993
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7974 test: 0.7967 | best val epoch -- val: 0.7974 test: 0.7967

====epoch 10
Train Loss 111.09684194040507
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7889 test: 0.7853 | best val epoch -- val: 0.7974 test: 0.7967

====epoch 11
Train Loss 109.06074569471805
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7967 test: 0.7763 | best val epoch -- val: 0.7974 test: 0.7967

====epoch 12
Train Loss 108.36742880618121
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7989 test: 0.7866 | best val epoch -- val: 0.7989 test: 0.7866

====epoch 13
Train Loss 107.55007274135572
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8010 test: 0.7844 | best val epoch -- val: 0.8010 test: 0.7844

====epoch 14
Train Loss 107.7389677180804
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8097 test: 0.7790 | best val epoch -- val: 0.8097 test: 0.7790

====epoch 15
Train Loss 105.9683023012221
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7931 test: 0.7794 | best val epoch -- val: 0.8097 test: 0.7790

====epoch 16
Train Loss 104.12749019012708
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8049 test: 0.7936 | best val epoch -- val: 0.8097 test: 0.7790

====epoch 17
Train Loss 103.4512629283068
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8168 test: 0.7925 | best val epoch -- val: 0.8168 test: 0.7925

====epoch 18
Train Loss 101.9543161057626
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8117 test: 0.7831 | best val epoch -- val: 0.8168 test: 0.7925

====epoch 19
Train Loss 101.25793639532965
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7895 test: 0.7679 | best val epoch -- val: 0.8168 test: 0.7925

====epoch 20
Train Loss 99.84313966098239
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8136 test: 0.7767 | best val epoch -- val: 0.8168 test: 0.7925

WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.4.
[09:14:14] WARNING: not removing hydrogen atom without neighbors
[09:14:14] WARNING: not removing hydrogen atom without neighbors
2022-09-13 09:14:16.902 | INFO     | modules.masked_transformer_encoder:__init__:122 - number of parameters: 0.000000e+00
=========================================
batch_size = 32
d_model = 128
dataset = hiv
decay = 0
device = 0
dim_feedforward = 512
eval_train = 0
filename =
gnn_JK = cat
gnn_dropout = 0.3
gnn_emb_dim = 300
gnn_num_layer = 5
gnn_residual = False
gnn_type = gin
gnn_virtual_node = False
graph_pooling = cls
input_model_file = models_graphtrans/graphtrans-sr-gcl.pth
lr = 0.0001
lr_scale = 1
max_input_len = 1000
nhead = 4
num_encoder_layers = 4
num_encoder_layers_masked = 0
num_workers = 0
pos_encoder = False
runseed = 1
seed = 12344
split = scaffold
transformer_activation = relu
transformer_dropout = 0.3
transformer_norm_input = True
transformer_prenorm = False
=========================================
hiv
scaffold
Loaded GraphTrans from models_graphtrans/graphtrans-sr-gcl.pth
====epoch 1
Train Loss 164.47276003498743
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7630 test: 0.7178 | best val epoch -- val: 0.7630 test: 0.7178

====epoch 2
Train Loss 136.2443368069711
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7400 test: 0.7332 | best val epoch -- val: 0.7630 test: 0.7178

====epoch 3
Train Loss 127.83290108986415
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7674 test: 0.7624 | best val epoch -- val: 0.7674 test: 0.7624

====epoch 4
Train Loss 122.54582866440035
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7878 test: 0.7980 | best val epoch -- val: 0.7878 test: 0.7980

====epoch 5
Train Loss 119.5153636040016
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7780 test: 0.7902 | best val epoch -- val: 0.7878 test: 0.7980

====epoch 6
Train Loss 118.03988767576264
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8008 test: 0.7688 | best val epoch -- val: 0.8008 test: 0.7688

====epoch 7
Train Loss 113.57032373004627
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7939 test: 0.7753 | best val epoch -- val: 0.8008 test: 0.7688

====epoch 8
Train Loss 112.31038231856422
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7791 test: 0.7901 | best val epoch -- val: 0.8008 test: 0.7688

====epoch 9
Train Loss 112.35800588467438
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7662 test: 0.7866 | best val epoch -- val: 0.8008 test: 0.7688

====epoch 10
Train Loss 110.40738508033178
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7816 test: 0.7969 | best val epoch -- val: 0.8008 test: 0.7688

====epoch 11
Train Loss 109.35547722810374
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8013 test: 0.7941 | best val epoch -- val: 0.8013 test: 0.7941

====epoch 12
Train Loss 108.11425426822076
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8114 test: 0.7854 | best val epoch -- val: 0.8114 test: 0.7854

====epoch 13
Train Loss 105.28622782364238
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8007 test: 0.7759 | best val epoch -- val: 0.8114 test: 0.7854

====epoch 14
Train Loss 104.5096573326881
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7962 test: 0.7755 | best val epoch -- val: 0.8114 test: 0.7854

====epoch 15
Train Loss 102.41751430878595
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7988 test: 0.7807 | best val epoch -- val: 0.8114 test: 0.7854

====epoch 16
Train Loss 102.30863071333965
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8111 test: 0.7889 | best val epoch -- val: 0.8114 test: 0.7854

====epoch 17
Train Loss 102.28587508058018
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8144 test: 0.7794 | best val epoch -- val: 0.8144 test: 0.7794

====epoch 18
Train Loss 101.49180406834992
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8154 test: 0.7739 | best val epoch -- val: 0.8154 test: 0.7739

====epoch 19
Train Loss 100.60180808350871
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8169 test: 0.7893 | best val epoch -- val: 0.8169 test: 0.7893

====epoch 20
Train Loss 98.05144537817928
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8130 test: 0.7609 | best val epoch -- val: 0.8169 test: 0.7893

WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.4.
[09:29:34] WARNING: not removing hydrogen atom without neighbors
[09:29:34] WARNING: not removing hydrogen atom without neighbors
2022-09-13 09:29:36.425 | INFO     | modules.masked_transformer_encoder:__init__:122 - number of parameters: 0.000000e+00
=========================================
batch_size = 32
d_model = 128
dataset = hiv
decay = 0
device = 0
dim_feedforward = 512
eval_train = 0
filename =
gnn_JK = cat
gnn_dropout = 0.3
gnn_emb_dim = 300
gnn_num_layer = 5
gnn_residual = False
gnn_type = gin
gnn_virtual_node = False
graph_pooling = cls
input_model_file = models_graphtrans/graphtrans-sr-gcl.pth
lr = 0.0001
lr_scale = 1
max_input_len = 1000
nhead = 4
num_encoder_layers = 4
num_encoder_layers_masked = 0
num_workers = 0
pos_encoder = False
runseed = 2
seed = 12344
split = scaffold
transformer_activation = relu
transformer_dropout = 0.3
transformer_norm_input = True
transformer_prenorm = False
=========================================
hiv
scaffold
Loaded GraphTrans from models_graphtrans/graphtrans-sr-gcl.pth
====epoch 1
Train Loss 165.10335796601888
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7274 test: 0.7032 | best val epoch -- val: 0.7274 test: 0.7032

====epoch 2
Train Loss 136.02719345271174
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7489 test: 0.7150 | best val epoch -- val: 0.7489 test: 0.7150

====epoch 3
Train Loss 129.39032002079165
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7838 test: 0.7790 | best val epoch -- val: 0.7838 test: 0.7790

====epoch 4
Train Loss 125.34288381718152
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7824 test: 0.7813 | best val epoch -- val: 0.7838 test: 0.7790

====epoch 5
Train Loss 120.9162059971189
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7755 test: 0.7663 | best val epoch -- val: 0.7838 test: 0.7790

====epoch 6
Train Loss 117.74035097911845
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7869 test: 0.8008 | best val epoch -- val: 0.7869 test: 0.8008

====epoch 7
Train Loss 116.40404002510388
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7972 test: 0.7921 | best val epoch -- val: 0.7972 test: 0.7921

====epoch 8
Train Loss 114.1720509097771
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7863 test: 0.7717 | best val epoch -- val: 0.7972 test: 0.7921

====epoch 9
Train Loss 112.66541742524329
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8034 test: 0.7854 | best val epoch -- val: 0.8034 test: 0.7854

====epoch 10
Train Loss 110.67204570780186
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8232 test: 0.7879 | best val epoch -- val: 0.8232 test: 0.7879

====epoch 11
Train Loss 110.38129157626433
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8145 test: 0.7848 | best val epoch -- val: 0.8232 test: 0.7879

====epoch 12
Train Loss 107.95858896126497
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8144 test: 0.7706 | best val epoch -- val: 0.8232 test: 0.7879

====epoch 13
Train Loss 107.14355722563906
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8006 test: 0.7684 | best val epoch -- val: 0.8232 test: 0.7879

====epoch 14
Train Loss 105.95018503987323
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8053 test: 0.7556 | best val epoch -- val: 0.8232 test: 0.7879

====epoch 15
Train Loss 104.85779830699765
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8226 test: 0.7718 | best val epoch -- val: 0.8232 test: 0.7879

====epoch 16
Train Loss 104.08289781147994
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8095 test: 0.7582 | best val epoch -- val: 0.8232 test: 0.7879

====epoch 17
Train Loss 102.97329038424328
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8126 test: 0.7592 | best val epoch -- val: 0.8232 test: 0.7879

====epoch 18
Train Loss 101.97545893474167
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8005 test: 0.7608 | best val epoch -- val: 0.8232 test: 0.7879

====epoch 19
Train Loss 100.47667827757691
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8045 test: 0.7634 | best val epoch -- val: 0.8232 test: 0.7879

====epoch 20
Train Loss 99.42131661327758
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8039 test: 0.7691 | best val epoch -- val: 0.8232 test: 0.7879

WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.4.
[09:44:36] WARNING: not removing hydrogen atom without neighbors
[09:44:36] WARNING: not removing hydrogen atom without neighbors
2022-09-13 09:44:39.009 | INFO     | modules.masked_transformer_encoder:__init__:122 - number of parameters: 0.000000e+00
=========================================
batch_size = 32
d_model = 128
dataset = hiv
decay = 0
device = 0
dim_feedforward = 512
eval_train = 0
filename =
gnn_JK = cat
gnn_dropout = 0.3
gnn_emb_dim = 300
gnn_num_layer = 5
gnn_residual = False
gnn_type = gin
gnn_virtual_node = False
graph_pooling = cls
input_model_file = models_graphtrans/graphtrans-sr-gcl.pth
lr = 0.0001
lr_scale = 1
max_input_len = 1000
nhead = 4
num_encoder_layers = 4
num_encoder_layers_masked = 0
num_workers = 0
pos_encoder = False
runseed = 3
seed = 12344
split = scaffold
transformer_activation = relu
transformer_dropout = 0.3
transformer_norm_input = True
transformer_prenorm = False
=========================================
hiv
scaffold
Loaded GraphTrans from models_graphtrans/graphtrans-sr-gcl.pth
====epoch 1
Train Loss 164.97363647499577
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7205 test: 0.7365 | best val epoch -- val: 0.7205 test: 0.7365

====epoch 2
Train Loss 135.5874854295456
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7517 test: 0.7760 | best val epoch -- val: 0.7517 test: 0.7760

====epoch 3
Train Loss 127.58403133713733
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7498 test: 0.7662 | best val epoch -- val: 0.7517 test: 0.7760

====epoch 4
Train Loss 123.77209144315584
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7717 test: 0.7802 | best val epoch -- val: 0.7717 test: 0.7802

====epoch 5
Train Loss 119.92235843742641
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7896 test: 0.7889 | best val epoch -- val: 0.7896 test: 0.7889

====epoch 6
Train Loss 117.18691698435319
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7893 test: 0.7752 | best val epoch -- val: 0.7896 test: 0.7889

====epoch 7
Train Loss 115.42792636951877
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8260 test: 0.7719 | best val epoch -- val: 0.8260 test: 0.7719

====epoch 8
Train Loss 114.72652727340996
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8061 test: 0.7862 | best val epoch -- val: 0.8260 test: 0.7719

====epoch 9
Train Loss 110.99232123547384
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7953 test: 0.7635 | best val epoch -- val: 0.8260 test: 0.7719

====epoch 10
Train Loss 110.88449799155026
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8102 test: 0.7574 | best val epoch -- val: 0.8260 test: 0.7719

====epoch 11
Train Loss 109.44988398814439
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8020 test: 0.7566 | best val epoch -- val: 0.8260 test: 0.7719

====epoch 12
Train Loss 108.7022052709043
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8053 test: 0.7570 | best val epoch -- val: 0.8260 test: 0.7719

====epoch 13
Train Loss 105.91204089081437
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8044 test: 0.7530 | best val epoch -- val: 0.8260 test: 0.7719

====epoch 14
Train Loss 106.36049987119239
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8063 test: 0.7616 | best val epoch -- val: 0.8260 test: 0.7719

====epoch 15
Train Loss 103.46772422104445
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8026 test: 0.7574 | best val epoch -- val: 0.8260 test: 0.7719

====epoch 16
Train Loss 103.03600257174207
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8098 test: 0.7615 | best val epoch -- val: 0.8260 test: 0.7719

====epoch 17
Train Loss 101.70239109380564
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8163 test: 0.7576 | best val epoch -- val: 0.8260 test: 0.7719

====epoch 18
Train Loss 100.83022129302444
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8047 test: 0.7644 | best val epoch -- val: 0.8260 test: 0.7719

====epoch 19
Train Loss 100.07841280124165
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8002 test: 0.7503 | best val epoch -- val: 0.8260 test: 0.7719

====epoch 20
Train Loss 99.33905994688811
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8234 test: 0.7651 | best val epoch -- val: 0.8260 test: 0.7719

WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.4.
[09:59:57] WARNING: not removing hydrogen atom without neighbors
[09:59:57] WARNING: not removing hydrogen atom without neighbors
2022-09-13 09:59:59.076 | INFO     | modules.masked_transformer_encoder:__init__:122 - number of parameters: 0.000000e+00
=========================================
batch_size = 32
d_model = 128
dataset = hiv
decay = 0
device = 0
dim_feedforward = 512
eval_train = 0
filename =
gnn_JK = cat
gnn_dropout = 0.3
gnn_emb_dim = 300
gnn_num_layer = 5
gnn_residual = False
gnn_type = gin
gnn_virtual_node = False
graph_pooling = cls
input_model_file = models_graphtrans/graphtrans-sr-gcl.pth
lr = 0.0001
lr_scale = 1
max_input_len = 1000
nhead = 4
num_encoder_layers = 4
num_encoder_layers_masked = 0
num_workers = 0
pos_encoder = False
runseed = 4
seed = 12344
split = scaffold
transformer_activation = relu
transformer_dropout = 0.3
transformer_norm_input = True
transformer_prenorm = False
=========================================
hiv
scaffold
Loaded GraphTrans from models_graphtrans/graphtrans-sr-gcl.pth
====epoch 1
Train Loss 165.20403367672648
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7513 test: 0.7065 | best val epoch -- val: 0.7513 test: 0.7065

====epoch 2
Train Loss 135.5509065897294
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7395 test: 0.7525 | best val epoch -- val: 0.7513 test: 0.7065

====epoch 3
Train Loss 129.17615565142614
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7393 test: 0.7590 | best val epoch -- val: 0.7513 test: 0.7065

====epoch 4
Train Loss 123.64851549183433
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7630 test: 0.7681 | best val epoch -- val: 0.7630 test: 0.7681

====epoch 5
Train Loss 121.41939884563666
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7881 test: 0.7909 | best val epoch -- val: 0.7881 test: 0.7909

====epoch 6
Train Loss 116.93223382868659
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7898 test: 0.7769 | best val epoch -- val: 0.7898 test: 0.7769

====epoch 7
Train Loss 114.8280139160957
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7906 test: 0.7998 | best val epoch -- val: 0.7906 test: 0.7998

====epoch 8
Train Loss 113.81517026538967
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8089 test: 0.7915 | best val epoch -- val: 0.8089 test: 0.7915

====epoch 9
Train Loss 110.75251711246906
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7985 test: 0.7861 | best val epoch -- val: 0.8089 test: 0.7915

====epoch 10
Train Loss 109.69212097272258
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7989 test: 0.7959 | best val epoch -- val: 0.8089 test: 0.7915

====epoch 11
Train Loss 108.81291905302773
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8053 test: 0.8034 | best val epoch -- val: 0.8089 test: 0.7915

====epoch 12
Train Loss 107.81754760376124
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8112 test: 0.7863 | best val epoch -- val: 0.8112 test: 0.7863

====epoch 13
Train Loss 106.09776887422176
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8350 test: 0.7930 | best val epoch -- val: 0.8350 test: 0.7930

====epoch 14
Train Loss 105.25476096142188
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8231 test: 0.7838 | best val epoch -- val: 0.8350 test: 0.7930

====epoch 15
Train Loss 103.68211129547473
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8065 test: 0.7676 | best val epoch -- val: 0.8350 test: 0.7930

====epoch 16
Train Loss 101.45685412972983
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8229 test: 0.7634 | best val epoch -- val: 0.8350 test: 0.7930

====epoch 17
Train Loss 101.3671901824476
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8195 test: 0.7626 | best val epoch -- val: 0.8350 test: 0.7930

====epoch 18
Train Loss 101.27988147687121
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8291 test: 0.7623 | best val epoch -- val: 0.8350 test: 0.7930

====epoch 19
Train Loss 99.26358755493493
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7979 test: 0.7416 | best val epoch -- val: 0.8350 test: 0.7930

====epoch 20
Train Loss 99.04144089899597
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8357 test: 0.7703 | best val epoch -- val: 0.8357 test: 0.7703

WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.4.
[10:15:44] WARNING: not removing hydrogen atom without neighbors
[10:15:44] WARNING: not removing hydrogen atom without neighbors
2022-09-13 10:15:46.899 | INFO     | modules.masked_transformer_encoder:__init__:122 - number of parameters: 0.000000e+00
=========================================
batch_size = 32
d_model = 128
dataset = hiv
decay = 0
device = 0
dim_feedforward = 512
eval_train = 0
filename =
gnn_JK = cat
gnn_dropout = 0.3
gnn_emb_dim = 300
gnn_num_layer = 5
gnn_residual = False
gnn_type = gin
gnn_virtual_node = False
graph_pooling = cls
input_model_file = models_graphtrans/graphtrans-sr-gcl.pth
lr = 0.0001
lr_scale = 1
max_input_len = 1000
nhead = 4
num_encoder_layers = 4
num_encoder_layers_masked = 0
num_workers = 0
pos_encoder = False
runseed = 5
seed = 12344
split = scaffold
transformer_activation = relu
transformer_dropout = 0.3
transformer_norm_input = True
transformer_prenorm = False
=========================================
hiv
scaffold
Loaded GraphTrans from models_graphtrans/graphtrans-sr-gcl.pth
====epoch 1
Train Loss 165.02804314127872
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7431 test: 0.7215 | best val epoch -- val: 0.7431 test: 0.7215

====epoch 2
Train Loss 136.9676454839934
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7566 test: 0.7024 | best val epoch -- val: 0.7566 test: 0.7024

====epoch 3
Train Loss 128.07095251560898
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7934 test: 0.7511 | best val epoch -- val: 0.7934 test: 0.7511

====epoch 4
Train Loss 125.00121816372226
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7853 test: 0.7804 | best val epoch -- val: 0.7934 test: 0.7511

====epoch 5
Train Loss 120.12213091526378
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8157 test: 0.7737 | best val epoch -- val: 0.8157 test: 0.7737

====epoch 6
Train Loss 117.51655887895706
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7829 test: 0.7733 | best val epoch -- val: 0.8157 test: 0.7737

====epoch 7
Train Loss 115.58731899957417
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8254 test: 0.7712 | best val epoch -- val: 0.8254 test: 0.7712

====epoch 8
Train Loss 113.34432476895174
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8093 test: 0.7681 | best val epoch -- val: 0.8254 test: 0.7712

====epoch 9
Train Loss 112.69369748468468
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7994 test: 0.7893 | best val epoch -- val: 0.8254 test: 0.7712

====epoch 10
Train Loss 109.50018448618333
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8093 test: 0.7852 | best val epoch -- val: 0.8254 test: 0.7712

====epoch 11
Train Loss 108.48089191284085
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8114 test: 0.7964 | best val epoch -- val: 0.8254 test: 0.7712

====epoch 12
Train Loss 108.11334393033134
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8046 test: 0.7804 | best val epoch -- val: 0.8254 test: 0.7712

====epoch 13
Train Loss 106.541117909837
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8118 test: 0.7652 | best val epoch -- val: 0.8254 test: 0.7712

====epoch 14
Train Loss 105.83125735831045
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8016 test: 0.7723 | best val epoch -- val: 0.8254 test: 0.7712

====epoch 15
Train Loss 103.36076532877594
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8017 test: 0.7600 | best val epoch -- val: 0.8254 test: 0.7712

====epoch 16
Train Loss 103.14379164763875
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8143 test: 0.7697 | best val epoch -- val: 0.8254 test: 0.7712

====epoch 17
Train Loss 101.78624377078734
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8350 test: 0.7859 | best val epoch -- val: 0.8350 test: 0.7859

====epoch 18
Train Loss 101.67084814309287
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8040 test: 0.7595 | best val epoch -- val: 0.8350 test: 0.7859

====epoch 19
Train Loss 100.98856201538334
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8156 test: 0.7615 | best val epoch -- val: 0.8350 test: 0.7859

====epoch 20
Train Loss 97.66928083782899
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7955 test: 0.7463 | best val epoch -- val: 0.8350 test: 0.7859

WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.4.
[10:31:27] WARNING: not removing hydrogen atom without neighbors
[10:31:27] WARNING: not removing hydrogen atom without neighbors
2022-09-13 10:31:29.839 | INFO     | modules.masked_transformer_encoder:__init__:122 - number of parameters: 0.000000e+00
=========================================
batch_size = 32
d_model = 128
dataset = hiv
decay = 0
device = 0
dim_feedforward = 512
eval_train = 0
filename =
gnn_JK = cat
gnn_dropout = 0.3
gnn_emb_dim = 300
gnn_num_layer = 5
gnn_residual = False
gnn_type = gin
gnn_virtual_node = False
graph_pooling = cls
input_model_file = models_graphtrans/graphtrans-sr-gcl.pth
lr = 0.0001
lr_scale = 1
max_input_len = 1000
nhead = 4
num_encoder_layers = 4
num_encoder_layers_masked = 0
num_workers = 0
pos_encoder = False
runseed = 6
seed = 12344
split = scaffold
transformer_activation = relu
transformer_dropout = 0.3
transformer_norm_input = True
transformer_prenorm = False
=========================================
hiv
scaffold
Loaded GraphTrans from models_graphtrans/graphtrans-sr-gcl.pth
====epoch 1
Train Loss 161.71358983666482
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7582 test: 0.7416 | best val epoch -- val: 0.7582 test: 0.7416

====epoch 2
Train Loss 134.56685544909382
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7162 test: 0.7450 | best val epoch -- val: 0.7582 test: 0.7416

====epoch 3
Train Loss 128.08303137108982
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7510 test: 0.7610 | best val epoch -- val: 0.7582 test: 0.7416

====epoch 4
Train Loss 123.51968090939694
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7571 test: 0.7627 | best val epoch -- val: 0.7582 test: 0.7416

====epoch 5
Train Loss 120.01964344950802
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7950 test: 0.7855 | best val epoch -- val: 0.7950 test: 0.7855

====epoch 6
Train Loss 118.02938171039244
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7811 test: 0.7886 | best val epoch -- val: 0.7950 test: 0.7855

====epoch 7
Train Loss 114.93121322718433
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7916 test: 0.7756 | best val epoch -- val: 0.7950 test: 0.7855

====epoch 8
Train Loss 113.75576592471639
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8008 test: 0.7843 | best val epoch -- val: 0.8008 test: 0.7843

====epoch 9
Train Loss 111.04767720534157
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8150 test: 0.7810 | best val epoch -- val: 0.8150 test: 0.7810

====epoch 10
Train Loss 110.25411390939706
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7890 test: 0.7744 | best val epoch -- val: 0.8150 test: 0.7810

====epoch 11
Train Loss 108.65286969144789
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8156 test: 0.7929 | best val epoch -- val: 0.8156 test: 0.7929

====epoch 12
Train Loss 108.01539160833666
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8150 test: 0.8010 | best val epoch -- val: 0.8156 test: 0.7929

====epoch 13
Train Loss 105.76170800207413
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8077 test: 0.7994 | best val epoch -- val: 0.8156 test: 0.7929

====epoch 14
Train Loss 104.78245755239304
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8004 test: 0.7840 | best val epoch -- val: 0.8156 test: 0.7929

====epoch 15
Train Loss 103.2868243130834
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8066 test: 0.7768 | best val epoch -- val: 0.8156 test: 0.7929

====epoch 16
Train Loss 102.62646597727229
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8126 test: 0.7910 | best val epoch -- val: 0.8156 test: 0.7929

====epoch 17
Train Loss 101.80631081398707
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8093 test: 0.7639 | best val epoch -- val: 0.8156 test: 0.7929

====epoch 18
Train Loss 101.18704918095167
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8040 test: 0.7869 | best val epoch -- val: 0.8156 test: 0.7929

====epoch 19
Train Loss 100.09249873561137
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8001 test: 0.7730 | best val epoch -- val: 0.8156 test: 0.7929

====epoch 20
Train Loss 99.25293337552367
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8110 test: 0.7831 | best val epoch -- val: 0.8156 test: 0.7929

WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.4.
[10:47:34] WARNING: not removing hydrogen atom without neighbors
[10:47:34] WARNING: not removing hydrogen atom without neighbors
2022-09-13 10:47:36.292 | INFO     | modules.masked_transformer_encoder:__init__:122 - number of parameters: 0.000000e+00
=========================================
batch_size = 32
d_model = 128
dataset = hiv
decay = 0
device = 0
dim_feedforward = 512
eval_train = 0
filename =
gnn_JK = cat
gnn_dropout = 0.3
gnn_emb_dim = 300
gnn_num_layer = 5
gnn_residual = False
gnn_type = gin
gnn_virtual_node = False
graph_pooling = cls
input_model_file = models_graphtrans/graphtrans-sr-gcl.pth
lr = 0.0001
lr_scale = 1
max_input_len = 1000
nhead = 4
num_encoder_layers = 4
num_encoder_layers_masked = 0
num_workers = 0
pos_encoder = False
runseed = 7
seed = 12344
split = scaffold
transformer_activation = relu
transformer_dropout = 0.3
transformer_norm_input = True
transformer_prenorm = False
=========================================
hiv
scaffold
Loaded GraphTrans from models_graphtrans/graphtrans-sr-gcl.pth
====epoch 1
Train Loss 166.22142478499637
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7029 test: 0.7408 | best val epoch -- val: 0.7029 test: 0.7408

====epoch 2
Train Loss 134.93539308586193
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7193 test: 0.7406 | best val epoch -- val: 0.7193 test: 0.7406

====epoch 3
Train Loss 127.77924366970032
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7586 test: 0.7900 | best val epoch -- val: 0.7586 test: 0.7900

====epoch 4
Train Loss 124.76341614270679
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7738 test: 0.7849 | best val epoch -- val: 0.7738 test: 0.7849

====epoch 5
Train Loss 120.33549133315323
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7715 test: 0.7774 | best val epoch -- val: 0.7738 test: 0.7849

====epoch 6
Train Loss 117.80161968130894
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8129 test: 0.7893 | best val epoch -- val: 0.8129 test: 0.7893

====epoch 7
Train Loss 116.71796681102185
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7918 test: 0.8017 | best val epoch -- val: 0.8129 test: 0.7893

====epoch 8
Train Loss 116.00450346917778
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8128 test: 0.7958 | best val epoch -- val: 0.8129 test: 0.7893

====epoch 9
Train Loss 113.13076602979561
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8192 test: 0.7979 | best val epoch -- val: 0.8192 test: 0.7979

====epoch 10
Train Loss 109.28172193087384
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8364 test: 0.7873 | best val epoch -- val: 0.8364 test: 0.7873

====epoch 11
Train Loss 109.74170693499752
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8252 test: 0.7897 | best val epoch -- val: 0.8364 test: 0.7873

====epoch 12
Train Loss 108.32749838747543
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8199 test: 0.7879 | best val epoch -- val: 0.8364 test: 0.7873

====epoch 13
Train Loss 107.03047701583823
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8205 test: 0.7652 | best val epoch -- val: 0.8364 test: 0.7873

====epoch 14
Train Loss 105.84047158974343
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8089 test: 0.7767 | best val epoch -- val: 0.8364 test: 0.7873

====epoch 15
Train Loss 104.1152797558866
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8223 test: 0.7633 | best val epoch -- val: 0.8364 test: 0.7873

====epoch 16
Train Loss 102.79263441077121
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8355 test: 0.7687 | best val epoch -- val: 0.8364 test: 0.7873

====epoch 17
Train Loss 102.1322979672053
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8122 test: 0.7707 | best val epoch -- val: 0.8364 test: 0.7873

====epoch 18
Train Loss 101.18719176971099
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8070 test: 0.7335 | best val epoch -- val: 0.8364 test: 0.7873

====epoch 19
Train Loss 99.44022870336147
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8216 test: 0.7566 | best val epoch -- val: 0.8364 test: 0.7873

====epoch 20
Train Loss 98.16199392444106
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8157 test: 0.7654 | best val epoch -- val: 0.8364 test: 0.7873

WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.4.
[11:03:46] WARNING: not removing hydrogen atom without neighbors
[11:03:46] WARNING: not removing hydrogen atom without neighbors
2022-09-13 11:03:48.883 | INFO     | modules.masked_transformer_encoder:__init__:122 - number of parameters: 0.000000e+00
=========================================
batch_size = 32
d_model = 128
dataset = hiv
decay = 0
device = 0
dim_feedforward = 512
eval_train = 0
filename =
gnn_JK = cat
gnn_dropout = 0.3
gnn_emb_dim = 300
gnn_num_layer = 5
gnn_residual = False
gnn_type = gin
gnn_virtual_node = False
graph_pooling = cls
input_model_file = models_graphtrans/graphtrans-sr-gcl.pth
lr = 0.0001
lr_scale = 1
max_input_len = 1000
nhead = 4
num_encoder_layers = 4
num_encoder_layers_masked = 0
num_workers = 0
pos_encoder = False
runseed = 8
seed = 12344
split = scaffold
transformer_activation = relu
transformer_dropout = 0.3
transformer_norm_input = True
transformer_prenorm = False
=========================================
hiv
scaffold
Loaded GraphTrans from models_graphtrans/graphtrans-sr-gcl.pth
====epoch 1
Train Loss 164.64603250214722
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7165 test: 0.7352 | best val epoch -- val: 0.7165 test: 0.7352

====epoch 2
Train Loss 137.37379957543754
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7611 test: 0.7577 | best val epoch -- val: 0.7611 test: 0.7577

====epoch 3
Train Loss 129.26248377201952
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7690 test: 0.7811 | best val epoch -- val: 0.7690 test: 0.7811

====epoch 4
Train Loss 123.64657273905054
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7691 test: 0.7814 | best val epoch -- val: 0.7691 test: 0.7814

====epoch 5
Train Loss 119.5956203124101
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7732 test: 0.7762 | best val epoch -- val: 0.7732 test: 0.7762

====epoch 6
Train Loss 117.63301689942053
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7781 test: 0.7769 | best val epoch -- val: 0.7781 test: 0.7769

====epoch 7
Train Loss 114.91959628883927
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7914 test: 0.7903 | best val epoch -- val: 0.7914 test: 0.7903

====epoch 8
Train Loss 113.02154257772501
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8154 test: 0.7849 | best val epoch -- val: 0.8154 test: 0.7849

====epoch 9
Train Loss 111.99013055895651
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8119 test: 0.7825 | best val epoch -- val: 0.8154 test: 0.7849

====epoch 10
Train Loss 107.92924756336478
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7920 test: 0.7770 | best val epoch -- val: 0.8154 test: 0.7849

====epoch 11
Train Loss 109.68274138842325
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7910 test: 0.7747 | best val epoch -- val: 0.8154 test: 0.7849

====epoch 12
Train Loss 108.63515583653307
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7836 test: 0.7549 | best val epoch -- val: 0.8154 test: 0.7849

====epoch 13
Train Loss 106.60620661906535
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7690 test: 0.7795 | best val epoch -- val: 0.8154 test: 0.7849

====epoch 14
Train Loss 105.78399648353854
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8014 test: 0.7481 | best val epoch -- val: 0.8154 test: 0.7849

====epoch 15
Train Loss 105.38581942146325
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7899 test: 0.7674 | best val epoch -- val: 0.8154 test: 0.7849

====epoch 16
Train Loss 104.00416885125092
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7961 test: 0.7703 | best val epoch -- val: 0.8154 test: 0.7849

====epoch 17
Train Loss 102.90227623870473
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7980 test: 0.7790 | best val epoch -- val: 0.8154 test: 0.7849

====epoch 18
Train Loss 102.20955861953534
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8149 test: 0.7880 | best val epoch -- val: 0.8154 test: 0.7849

====epoch 19
Train Loss 100.0707134375449
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7907 test: 0.7733 | best val epoch -- val: 0.8154 test: 0.7849

====epoch 20
Train Loss 98.29437968356147
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8120 test: 0.7913 | best val epoch -- val: 0.8154 test: 0.7849

WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.4.
[11:19:02] WARNING: not removing hydrogen atom without neighbors
[11:19:02] WARNING: not removing hydrogen atom without neighbors
2022-09-13 11:19:04.501 | INFO     | modules.masked_transformer_encoder:__init__:122 - number of parameters: 0.000000e+00
=========================================
batch_size = 32
d_model = 128
dataset = hiv
decay = 0
device = 0
dim_feedforward = 512
eval_train = 0
filename =
gnn_JK = cat
gnn_dropout = 0.3
gnn_emb_dim = 300
gnn_num_layer = 5
gnn_residual = False
gnn_type = gin
gnn_virtual_node = False
graph_pooling = cls
input_model_file = models_graphtrans/graphtrans-sr-gcl.pth
lr = 0.0001
lr_scale = 1
max_input_len = 1000
nhead = 4
num_encoder_layers = 4
num_encoder_layers_masked = 0
num_workers = 0
pos_encoder = False
runseed = 9
seed = 12344
split = scaffold
transformer_activation = relu
transformer_dropout = 0.3
transformer_norm_input = True
transformer_prenorm = False
=========================================
hiv
scaffold
Loaded GraphTrans from models_graphtrans/graphtrans-sr-gcl.pth
====epoch 1
Train Loss 162.1427026193759
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7396 test: 0.6910 | best val epoch -- val: 0.7396 test: 0.6910

====epoch 2
Train Loss 134.3109082284652
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7395 test: 0.7384 | best val epoch -- val: 0.7396 test: 0.6910

====epoch 3
Train Loss 128.1321189321599
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7452 test: 0.7615 | best val epoch -- val: 0.7452 test: 0.7615

====epoch 4
Train Loss 124.97510074912029
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7658 test: 0.7710 | best val epoch -- val: 0.7658 test: 0.7710

====epoch 5
Train Loss 119.93090696993288
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7681 test: 0.7895 | best val epoch -- val: 0.7681 test: 0.7895

====epoch 6
Train Loss 117.64058326776109
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7918 test: 0.7944 | best val epoch -- val: 0.7918 test: 0.7944

====epoch 7
Train Loss 116.07538497108202
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7523 test: 0.7503 | best val epoch -- val: 0.7918 test: 0.7944

====epoch 8
Train Loss 112.56517893216638
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7941 test: 0.7830 | best val epoch -- val: 0.7941 test: 0.7830

====epoch 9
Train Loss 112.63425170152968
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8036 test: 0.7866 | best val epoch -- val: 0.8036 test: 0.7866

====epoch 10
Train Loss 109.38955427620441
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7962 test: 0.7908 | best val epoch -- val: 0.8036 test: 0.7866

====epoch 11
Train Loss 107.10992059069673
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8012 test: 0.7703 | best val epoch -- val: 0.8036 test: 0.7866

====epoch 12
Train Loss 107.9294450318344
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7984 test: 0.7888 | best val epoch -- val: 0.8036 test: 0.7866

====epoch 13
Train Loss 105.47887722662666
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7746 test: 0.7712 | best val epoch -- val: 0.8036 test: 0.7866

====epoch 14
Train Loss 105.02691959508121
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8015 test: 0.7847 | best val epoch -- val: 0.8036 test: 0.7866

====epoch 15
Train Loss 102.08386176734618
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8149 test: 0.7890 | best val epoch -- val: 0.8149 test: 0.7890

====epoch 16
Train Loss 101.85510214064362
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8022 test: 0.7614 | best val epoch -- val: 0.8149 test: 0.7890

====epoch 17
Train Loss 101.52466597635421
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8082 test: 0.7678 | best val epoch -- val: 0.8149 test: 0.7890

====epoch 18
Train Loss 100.29881794812964
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8102 test: 0.7443 | best val epoch -- val: 0.8149 test: 0.7890

====epoch 19
Train Loss 98.86251932900684
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8125 test: 0.7699 | best val epoch -- val: 0.8149 test: 0.7890

====epoch 20
Train Loss 97.87226958590391
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7841 test: 0.7728 | best val epoch -- val: 0.8149 test: 0.7890

[12:53:30] WARNING: not removing hydrogen atom without neighbors
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.4.
2022-09-13 12:53:32.336 | INFO     | modules.masked_transformer_encoder:__init__:122 - number of parameters: 0.000000e+00
=========================================
batch_size = 32
d_model = 128
dataset = tox21
decay = 0
device = 0
dim_feedforward = 512
eval_train = 0
filename =
gnn_JK = cat
gnn_dropout = 0.3
gnn_emb_dim = 300
gnn_num_layer = 5
gnn_residual = False
gnn_type = gin
gnn_virtual_node = False
graph_pooling = cls
input_model_file = models_graphtrans/graphtrans-sr-gcl.pth
lr = 0.0001
lr_scale = 1
max_input_len = 1000
nhead = 4
num_encoder_layers = 4
num_encoder_layers_masked = 0
num_workers = 0
pos_encoder = False
runseed = 0
seed = 12344
split = scaffold
transformer_activation = relu
transformer_dropout = 0.3
transformer_norm_input = True
transformer_prenorm = False
=========================================
tox21
scaffold
Loaded GraphTrans from models_graphtrans/graphtrans-sr-gcl.pth
====epoch 1
Train Loss 64.94991168485626
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.5920 test: 0.6004 | best val epoch -- val: 0.5920 test: 0.6004

====epoch 2
Train Loss 47.329803140640536
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6621 test: 0.6546 | best val epoch -- val: 0.6621 test: 0.6546

====epoch 3
Train Loss 42.6527362799658
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7272 test: 0.7071 | best val epoch -- val: 0.7272 test: 0.7071

====epoch 4
Train Loss 40.1274329942469
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7493 test: 0.7367 | best val epoch -- val: 0.7493 test: 0.7367

====epoch 5
Train Loss 39.05447036482506
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7648 test: 0.7412 | best val epoch -- val: 0.7648 test: 0.7412

====epoch 6
Train Loss 38.00089087015202
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7672 test: 0.7473 | best val epoch -- val: 0.7672 test: 0.7473

====epoch 7
Train Loss 37.33735620086977
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7748 test: 0.7465 | best val epoch -- val: 0.7748 test: 0.7465

====epoch 8
Train Loss 36.376968949626374
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7753 test: 0.7596 | best val epoch -- val: 0.7753 test: 0.7596

====epoch 9
Train Loss 35.696595748037
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7816 test: 0.7642 | best val epoch -- val: 0.7816 test: 0.7642

====epoch 10
Train Loss 35.13797469326417
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7757 test: 0.7606 | best val epoch -- val: 0.7816 test: 0.7642

====epoch 11
Train Loss 34.72313412533959
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7788 test: 0.7693 | best val epoch -- val: 0.7816 test: 0.7642

====epoch 12
Train Loss 34.36242729742401
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7835 test: 0.7727 | best val epoch -- val: 0.7835 test: 0.7727

====epoch 13
Train Loss 33.624056453271244
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7793 test: 0.7766 | best val epoch -- val: 0.7835 test: 0.7727

====epoch 14
Train Loss 33.66163443975393
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7824 test: 0.7772 | best val epoch -- val: 0.7835 test: 0.7727

====epoch 15
Train Loss 33.02041749513242
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7879 test: 0.7740 | best val epoch -- val: 0.7879 test: 0.7740

====epoch 16
Train Loss 32.853801370907775
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7868 test: 0.7699 | best val epoch -- val: 0.7879 test: 0.7740

====epoch 17
Train Loss 32.47321660534087
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7832 test: 0.7702 | best val epoch -- val: 0.7879 test: 0.7740

====epoch 18
Train Loss 32.62725437197405
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7825 test: 0.7705 | best val epoch -- val: 0.7879 test: 0.7740

====epoch 19
Train Loss 31.900796999316018
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7834 test: 0.7688 | best val epoch -- val: 0.7879 test: 0.7740

====epoch 20
Train Loss 32.08388578721828
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7823 test: 0.7754 | best val epoch -- val: 0.7879 test: 0.7740

====epoch 21
Train Loss 31.760137067495194
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7792 test: 0.7773 | best val epoch -- val: 0.7879 test: 0.7740

====epoch 22
Train Loss 31.27453963062786
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7833 test: 0.7848 | best val epoch -- val: 0.7879 test: 0.7740

====epoch 23
Train Loss 30.937594688997912
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7892 test: 0.7835 | best val epoch -- val: 0.7892 test: 0.7835

====epoch 24
Train Loss 30.808619600089916
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7855 test: 0.7732 | best val epoch -- val: 0.7892 test: 0.7835

====epoch 25
Train Loss 30.537012853153453
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7898 test: 0.7805 | best val epoch -- val: 0.7898 test: 0.7805

====epoch 26
Train Loss 30.454648187214275
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7941 test: 0.7761 | best val epoch -- val: 0.7941 test: 0.7761

====epoch 27
Train Loss 29.849004089514015
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7866 test: 0.7781 | best val epoch -- val: 0.7941 test: 0.7761

====epoch 28
Train Loss 29.744314039125396
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7946 test: 0.7744 | best val epoch -- val: 0.7946 test: 0.7744

====epoch 29
Train Loss 29.880204876599368
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7943 test: 0.7797 | best val epoch -- val: 0.7946 test: 0.7744

====epoch 30
Train Loss 29.638257766536803
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7967 test: 0.7783 | best val epoch -- val: 0.7967 test: 0.7783

====epoch 31
Train Loss 29.24479915471677
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7953 test: 0.7797 | best val epoch -- val: 0.7967 test: 0.7783

====epoch 32
Train Loss 28.964663398155274
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8031 test: 0.7790 | best val epoch -- val: 0.8031 test: 0.7790

====epoch 33
Train Loss 29.032528723936807
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7969 test: 0.7798 | best val epoch -- val: 0.8031 test: 0.7790

====epoch 34
Train Loss 28.66088086114355
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7927 test: 0.7741 | best val epoch -- val: 0.8031 test: 0.7790

====epoch 35
Train Loss 28.53531936380588
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7912 test: 0.7714 | best val epoch -- val: 0.8031 test: 0.7790

====epoch 36
Train Loss 28.505113756021146
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7979 test: 0.7779 | best val epoch -- val: 0.8031 test: 0.7790

====epoch 37
Train Loss 27.94716942944152
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7978 test: 0.7766 | best val epoch -- val: 0.8031 test: 0.7790

====epoch 38
Train Loss 27.721582902227865
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7951 test: 0.7687 | best val epoch -- val: 0.8031 test: 0.7790

====epoch 39
Train Loss 27.712776747606377
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7969 test: 0.7716 | best val epoch -- val: 0.8031 test: 0.7790

====epoch 40
Train Loss 27.588191360717538
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7903 test: 0.7688 | best val epoch -- val: 0.8031 test: 0.7790

====epoch 41
Train Loss 27.46187962279512
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7947 test: 0.7687 | best val epoch -- val: 0.8031 test: 0.7790

====epoch 42
Train Loss 27.336958248436204
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7944 test: 0.7710 | best val epoch -- val: 0.8031 test: 0.7790

====epoch 43
Train Loss 27.033752097246975
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7901 test: 0.7680 | best val epoch -- val: 0.8031 test: 0.7790

====epoch 44
Train Loss 26.978471017319425
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7954 test: 0.7721 | best val epoch -- val: 0.8031 test: 0.7790

====epoch 45
Train Loss 27.050003209685986
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7984 test: 0.7709 | best val epoch -- val: 0.8031 test: 0.7790

====epoch 46
Train Loss 26.633657124811453
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7932 test: 0.7677 | best val epoch -- val: 0.8031 test: 0.7790

====epoch 47
Train Loss 26.559036694531887
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7927 test: 0.7689 | best val epoch -- val: 0.8031 test: 0.7790

====epoch 48
Train Loss 26.141685362602686
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7969 test: 0.7723 | best val epoch -- val: 0.8031 test: 0.7790

====epoch 49
Train Loss 26.009011418650193
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7888 test: 0.7672 | best val epoch -- val: 0.8031 test: 0.7790

====epoch 50
Train Loss 26.34375799818815
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7919 test: 0.7682 | best val epoch -- val: 0.8031 test: 0.7790

====epoch 51
Train Loss 25.957413702461277
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7911 test: 0.7677 | best val epoch -- val: 0.8031 test: 0.7790

====epoch 52
Train Loss 26.12883372119694
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7875 test: 0.7627 | best val epoch -- val: 0.8031 test: 0.7790

====epoch 53
Train Loss 25.63116476031873
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7894 test: 0.7628 | best val epoch -- val: 0.8031 test: 0.7790

====epoch 54
Train Loss 25.640721635792932
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7919 test: 0.7685 | best val epoch -- val: 0.8031 test: 0.7790

====epoch 55
Train Loss 25.732289611487744
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7948 test: 0.7673 | best val epoch -- val: 0.8031 test: 0.7790

====epoch 56
Train Loss 25.40711840501761
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7962 test: 0.7635 | best val epoch -- val: 0.8031 test: 0.7790

====epoch 57
Train Loss 25.13854844909526
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7944 test: 0.7603 | best val epoch -- val: 0.8031 test: 0.7790

====epoch 58
Train Loss 25.18429652119631
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7960 test: 0.7633 | best val epoch -- val: 0.8031 test: 0.7790

====epoch 59
Train Loss 24.954550553871368
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7962 test: 0.7594 | best val epoch -- val: 0.8031 test: 0.7790

====epoch 60
Train Loss 24.87996107885554
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7892 test: 0.7602 | best val epoch -- val: 0.8031 test: 0.7790

====epoch 61
Train Loss 24.734806415566382
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7965 test: 0.7660 | best val epoch -- val: 0.8031 test: 0.7790

====epoch 62
Train Loss 24.66821787041024
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7953 test: 0.7613 | best val epoch -- val: 0.8031 test: 0.7790

====epoch 63
Train Loss 24.52469717729242
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7937 test: 0.7582 | best val epoch -- val: 0.8031 test: 0.7790

====epoch 64
Train Loss 24.421792557457735
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7938 test: 0.7589 | best val epoch -- val: 0.8031 test: 0.7790

====epoch 65
Train Loss 24.22752024115931
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7898 test: 0.7595 | best val epoch -- val: 0.8031 test: 0.7790

====epoch 66
Train Loss 24.37253581943773
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7904 test: 0.7585 | best val epoch -- val: 0.8031 test: 0.7790

====epoch 67
Train Loss 24.3612139000115
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7821 test: 0.7538 | best val epoch -- val: 0.8031 test: 0.7790

====epoch 68
Train Loss 23.74929278492577
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7923 test: 0.7593 | best val epoch -- val: 0.8031 test: 0.7790

====epoch 69
Train Loss 23.7022095170081
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7982 test: 0.7652 | best val epoch -- val: 0.8031 test: 0.7790

====epoch 70
Train Loss 23.64431477244561
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7911 test: 0.7642 | best val epoch -- val: 0.8031 test: 0.7790

====epoch 71
Train Loss 23.70103349065922
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7966 test: 0.7657 | best val epoch -- val: 0.8031 test: 0.7790

====epoch 72
Train Loss 23.429531815431986
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7908 test: 0.7625 | best val epoch -- val: 0.8031 test: 0.7790

====epoch 73
Train Loss 23.232216372062943
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7911 test: 0.7610 | best val epoch -- val: 0.8031 test: 0.7790

====epoch 74
Train Loss 22.913993850090712
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7915 test: 0.7562 | best val epoch -- val: 0.8031 test: 0.7790

====epoch 75
Train Loss 23.232873474211335
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7901 test: 0.7549 | best val epoch -- val: 0.8031 test: 0.7790

====epoch 76
Train Loss 22.618430554595193
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7912 test: 0.7556 | best val epoch -- val: 0.8031 test: 0.7790

====epoch 77
Train Loss 22.95376386475407
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7913 test: 0.7611 | best val epoch -- val: 0.8031 test: 0.7790

====epoch 78
Train Loss 22.972176977820382
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7910 test: 0.7608 | best val epoch -- val: 0.8031 test: 0.7790

====epoch 79
Train Loss 22.498587343432554
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7902 test: 0.7607 | best val epoch -- val: 0.8031 test: 0.7790

====epoch 80
Train Loss 22.449614407314822
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7866 test: 0.7583 | best val epoch -- val: 0.8031 test: 0.7790

====epoch 81
Train Loss 22.544899890140037
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7849 test: 0.7603 | best val epoch -- val: 0.8031 test: 0.7790

====epoch 82
Train Loss 22.386536657976396
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7749 test: 0.7517 | best val epoch -- val: 0.8031 test: 0.7790

====epoch 83
Train Loss 22.348113476670704
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7815 test: 0.7602 | best val epoch -- val: 0.8031 test: 0.7790

====epoch 84
Train Loss 21.940246875235214
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7813 test: 0.7588 | best val epoch -- val: 0.8031 test: 0.7790

====epoch 85
Train Loss 22.02643242061191
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7895 test: 0.7587 | best val epoch -- val: 0.8031 test: 0.7790

====epoch 86
Train Loss 22.116400152214997
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7812 test: 0.7592 | best val epoch -- val: 0.8031 test: 0.7790

====epoch 87
Train Loss 21.71411066664926
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7912 test: 0.7593 | best val epoch -- val: 0.8031 test: 0.7790

====epoch 88
Train Loss 21.41641022250702
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7800 test: 0.7602 | best val epoch -- val: 0.8031 test: 0.7790

====epoch 89
Train Loss 21.629203134323046
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7827 test: 0.7517 | best val epoch -- val: 0.8031 test: 0.7790

====epoch 90
Train Loss 21.410879412269193
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7798 test: 0.7556 | best val epoch -- val: 0.8031 test: 0.7790

====epoch 91
Train Loss 21.298449448329478
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7784 test: 0.7543 | best val epoch -- val: 0.8031 test: 0.7790

====epoch 92
Train Loss 21.042808564961067
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7747 test: 0.7567 | best val epoch -- val: 0.8031 test: 0.7790

====epoch 93
Train Loss 20.940767584876852
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7765 test: 0.7595 | best val epoch -- val: 0.8031 test: 0.7790

====epoch 94
Train Loss 20.936217858913327
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7816 test: 0.7567 | best val epoch -- val: 0.8031 test: 0.7790

====epoch 95
Train Loss 20.953067140697005
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7818 test: 0.7604 | best val epoch -- val: 0.8031 test: 0.7790

====epoch 96
Train Loss 20.495116788603003
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7765 test: 0.7560 | best val epoch -- val: 0.8031 test: 0.7790

====epoch 97
Train Loss 20.532565008371883
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7790 test: 0.7590 | best val epoch -- val: 0.8031 test: 0.7790

====epoch 98
Train Loss 20.526103638364273
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7744 test: 0.7603 | best val epoch -- val: 0.8031 test: 0.7790

====epoch 99
Train Loss 20.39179249585907
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7681 test: 0.7519 | best val epoch -- val: 0.8031 test: 0.7790

====epoch 100
Train Loss 20.148555926244466
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7820 test: 0.7576 | best val epoch -- val: 0.8031 test: 0.7790

[13:07:21] WARNING: not removing hydrogen atom without neighbors
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.4.
2022-09-13 13:07:23.590 | INFO     | modules.masked_transformer_encoder:__init__:122 - number of parameters: 0.000000e+00
=========================================
batch_size = 32
d_model = 128
dataset = tox21
decay = 0
device = 0
dim_feedforward = 512
eval_train = 0
filename =
gnn_JK = cat
gnn_dropout = 0.3
gnn_emb_dim = 300
gnn_num_layer = 5
gnn_residual = False
gnn_type = gin
gnn_virtual_node = False
graph_pooling = cls
input_model_file = models_graphtrans/graphtrans-sr-gcl.pth
lr = 0.0001
lr_scale = 1
max_input_len = 1000
nhead = 4
num_encoder_layers = 4
num_encoder_layers_masked = 0
num_workers = 0
pos_encoder = False
runseed = 1
seed = 12344
split = scaffold
transformer_activation = relu
transformer_dropout = 0.3
transformer_norm_input = True
transformer_prenorm = False
=========================================
tox21
scaffold
Loaded GraphTrans from models_graphtrans/graphtrans-sr-gcl.pth
====epoch 1
Train Loss 65.43669249770618
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.5404 test: 0.5641 | best val epoch -- val: 0.5404 test: 0.5641

====epoch 2
Train Loss 48.024564561904434
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6091 test: 0.6117 | best val epoch -- val: 0.6091 test: 0.6117

====epoch 3
Train Loss 44.220562759735586
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7171 test: 0.6937 | best val epoch -- val: 0.7171 test: 0.6937

====epoch 4
Train Loss 40.952304677853604
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7355 test: 0.7061 | best val epoch -- val: 0.7355 test: 0.7061

====epoch 5
Train Loss 39.784636193350025
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7559 test: 0.7261 | best val epoch -- val: 0.7559 test: 0.7261

====epoch 6
Train Loss 38.670873912347545
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7680 test: 0.7341 | best val epoch -- val: 0.7680 test: 0.7341

====epoch 7
Train Loss 37.48953155899329
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7677 test: 0.7428 | best val epoch -- val: 0.7680 test: 0.7341

====epoch 8
Train Loss 36.90433521496409
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7692 test: 0.7375 | best val epoch -- val: 0.7692 test: 0.7375

====epoch 9
Train Loss 36.377692971318545
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7853 test: 0.7403 | best val epoch -- val: 0.7853 test: 0.7403

====epoch 10
Train Loss 35.51088837155876
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7834 test: 0.7432 | best val epoch -- val: 0.7853 test: 0.7403

====epoch 11
Train Loss 35.12201926901223
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7877 test: 0.7514 | best val epoch -- val: 0.7877 test: 0.7514

====epoch 12
Train Loss 34.60277318720401
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7882 test: 0.7493 | best val epoch -- val: 0.7882 test: 0.7493

====epoch 13
Train Loss 34.36776159899043
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7922 test: 0.7533 | best val epoch -- val: 0.7922 test: 0.7533

====epoch 14
Train Loss 33.54246562851593
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7930 test: 0.7545 | best val epoch -- val: 0.7930 test: 0.7545

====epoch 15
Train Loss 33.17618138803316
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7883 test: 0.7623 | best val epoch -- val: 0.7930 test: 0.7545

====epoch 16
Train Loss 33.22082800283265
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7952 test: 0.7717 | best val epoch -- val: 0.7952 test: 0.7717

====epoch 17
Train Loss 32.80883123554086
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7989 test: 0.7707 | best val epoch -- val: 0.7989 test: 0.7707

====epoch 18
Train Loss 32.56820113980897
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8010 test: 0.7681 | best val epoch -- val: 0.8010 test: 0.7681

====epoch 19
Train Loss 32.37582337117651
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7975 test: 0.7635 | best val epoch -- val: 0.8010 test: 0.7681

====epoch 20
Train Loss 31.90259427629596
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7954 test: 0.7728 | best val epoch -- val: 0.8010 test: 0.7681

====epoch 21
Train Loss 31.377199114241165
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8015 test: 0.7693 | best val epoch -- val: 0.8015 test: 0.7693

====epoch 22
Train Loss 31.437319391611958
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8052 test: 0.7661 | best val epoch -- val: 0.8052 test: 0.7661

====epoch 23
Train Loss 31.292040366364827
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8010 test: 0.7701 | best val epoch -- val: 0.8052 test: 0.7661

====epoch 24
Train Loss 30.980215046472857
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8031 test: 0.7804 | best val epoch -- val: 0.8052 test: 0.7661

====epoch 25
Train Loss 30.793832410240537
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8075 test: 0.7820 | best val epoch -- val: 0.8075 test: 0.7820

====epoch 26
Train Loss 30.71727208611209
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8062 test: 0.7832 | best val epoch -- val: 0.8075 test: 0.7820

====epoch 27
Train Loss 30.46334373769438
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8039 test: 0.7758 | best val epoch -- val: 0.8075 test: 0.7820

====epoch 28
Train Loss 30.255040489842255
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7997 test: 0.7800 | best val epoch -- val: 0.8075 test: 0.7820

====epoch 29
Train Loss 29.98590159156836
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8031 test: 0.7825 | best val epoch -- val: 0.8075 test: 0.7820

====epoch 30
Train Loss 29.73308447435931
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7997 test: 0.7789 | best val epoch -- val: 0.8075 test: 0.7820

====epoch 31
Train Loss 29.675222531588275
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7985 test: 0.7806 | best val epoch -- val: 0.8075 test: 0.7820

====epoch 32
Train Loss 29.432545277096036
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7983 test: 0.7834 | best val epoch -- val: 0.8075 test: 0.7820

====epoch 33
Train Loss 29.3914408760774
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8043 test: 0.7864 | best val epoch -- val: 0.8075 test: 0.7820

====epoch 34
Train Loss 28.815296014631034
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7977 test: 0.7757 | best val epoch -- val: 0.8075 test: 0.7820

====epoch 35
Train Loss 28.655922031014914
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8003 test: 0.7780 | best val epoch -- val: 0.8075 test: 0.7820

====epoch 36
Train Loss 28.628009044629387
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8001 test: 0.7727 | best val epoch -- val: 0.8075 test: 0.7820

====epoch 37
Train Loss 28.332325609908715
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8000 test: 0.7805 | best val epoch -- val: 0.8075 test: 0.7820

====epoch 38
Train Loss 28.288893830754034
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7976 test: 0.7821 | best val epoch -- val: 0.8075 test: 0.7820

====epoch 39
Train Loss 28.038503017162217
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8021 test: 0.7809 | best val epoch -- val: 0.8075 test: 0.7820

====epoch 40
Train Loss 28.16007951550401
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7984 test: 0.7770 | best val epoch -- val: 0.8075 test: 0.7820

====epoch 41
Train Loss 27.778780525442855
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8007 test: 0.7770 | best val epoch -- val: 0.8075 test: 0.7820

====epoch 42
Train Loss 27.78088072510906
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8059 test: 0.7784 | best val epoch -- val: 0.8075 test: 0.7820

====epoch 43
Train Loss 27.466991631856878
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8011 test: 0.7798 | best val epoch -- val: 0.8075 test: 0.7820

====epoch 44
Train Loss 27.181419790451773
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8079 test: 0.7824 | best val epoch -- val: 0.8079 test: 0.7824

====epoch 45
Train Loss 27.169061022172748
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8081 test: 0.7739 | best val epoch -- val: 0.8081 test: 0.7739

====epoch 46
Train Loss 27.032817014966177
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8089 test: 0.7693 | best val epoch -- val: 0.8089 test: 0.7693

====epoch 47
Train Loss 26.72403990379985
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8065 test: 0.7682 | best val epoch -- val: 0.8089 test: 0.7693

====epoch 48
Train Loss 26.450462395103198
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8001 test: 0.7689 | best val epoch -- val: 0.8089 test: 0.7693

====epoch 49
Train Loss 26.25683113519137
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8068 test: 0.7672 | best val epoch -- val: 0.8089 test: 0.7693

====epoch 50
Train Loss 26.258500719940322
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8065 test: 0.7763 | best val epoch -- val: 0.8089 test: 0.7693

====epoch 51
Train Loss 26.22209690498844
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8037 test: 0.7726 | best val epoch -- val: 0.8089 test: 0.7693

====epoch 52
Train Loss 25.8431176053727
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8076 test: 0.7766 | best val epoch -- val: 0.8089 test: 0.7693

====epoch 53
Train Loss 26.078108591384765
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8046 test: 0.7751 | best val epoch -- val: 0.8089 test: 0.7693

====epoch 54
Train Loss 25.634141713467084
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8097 test: 0.7776 | best val epoch -- val: 0.8097 test: 0.7776

====epoch 55
Train Loss 25.75414720768232
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8044 test: 0.7678 | best val epoch -- val: 0.8097 test: 0.7776

====epoch 56
Train Loss 25.32731816646746
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8071 test: 0.7710 | best val epoch -- val: 0.8097 test: 0.7776

====epoch 57
Train Loss 25.07726968523478
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8043 test: 0.7674 | best val epoch -- val: 0.8097 test: 0.7776

====epoch 58
Train Loss 25.76384957856756
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8037 test: 0.7659 | best val epoch -- val: 0.8097 test: 0.7776

====epoch 59
Train Loss 25.06036038009152
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8071 test: 0.7694 | best val epoch -- val: 0.8097 test: 0.7776

====epoch 60
Train Loss 24.92658571560106
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8064 test: 0.7674 | best val epoch -- val: 0.8097 test: 0.7776

====epoch 61
Train Loss 24.809246488636514
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8070 test: 0.7715 | best val epoch -- val: 0.8097 test: 0.7776

====epoch 62
Train Loss 24.79068481614634
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8082 test: 0.7692 | best val epoch -- val: 0.8097 test: 0.7776

====epoch 63
Train Loss 24.619884958211788
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8046 test: 0.7688 | best val epoch -- val: 0.8097 test: 0.7776

====epoch 64
Train Loss 24.47479447476559
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8051 test: 0.7664 | best val epoch -- val: 0.8097 test: 0.7776

====epoch 65
Train Loss 24.447781856669852
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8057 test: 0.7680 | best val epoch -- val: 0.8097 test: 0.7776

====epoch 66
Train Loss 24.00598332758426
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7992 test: 0.7608 | best val epoch -- val: 0.8097 test: 0.7776

====epoch 67
Train Loss 24.014458046114854
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8061 test: 0.7686 | best val epoch -- val: 0.8097 test: 0.7776

====epoch 68
Train Loss 23.91956892736716
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7998 test: 0.7648 | best val epoch -- val: 0.8097 test: 0.7776

====epoch 69
Train Loss 23.97482132333417
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8047 test: 0.7671 | best val epoch -- val: 0.8097 test: 0.7776

====epoch 70
Train Loss 24.02347776332591
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7999 test: 0.7709 | best val epoch -- val: 0.8097 test: 0.7776

====epoch 71
Train Loss 23.80629846792844
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8024 test: 0.7619 | best val epoch -- val: 0.8097 test: 0.7776

====epoch 72
Train Loss 23.43698087738696
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7962 test: 0.7622 | best val epoch -- val: 0.8097 test: 0.7776

====epoch 73
Train Loss 23.44591570998934
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7955 test: 0.7575 | best val epoch -- val: 0.8097 test: 0.7776

====epoch 74
Train Loss 23.458555211308862
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7922 test: 0.7586 | best val epoch -- val: 0.8097 test: 0.7776

====epoch 75
Train Loss 23.503048463043147
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7910 test: 0.7593 | best val epoch -- val: 0.8097 test: 0.7776

====epoch 76
Train Loss 22.877969991238427
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7911 test: 0.7559 | best val epoch -- val: 0.8097 test: 0.7776

====epoch 77
Train Loss 22.8437487327293
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7942 test: 0.7611 | best val epoch -- val: 0.8097 test: 0.7776

====epoch 78
Train Loss 23.30489881411504
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7993 test: 0.7575 | best val epoch -- val: 0.8097 test: 0.7776

====epoch 79
Train Loss 22.683138938746374
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8004 test: 0.7615 | best val epoch -- val: 0.8097 test: 0.7776

====epoch 80
Train Loss 22.68594617116848
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8034 test: 0.7643 | best val epoch -- val: 0.8097 test: 0.7776

====epoch 81
Train Loss 22.37880283869024
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8021 test: 0.7675 | best val epoch -- val: 0.8097 test: 0.7776

====epoch 82
Train Loss 22.65371698574312
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8021 test: 0.7693 | best val epoch -- val: 0.8097 test: 0.7776

====epoch 83
Train Loss 22.455432324945328
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7999 test: 0.7626 | best val epoch -- val: 0.8097 test: 0.7776

====epoch 84
Train Loss 22.206748562369224
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7962 test: 0.7616 | best val epoch -- val: 0.8097 test: 0.7776

====epoch 85
Train Loss 22.153315918236665
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7970 test: 0.7696 | best val epoch -- val: 0.8097 test: 0.7776

====epoch 86
Train Loss 22.66651776120725
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7974 test: 0.7595 | best val epoch -- val: 0.8097 test: 0.7776

====epoch 87
Train Loss 22.063075498133006
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8029 test: 0.7664 | best val epoch -- val: 0.8097 test: 0.7776

====epoch 88
Train Loss 21.52314009423257
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7950 test: 0.7615 | best val epoch -- val: 0.8097 test: 0.7776

====epoch 89
Train Loss 21.5765836596717
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7985 test: 0.7632 | best val epoch -- val: 0.8097 test: 0.7776

====epoch 90
Train Loss 21.766556213680488
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7905 test: 0.7561 | best val epoch -- val: 0.8097 test: 0.7776

====epoch 91
Train Loss 21.69656856161018
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7919 test: 0.7642 | best val epoch -- val: 0.8097 test: 0.7776

====epoch 92
Train Loss 21.905844273342858
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7892 test: 0.7530 | best val epoch -- val: 0.8097 test: 0.7776

====epoch 93
Train Loss 21.296260835504096
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7948 test: 0.7591 | best val epoch -- val: 0.8097 test: 0.7776

====epoch 94
Train Loss 21.083386517951553
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7946 test: 0.7584 | best val epoch -- val: 0.8097 test: 0.7776

====epoch 95
Train Loss 21.12162373269645
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7896 test: 0.7554 | best val epoch -- val: 0.8097 test: 0.7776

====epoch 96
Train Loss 21.047860920191805
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7915 test: 0.7630 | best val epoch -- val: 0.8097 test: 0.7776

====epoch 97
Train Loss 21.04949010991615
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7965 test: 0.7528 | best val epoch -- val: 0.8097 test: 0.7776

====epoch 98
Train Loss 21.135083684395948
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7953 test: 0.7616 | best val epoch -- val: 0.8097 test: 0.7776

====epoch 99
Train Loss 20.944355789483087
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7969 test: 0.7627 | best val epoch -- val: 0.8097 test: 0.7776

====epoch 100
Train Loss 20.366921444434045
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7958 test: 0.7624 | best val epoch -- val: 0.8097 test: 0.7776

[13:21:22] WARNING: not removing hydrogen atom without neighbors
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.4.
2022-09-13 13:21:24.979 | INFO     | modules.masked_transformer_encoder:__init__:122 - number of parameters: 0.000000e+00
=========================================
batch_size = 32
d_model = 128
dataset = tox21
decay = 0
device = 0
dim_feedforward = 512
eval_train = 0
filename =
gnn_JK = cat
gnn_dropout = 0.3
gnn_emb_dim = 300
gnn_num_layer = 5
gnn_residual = False
gnn_type = gin
gnn_virtual_node = False
graph_pooling = cls
input_model_file = models_graphtrans/graphtrans-sr-gcl.pth
lr = 0.0001
lr_scale = 1
max_input_len = 1000
nhead = 4
num_encoder_layers = 4
num_encoder_layers_masked = 0
num_workers = 0
pos_encoder = False
runseed = 2
seed = 12344
split = scaffold
transformer_activation = relu
transformer_dropout = 0.3
transformer_norm_input = True
transformer_prenorm = False
=========================================
tox21
scaffold
Loaded GraphTrans from models_graphtrans/graphtrans-sr-gcl.pth
====epoch 1
Train Loss 63.81199803031731
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.5867 test: 0.5737 | best val epoch -- val: 0.5867 test: 0.5737

====epoch 2
Train Loss 46.938955531997266
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6559 test: 0.6425 | best val epoch -- val: 0.6559 test: 0.6425

====epoch 3
Train Loss 42.655162517007795
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7159 test: 0.6892 | best val epoch -- val: 0.7159 test: 0.6892

====epoch 4
Train Loss 40.62982629728551
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7510 test: 0.7248 | best val epoch -- val: 0.7510 test: 0.7248

====epoch 5
Train Loss 39.12268580339586
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7689 test: 0.7336 | best val epoch -- val: 0.7689 test: 0.7336

====epoch 6
Train Loss 38.14819639061719
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7683 test: 0.7363 | best val epoch -- val: 0.7689 test: 0.7336

====epoch 7
Train Loss 37.27131363362427
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7795 test: 0.7463 | best val epoch -- val: 0.7795 test: 0.7463

====epoch 8
Train Loss 36.875573658499555
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7790 test: 0.7484 | best val epoch -- val: 0.7795 test: 0.7463

====epoch 9
Train Loss 36.021358356651774
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7743 test: 0.7480 | best val epoch -- val: 0.7795 test: 0.7463

====epoch 10
Train Loss 35.51382895701494
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7834 test: 0.7624 | best val epoch -- val: 0.7834 test: 0.7624

====epoch 11
Train Loss 35.17994413909229
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7854 test: 0.7615 | best val epoch -- val: 0.7854 test: 0.7615

====epoch 12
Train Loss 34.71853499222966
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7887 test: 0.7637 | best val epoch -- val: 0.7887 test: 0.7637

====epoch 13
Train Loss 33.83527076370614
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7843 test: 0.7679 | best val epoch -- val: 0.7887 test: 0.7637

====epoch 14
Train Loss 33.647337370369975
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7827 test: 0.7681 | best val epoch -- val: 0.7887 test: 0.7637

====epoch 15
Train Loss 33.340211139128044
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7934 test: 0.7719 | best val epoch -- val: 0.7934 test: 0.7719

====epoch 16
Train Loss 32.67945960947288
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7893 test: 0.7740 | best val epoch -- val: 0.7934 test: 0.7719

====epoch 17
Train Loss 32.39792023309774
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7873 test: 0.7698 | best val epoch -- val: 0.7934 test: 0.7719

====epoch 18
Train Loss 32.6125213873685
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7833 test: 0.7717 | best val epoch -- val: 0.7934 test: 0.7719

====epoch 19
Train Loss 32.11421789142482
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7923 test: 0.7729 | best val epoch -- val: 0.7934 test: 0.7719

====epoch 20
Train Loss 31.450945831879146
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7916 test: 0.7738 | best val epoch -- val: 0.7934 test: 0.7719

====epoch 21
Train Loss 31.524755436934306
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7977 test: 0.7710 | best val epoch -- val: 0.7977 test: 0.7710

====epoch 22
Train Loss 31.48463939548953
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7980 test: 0.7740 | best val epoch -- val: 0.7980 test: 0.7740

====epoch 23
Train Loss 31.01137624808071
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7999 test: 0.7749 | best val epoch -- val: 0.7999 test: 0.7749

====epoch 24
Train Loss 30.69865748470786
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7976 test: 0.7728 | best val epoch -- val: 0.7999 test: 0.7749

====epoch 25
Train Loss 30.56125829206644
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8051 test: 0.7674 | best val epoch -- val: 0.8051 test: 0.7674

====epoch 26
Train Loss 30.342533400446122
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8018 test: 0.7753 | best val epoch -- val: 0.8051 test: 0.7674

====epoch 27
Train Loss 30.29539504865212
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8022 test: 0.7767 | best val epoch -- val: 0.8051 test: 0.7674

====epoch 28
Train Loss 29.625108795135088
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7931 test: 0.7723 | best val epoch -- val: 0.8051 test: 0.7674

====epoch 29
Train Loss 29.752883101387127
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7987 test: 0.7745 | best val epoch -- val: 0.8051 test: 0.7674

====epoch 30
Train Loss 29.464005856031992
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7995 test: 0.7733 | best val epoch -- val: 0.8051 test: 0.7674

====epoch 31
Train Loss 28.961919404558152
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8075 test: 0.7758 | best val epoch -- val: 0.8075 test: 0.7758

====epoch 32
Train Loss 28.958795060274717
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8026 test: 0.7702 | best val epoch -- val: 0.8075 test: 0.7758

====epoch 33
Train Loss 28.721907663749285
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8021 test: 0.7736 | best val epoch -- val: 0.8075 test: 0.7758

====epoch 34
Train Loss 28.564983089349337
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8065 test: 0.7698 | best val epoch -- val: 0.8075 test: 0.7758

====epoch 35
Train Loss 28.309221216067844
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7989 test: 0.7648 | best val epoch -- val: 0.8075 test: 0.7758

====epoch 36
Train Loss 28.21744786845758
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8044 test: 0.7672 | best val epoch -- val: 0.8075 test: 0.7758

====epoch 37
Train Loss 28.22716635320197
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8062 test: 0.7702 | best val epoch -- val: 0.8075 test: 0.7758

====epoch 38
Train Loss 28.131666135315577
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8045 test: 0.7690 | best val epoch -- val: 0.8075 test: 0.7758

====epoch 39
Train Loss 27.457129204490734
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8067 test: 0.7718 | best val epoch -- val: 0.8075 test: 0.7758

====epoch 40
Train Loss 27.555012811570677
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7982 test: 0.7669 | best val epoch -- val: 0.8075 test: 0.7758

====epoch 41
Train Loss 27.690570246780947
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7980 test: 0.7684 | best val epoch -- val: 0.8075 test: 0.7758

====epoch 42
Train Loss 26.93728516772283
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8028 test: 0.7698 | best val epoch -- val: 0.8075 test: 0.7758

====epoch 43
Train Loss 26.778865681485463
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8017 test: 0.7624 | best val epoch -- val: 0.8075 test: 0.7758

====epoch 44
Train Loss 26.98584023430528
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7977 test: 0.7631 | best val epoch -- val: 0.8075 test: 0.7758

====epoch 45
Train Loss 26.692345250847183
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7940 test: 0.7678 | best val epoch -- val: 0.8075 test: 0.7758

====epoch 46
Train Loss 26.60429970613207
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7955 test: 0.7675 | best val epoch -- val: 0.8075 test: 0.7758

====epoch 47
Train Loss 26.147091003961034
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8018 test: 0.7684 | best val epoch -- val: 0.8075 test: 0.7758

====epoch 48
Train Loss 26.04230083004993
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8055 test: 0.7657 | best val epoch -- val: 0.8075 test: 0.7758

====epoch 49
Train Loss 26.14344804569356
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8023 test: 0.7674 | best val epoch -- val: 0.8075 test: 0.7758

====epoch 50
Train Loss 26.289375992777504
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7967 test: 0.7686 | best val epoch -- val: 0.8075 test: 0.7758

====epoch 51
Train Loss 25.816901624593097
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7967 test: 0.7632 | best val epoch -- val: 0.8075 test: 0.7758

====epoch 52
Train Loss 25.684882578492946
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8038 test: 0.7680 | best val epoch -- val: 0.8075 test: 0.7758

====epoch 53
Train Loss 25.248317126256755
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8017 test: 0.7640 | best val epoch -- val: 0.8075 test: 0.7758

====epoch 54
Train Loss 25.439192688245576
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7973 test: 0.7636 | best val epoch -- val: 0.8075 test: 0.7758

====epoch 55
Train Loss 25.49016112234335
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8022 test: 0.7675 | best val epoch -- val: 0.8075 test: 0.7758

====epoch 56
Train Loss 25.234634050319528
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7929 test: 0.7552 | best val epoch -- val: 0.8075 test: 0.7758

====epoch 57
Train Loss 25.00980580996598
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7981 test: 0.7624 | best val epoch -- val: 0.8075 test: 0.7758

====epoch 58
Train Loss 24.532507693288448
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7888 test: 0.7613 | best val epoch -- val: 0.8075 test: 0.7758

====epoch 59
Train Loss 24.686288072223327
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7998 test: 0.7685 | best val epoch -- val: 0.8075 test: 0.7758

====epoch 60
Train Loss 24.561618664925273
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7944 test: 0.7635 | best val epoch -- val: 0.8075 test: 0.7758

====epoch 61
Train Loss 24.521898236031497
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7981 test: 0.7607 | best val epoch -- val: 0.8075 test: 0.7758

====epoch 62
Train Loss 24.19557229682636
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7943 test: 0.7647 | best val epoch -- val: 0.8075 test: 0.7758

====epoch 63
Train Loss 23.891195283345446
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7875 test: 0.7517 | best val epoch -- val: 0.8075 test: 0.7758

====epoch 64
Train Loss 23.94660119500617
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7900 test: 0.7529 | best val epoch -- val: 0.8075 test: 0.7758

====epoch 65
Train Loss 23.78274784009384
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7937 test: 0.7591 | best val epoch -- val: 0.8075 test: 0.7758

====epoch 66
Train Loss 23.857322272072995
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7915 test: 0.7645 | best val epoch -- val: 0.8075 test: 0.7758

====epoch 67
Train Loss 23.521301054376078
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7926 test: 0.7612 | best val epoch -- val: 0.8075 test: 0.7758

====epoch 68
Train Loss 23.503823473228756
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7928 test: 0.7613 | best val epoch -- val: 0.8075 test: 0.7758

====epoch 69
Train Loss 23.384995530305748
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7962 test: 0.7580 | best val epoch -- val: 0.8075 test: 0.7758

====epoch 70
Train Loss 23.223828973977916
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7927 test: 0.7533 | best val epoch -- val: 0.8075 test: 0.7758

====epoch 71
Train Loss 22.897007388798333
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7888 test: 0.7516 | best val epoch -- val: 0.8075 test: 0.7758

====epoch 72
Train Loss 23.067874815976293
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7908 test: 0.7577 | best val epoch -- val: 0.8075 test: 0.7758

====epoch 73
Train Loss 22.701523945313188
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7913 test: 0.7563 | best val epoch -- val: 0.8075 test: 0.7758

====epoch 74
Train Loss 22.536635146569996
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7895 test: 0.7567 | best val epoch -- val: 0.8075 test: 0.7758

====epoch 75
Train Loss 22.458988152377135
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7971 test: 0.7590 | best val epoch -- val: 0.8075 test: 0.7758

====epoch 76
Train Loss 22.202998203010566
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7956 test: 0.7565 | best val epoch -- val: 0.8075 test: 0.7758

====epoch 77
Train Loss 22.332771329117456
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7954 test: 0.7496 | best val epoch -- val: 0.8075 test: 0.7758

====epoch 78
Train Loss 22.360225653793286
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7888 test: 0.7493 | best val epoch -- val: 0.8075 test: 0.7758

====epoch 79
Train Loss 22.139887764230846
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7936 test: 0.7534 | best val epoch -- val: 0.8075 test: 0.7758

====epoch 80
Train Loss 22.190917091007034
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7955 test: 0.7576 | best val epoch -- val: 0.8075 test: 0.7758

====epoch 81
Train Loss 22.058726978464506
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7875 test: 0.7534 | best val epoch -- val: 0.8075 test: 0.7758

====epoch 82
Train Loss 21.713526256969782
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7935 test: 0.7609 | best val epoch -- val: 0.8075 test: 0.7758

====epoch 83
Train Loss 21.66429676562392
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7882 test: 0.7622 | best val epoch -- val: 0.8075 test: 0.7758

====epoch 84
Train Loss 21.788934871107877
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7892 test: 0.7576 | best val epoch -- val: 0.8075 test: 0.7758

====epoch 85
Train Loss 21.48519920810883
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7836 test: 0.7539 | best val epoch -- val: 0.8075 test: 0.7758

====epoch 86
Train Loss 21.103672183450286
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7867 test: 0.7535 | best val epoch -- val: 0.8075 test: 0.7758

====epoch 87
Train Loss 21.20954154967591
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7892 test: 0.7516 | best val epoch -- val: 0.8075 test: 0.7758

====epoch 88
Train Loss 21.147176409693586
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7822 test: 0.7550 | best val epoch -- val: 0.8075 test: 0.7758

====epoch 89
Train Loss 21.0370812875918
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7883 test: 0.7520 | best val epoch -- val: 0.8075 test: 0.7758

====epoch 90
Train Loss 20.833326943040774
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7940 test: 0.7523 | best val epoch -- val: 0.8075 test: 0.7758

====epoch 91
Train Loss 20.419626383957894
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7878 test: 0.7540 | best val epoch -- val: 0.8075 test: 0.7758

====epoch 92
Train Loss 20.737180325012968
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7815 test: 0.7465 | best val epoch -- val: 0.8075 test: 0.7758

====epoch 93
Train Loss 20.065998773771465
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7811 test: 0.7549 | best val epoch -- val: 0.8075 test: 0.7758

====epoch 94
Train Loss 20.582099332062786
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7768 test: 0.7535 | best val epoch -- val: 0.8075 test: 0.7758

====epoch 95
Train Loss 20.465539134489998
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7866 test: 0.7546 | best val epoch -- val: 0.8075 test: 0.7758

====epoch 96
Train Loss 20.23118562538136
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7859 test: 0.7554 | best val epoch -- val: 0.8075 test: 0.7758

====epoch 97
Train Loss 19.964495657686392
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7909 test: 0.7605 | best val epoch -- val: 0.8075 test: 0.7758

====epoch 98
Train Loss 20.06742079855058
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7868 test: 0.7516 | best val epoch -- val: 0.8075 test: 0.7758

====epoch 99
Train Loss 20.01521031361422
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7856 test: 0.7533 | best val epoch -- val: 0.8075 test: 0.7758

====epoch 100
Train Loss 19.855612968450014
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7802 test: 0.7511 | best val epoch -- val: 0.8075 test: 0.7758

[13:34:51] WARNING: not removing hydrogen atom without neighbors
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.4.
2022-09-13 13:34:54.297 | INFO     | modules.masked_transformer_encoder:__init__:122 - number of parameters: 0.000000e+00
=========================================
batch_size = 32
d_model = 128
dataset = tox21
decay = 0
device = 0
dim_feedforward = 512
eval_train = 0
filename =
gnn_JK = cat
gnn_dropout = 0.3
gnn_emb_dim = 300
gnn_num_layer = 5
gnn_residual = False
gnn_type = gin
gnn_virtual_node = False
graph_pooling = cls
input_model_file = models_graphtrans/graphtrans-sr-gcl.pth
lr = 0.0001
lr_scale = 1
max_input_len = 1000
nhead = 4
num_encoder_layers = 4
num_encoder_layers_masked = 0
num_workers = 0
pos_encoder = False
runseed = 3
seed = 12344
split = scaffold
transformer_activation = relu
transformer_dropout = 0.3
transformer_norm_input = True
transformer_prenorm = False
=========================================
tox21
scaffold
Loaded GraphTrans from models_graphtrans/graphtrans-sr-gcl.pth
====epoch 1
Train Loss 67.23776004849827
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.5326 test: 0.5474 | best val epoch -- val: 0.5326 test: 0.5474

====epoch 2
Train Loss 48.11687323735598
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.5997 test: 0.5970 | best val epoch -- val: 0.5997 test: 0.5970

====epoch 3
Train Loss 44.52150901119104
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7002 test: 0.6767 | best val epoch -- val: 0.7002 test: 0.6767

====epoch 4
Train Loss 41.23528457064309
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7431 test: 0.7026 | best val epoch -- val: 0.7431 test: 0.7026

====epoch 5
Train Loss 39.875477738412854
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7667 test: 0.7243 | best val epoch -- val: 0.7667 test: 0.7243

====epoch 6
Train Loss 38.64919351592949
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7826 test: 0.7362 | best val epoch -- val: 0.7826 test: 0.7362

====epoch 7
Train Loss 37.787946693158965
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7926 test: 0.7412 | best val epoch -- val: 0.7926 test: 0.7412

====epoch 8
Train Loss 37.32834731423452
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7975 test: 0.7430 | best val epoch -- val: 0.7975 test: 0.7430

====epoch 9
Train Loss 36.06067357969685
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7980 test: 0.7425 | best val epoch -- val: 0.7980 test: 0.7425

====epoch 10
Train Loss 35.78540558960134
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7923 test: 0.7448 | best val epoch -- val: 0.7980 test: 0.7425

====epoch 11
Train Loss 35.20804196678341
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7936 test: 0.7465 | best val epoch -- val: 0.7980 test: 0.7425

====epoch 12
Train Loss 34.75009686714258
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7954 test: 0.7508 | best val epoch -- val: 0.7980 test: 0.7425

====epoch 13
Train Loss 34.472749809309356
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7873 test: 0.7571 | best val epoch -- val: 0.7980 test: 0.7425

====epoch 14
Train Loss 33.47237617272977
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7894 test: 0.7580 | best val epoch -- val: 0.7980 test: 0.7425

====epoch 15
Train Loss 33.521214214543356
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7886 test: 0.7585 | best val epoch -- val: 0.7980 test: 0.7425

====epoch 16
Train Loss 32.866298130068124
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7981 test: 0.7622 | best val epoch -- val: 0.7981 test: 0.7622

====epoch 17
Train Loss 32.794382913820996
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7954 test: 0.7624 | best val epoch -- val: 0.7981 test: 0.7622

====epoch 18
Train Loss 32.59470334135392
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8021 test: 0.7773 | best val epoch -- val: 0.8021 test: 0.7773

====epoch 19
Train Loss 32.20108198895013
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7981 test: 0.7651 | best val epoch -- val: 0.8021 test: 0.7773

====epoch 20
Train Loss 31.98558265738025
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8004 test: 0.7714 | best val epoch -- val: 0.8021 test: 0.7773

====epoch 21
Train Loss 31.875786110643322
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8008 test: 0.7677 | best val epoch -- val: 0.8021 test: 0.7773

====epoch 22
Train Loss 31.692282900021898
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8004 test: 0.7743 | best val epoch -- val: 0.8021 test: 0.7773

====epoch 23
Train Loss 31.377707257584923
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8058 test: 0.7742 | best val epoch -- val: 0.8058 test: 0.7742

====epoch 24
Train Loss 30.969134222179846
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8053 test: 0.7649 | best val epoch -- val: 0.8058 test: 0.7742

====epoch 25
Train Loss 30.84915351354313
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8042 test: 0.7673 | best val epoch -- val: 0.8058 test: 0.7742

====epoch 26
Train Loss 30.448200999432903
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8044 test: 0.7696 | best val epoch -- val: 0.8058 test: 0.7742

====epoch 27
Train Loss 30.126315369577608
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8054 test: 0.7690 | best val epoch -- val: 0.8058 test: 0.7742

====epoch 28
Train Loss 30.049990349261616
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8066 test: 0.7671 | best val epoch -- val: 0.8066 test: 0.7671

====epoch 29
Train Loss 29.79742121281973
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8037 test: 0.7711 | best val epoch -- val: 0.8066 test: 0.7671

====epoch 30
Train Loss 29.49247669220648
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8026 test: 0.7682 | best val epoch -- val: 0.8066 test: 0.7671

====epoch 31
Train Loss 29.301476191834805
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8106 test: 0.7729 | best val epoch -- val: 0.8106 test: 0.7729

====epoch 32
Train Loss 29.239452509900456
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8062 test: 0.7652 | best val epoch -- val: 0.8106 test: 0.7729

====epoch 33
Train Loss 28.893378408512728
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8003 test: 0.7710 | best val epoch -- val: 0.8106 test: 0.7729

====epoch 34
Train Loss 28.907669512323984
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8001 test: 0.7694 | best val epoch -- val: 0.8106 test: 0.7729

====epoch 35
Train Loss 28.538175221308354
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8028 test: 0.7675 | best val epoch -- val: 0.8106 test: 0.7729

====epoch 36
Train Loss 28.463545243392534
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8048 test: 0.7671 | best val epoch -- val: 0.8106 test: 0.7729

====epoch 37
Train Loss 28.75348467115871
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8028 test: 0.7658 | best val epoch -- val: 0.8106 test: 0.7729

====epoch 38
Train Loss 28.06804490862459
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8075 test: 0.7672 | best val epoch -- val: 0.8106 test: 0.7729

====epoch 39
Train Loss 28.06727897414661
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8063 test: 0.7705 | best val epoch -- val: 0.8106 test: 0.7729

====epoch 40
Train Loss 27.674377930864242
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8019 test: 0.7652 | best val epoch -- val: 0.8106 test: 0.7729

====epoch 41
Train Loss 27.4374877187642
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8105 test: 0.7628 | best val epoch -- val: 0.8106 test: 0.7729

====epoch 42
Train Loss 27.62013507695745
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8079 test: 0.7648 | best val epoch -- val: 0.8106 test: 0.7729

====epoch 43
Train Loss 27.495658298423283
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8120 test: 0.7589 | best val epoch -- val: 0.8120 test: 0.7589

====epoch 44
Train Loss 27.344672082685065
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8090 test: 0.7610 | best val epoch -- val: 0.8120 test: 0.7589

====epoch 45
Train Loss 27.020118940445194
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8061 test: 0.7642 | best val epoch -- val: 0.8120 test: 0.7589

====epoch 46
Train Loss 26.897228435759715
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8062 test: 0.7711 | best val epoch -- val: 0.8120 test: 0.7589

====epoch 47
Train Loss 26.440551869485233
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8081 test: 0.7726 | best val epoch -- val: 0.8120 test: 0.7589

====epoch 48
Train Loss 26.673123514201052
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8044 test: 0.7645 | best val epoch -- val: 0.8120 test: 0.7589

====epoch 49
Train Loss 26.460912816572353
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8032 test: 0.7668 | best val epoch -- val: 0.8120 test: 0.7589

====epoch 50
Train Loss 26.20330961185568
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8097 test: 0.7595 | best val epoch -- val: 0.8120 test: 0.7589

====epoch 51
Train Loss 26.33047076179542
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8107 test: 0.7649 | best val epoch -- val: 0.8120 test: 0.7589

====epoch 52
Train Loss 25.877845632089674
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8031 test: 0.7561 | best val epoch -- val: 0.8120 test: 0.7589

====epoch 53
Train Loss 25.64273167100046
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8110 test: 0.7712 | best val epoch -- val: 0.8120 test: 0.7589

====epoch 54
Train Loss 25.758703363761473
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8060 test: 0.7490 | best val epoch -- val: 0.8120 test: 0.7589

====epoch 55
Train Loss 25.609523251031977
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8059 test: 0.7592 | best val epoch -- val: 0.8120 test: 0.7589

====epoch 56
Train Loss 25.60095974972378
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8100 test: 0.7619 | best val epoch -- val: 0.8120 test: 0.7589

====epoch 57
Train Loss 25.39326053222908
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8040 test: 0.7617 | best val epoch -- val: 0.8120 test: 0.7589

====epoch 58
Train Loss 24.95847265871315
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8075 test: 0.7588 | best val epoch -- val: 0.8120 test: 0.7589

====epoch 59
Train Loss 24.777871766340215
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8072 test: 0.7583 | best val epoch -- val: 0.8120 test: 0.7589

====epoch 60
Train Loss 25.040874472312552
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8010 test: 0.7633 | best val epoch -- val: 0.8120 test: 0.7589

====epoch 61
Train Loss 24.65277197793749
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7956 test: 0.7664 | best val epoch -- val: 0.8120 test: 0.7589

====epoch 62
Train Loss 24.907289357904535
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7952 test: 0.7588 | best val epoch -- val: 0.8120 test: 0.7589

====epoch 63
Train Loss 24.47837486229743
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7992 test: 0.7546 | best val epoch -- val: 0.8120 test: 0.7589

====epoch 64
Train Loss 23.94721878645775
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7976 test: 0.7586 | best val epoch -- val: 0.8120 test: 0.7589

====epoch 65
Train Loss 23.942647317004955
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8008 test: 0.7589 | best val epoch -- val: 0.8120 test: 0.7589

====epoch 66
Train Loss 24.302078378446797
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8051 test: 0.7651 | best val epoch -- val: 0.8120 test: 0.7589

====epoch 67
Train Loss 24.02900484560426
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8052 test: 0.7655 | best val epoch -- val: 0.8120 test: 0.7589

====epoch 68
Train Loss 23.983237294118624
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7935 test: 0.7553 | best val epoch -- val: 0.8120 test: 0.7589

====epoch 69
Train Loss 23.87418978909968
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8053 test: 0.7621 | best val epoch -- val: 0.8120 test: 0.7589

====epoch 70
Train Loss 23.596650586641424
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8019 test: 0.7590 | best val epoch -- val: 0.8120 test: 0.7589

====epoch 71
Train Loss 23.582111786500715
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7931 test: 0.7572 | best val epoch -- val: 0.8120 test: 0.7589

====epoch 72
Train Loss 23.21538283334124
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7926 test: 0.7544 | best val epoch -- val: 0.8120 test: 0.7589

====epoch 73
Train Loss 23.215550126993207
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7961 test: 0.7609 | best val epoch -- val: 0.8120 test: 0.7589

====epoch 74
Train Loss 23.1314383160128
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7955 test: 0.7603 | best val epoch -- val: 0.8120 test: 0.7589

====epoch 75
Train Loss 23.086796274514082
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8029 test: 0.7530 | best val epoch -- val: 0.8120 test: 0.7589

====epoch 76
Train Loss 22.677309612428438
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7906 test: 0.7507 | best val epoch -- val: 0.8120 test: 0.7589

====epoch 77
Train Loss 22.815815492687005
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7962 test: 0.7582 | best val epoch -- val: 0.8120 test: 0.7589

====epoch 78
Train Loss 22.515218587241087
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8010 test: 0.7622 | best val epoch -- val: 0.8120 test: 0.7589

====epoch 79
Train Loss 22.480008448114102
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8015 test: 0.7604 | best val epoch -- val: 0.8120 test: 0.7589

====epoch 80
Train Loss 22.243383715208797
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8025 test: 0.7650 | best val epoch -- val: 0.8120 test: 0.7589

====epoch 81
Train Loss 22.305508431436007
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7928 test: 0.7561 | best val epoch -- val: 0.8120 test: 0.7589

====epoch 82
Train Loss 22.182658621998563
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8008 test: 0.7659 | best val epoch -- val: 0.8120 test: 0.7589

====epoch 83
Train Loss 21.641106353406737
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8014 test: 0.7582 | best val epoch -- val: 0.8120 test: 0.7589

====epoch 84
Train Loss 22.19126994480591
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7953 test: 0.7580 | best val epoch -- val: 0.8120 test: 0.7589

====epoch 85
Train Loss 22.017636926328965
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7949 test: 0.7598 | best val epoch -- val: 0.8120 test: 0.7589

====epoch 86
Train Loss 21.661688406806906
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7986 test: 0.7569 | best val epoch -- val: 0.8120 test: 0.7589

====epoch 87
Train Loss 21.392940304021074
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7923 test: 0.7573 | best val epoch -- val: 0.8120 test: 0.7589

====epoch 88
Train Loss 21.30361749973687
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8068 test: 0.7659 | best val epoch -- val: 0.8120 test: 0.7589

====epoch 89
Train Loss 20.881364645291175
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7925 test: 0.7598 | best val epoch -- val: 0.8120 test: 0.7589

====epoch 90
Train Loss 20.759231640064826
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7917 test: 0.7455 | best val epoch -- val: 0.8120 test: 0.7589

====epoch 91
Train Loss 21.244729979162663
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7943 test: 0.7555 | best val epoch -- val: 0.8120 test: 0.7589

====epoch 92
Train Loss 20.940360314255635
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7937 test: 0.7546 | best val epoch -- val: 0.8120 test: 0.7589

====epoch 93
Train Loss 20.904077108096576
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7985 test: 0.7549 | best val epoch -- val: 0.8120 test: 0.7589

====epoch 94
Train Loss 20.62579604183579
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8005 test: 0.7562 | best val epoch -- val: 0.8120 test: 0.7589

====epoch 95
Train Loss 20.597993217014835
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7943 test: 0.7593 | best val epoch -- val: 0.8120 test: 0.7589

====epoch 96
Train Loss 20.23742187947562
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7900 test: 0.7566 | best val epoch -- val: 0.8120 test: 0.7589

====epoch 97
Train Loss 20.74157628413278
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7976 test: 0.7602 | best val epoch -- val: 0.8120 test: 0.7589

====epoch 98
Train Loss 20.36908027697865
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7938 test: 0.7601 | best val epoch -- val: 0.8120 test: 0.7589

====epoch 99
Train Loss 20.10386125507538
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7974 test: 0.7555 | best val epoch -- val: 0.8120 test: 0.7589

====epoch 100
Train Loss 20.05536457426609
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7795 test: 0.7527 | best val epoch -- val: 0.8120 test: 0.7589

[13:48:10] WARNING: not removing hydrogen atom without neighbors
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.4.
2022-09-13 13:48:13.058 | INFO     | modules.masked_transformer_encoder:__init__:122 - number of parameters: 0.000000e+00
=========================================
batch_size = 32
d_model = 128
dataset = tox21
decay = 0
device = 0
dim_feedforward = 512
eval_train = 0
filename =
gnn_JK = cat
gnn_dropout = 0.3
gnn_emb_dim = 300
gnn_num_layer = 5
gnn_residual = False
gnn_type = gin
gnn_virtual_node = False
graph_pooling = cls
input_model_file = models_graphtrans/graphtrans-sr-gcl.pth
lr = 0.0001
lr_scale = 1
max_input_len = 1000
nhead = 4
num_encoder_layers = 4
num_encoder_layers_masked = 0
num_workers = 0
pos_encoder = False
runseed = 4
seed = 12344
split = scaffold
transformer_activation = relu
transformer_dropout = 0.3
transformer_norm_input = True
transformer_prenorm = False
=========================================
tox21
scaffold
Loaded GraphTrans from models_graphtrans/graphtrans-sr-gcl.pth
====epoch 1
Train Loss 65.65588054152852
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.5638 test: 0.5717 | best val epoch -- val: 0.5638 test: 0.5717

====epoch 2
Train Loss 47.412541492827565
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6541 test: 0.6347 | best val epoch -- val: 0.6541 test: 0.6347

====epoch 3
Train Loss 42.43693789350194
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7353 test: 0.7124 | best val epoch -- val: 0.7353 test: 0.7124

====epoch 4
Train Loss 40.36416062156612
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7624 test: 0.7234 | best val epoch -- val: 0.7624 test: 0.7234

====epoch 5
Train Loss 38.93579766997685
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7673 test: 0.7314 | best val epoch -- val: 0.7673 test: 0.7314

====epoch 6
Train Loss 37.906623074859496
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7790 test: 0.7375 | best val epoch -- val: 0.7790 test: 0.7375

====epoch 7
Train Loss 36.910935761215086
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7786 test: 0.7470 | best val epoch -- val: 0.7790 test: 0.7375

====epoch 8
Train Loss 36.16131696305774
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7811 test: 0.7528 | best val epoch -- val: 0.7811 test: 0.7528

====epoch 9
Train Loss 35.67102314286069
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7798 test: 0.7538 | best val epoch -- val: 0.7811 test: 0.7528

====epoch 10
Train Loss 34.7883775795373
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7816 test: 0.7550 | best val epoch -- val: 0.7816 test: 0.7550

====epoch 11
Train Loss 34.36160879952016
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7790 test: 0.7534 | best val epoch -- val: 0.7816 test: 0.7550

====epoch 12
Train Loss 33.93035505730406
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7763 test: 0.7609 | best val epoch -- val: 0.7816 test: 0.7550

====epoch 13
Train Loss 33.624935860808726
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7824 test: 0.7585 | best val epoch -- val: 0.7824 test: 0.7585

====epoch 14
Train Loss 33.46641601203584
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7866 test: 0.7643 | best val epoch -- val: 0.7866 test: 0.7643

====epoch 15
Train Loss 33.16410612856056
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7858 test: 0.7714 | best val epoch -- val: 0.7866 test: 0.7643

====epoch 16
Train Loss 32.59995008108242
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7875 test: 0.7630 | best val epoch -- val: 0.7875 test: 0.7630

====epoch 17
Train Loss 32.534901064508674
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7931 test: 0.7639 | best val epoch -- val: 0.7931 test: 0.7639

====epoch 18
Train Loss 32.050323421778344
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7851 test: 0.7596 | best val epoch -- val: 0.7931 test: 0.7639

====epoch 19
Train Loss 31.964235222364504
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7876 test: 0.7694 | best val epoch -- val: 0.7931 test: 0.7639

====epoch 20
Train Loss 31.655013290854107
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7873 test: 0.7712 | best val epoch -- val: 0.7931 test: 0.7639

====epoch 21
Train Loss 31.501186694476683
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7904 test: 0.7665 | best val epoch -- val: 0.7931 test: 0.7639

====epoch 22
Train Loss 31.12863444634224
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7925 test: 0.7681 | best val epoch -- val: 0.7931 test: 0.7639

====epoch 23
Train Loss 30.687136350875257
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7882 test: 0.7689 | best val epoch -- val: 0.7931 test: 0.7639

====epoch 24
Train Loss 30.671629031927726
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7916 test: 0.7720 | best val epoch -- val: 0.7931 test: 0.7639

====epoch 25
Train Loss 30.415507380990526
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7981 test: 0.7769 | best val epoch -- val: 0.7981 test: 0.7769

====epoch 26
Train Loss 29.789631207616118
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7973 test: 0.7718 | best val epoch -- val: 0.7981 test: 0.7769

====epoch 27
Train Loss 30.05164506743983
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7998 test: 0.7758 | best val epoch -- val: 0.7998 test: 0.7758

====epoch 28
Train Loss 29.15613699022155
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7961 test: 0.7730 | best val epoch -- val: 0.7998 test: 0.7758

====epoch 29
Train Loss 29.665025974077032
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7968 test: 0.7745 | best val epoch -- val: 0.7998 test: 0.7758

====epoch 30
Train Loss 29.27223150408012
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7969 test: 0.7821 | best val epoch -- val: 0.7998 test: 0.7758

====epoch 31
Train Loss 28.89027226402668
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7980 test: 0.7720 | best val epoch -- val: 0.7998 test: 0.7758

====epoch 32
Train Loss 29.09869887821813
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7949 test: 0.7758 | best val epoch -- val: 0.7998 test: 0.7758

====epoch 33
Train Loss 28.423116667658306
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7935 test: 0.7777 | best val epoch -- val: 0.7998 test: 0.7758

====epoch 34
Train Loss 28.47082971728606
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7897 test: 0.7760 | best val epoch -- val: 0.7998 test: 0.7758

====epoch 35
Train Loss 28.22111804511152
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7970 test: 0.7774 | best val epoch -- val: 0.7998 test: 0.7758

====epoch 36
Train Loss 28.3261391836596
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7977 test: 0.7767 | best val epoch -- val: 0.7998 test: 0.7758

====epoch 37
Train Loss 28.116423653927697
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7980 test: 0.7731 | best val epoch -- val: 0.7998 test: 0.7758

====epoch 38
Train Loss 27.86714716947559
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8004 test: 0.7777 | best val epoch -- val: 0.8004 test: 0.7777

====epoch 39
Train Loss 28.05161796740649
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7959 test: 0.7767 | best val epoch -- val: 0.8004 test: 0.7777

====epoch 40
Train Loss 27.200919033743965
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7928 test: 0.7675 | best val epoch -- val: 0.8004 test: 0.7777

====epoch 41
Train Loss 27.369691640341852
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7902 test: 0.7742 | best val epoch -- val: 0.8004 test: 0.7777

====epoch 42
Train Loss 27.274663665645512
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7962 test: 0.7766 | best val epoch -- val: 0.8004 test: 0.7777

====epoch 43
Train Loss 26.84554804329128
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7947 test: 0.7661 | best val epoch -- val: 0.8004 test: 0.7777

====epoch 44
Train Loss 26.883689925466182
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7937 test: 0.7740 | best val epoch -- val: 0.8004 test: 0.7777

====epoch 45
Train Loss 26.710223096741977
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7971 test: 0.7688 | best val epoch -- val: 0.8004 test: 0.7777

====epoch 46
Train Loss 26.657206824406003
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7979 test: 0.7692 | best val epoch -- val: 0.8004 test: 0.7777

====epoch 47
Train Loss 26.554710410458735
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7987 test: 0.7696 | best val epoch -- val: 0.8004 test: 0.7777

====epoch 48
Train Loss 26.19049787532616
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7971 test: 0.7623 | best val epoch -- val: 0.8004 test: 0.7777

====epoch 49
Train Loss 26.098914262294297
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7894 test: 0.7682 | best val epoch -- val: 0.8004 test: 0.7777

====epoch 50
Train Loss 26.04266649363609
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7945 test: 0.7638 | best val epoch -- val: 0.8004 test: 0.7777

====epoch 51
Train Loss 25.93860127933113
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7919 test: 0.7777 | best val epoch -- val: 0.8004 test: 0.7777

====epoch 52
Train Loss 25.469323214395963
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7926 test: 0.7686 | best val epoch -- val: 0.8004 test: 0.7777

====epoch 53
Train Loss 25.385733079654468
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7945 test: 0.7647 | best val epoch -- val: 0.8004 test: 0.7777

====epoch 54
Train Loss 25.330553556658757
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7989 test: 0.7628 | best val epoch -- val: 0.8004 test: 0.7777

====epoch 55
Train Loss 25.673583392582877
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7962 test: 0.7723 | best val epoch -- val: 0.8004 test: 0.7777

====epoch 56
Train Loss 25.074888564303503
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7884 test: 0.7682 | best val epoch -- val: 0.8004 test: 0.7777

====epoch 57
Train Loss 25.047266373390446
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7944 test: 0.7667 | best val epoch -- val: 0.8004 test: 0.7777

====epoch 58
Train Loss 24.699711179788896
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7988 test: 0.7739 | best val epoch -- val: 0.8004 test: 0.7777

====epoch 59
Train Loss 24.63542482836657
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8007 test: 0.7718 | best val epoch -- val: 0.8007 test: 0.7718

====epoch 60
Train Loss 24.44014731423701
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7973 test: 0.7649 | best val epoch -- val: 0.8007 test: 0.7718

====epoch 61
Train Loss 24.176225002797494
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7976 test: 0.7688 | best val epoch -- val: 0.8007 test: 0.7718

====epoch 62
Train Loss 24.58494513729145
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8028 test: 0.7654 | best val epoch -- val: 0.8028 test: 0.7654

====epoch 63
Train Loss 24.00107710581286
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8058 test: 0.7651 | best val epoch -- val: 0.8058 test: 0.7651

====epoch 64
Train Loss 24.010746733366346
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8027 test: 0.7629 | best val epoch -- val: 0.8058 test: 0.7651

====epoch 65
Train Loss 24.152435177207096
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8008 test: 0.7637 | best val epoch -- val: 0.8058 test: 0.7651

====epoch 66
Train Loss 23.709887691911007
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7991 test: 0.7623 | best val epoch -- val: 0.8058 test: 0.7651

====epoch 67
Train Loss 23.68199037182046
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7996 test: 0.7612 | best val epoch -- val: 0.8058 test: 0.7651

====epoch 68
Train Loss 23.25381963824384
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7979 test: 0.7557 | best val epoch -- val: 0.8058 test: 0.7651

====epoch 69
Train Loss 23.42678793138051
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7925 test: 0.7573 | best val epoch -- val: 0.8058 test: 0.7651

====epoch 70
Train Loss 23.19674120773269
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7974 test: 0.7548 | best val epoch -- val: 0.8058 test: 0.7651

====epoch 71
Train Loss 23.16038200158161
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8007 test: 0.7637 | best val epoch -- val: 0.8058 test: 0.7651

====epoch 72
Train Loss 23.1299965353197
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8009 test: 0.7640 | best val epoch -- val: 0.8058 test: 0.7651

====epoch 73
Train Loss 22.974829248470314
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7952 test: 0.7607 | best val epoch -- val: 0.8058 test: 0.7651

====epoch 74
Train Loss 22.828330180790402
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8039 test: 0.7633 | best val epoch -- val: 0.8058 test: 0.7651

====epoch 75
Train Loss 22.6175366499202
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8046 test: 0.7653 | best val epoch -- val: 0.8058 test: 0.7651

====epoch 76
Train Loss 22.444809871595492
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7986 test: 0.7584 | best val epoch -- val: 0.8058 test: 0.7651

====epoch 77
Train Loss 22.387506853413353
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8000 test: 0.7526 | best val epoch -- val: 0.8058 test: 0.7651

====epoch 78
Train Loss 22.386223426019427
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7978 test: 0.7524 | best val epoch -- val: 0.8058 test: 0.7651

====epoch 79
Train Loss 22.289640503008286
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7981 test: 0.7560 | best val epoch -- val: 0.8058 test: 0.7651

====epoch 80
Train Loss 21.873106657931547
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7993 test: 0.7512 | best val epoch -- val: 0.8058 test: 0.7651

====epoch 81
Train Loss 21.88393132257116
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8024 test: 0.7558 | best val epoch -- val: 0.8058 test: 0.7651

====epoch 82
Train Loss 22.006324324761852
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7990 test: 0.7578 | best val epoch -- val: 0.8058 test: 0.7651

====epoch 83
Train Loss 21.74564253694403
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7956 test: 0.7625 | best val epoch -- val: 0.8058 test: 0.7651

====epoch 84
Train Loss 21.68023041528298
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7900 test: 0.7523 | best val epoch -- val: 0.8058 test: 0.7651

====epoch 85
Train Loss 21.189613427086293
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7932 test: 0.7496 | best val epoch -- val: 0.8058 test: 0.7651

====epoch 86
Train Loss 21.58222340601184
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7962 test: 0.7538 | best val epoch -- val: 0.8058 test: 0.7651

====epoch 87
Train Loss 21.263135245115723
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7962 test: 0.7525 | best val epoch -- val: 0.8058 test: 0.7651

====epoch 88
Train Loss 20.874443867399876
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7972 test: 0.7483 | best val epoch -- val: 0.8058 test: 0.7651

====epoch 89
Train Loss 21.21490540304681
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7969 test: 0.7450 | best val epoch -- val: 0.8058 test: 0.7651

====epoch 90
Train Loss 21.00438264649328
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8020 test: 0.7466 | best val epoch -- val: 0.8058 test: 0.7651

====epoch 91
Train Loss 20.82025788309
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7967 test: 0.7488 | best val epoch -- val: 0.8058 test: 0.7651

====epoch 92
Train Loss 20.764925597969473
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8005 test: 0.7456 | best val epoch -- val: 0.8058 test: 0.7651

====epoch 93
Train Loss 20.691065186632898
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8017 test: 0.7445 | best val epoch -- val: 0.8058 test: 0.7651

====epoch 94
Train Loss 20.320857554419348
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7992 test: 0.7479 | best val epoch -- val: 0.8058 test: 0.7651

====epoch 95
Train Loss 20.164102294971045
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8001 test: 0.7499 | best val epoch -- val: 0.8058 test: 0.7651

====epoch 96
Train Loss 20.480136185965545
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8003 test: 0.7469 | best val epoch -- val: 0.8058 test: 0.7651

====epoch 97
Train Loss 19.96543345995178
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8016 test: 0.7442 | best val epoch -- val: 0.8058 test: 0.7651

====epoch 98
Train Loss 20.080091252471213
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7985 test: 0.7445 | best val epoch -- val: 0.8058 test: 0.7651

====epoch 99
Train Loss 20.041731102527606
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7966 test: 0.7494 | best val epoch -- val: 0.8058 test: 0.7651

====epoch 100
Train Loss 19.97829658847751
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7936 test: 0.7423 | best val epoch -- val: 0.8058 test: 0.7651

[14:01:49] WARNING: not removing hydrogen atom without neighbors
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.4.
2022-09-13 14:01:50.948 | INFO     | modules.masked_transformer_encoder:__init__:122 - number of parameters: 0.000000e+00
=========================================
batch_size = 32
d_model = 128
dataset = tox21
decay = 0
device = 0
dim_feedforward = 512
eval_train = 0
filename =
gnn_JK = cat
gnn_dropout = 0.3
gnn_emb_dim = 300
gnn_num_layer = 5
gnn_residual = False
gnn_type = gin
gnn_virtual_node = False
graph_pooling = cls
input_model_file = models_graphtrans/graphtrans-sr-gcl.pth
lr = 0.0001
lr_scale = 1
max_input_len = 1000
nhead = 4
num_encoder_layers = 4
num_encoder_layers_masked = 0
num_workers = 0
pos_encoder = False
runseed = 5
seed = 12344
split = scaffold
transformer_activation = relu
transformer_dropout = 0.3
transformer_norm_input = True
transformer_prenorm = False
=========================================
tox21
scaffold
Loaded GraphTrans from models_graphtrans/graphtrans-sr-gcl.pth
====epoch 1
Train Loss 61.922838148280356
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.5505 test: 0.5224 | best val epoch -- val: 0.5505 test: 0.5224

====epoch 2
Train Loss 47.712250979042764
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6404 test: 0.6143 | best val epoch -- val: 0.6404 test: 0.6143

====epoch 3
Train Loss 43.748380832415506
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7295 test: 0.6954 | best val epoch -- val: 0.7295 test: 0.6954

====epoch 4
Train Loss 41.145478061824285
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7450 test: 0.7189 | best val epoch -- val: 0.7450 test: 0.7189

====epoch 5
Train Loss 39.416087790569
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7587 test: 0.7314 | best val epoch -- val: 0.7587 test: 0.7314

====epoch 6
Train Loss 38.10787883876189
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7693 test: 0.7371 | best val epoch -- val: 0.7693 test: 0.7371

====epoch 7
Train Loss 37.4713067604984
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7747 test: 0.7468 | best val epoch -- val: 0.7747 test: 0.7468

====epoch 8
Train Loss 36.97462246552613
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7840 test: 0.7399 | best val epoch -- val: 0.7840 test: 0.7399

====epoch 9
Train Loss 35.77123650621045
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7861 test: 0.7460 | best val epoch -- val: 0.7861 test: 0.7460

====epoch 10
Train Loss 35.517668973795374
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7858 test: 0.7508 | best val epoch -- val: 0.7861 test: 0.7460

====epoch 11
Train Loss 35.303578180143006
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7949 test: 0.7553 | best val epoch -- val: 0.7949 test: 0.7553

====epoch 12
Train Loss 34.73703546501265
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7937 test: 0.7545 | best val epoch -- val: 0.7949 test: 0.7553

====epoch 13
Train Loss 34.03079541968872
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7817 test: 0.7611 | best val epoch -- val: 0.7949 test: 0.7553

====epoch 14
Train Loss 33.66790487002025
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7901 test: 0.7683 | best val epoch -- val: 0.7949 test: 0.7553

====epoch 15
Train Loss 33.663696443689155
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7949 test: 0.7663 | best val epoch -- val: 0.7949 test: 0.7553

====epoch 16
Train Loss 33.195154281829865
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7922 test: 0.7694 | best val epoch -- val: 0.7949 test: 0.7553

====epoch 17
Train Loss 32.70936691538908
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7969 test: 0.7684 | best val epoch -- val: 0.7969 test: 0.7684

====epoch 18
Train Loss 32.42068276255011
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7991 test: 0.7739 | best val epoch -- val: 0.7991 test: 0.7739

====epoch 19
Train Loss 32.25445736725567
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8010 test: 0.7778 | best val epoch -- val: 0.8010 test: 0.7778

====epoch 20
Train Loss 32.07979023189444
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7989 test: 0.7772 | best val epoch -- val: 0.8010 test: 0.7778

====epoch 21
Train Loss 31.82028180200813
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8040 test: 0.7788 | best val epoch -- val: 0.8040 test: 0.7788

====epoch 22
Train Loss 31.365106860796292
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7999 test: 0.7791 | best val epoch -- val: 0.8040 test: 0.7788

====epoch 23
Train Loss 31.427203987252316
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7997 test: 0.7758 | best val epoch -- val: 0.8040 test: 0.7788

====epoch 24
Train Loss 31.02472475431356
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8066 test: 0.7768 | best val epoch -- val: 0.8066 test: 0.7768

====epoch 25
Train Loss 30.514155794138922
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8011 test: 0.7782 | best val epoch -- val: 0.8066 test: 0.7768

====epoch 26
Train Loss 30.741827239019266
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8020 test: 0.7820 | best val epoch -- val: 0.8066 test: 0.7768

====epoch 27
Train Loss 30.41310231780266
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8044 test: 0.7776 | best val epoch -- val: 0.8066 test: 0.7768

====epoch 28
Train Loss 29.978325471269706
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7965 test: 0.7737 | best val epoch -- val: 0.8066 test: 0.7768

====epoch 29
Train Loss 29.646701094316043
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7973 test: 0.7856 | best val epoch -- val: 0.8066 test: 0.7768

====epoch 30
Train Loss 29.63234667814977
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8012 test: 0.7782 | best val epoch -- val: 0.8066 test: 0.7768

====epoch 31
Train Loss 29.453517439719395
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8040 test: 0.7777 | best val epoch -- val: 0.8066 test: 0.7768

====epoch 32
Train Loss 29.341866063172613
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8009 test: 0.7822 | best val epoch -- val: 0.8066 test: 0.7768

====epoch 33
Train Loss 28.905347661206548
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8004 test: 0.7796 | best val epoch -- val: 0.8066 test: 0.7768

====epoch 34
Train Loss 28.79673689855947
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7901 test: 0.7773 | best val epoch -- val: 0.8066 test: 0.7768

====epoch 35
Train Loss 29.07900110258583
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7916 test: 0.7793 | best val epoch -- val: 0.8066 test: 0.7768

====epoch 36
Train Loss 28.352116095513363
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7943 test: 0.7767 | best val epoch -- val: 0.8066 test: 0.7768

====epoch 37
Train Loss 28.469599562360862
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7998 test: 0.7834 | best val epoch -- val: 0.8066 test: 0.7768

====epoch 38
Train Loss 27.992761955139763
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7952 test: 0.7791 | best val epoch -- val: 0.8066 test: 0.7768

====epoch 39
Train Loss 27.932514204187733
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8069 test: 0.7831 | best val epoch -- val: 0.8069 test: 0.7831

====epoch 40
Train Loss 27.853594246581377
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8002 test: 0.7726 | best val epoch -- val: 0.8069 test: 0.7831

====epoch 41
Train Loss 27.75676387969938
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8010 test: 0.7779 | best val epoch -- val: 0.8069 test: 0.7831

====epoch 42
Train Loss 27.539721650088463
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7954 test: 0.7721 | best val epoch -- val: 0.8069 test: 0.7831

====epoch 43
Train Loss 27.470814715430894
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8012 test: 0.7768 | best val epoch -- val: 0.8069 test: 0.7831

====epoch 44
Train Loss 27.353263801139025
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7956 test: 0.7725 | best val epoch -- val: 0.8069 test: 0.7831

====epoch 45
Train Loss 27.176872834164215
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8049 test: 0.7791 | best val epoch -- val: 0.8069 test: 0.7831

====epoch 46
Train Loss 26.810735363359402
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7864 test: 0.7631 | best val epoch -- val: 0.8069 test: 0.7831

====epoch 47
Train Loss 26.72073617671391
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7997 test: 0.7739 | best val epoch -- val: 0.8069 test: 0.7831

====epoch 48
Train Loss 26.632711899873073
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8020 test: 0.7757 | best val epoch -- val: 0.8069 test: 0.7831

====epoch 49
Train Loss 26.464366015567208
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8003 test: 0.7774 | best val epoch -- val: 0.8069 test: 0.7831

====epoch 50
Train Loss 25.876828095774513
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7912 test: 0.7729 | best val epoch -- val: 0.8069 test: 0.7831

====epoch 51
Train Loss 25.90159390627337
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7943 test: 0.7779 | best val epoch -- val: 0.8069 test: 0.7831

====epoch 52
Train Loss 26.143618178415085
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8030 test: 0.7719 | best val epoch -- val: 0.8069 test: 0.7831

====epoch 53
Train Loss 25.986110194814408
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7916 test: 0.7718 | best val epoch -- val: 0.8069 test: 0.7831

====epoch 54
Train Loss 26.086808332222194
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7880 test: 0.7671 | best val epoch -- val: 0.8069 test: 0.7831

====epoch 55
Train Loss 25.793072018457085
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8027 test: 0.7677 | best val epoch -- val: 0.8069 test: 0.7831

====epoch 56
Train Loss 25.257889469804322
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7976 test: 0.7669 | best val epoch -- val: 0.8069 test: 0.7831

====epoch 57
Train Loss 25.376201877034664
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8028 test: 0.7699 | best val epoch -- val: 0.8069 test: 0.7831

====epoch 58
Train Loss 25.254644678305365
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8029 test: 0.7714 | best val epoch -- val: 0.8069 test: 0.7831

====epoch 59
Train Loss 25.250710780237792
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7991 test: 0.7715 | best val epoch -- val: 0.8069 test: 0.7831

====epoch 60
Train Loss 25.094003462852527
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7989 test: 0.7648 | best val epoch -- val: 0.8069 test: 0.7831

====epoch 61
Train Loss 25.038065015537303
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8033 test: 0.7720 | best val epoch -- val: 0.8069 test: 0.7831

====epoch 62
Train Loss 24.59606810200676
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8034 test: 0.7701 | best val epoch -- val: 0.8069 test: 0.7831

====epoch 63
Train Loss 24.860953835502283
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8029 test: 0.7686 | best val epoch -- val: 0.8069 test: 0.7831

====epoch 64
Train Loss 24.499770724089185
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8059 test: 0.7699 | best val epoch -- val: 0.8069 test: 0.7831

====epoch 65
Train Loss 24.37724043311408
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7997 test: 0.7578 | best val epoch -- val: 0.8069 test: 0.7831

====epoch 66
Train Loss 24.243002656072566
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7923 test: 0.7525 | best val epoch -- val: 0.8069 test: 0.7831

====epoch 67
Train Loss 23.754292727271853
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7934 test: 0.7554 | best val epoch -- val: 0.8069 test: 0.7831

====epoch 68
Train Loss 24.04802555362644
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8042 test: 0.7662 | best val epoch -- val: 0.8069 test: 0.7831

====epoch 69
Train Loss 23.545760981784433
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7985 test: 0.7640 | best val epoch -- val: 0.8069 test: 0.7831

====epoch 70
Train Loss 23.694231320416613
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8070 test: 0.7714 | best val epoch -- val: 0.8070 test: 0.7714

====epoch 71
Train Loss 23.646031018498597
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8002 test: 0.7692 | best val epoch -- val: 0.8070 test: 0.7714

====epoch 72
Train Loss 23.592390768444886
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8000 test: 0.7653 | best val epoch -- val: 0.8070 test: 0.7714

====epoch 73
Train Loss 23.287459567462992
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7943 test: 0.7637 | best val epoch -- val: 0.8070 test: 0.7714

====epoch 74
Train Loss 23.278593208346955
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7897 test: 0.7550 | best val epoch -- val: 0.8070 test: 0.7714

====epoch 75
Train Loss 23.166251708776848
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7977 test: 0.7630 | best val epoch -- val: 0.8070 test: 0.7714

====epoch 76
Train Loss 23.32964779334284
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7930 test: 0.7629 | best val epoch -- val: 0.8070 test: 0.7714

====epoch 77
Train Loss 23.134363252311154
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8013 test: 0.7699 | best val epoch -- val: 0.8070 test: 0.7714

====epoch 78
Train Loss 22.652056661792145
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7889 test: 0.7625 | best val epoch -- val: 0.8070 test: 0.7714

====epoch 79
Train Loss 22.5087135679944
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7898 test: 0.7683 | best val epoch -- val: 0.8070 test: 0.7714

====epoch 80
Train Loss 22.7677559635008
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7990 test: 0.7683 | best val epoch -- val: 0.8070 test: 0.7714

====epoch 81
Train Loss 22.729268221935754
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8054 test: 0.7672 | best val epoch -- val: 0.8070 test: 0.7714

====epoch 82
Train Loss 22.53163862367804
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8025 test: 0.7660 | best val epoch -- val: 0.8070 test: 0.7714

====epoch 83
Train Loss 22.06764637875546
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8009 test: 0.7693 | best val epoch -- val: 0.8070 test: 0.7714

====epoch 84
Train Loss 22.13461589458269
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7944 test: 0.7614 | best val epoch -- val: 0.8070 test: 0.7714

====epoch 85
Train Loss 22.098511685252355
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7920 test: 0.7632 | best val epoch -- val: 0.8070 test: 0.7714

====epoch 86
Train Loss 21.701107852950603
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7908 test: 0.7652 | best val epoch -- val: 0.8070 test: 0.7714

====epoch 87
Train Loss 21.761962037644913
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7823 test: 0.7576 | best val epoch -- val: 0.8070 test: 0.7714

====epoch 88
Train Loss 21.93794526805218
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7907 test: 0.7665 | best val epoch -- val: 0.8070 test: 0.7714

====epoch 89
Train Loss 21.670772004275424
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7851 test: 0.7602 | best val epoch -- val: 0.8070 test: 0.7714

====epoch 90
Train Loss 21.392292342652585
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7897 test: 0.7659 | best val epoch -- val: 0.8070 test: 0.7714

====epoch 91
Train Loss 21.362542375589967
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7926 test: 0.7677 | best val epoch -- val: 0.8070 test: 0.7714

====epoch 92
Train Loss 21.259413076287164
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7928 test: 0.7640 | best val epoch -- val: 0.8070 test: 0.7714

====epoch 93
Train Loss 21.219660844424187
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7976 test: 0.7603 | best val epoch -- val: 0.8070 test: 0.7714

====epoch 94
Train Loss 21.243719084772394
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7929 test: 0.7563 | best val epoch -- val: 0.8070 test: 0.7714

====epoch 95
Train Loss 21.228715579970498
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7917 test: 0.7550 | best val epoch -- val: 0.8070 test: 0.7714

====epoch 96
Train Loss 20.688776347936358
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7920 test: 0.7626 | best val epoch -- val: 0.8070 test: 0.7714

====epoch 97
Train Loss 20.660695236412344
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7910 test: 0.7589 | best val epoch -- val: 0.8070 test: 0.7714

====epoch 98
Train Loss 20.811791029242485
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7869 test: 0.7625 | best val epoch -- val: 0.8070 test: 0.7714

====epoch 99
Train Loss 20.549314273200565
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7918 test: 0.7601 | best val epoch -- val: 0.8070 test: 0.7714

====epoch 100
Train Loss 20.439104012736863
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7885 test: 0.7575 | best val epoch -- val: 0.8070 test: 0.7714

[14:15:14] WARNING: not removing hydrogen atom without neighbors
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.4.
2022-09-13 14:15:16.880 | INFO     | modules.masked_transformer_encoder:__init__:122 - number of parameters: 0.000000e+00
=========================================
batch_size = 32
d_model = 128
dataset = tox21
decay = 0
device = 0
dim_feedforward = 512
eval_train = 0
filename =
gnn_JK = cat
gnn_dropout = 0.3
gnn_emb_dim = 300
gnn_num_layer = 5
gnn_residual = False
gnn_type = gin
gnn_virtual_node = False
graph_pooling = cls
input_model_file = models_graphtrans/graphtrans-sr-gcl.pth
lr = 0.0001
lr_scale = 1
max_input_len = 1000
nhead = 4
num_encoder_layers = 4
num_encoder_layers_masked = 0
num_workers = 0
pos_encoder = False
runseed = 6
seed = 12344
split = scaffold
transformer_activation = relu
transformer_dropout = 0.3
transformer_norm_input = True
transformer_prenorm = False
=========================================
tox21
scaffold
Loaded GraphTrans from models_graphtrans/graphtrans-sr-gcl.pth
====epoch 1
Train Loss 65.7294191492918
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.5893 test: 0.5884 | best val epoch -- val: 0.5893 test: 0.5884

====epoch 2
Train Loss 47.709105863652795
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6624 test: 0.6397 | best val epoch -- val: 0.6624 test: 0.6397

====epoch 3
Train Loss 43.27014099853939
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7265 test: 0.6913 | best val epoch -- val: 0.7265 test: 0.6913

====epoch 4
Train Loss 40.53125476149904
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7428 test: 0.7089 | best val epoch -- val: 0.7428 test: 0.7089

====epoch 5
Train Loss 39.13217999702427
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7604 test: 0.7317 | best val epoch -- val: 0.7604 test: 0.7317

====epoch 6
Train Loss 37.93670266953188
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7750 test: 0.7386 | best val epoch -- val: 0.7750 test: 0.7386

====epoch 7
Train Loss 37.15106460729828
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7683 test: 0.7348 | best val epoch -- val: 0.7750 test: 0.7386

====epoch 8
Train Loss 36.46629192980119
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7856 test: 0.7453 | best val epoch -- val: 0.7856 test: 0.7453

====epoch 9
Train Loss 35.67479244223496
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7843 test: 0.7569 | best val epoch -- val: 0.7856 test: 0.7453

====epoch 10
Train Loss 35.19955450003901
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7881 test: 0.7616 | best val epoch -- val: 0.7881 test: 0.7616

====epoch 11
Train Loss 34.63079700679967
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7926 test: 0.7622 | best val epoch -- val: 0.7926 test: 0.7622

====epoch 12
Train Loss 34.19429855388342
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7828 test: 0.7688 | best val epoch -- val: 0.7926 test: 0.7622

====epoch 13
Train Loss 34.0708174157153
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7887 test: 0.7671 | best val epoch -- val: 0.7926 test: 0.7622

====epoch 14
Train Loss 33.40367215850882
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7955 test: 0.7653 | best val epoch -- val: 0.7955 test: 0.7653

====epoch 15
Train Loss 33.04690544879832
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7958 test: 0.7666 | best val epoch -- val: 0.7958 test: 0.7666

====epoch 16
Train Loss 32.89103876706442
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7898 test: 0.7714 | best val epoch -- val: 0.7958 test: 0.7666

====epoch 17
Train Loss 32.43021080129655
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7885 test: 0.7787 | best val epoch -- val: 0.7958 test: 0.7666

====epoch 18
Train Loss 32.193821585708264
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7934 test: 0.7778 | best val epoch -- val: 0.7958 test: 0.7666

====epoch 19
Train Loss 31.627851378608035
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7894 test: 0.7708 | best val epoch -- val: 0.7958 test: 0.7666

====epoch 20
Train Loss 31.850347279191297
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7912 test: 0.7745 | best val epoch -- val: 0.7958 test: 0.7666

====epoch 21
Train Loss 31.501711233169477
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7959 test: 0.7757 | best val epoch -- val: 0.7959 test: 0.7757

====epoch 22
Train Loss 31.32777329806467
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7912 test: 0.7741 | best val epoch -- val: 0.7959 test: 0.7757

====epoch 23
Train Loss 30.898809349448282
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7990 test: 0.7732 | best val epoch -- val: 0.7990 test: 0.7732

====epoch 24
Train Loss 30.59795385338243
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7974 test: 0.7762 | best val epoch -- val: 0.7990 test: 0.7732

====epoch 25
Train Loss 30.57601298959867
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7930 test: 0.7796 | best val epoch -- val: 0.7990 test: 0.7732

====epoch 26
Train Loss 30.20868460881556
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7876 test: 0.7737 | best val epoch -- val: 0.7990 test: 0.7732

====epoch 27
Train Loss 30.05179567157534
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7891 test: 0.7676 | best val epoch -- val: 0.7990 test: 0.7732

====epoch 28
Train Loss 29.955150299269977
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7862 test: 0.7763 | best val epoch -- val: 0.7990 test: 0.7732

====epoch 29
Train Loss 29.581369207419307
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7827 test: 0.7741 | best val epoch -- val: 0.7990 test: 0.7732

====epoch 30
Train Loss 28.99059184695973
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7908 test: 0.7786 | best val epoch -- val: 0.7990 test: 0.7732

====epoch 31
Train Loss 28.916370874353056
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7965 test: 0.7832 | best val epoch -- val: 0.7990 test: 0.7732

====epoch 32
Train Loss 28.72979474325697
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7937 test: 0.7782 | best val epoch -- val: 0.7990 test: 0.7732

====epoch 33
Train Loss 28.69747663406417
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7949 test: 0.7785 | best val epoch -- val: 0.7990 test: 0.7732

====epoch 34
Train Loss 28.758450814513974
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7963 test: 0.7760 | best val epoch -- val: 0.7990 test: 0.7732

====epoch 35
Train Loss 28.217311216477107
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8023 test: 0.7810 | best val epoch -- val: 0.8023 test: 0.7810

====epoch 36
Train Loss 28.071135780965136
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7928 test: 0.7772 | best val epoch -- val: 0.8023 test: 0.7810

====epoch 37
Train Loss 27.994237575194205
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7836 test: 0.7710 | best val epoch -- val: 0.8023 test: 0.7810

====epoch 38
Train Loss 27.561216643264746
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7954 test: 0.7781 | best val epoch -- val: 0.8023 test: 0.7810

====epoch 39
Train Loss 27.546953479969297
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7972 test: 0.7856 | best val epoch -- val: 0.8023 test: 0.7810

====epoch 40
Train Loss 27.59216888641408
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7931 test: 0.7722 | best val epoch -- val: 0.8023 test: 0.7810

====epoch 41
Train Loss 27.521497162462133
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7936 test: 0.7711 | best val epoch -- val: 0.8023 test: 0.7810

====epoch 42
Train Loss 27.060067384035627
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7986 test: 0.7847 | best val epoch -- val: 0.8023 test: 0.7810

====epoch 43
Train Loss 27.082144199870484
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7904 test: 0.7689 | best val epoch -- val: 0.8023 test: 0.7810

====epoch 44
Train Loss 26.800314443754004
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7885 test: 0.7648 | best val epoch -- val: 0.8023 test: 0.7810

====epoch 45
Train Loss 26.831251207295278
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7928 test: 0.7739 | best val epoch -- val: 0.8023 test: 0.7810

====epoch 46
Train Loss 26.714104468661986
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7934 test: 0.7755 | best val epoch -- val: 0.8023 test: 0.7810

====epoch 47
Train Loss 26.253740071716766
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7846 test: 0.7776 | best val epoch -- val: 0.8023 test: 0.7810

====epoch 48
Train Loss 26.325067893561755
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7884 test: 0.7751 | best val epoch -- val: 0.8023 test: 0.7810

====epoch 49
Train Loss 26.29428759335405
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7933 test: 0.7697 | best val epoch -- val: 0.8023 test: 0.7810

====epoch 50
Train Loss 26.039162425829655
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7933 test: 0.7707 | best val epoch -- val: 0.8023 test: 0.7810

====epoch 51
Train Loss 25.649218518941538
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7899 test: 0.7679 | best val epoch -- val: 0.8023 test: 0.7810

====epoch 52
Train Loss 25.74024530322972
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7961 test: 0.7684 | best val epoch -- val: 0.8023 test: 0.7810

====epoch 53
Train Loss 25.42889558407783
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7917 test: 0.7659 | best val epoch -- val: 0.8023 test: 0.7810

====epoch 54
Train Loss 25.28267060258781
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7919 test: 0.7633 | best val epoch -- val: 0.8023 test: 0.7810

====epoch 55
Train Loss 25.00941562463658
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7973 test: 0.7681 | best val epoch -- val: 0.8023 test: 0.7810

====epoch 56
Train Loss 25.2058544731055
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7874 test: 0.7681 | best val epoch -- val: 0.8023 test: 0.7810

====epoch 57
Train Loss 25.334044756950473
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7960 test: 0.7718 | best val epoch -- val: 0.8023 test: 0.7810

====epoch 58
Train Loss 24.944616067203363
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7896 test: 0.7711 | best val epoch -- val: 0.8023 test: 0.7810

====epoch 59
Train Loss 24.912853217173332
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7901 test: 0.7693 | best val epoch -- val: 0.8023 test: 0.7810

====epoch 60
Train Loss 24.649670371270012
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7819 test: 0.7581 | best val epoch -- val: 0.8023 test: 0.7810

====epoch 61
Train Loss 24.504816409432056
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7935 test: 0.7709 | best val epoch -- val: 0.8023 test: 0.7810

====epoch 62
Train Loss 24.04142321665688
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7857 test: 0.7687 | best val epoch -- val: 0.8023 test: 0.7810

====epoch 63
Train Loss 24.078339607464077
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7855 test: 0.7701 | best val epoch -- val: 0.8023 test: 0.7810

====epoch 64
Train Loss 24.070594615484563
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7840 test: 0.7642 | best val epoch -- val: 0.8023 test: 0.7810

====epoch 65
Train Loss 23.817222602448936
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7884 test: 0.7676 | best val epoch -- val: 0.8023 test: 0.7810

====epoch 66
Train Loss 23.75696568841387
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7851 test: 0.7664 | best val epoch -- val: 0.8023 test: 0.7810

====epoch 67
Train Loss 24.040583467895843
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7827 test: 0.7718 | best val epoch -- val: 0.8023 test: 0.7810

====epoch 68
Train Loss 23.65973174819152
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7838 test: 0.7662 | best val epoch -- val: 0.8023 test: 0.7810

====epoch 69
Train Loss 23.353986494142436
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7843 test: 0.7704 | best val epoch -- val: 0.8023 test: 0.7810

====epoch 70
Train Loss 23.46292057616582
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7849 test: 0.7714 | best val epoch -- val: 0.8023 test: 0.7810

====epoch 71
Train Loss 23.309842380714432
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7837 test: 0.7662 | best val epoch -- val: 0.8023 test: 0.7810

====epoch 72
Train Loss 23.01372368910521
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7841 test: 0.7657 | best val epoch -- val: 0.8023 test: 0.7810

====epoch 73
Train Loss 22.790618524440816
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7866 test: 0.7654 | best val epoch -- val: 0.8023 test: 0.7810

====epoch 74
Train Loss 22.714317142621738
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7812 test: 0.7600 | best val epoch -- val: 0.8023 test: 0.7810

====epoch 75
Train Loss 22.405039533918337
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7858 test: 0.7601 | best val epoch -- val: 0.8023 test: 0.7810

====epoch 76
Train Loss 22.598589428000412
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7857 test: 0.7619 | best val epoch -- val: 0.8023 test: 0.7810

====epoch 77
Train Loss 22.663971339214957
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7814 test: 0.7576 | best val epoch -- val: 0.8023 test: 0.7810

====epoch 78
Train Loss 22.241972255634593
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7840 test: 0.7572 | best val epoch -- val: 0.8023 test: 0.7810

====epoch 79
Train Loss 22.005837537260994
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7843 test: 0.7558 | best val epoch -- val: 0.8023 test: 0.7810

====epoch 80
Train Loss 22.08086360796474
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7860 test: 0.7527 | best val epoch -- val: 0.8023 test: 0.7810

====epoch 81
Train Loss 21.819035598103266
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7900 test: 0.7549 | best val epoch -- val: 0.8023 test: 0.7810

====epoch 82
Train Loss 21.6229110377826
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7832 test: 0.7594 | best val epoch -- val: 0.8023 test: 0.7810

====epoch 83
Train Loss 21.632590929062296
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7843 test: 0.7521 | best val epoch -- val: 0.8023 test: 0.7810

====epoch 84
Train Loss 21.923831288103717
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7823 test: 0.7566 | best val epoch -- val: 0.8023 test: 0.7810

====epoch 85
Train Loss 21.44111563356109
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7771 test: 0.7534 | best val epoch -- val: 0.8023 test: 0.7810

====epoch 86
Train Loss 21.445159071293297
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7810 test: 0.7610 | best val epoch -- val: 0.8023 test: 0.7810

====epoch 87
Train Loss 21.48617072253873
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7791 test: 0.7531 | best val epoch -- val: 0.8023 test: 0.7810

====epoch 88
Train Loss 20.997510989303343
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7802 test: 0.7534 | best val epoch -- val: 0.8023 test: 0.7810

====epoch 89
Train Loss 20.87796510219011
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7802 test: 0.7540 | best val epoch -- val: 0.8023 test: 0.7810

====epoch 90
Train Loss 21.056790466192975
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7808 test: 0.7512 | best val epoch -- val: 0.8023 test: 0.7810

====epoch 91
Train Loss 20.61126465754738
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7746 test: 0.7533 | best val epoch -- val: 0.8023 test: 0.7810

====epoch 92
Train Loss 21.014015267883952
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7798 test: 0.7550 | best val epoch -- val: 0.8023 test: 0.7810

====epoch 93
Train Loss 20.388101426788324
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7764 test: 0.7572 | best val epoch -- val: 0.8023 test: 0.7810

====epoch 94
Train Loss 20.41837580946773
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7791 test: 0.7545 | best val epoch -- val: 0.8023 test: 0.7810

====epoch 95
Train Loss 20.299264626758323
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7810 test: 0.7577 | best val epoch -- val: 0.8023 test: 0.7810

====epoch 96
Train Loss 20.507957157559893
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7777 test: 0.7528 | best val epoch -- val: 0.8023 test: 0.7810

====epoch 97
Train Loss 20.30440233694645
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7860 test: 0.7548 | best val epoch -- val: 0.8023 test: 0.7810

====epoch 98
Train Loss 20.515939734425
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7857 test: 0.7589 | best val epoch -- val: 0.8023 test: 0.7810

====epoch 99
Train Loss 19.53654352673136
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7729 test: 0.7410 | best val epoch -- val: 0.8023 test: 0.7810

====epoch 100
Train Loss 19.761181409262733
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7819 test: 0.7548 | best val epoch -- val: 0.8023 test: 0.7810

[14:28:34] WARNING: not removing hydrogen atom without neighbors
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.4.
2022-09-13 14:28:36.737 | INFO     | modules.masked_transformer_encoder:__init__:122 - number of parameters: 0.000000e+00
=========================================
batch_size = 32
d_model = 128
dataset = tox21
decay = 0
device = 0
dim_feedforward = 512
eval_train = 0
filename =
gnn_JK = cat
gnn_dropout = 0.3
gnn_emb_dim = 300
gnn_num_layer = 5
gnn_residual = False
gnn_type = gin
gnn_virtual_node = False
graph_pooling = cls
input_model_file = models_graphtrans/graphtrans-sr-gcl.pth
lr = 0.0001
lr_scale = 1
max_input_len = 1000
nhead = 4
num_encoder_layers = 4
num_encoder_layers_masked = 0
num_workers = 0
pos_encoder = False
runseed = 7
seed = 12344
split = scaffold
transformer_activation = relu
transformer_dropout = 0.3
transformer_norm_input = True
transformer_prenorm = False
=========================================
tox21
scaffold
Loaded GraphTrans from models_graphtrans/graphtrans-sr-gcl.pth
====epoch 1
Train Loss 66.3366470494505
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.5666 test: 0.5549 | best val epoch -- val: 0.5666 test: 0.5549

====epoch 2
Train Loss 47.728137041023096
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6556 test: 0.6485 | best val epoch -- val: 0.6556 test: 0.6485

====epoch 3
Train Loss 43.376707936754585
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7157 test: 0.6890 | best val epoch -- val: 0.7157 test: 0.6890

====epoch 4
Train Loss 40.889094934989785
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7414 test: 0.7097 | best val epoch -- val: 0.7414 test: 0.7097

====epoch 5
Train Loss 39.49181916763336
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7624 test: 0.7254 | best val epoch -- val: 0.7624 test: 0.7254

====epoch 6
Train Loss 38.7053994578013
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7629 test: 0.7359 | best val epoch -- val: 0.7629 test: 0.7359

====epoch 7
Train Loss 37.775782248758546
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7676 test: 0.7438 | best val epoch -- val: 0.7676 test: 0.7438

====epoch 8
Train Loss 37.31592674995801
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7737 test: 0.7447 | best val epoch -- val: 0.7737 test: 0.7447

====epoch 9
Train Loss 36.37841826174026
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7713 test: 0.7502 | best val epoch -- val: 0.7737 test: 0.7447

====epoch 10
Train Loss 35.7453578058626
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7734 test: 0.7564 | best val epoch -- val: 0.7737 test: 0.7447

====epoch 11
Train Loss 35.14931637751925
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7809 test: 0.7565 | best val epoch -- val: 0.7809 test: 0.7565

====epoch 12
Train Loss 34.80287974513242
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7761 test: 0.7600 | best val epoch -- val: 0.7809 test: 0.7565

====epoch 13
Train Loss 34.1486215721911
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7775 test: 0.7571 | best val epoch -- val: 0.7809 test: 0.7565

====epoch 14
Train Loss 33.661607000199055
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7749 test: 0.7601 | best val epoch -- val: 0.7809 test: 0.7565

====epoch 15
Train Loss 33.611265490030696
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7832 test: 0.7640 | best val epoch -- val: 0.7832 test: 0.7640

====epoch 16
Train Loss 33.170953812789044
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7848 test: 0.7693 | best val epoch -- val: 0.7848 test: 0.7693

====epoch 17
Train Loss 32.630032272121504
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7839 test: 0.7757 | best val epoch -- val: 0.7848 test: 0.7693

====epoch 18
Train Loss 32.44812823906424
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7947 test: 0.7735 | best val epoch -- val: 0.7947 test: 0.7735

====epoch 19
Train Loss 32.3297144565351
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7855 test: 0.7803 | best val epoch -- val: 0.7947 test: 0.7735

====epoch 20
Train Loss 31.97753357886176
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7878 test: 0.7723 | best val epoch -- val: 0.7947 test: 0.7735

====epoch 21
Train Loss 31.546962186012085
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7846 test: 0.7799 | best val epoch -- val: 0.7947 test: 0.7735

====epoch 22
Train Loss 31.34533098786426
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7947 test: 0.7792 | best val epoch -- val: 0.7947 test: 0.7792

====epoch 23
Train Loss 31.36425734228219
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7811 test: 0.7774 | best val epoch -- val: 0.7947 test: 0.7792

====epoch 24
Train Loss 31.30381233113318
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7986 test: 0.7808 | best val epoch -- val: 0.7986 test: 0.7808

====epoch 25
Train Loss 30.710763741497363
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7940 test: 0.7816 | best val epoch -- val: 0.7986 test: 0.7808

====epoch 26
Train Loss 30.628306853444858
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7891 test: 0.7776 | best val epoch -- val: 0.7986 test: 0.7808

====epoch 27
Train Loss 30.378425015753063
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7978 test: 0.7788 | best val epoch -- val: 0.7986 test: 0.7808

====epoch 28
Train Loss 30.07294794276334
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7917 test: 0.7759 | best val epoch -- val: 0.7986 test: 0.7808

====epoch 29
Train Loss 29.756926603466077
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7954 test: 0.7780 | best val epoch -- val: 0.7986 test: 0.7808

====epoch 30
Train Loss 29.531815242047248
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7950 test: 0.7838 | best val epoch -- val: 0.7986 test: 0.7808

====epoch 31
Train Loss 29.575158491368224
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7931 test: 0.7799 | best val epoch -- val: 0.7986 test: 0.7808

====epoch 32
Train Loss 29.110159289001768
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7921 test: 0.7827 | best val epoch -- val: 0.7986 test: 0.7808

====epoch 33
Train Loss 28.99878946587376
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7951 test: 0.7776 | best val epoch -- val: 0.7986 test: 0.7808

====epoch 34
Train Loss 28.72222403153259
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8050 test: 0.7809 | best val epoch -- val: 0.8050 test: 0.7809

====epoch 35
Train Loss 28.624043623448568
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8023 test: 0.7784 | best val epoch -- val: 0.8050 test: 0.7809

====epoch 36
Train Loss 28.708380339971036
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8090 test: 0.7801 | best val epoch -- val: 0.8090 test: 0.7801

====epoch 37
Train Loss 28.012238648139625
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8010 test: 0.7765 | best val epoch -- val: 0.8090 test: 0.7801

====epoch 38
Train Loss 28.193800544639885
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7973 test: 0.7831 | best val epoch -- val: 0.8090 test: 0.7801

====epoch 39
Train Loss 28.09827663845782
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7963 test: 0.7778 | best val epoch -- val: 0.8090 test: 0.7801

====epoch 40
Train Loss 27.777748463254788
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7908 test: 0.7764 | best val epoch -- val: 0.8090 test: 0.7801

====epoch 41
Train Loss 27.76490893621775
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7935 test: 0.7688 | best val epoch -- val: 0.8090 test: 0.7801

====epoch 42
Train Loss 27.371286590599126
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8073 test: 0.7734 | best val epoch -- val: 0.8090 test: 0.7801

====epoch 43
Train Loss 27.41757292897129
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8016 test: 0.7730 | best val epoch -- val: 0.8090 test: 0.7801

====epoch 44
Train Loss 27.33793478446479
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8032 test: 0.7729 | best val epoch -- val: 0.8090 test: 0.7801

====epoch 45
Train Loss 26.897289037555797
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7965 test: 0.7727 | best val epoch -- val: 0.8090 test: 0.7801

====epoch 46
Train Loss 26.79305063082009
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7900 test: 0.7708 | best val epoch -- val: 0.8090 test: 0.7801

====epoch 47
Train Loss 26.822600317560244
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7964 test: 0.7658 | best val epoch -- val: 0.8090 test: 0.7801

====epoch 48
Train Loss 26.48590191556099
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7960 test: 0.7680 | best val epoch -- val: 0.8090 test: 0.7801

====epoch 49
Train Loss 26.25335204799398
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8001 test: 0.7748 | best val epoch -- val: 0.8090 test: 0.7801

====epoch 50
Train Loss 26.06574550683267
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7867 test: 0.7647 | best val epoch -- val: 0.8090 test: 0.7801

====epoch 51
Train Loss 26.01999395178406
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7929 test: 0.7730 | best val epoch -- val: 0.8090 test: 0.7801

====epoch 52
Train Loss 25.84135181333041
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7929 test: 0.7649 | best val epoch -- val: 0.8090 test: 0.7801

====epoch 53
Train Loss 25.593323056684333
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7927 test: 0.7648 | best val epoch -- val: 0.8090 test: 0.7801

====epoch 54
Train Loss 25.756551239540578
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7970 test: 0.7726 | best val epoch -- val: 0.8090 test: 0.7801

====epoch 55
Train Loss 25.491298152130494
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7950 test: 0.7685 | best val epoch -- val: 0.8090 test: 0.7801

====epoch 56
Train Loss 25.54773229764312
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8029 test: 0.7764 | best val epoch -- val: 0.8090 test: 0.7801

====epoch 57
Train Loss 25.412845521049757
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7925 test: 0.7697 | best val epoch -- val: 0.8090 test: 0.7801

====epoch 58
Train Loss 25.00475283913327
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7977 test: 0.7615 | best val epoch -- val: 0.8090 test: 0.7801

====epoch 59
Train Loss 24.872584507872183
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8004 test: 0.7669 | best val epoch -- val: 0.8090 test: 0.7801

====epoch 60
Train Loss 25.04920281278341
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7846 test: 0.7620 | best val epoch -- val: 0.8090 test: 0.7801

====epoch 61
Train Loss 24.826034141697505
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7951 test: 0.7658 | best val epoch -- val: 0.8090 test: 0.7801

====epoch 62
Train Loss 24.70671864444904
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7992 test: 0.7595 | best val epoch -- val: 0.8090 test: 0.7801

====epoch 63
Train Loss 24.56931673726251
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7936 test: 0.7608 | best val epoch -- val: 0.8090 test: 0.7801

====epoch 64
Train Loss 24.586276211910143
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7945 test: 0.7574 | best val epoch -- val: 0.8090 test: 0.7801

====epoch 65
Train Loss 24.149800885934525
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7958 test: 0.7654 | best val epoch -- val: 0.8090 test: 0.7801

====epoch 66
Train Loss 24.312131838352713
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7961 test: 0.7633 | best val epoch -- val: 0.8090 test: 0.7801

====epoch 67
Train Loss 24.045564306704122
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7935 test: 0.7629 | best val epoch -- val: 0.8090 test: 0.7801

====epoch 68
Train Loss 23.873405814655403
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7993 test: 0.7654 | best val epoch -- val: 0.8090 test: 0.7801

====epoch 69
Train Loss 23.645253689088904
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7908 test: 0.7595 | best val epoch -- val: 0.8090 test: 0.7801

====epoch 70
Train Loss 23.741259600628943
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7909 test: 0.7580 | best val epoch -- val: 0.8090 test: 0.7801

====epoch 71
Train Loss 23.75152317475943
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7960 test: 0.7649 | best val epoch -- val: 0.8090 test: 0.7801

====epoch 72
Train Loss 23.552203166419996
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7895 test: 0.7592 | best val epoch -- val: 0.8090 test: 0.7801

====epoch 73
Train Loss 23.120199199631745
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7921 test: 0.7639 | best val epoch -- val: 0.8090 test: 0.7801

====epoch 74
Train Loss 22.99333072261549
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7904 test: 0.7594 | best val epoch -- val: 0.8090 test: 0.7801

====epoch 75
Train Loss 23.16195889258828
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7950 test: 0.7648 | best val epoch -- val: 0.8090 test: 0.7801

====epoch 76
Train Loss 23.02182721131967
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7907 test: 0.7618 | best val epoch -- val: 0.8090 test: 0.7801

====epoch 77
Train Loss 22.912356671782394
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7952 test: 0.7600 | best val epoch -- val: 0.8090 test: 0.7801

====epoch 78
Train Loss 22.509497014552515
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7910 test: 0.7655 | best val epoch -- val: 0.8090 test: 0.7801

====epoch 79
Train Loss 22.758218099601006
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7870 test: 0.7626 | best val epoch -- val: 0.8090 test: 0.7801

====epoch 80
Train Loss 22.40227008187272
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7980 test: 0.7644 | best val epoch -- val: 0.8090 test: 0.7801

====epoch 81
Train Loss 22.426125874517233
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7893 test: 0.7587 | best val epoch -- val: 0.8090 test: 0.7801

====epoch 82
Train Loss 21.820097980199705
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7932 test: 0.7609 | best val epoch -- val: 0.8090 test: 0.7801

====epoch 83
Train Loss 21.994425392521233
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7967 test: 0.7625 | best val epoch -- val: 0.8090 test: 0.7801

====epoch 84
Train Loss 22.178424875975683
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7897 test: 0.7638 | best val epoch -- val: 0.8090 test: 0.7801

====epoch 85
Train Loss 21.95704754428636
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7988 test: 0.7652 | best val epoch -- val: 0.8090 test: 0.7801

====epoch 86
Train Loss 21.73310865293615
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7945 test: 0.7526 | best val epoch -- val: 0.8090 test: 0.7801

====epoch 87
Train Loss 21.522981310056284
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7867 test: 0.7633 | best val epoch -- val: 0.8090 test: 0.7801

====epoch 88
Train Loss 21.64221049182317
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7903 test: 0.7584 | best val epoch -- val: 0.8090 test: 0.7801

====epoch 89
Train Loss 21.510433896886592
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7878 test: 0.7655 | best val epoch -- val: 0.8090 test: 0.7801

====epoch 90
Train Loss 21.190815431292286
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7860 test: 0.7597 | best val epoch -- val: 0.8090 test: 0.7801

====epoch 91
Train Loss 21.227052013600556
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7911 test: 0.7513 | best val epoch -- val: 0.8090 test: 0.7801

====epoch 92
Train Loss 21.41078456085562
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7870 test: 0.7523 | best val epoch -- val: 0.8090 test: 0.7801

====epoch 93
Train Loss 21.138460397443364
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7911 test: 0.7674 | best val epoch -- val: 0.8090 test: 0.7801

====epoch 94
Train Loss 20.827449728805636
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7941 test: 0.7570 | best val epoch -- val: 0.8090 test: 0.7801

====epoch 95
Train Loss 20.605476096517453
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7910 test: 0.7581 | best val epoch -- val: 0.8090 test: 0.7801

====epoch 96
Train Loss 20.533949180716508
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7929 test: 0.7605 | best val epoch -- val: 0.8090 test: 0.7801

====epoch 97
Train Loss 20.50764725706003
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7803 test: 0.7485 | best val epoch -- val: 0.8090 test: 0.7801

====epoch 98
Train Loss 20.602535659736322
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7950 test: 0.7529 | best val epoch -- val: 0.8090 test: 0.7801

====epoch 99
Train Loss 20.262582166834047
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7984 test: 0.7550 | best val epoch -- val: 0.8090 test: 0.7801

====epoch 100
Train Loss 20.206086604705256
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7943 test: 0.7561 | best val epoch -- val: 0.8090 test: 0.7801

[14:42:04] WARNING: not removing hydrogen atom without neighbors
2022-09-13 14:42:06.911 | INFO     | modules.masked_transformer_encoder:__init__:122 - number of parameters: 0.000000e+00
=========================================
batch_size = 32
d_model = 128
dataset = tox21
decay = 0
device = 0
dim_feedforward = 512
eval_train = 0
filename =
gnn_JK = cat
gnn_dropout = 0.3
gnn_emb_dim = 300
gnn_num_layer = 5
gnn_residual = False
gnn_type = gin
gnn_virtual_node = False
graph_pooling = cls
input_model_file = models_graphtrans/graphtrans-sr-gcl.pth
lr = 0.0001
lr_scale = 1
max_input_len = 1000
nhead = 4
num_encoder_layers = 4
num_encoder_layers_masked = 0
num_workers = 0
pos_encoder = False
runseed = 8
seed = 12344
split = scaffold
transformer_activation = relu
transformer_dropout = 0.3
transformer_norm_input = True
transformer_prenorm = False
=========================================
tox21
scaffold
Loaded GraphTrans from models_graphtrans/graphtrans-sr-gcl.pth
====epoch 1
Train Loss 62.55936123518421
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6042 test: 0.5826 | best val epoch -- val: 0.6042 test: 0.5826

====epoch 2
Train Loss 47.29262925241318
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6789 test: 0.6526 | best val epoch -- val: 0.6789 test: 0.6526

====epoch 3
Train Loss 42.23504139959301
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7322 test: 0.6930 | best val epoch -- val: 0.7322 test: 0.6930

====epoch 4
Train Loss 40.18931267014427
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7469 test: 0.7191 | best val epoch -- val: 0.7469 test: 0.7191

====epoch 5
Train Loss 39.16408273002938
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7585 test: 0.7291 | best val epoch -- val: 0.7585 test: 0.7291

====epoch 6
Train Loss 38.16801645354913
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7659 test: 0.7326 | best val epoch -- val: 0.7659 test: 0.7326

====epoch 7
Train Loss 37.15533826104468
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7658 test: 0.7371 | best val epoch -- val: 0.7659 test: 0.7326

====epoch 8
Train Loss 36.74963949115334
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7718 test: 0.7410 | best val epoch -- val: 0.7718 test: 0.7410

====epoch 9
Train Loss 36.44162979645222
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7694 test: 0.7392 | best val epoch -- val: 0.7718 test: 0.7410

====epoch 10
Train Loss 35.90263853701055
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7724 test: 0.7455 | best val epoch -- val: 0.7724 test: 0.7455

====epoch 11
Train Loss 35.15262000324445
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7675 test: 0.7495 | best val epoch -- val: 0.7724 test: 0.7455

====epoch 12
Train Loss 34.52234554517638
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7708 test: 0.7575 | best val epoch -- val: 0.7724 test: 0.7455

====epoch 13
Train Loss 34.3208282395697
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7765 test: 0.7699 | best val epoch -- val: 0.7765 test: 0.7699

====epoch 14
Train Loss 33.97040657918727
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7771 test: 0.7704 | best val epoch -- val: 0.7771 test: 0.7704

====epoch 15
Train Loss 33.66843040381565
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7803 test: 0.7739 | best val epoch -- val: 0.7803 test: 0.7739

====epoch 16
Train Loss 33.23152246720559
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7844 test: 0.7730 | best val epoch -- val: 0.7844 test: 0.7730

====epoch 17
Train Loss 32.846930306960765
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7871 test: 0.7676 | best val epoch -- val: 0.7871 test: 0.7676

====epoch 18
Train Loss 32.77515659918617
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7902 test: 0.7761 | best val epoch -- val: 0.7902 test: 0.7761

====epoch 19
Train Loss 32.397544469618566
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7900 test: 0.7762 | best val epoch -- val: 0.7902 test: 0.7761

====epoch 20
Train Loss 32.288359057124644
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7879 test: 0.7782 | best val epoch -- val: 0.7902 test: 0.7761

====epoch 21
Train Loss 31.77944311640264
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7817 test: 0.7807 | best val epoch -- val: 0.7902 test: 0.7761

====epoch 22
Train Loss 31.53150031180727
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7877 test: 0.7702 | best val epoch -- val: 0.7902 test: 0.7761

====epoch 23
Train Loss 31.275392087876742
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7820 test: 0.7723 | best val epoch -- val: 0.7902 test: 0.7761

====epoch 24
Train Loss 31.30046443342076
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7820 test: 0.7738 | best val epoch -- val: 0.7902 test: 0.7761

====epoch 25
Train Loss 31.03878957144528
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7861 test: 0.7728 | best val epoch -- val: 0.7902 test: 0.7761

====epoch 26
Train Loss 30.243675590359125
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7838 test: 0.7796 | best val epoch -- val: 0.7902 test: 0.7761

====epoch 27
Train Loss 30.518292637067866
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7880 test: 0.7694 | best val epoch -- val: 0.7902 test: 0.7761

====epoch 28
Train Loss 30.169390050867534
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7855 test: 0.7709 | best val epoch -- val: 0.7902 test: 0.7761

====epoch 29
Train Loss 30.169390009217214
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7931 test: 0.7748 | best val epoch -- val: 0.7931 test: 0.7748

====epoch 30
Train Loss 29.563648907467975
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7824 test: 0.7725 | best val epoch -- val: 0.7931 test: 0.7748

====epoch 31
Train Loss 29.80764101343493
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7873 test: 0.7750 | best val epoch -- val: 0.7931 test: 0.7748

====epoch 32
Train Loss 29.545005971238055
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7953 test: 0.7799 | best val epoch -- val: 0.7953 test: 0.7799

====epoch 33
Train Loss 28.952361319747254
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7947 test: 0.7732 | best val epoch -- val: 0.7953 test: 0.7799

====epoch 34
Train Loss 28.940677040187765
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7894 test: 0.7776 | best val epoch -- val: 0.7953 test: 0.7799

====epoch 35
Train Loss 28.70452483899429
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7894 test: 0.7738 | best val epoch -- val: 0.7953 test: 0.7799

====epoch 36
Train Loss 28.505647310382717
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7978 test: 0.7671 | best val epoch -- val: 0.7978 test: 0.7671

====epoch 37
Train Loss 28.487845706016408
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7873 test: 0.7679 | best val epoch -- val: 0.7978 test: 0.7671

====epoch 38
Train Loss 28.3230711439449
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7913 test: 0.7709 | best val epoch -- val: 0.7978 test: 0.7671

====epoch 39
Train Loss 28.173447916865864
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7904 test: 0.7653 | best val epoch -- val: 0.7978 test: 0.7671

====epoch 40
Train Loss 28.040373135837605
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7950 test: 0.7694 | best val epoch -- val: 0.7978 test: 0.7671

====epoch 41
Train Loss 28.101245122300085
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7905 test: 0.7687 | best val epoch -- val: 0.7978 test: 0.7671

====epoch 42
Train Loss 27.800978101908434
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7931 test: 0.7715 | best val epoch -- val: 0.7978 test: 0.7671

====epoch 43
Train Loss 27.540729103293575
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7979 test: 0.7616 | best val epoch -- val: 0.7979 test: 0.7616

====epoch 44
Train Loss 27.367416248675035
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7912 test: 0.7658 | best val epoch -- val: 0.7979 test: 0.7616

====epoch 45WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.4.

Train Loss 27.2543464820475
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7922 test: 0.7689 | best val epoch -- val: 0.7979 test: 0.7616

====epoch 46
Train Loss 26.997775472932627
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7917 test: 0.7672 | best val epoch -- val: 0.7979 test: 0.7616

====epoch 47
Train Loss 27.033451548521317
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7846 test: 0.7587 | best val epoch -- val: 0.7979 test: 0.7616

====epoch 48
Train Loss 26.768185920213686
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7889 test: 0.7694 | best val epoch -- val: 0.7979 test: 0.7616

====epoch 49
Train Loss 26.643960735491074
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7916 test: 0.7627 | best val epoch -- val: 0.7979 test: 0.7616

====epoch 50
Train Loss 26.611468351613013
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7970 test: 0.7687 | best val epoch -- val: 0.7979 test: 0.7616

====epoch 51
Train Loss 26.387567938497966
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7966 test: 0.7636 | best val epoch -- val: 0.7979 test: 0.7616

====epoch 52
Train Loss 26.15575418337517
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7919 test: 0.7624 | best val epoch -- val: 0.7979 test: 0.7616

====epoch 53
Train Loss 26.158418225863993
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7914 test: 0.7612 | best val epoch -- val: 0.7979 test: 0.7616

====epoch 54
Train Loss 25.999049566860506
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7897 test: 0.7638 | best val epoch -- val: 0.7979 test: 0.7616

====epoch 55
Train Loss 25.863795120392304
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7900 test: 0.7698 | best val epoch -- val: 0.7979 test: 0.7616

====epoch 56
Train Loss 25.486525705647608
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7895 test: 0.7729 | best val epoch -- val: 0.7979 test: 0.7616

====epoch 57
Train Loss 25.63660224609886
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7866 test: 0.7608 | best val epoch -- val: 0.7979 test: 0.7616

====epoch 58
Train Loss 25.708443927303247
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7847 test: 0.7665 | best val epoch -- val: 0.7979 test: 0.7616

====epoch 59
Train Loss 25.619335918506536
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7938 test: 0.7575 | best val epoch -- val: 0.7979 test: 0.7616

====epoch 60
Train Loss 25.365445978724214
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7924 test: 0.7633 | best val epoch -- val: 0.7979 test: 0.7616

====epoch 61
Train Loss 24.927744431111943
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7915 test: 0.7701 | best val epoch -- val: 0.7979 test: 0.7616

====epoch 62
Train Loss 24.94784464510654
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7947 test: 0.7699 | best val epoch -- val: 0.7979 test: 0.7616

====epoch 63
Train Loss 24.956067889147715
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7933 test: 0.7731 | best val epoch -- val: 0.7979 test: 0.7616

====epoch 64
Train Loss 24.80555816109663
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7960 test: 0.7774 | best val epoch -- val: 0.7979 test: 0.7616

====epoch 65
Train Loss 24.49178079968086
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7891 test: 0.7736 | best val epoch -- val: 0.7979 test: 0.7616

====epoch 66
Train Loss 24.247519372604128
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7918 test: 0.7729 | best val epoch -- val: 0.7979 test: 0.7616

====epoch 67
Train Loss 24.21497973315823
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7965 test: 0.7743 | best val epoch -- val: 0.7979 test: 0.7616

====epoch 68
Train Loss 23.95368997286638
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7932 test: 0.7715 | best val epoch -- val: 0.7979 test: 0.7616

====epoch 69
Train Loss 24.17413326926936
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7897 test: 0.7724 | best val epoch -- val: 0.7979 test: 0.7616

====epoch 70
Train Loss 23.964791644864835
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7995 test: 0.7753 | best val epoch -- val: 0.7995 test: 0.7753

====epoch 71
Train Loss 23.57319197580616
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7941 test: 0.7714 | best val epoch -- val: 0.7995 test: 0.7753

====epoch 72
Train Loss 23.856790861541928
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7934 test: 0.7636 | best val epoch -- val: 0.7995 test: 0.7753

====epoch 73
Train Loss 23.679279588263906
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7945 test: 0.7673 | best val epoch -- val: 0.7995 test: 0.7753

====epoch 74
Train Loss 23.859264275420454
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7940 test: 0.7684 | best val epoch -- val: 0.7995 test: 0.7753

====epoch 75
Train Loss 23.499857089148964
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7873 test: 0.7634 | best val epoch -- val: 0.7995 test: 0.7753

====epoch 76
Train Loss 23.357798941784324
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7879 test: 0.7585 | best val epoch -- val: 0.7995 test: 0.7753

====epoch 77
Train Loss 22.969054645511264
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7806 test: 0.7657 | best val epoch -- val: 0.7995 test: 0.7753

====epoch 78
Train Loss 23.02834380488459
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7859 test: 0.7638 | best val epoch -- val: 0.7995 test: 0.7753

====epoch 79
Train Loss 22.81701176122986
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7866 test: 0.7598 | best val epoch -- val: 0.7995 test: 0.7753

====epoch 80
Train Loss 22.885785685874975
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7919 test: 0.7673 | best val epoch -- val: 0.7995 test: 0.7753

====epoch 81
Train Loss 22.633973774835724
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7902 test: 0.7591 | best val epoch -- val: 0.7995 test: 0.7753

====epoch 82
Train Loss 22.41085736387925
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7832 test: 0.7632 | best val epoch -- val: 0.7995 test: 0.7753

====epoch 83
Train Loss 22.499681033519806
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7839 test: 0.7677 | best val epoch -- val: 0.7995 test: 0.7753

====epoch 84
Train Loss 22.347055355057826
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7749 test: 0.7557 | best val epoch -- val: 0.7995 test: 0.7753

====epoch 85
Train Loss 22.294187424655732
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7825 test: 0.7641 | best val epoch -- val: 0.7995 test: 0.7753

====epoch 86
Train Loss 22.52035288619398
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7902 test: 0.7618 | best val epoch -- val: 0.7995 test: 0.7753

====epoch 87
Train Loss 22.133407756200306
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7857 test: 0.7527 | best val epoch -- val: 0.7995 test: 0.7753

====epoch 88
Train Loss 21.968036544225352
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7847 test: 0.7660 | best val epoch -- val: 0.7995 test: 0.7753

====epoch 89
Train Loss 21.516869497570337
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7810 test: 0.7585 | best val epoch -- val: 0.7995 test: 0.7753

====epoch 90
Train Loss 21.701847750996425
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7823 test: 0.7580 | best val epoch -- val: 0.7995 test: 0.7753

====epoch 91
Train Loss 21.525212665088628
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7880 test: 0.7575 | best val epoch -- val: 0.7995 test: 0.7753

====epoch 92
Train Loss 21.92123823332893
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7883 test: 0.7542 | best val epoch -- val: 0.7995 test: 0.7753

====epoch 93
Train Loss 21.624967244884182
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7843 test: 0.7526 | best val epoch -- val: 0.7995 test: 0.7753

====epoch 94
Train Loss 21.019634761106236
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7835 test: 0.7600 | best val epoch -- val: 0.7995 test: 0.7753

====epoch 95
Train Loss 21.064829858339
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7754 test: 0.7579 | best val epoch -- val: 0.7995 test: 0.7753

====epoch 96
Train Loss 21.165307482889517
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7789 test: 0.7583 | best val epoch -- val: 0.7995 test: 0.7753

====epoch 97
Train Loss 21.075998376354647
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7862 test: 0.7595 | best val epoch -- val: 0.7995 test: 0.7753

====epoch 98
Train Loss 20.97402858919236
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7805 test: 0.7517 | best val epoch -- val: 0.7995 test: 0.7753

====epoch 99
Train Loss 20.796845613298107
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7821 test: 0.7593 | best val epoch -- val: 0.7995 test: 0.7753

====epoch 100
Train Loss 20.635938980541386
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7883 test: 0.7566 | best val epoch -- val: 0.7995 test: 0.7753

[14:54:42] WARNING: not removing hydrogen atom without neighbors
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.4.
2022-09-13 14:54:44.836 | INFO     | modules.masked_transformer_encoder:__init__:122 - number of parameters: 0.000000e+00
=========================================
batch_size = 32
d_model = 128
dataset = tox21
decay = 0
device = 0
dim_feedforward = 512
eval_train = 0
filename =
gnn_JK = cat
gnn_dropout = 0.3
gnn_emb_dim = 300
gnn_num_layer = 5
gnn_residual = False
gnn_type = gin
gnn_virtual_node = False
graph_pooling = cls
input_model_file = models_graphtrans/graphtrans-sr-gcl.pth
lr = 0.0001
lr_scale = 1
max_input_len = 1000
nhead = 4
num_encoder_layers = 4
num_encoder_layers_masked = 0
num_workers = 0
pos_encoder = False
runseed = 9
seed = 12344
split = scaffold
transformer_activation = relu
transformer_dropout = 0.3
transformer_norm_input = True
transformer_prenorm = False
=========================================
tox21
scaffold
Loaded GraphTrans from models_graphtrans/graphtrans-sr-gcl.pth
====epoch 1
Train Loss 67.15870376989383
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6226 test: 0.6117 | best val epoch -- val: 0.6226 test: 0.6117

====epoch 2
Train Loss 47.5550285430358
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6586 test: 0.6314 | best val epoch -- val: 0.6586 test: 0.6314

====epoch 3
Train Loss 43.01416111090896
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7263 test: 0.7004 | best val epoch -- val: 0.7263 test: 0.7004

====epoch 4
Train Loss 40.6325743677717
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7435 test: 0.7178 | best val epoch -- val: 0.7435 test: 0.7178

====epoch 5
Train Loss 39.52826467323708
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7536 test: 0.7290 | best val epoch -- val: 0.7536 test: 0.7290

====epoch 6
Train Loss 38.44795293280247
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7763 test: 0.7495 | best val epoch -- val: 0.7763 test: 0.7495

====epoch 7
Train Loss 37.567302190717186
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7824 test: 0.7566 | best val epoch -- val: 0.7824 test: 0.7566

====epoch 8
Train Loss 36.85909219429507
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7771 test: 0.7559 | best val epoch -- val: 0.7824 test: 0.7566

====epoch 9
Train Loss 35.94339635943034
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7854 test: 0.7602 | best val epoch -- val: 0.7854 test: 0.7602

====epoch 10
Train Loss 35.392619616777566
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7824 test: 0.7668 | best val epoch -- val: 0.7854 test: 0.7602

====epoch 11
Train Loss 34.9456265260077
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7891 test: 0.7722 | best val epoch -- val: 0.7891 test: 0.7722

====epoch 12
Train Loss 34.285471239584105
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7822 test: 0.7671 | best val epoch -- val: 0.7891 test: 0.7722

====epoch 13
Train Loss 34.23109448327459
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7931 test: 0.7750 | best val epoch -- val: 0.7931 test: 0.7750

====epoch 14
Train Loss 33.272528638061466
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7893 test: 0.7750 | best val epoch -- val: 0.7931 test: 0.7750

====epoch 15
Train Loss 33.245412245665136
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7901 test: 0.7774 | best val epoch -- val: 0.7931 test: 0.7750

====epoch 16
Train Loss 32.91783787865389
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7927 test: 0.7799 | best val epoch -- val: 0.7931 test: 0.7750

====epoch 17
Train Loss 32.43253710938425
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8039 test: 0.8097 | best val epoch -- val: 0.8039 test: 0.8097

====epoch 18
Train Loss 32.178773326201835
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8006 test: 0.7801 | best val epoch -- val: 0.8039 test: 0.8097

====epoch 19
Train Loss 32.24794627005032
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7997 test: 0.7795 | best val epoch -- val: 0.8039 test: 0.8097

====epoch 20
Train Loss 31.880178963102495
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7987 test: 0.7854 | best val epoch -- val: 0.8039 test: 0.8097

====epoch 21
Train Loss 31.588200677121012
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8011 test: 0.7807 | best val epoch -- val: 0.8039 test: 0.8097

====epoch 22
Train Loss 31.320469908478643
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8015 test: 0.7828 | best val epoch -- val: 0.8039 test: 0.8097

====epoch 23
Train Loss 31.067491931771826
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8023 test: 0.7811 | best val epoch -- val: 0.8039 test: 0.8097

====epoch 24
Train Loss 30.910830764673456
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8014 test: 0.7841 | best val epoch -- val: 0.8039 test: 0.8097

====epoch 25
Train Loss 30.693415402020754
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8025 test: 0.7842 | best val epoch -- val: 0.8039 test: 0.8097

====epoch 26
Train Loss 30.38643267514786
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8076 test: 0.7850 | best val epoch -- val: 0.8076 test: 0.7850

====epoch 27
Train Loss 29.874259977551013
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8031 test: 0.7817 | best val epoch -- val: 0.8076 test: 0.7850

====epoch 28
Train Loss 29.65872367290707
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8100 test: 0.7849 | best val epoch -- val: 0.8100 test: 0.7849

====epoch 29
Train Loss 29.44804166231777
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8037 test: 0.7842 | best val epoch -- val: 0.8100 test: 0.7849

====epoch 30
Train Loss 29.442730268369846
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8022 test: 0.7844 | best val epoch -- val: 0.8100 test: 0.7849

====epoch 31
Train Loss 29.30569557371292
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8065 test: 0.7820 | best val epoch -- val: 0.8100 test: 0.7849

====epoch 32
Train Loss 28.887415852218357
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8093 test: 0.7892 | best val epoch -- val: 0.8100 test: 0.7849

====epoch 33
Train Loss 29.114943162631384
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8105 test: 0.7783 | best val epoch -- val: 0.8105 test: 0.7783

====epoch 34
Train Loss 28.60414018900863
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8136 test: 0.7862 | best val epoch -- val: 0.8136 test: 0.7862

====epoch 35
Train Loss 28.386819323757653
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8065 test: 0.7778 | best val epoch -- val: 0.8136 test: 0.7862

====epoch 36
Train Loss 28.102032904098948
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8014 test: 0.7758 | best val epoch -- val: 0.8136 test: 0.7862

====epoch 37
Train Loss 27.9750856318007
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8023 test: 0.7740 | best val epoch -- val: 0.8136 test: 0.7862

====epoch 38
Train Loss 27.757437851575137
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8056 test: 0.7759 | best val epoch -- val: 0.8136 test: 0.7862

====epoch 39
Train Loss 27.5415462626158
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8028 test: 0.7781 | best val epoch -- val: 0.8136 test: 0.7862

====epoch 40
Train Loss 27.514830311372418
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8074 test: 0.7847 | best val epoch -- val: 0.8136 test: 0.7862

====epoch 41
Train Loss 27.43972280555901
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8061 test: 0.7732 | best val epoch -- val: 0.8136 test: 0.7862

====epoch 42
Train Loss 27.145363317757084
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8041 test: 0.7759 | best val epoch -- val: 0.8136 test: 0.7862

====epoch 43
Train Loss 26.791547422943097
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8051 test: 0.7718 | best val epoch -- val: 0.8136 test: 0.7862

====epoch 44
Train Loss 27.072951138272483
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8044 test: 0.7726 | best val epoch -- val: 0.8136 test: 0.7862

====epoch 45
Train Loss 26.991186625504227
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8033 test: 0.7728 | best val epoch -- val: 0.8136 test: 0.7862

====epoch 46
Train Loss 26.897244817306717
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8044 test: 0.7703 | best val epoch -- val: 0.8136 test: 0.7862

====epoch 47
Train Loss 26.342012346943857
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8001 test: 0.7790 | best val epoch -- val: 0.8136 test: 0.7862

====epoch 48
Train Loss 26.154534306528863
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8030 test: 0.7726 | best val epoch -- val: 0.8136 test: 0.7862

====epoch 49
Train Loss 26.29773817980116
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7951 test: 0.7742 | best val epoch -- val: 0.8136 test: 0.7862

====epoch 50
Train Loss 25.993039135934225
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8017 test: 0.7772 | best val epoch -- val: 0.8136 test: 0.7862

====epoch 51
Train Loss 26.25665944445071
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7923 test: 0.7741 | best val epoch -- val: 0.8136 test: 0.7862

====epoch 52
Train Loss 25.821721461278557
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7964 test: 0.7738 | best val epoch -- val: 0.8136 test: 0.7862

====epoch 53
Train Loss 25.47997260597386
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7934 test: 0.7736 | best val epoch -- val: 0.8136 test: 0.7862

====epoch 54
Train Loss 25.511849770657467
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7966 test: 0.7726 | best val epoch -- val: 0.8136 test: 0.7862

====epoch 55
Train Loss 25.94298993252089
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8032 test: 0.7789 | best val epoch -- val: 0.8136 test: 0.7862

====epoch 56
Train Loss 25.14731154339937
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8035 test: 0.7762 | best val epoch -- val: 0.8136 test: 0.7862

====epoch 57
Train Loss 25.36289609528013
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7977 test: 0.7768 | best val epoch -- val: 0.8136 test: 0.7862

====epoch 58
Train Loss 24.942878668763967
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8021 test: 0.7776 | best val epoch -- val: 0.8136 test: 0.7862

====epoch 59
Train Loss 25.041636058763793
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7934 test: 0.7709 | best val epoch -- val: 0.8136 test: 0.7862

====epoch 60
Train Loss 24.921463026607956
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8012 test: 0.7810 | best val epoch -- val: 0.8136 test: 0.7862

====epoch 61
Train Loss 24.694573665825153
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7921 test: 0.7717 | best val epoch -- val: 0.8136 test: 0.7862

====epoch 62
Train Loss 24.609725248792977
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7995 test: 0.7736 | best val epoch -- val: 0.8136 test: 0.7862

====epoch 63
Train Loss 24.472800785091838
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7970 test: 0.7730 | best val epoch -- val: 0.8136 test: 0.7862

====epoch 64
Train Loss 24.390058961847064
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7978 test: 0.7671 | best val epoch -- val: 0.8136 test: 0.7862

====epoch 65
Train Loss 24.245879691206326
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7987 test: 0.7697 | best val epoch -- val: 0.8136 test: 0.7862

====epoch 66
Train Loss 24.323049515729743
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7979 test: 0.7685 | best val epoch -- val: 0.8136 test: 0.7862

====epoch 67
Train Loss 24.192339504824197
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7967 test: 0.7691 | best val epoch -- val: 0.8136 test: 0.7862

====epoch 68
Train Loss 23.772608952796602
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7945 test: 0.7652 | best val epoch -- val: 0.8136 test: 0.7862

====epoch 69
Train Loss 23.769245495920778
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7940 test: 0.7614 | best val epoch -- val: 0.8136 test: 0.7862

====epoch 70
Train Loss 23.66582833749498
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7992 test: 0.7660 | best val epoch -- val: 0.8136 test: 0.7862

====epoch 71
Train Loss 23.24270901853099
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7978 test: 0.7686 | best val epoch -- val: 0.8136 test: 0.7862

====epoch 72
Train Loss 23.501947804263434
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7956 test: 0.7685 | best val epoch -- val: 0.8136 test: 0.7862

====epoch 73
Train Loss 23.35048478116606
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8002 test: 0.7750 | best val epoch -- val: 0.8136 test: 0.7862

====epoch 74
Train Loss 22.999760358156216
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8018 test: 0.7716 | best val epoch -- val: 0.8136 test: 0.7862

====epoch 75
Train Loss 23.062054119018605
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8021 test: 0.7757 | best val epoch -- val: 0.8136 test: 0.7862

====epoch 76
Train Loss 22.963277989654042
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7944 test: 0.7686 | best val epoch -- val: 0.8136 test: 0.7862

====epoch 77
Train Loss 22.82077102598223
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7993 test: 0.7698 | best val epoch -- val: 0.8136 test: 0.7862

====epoch 78
Train Loss 22.70705709474663
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7939 test: 0.7718 | best val epoch -- val: 0.8136 test: 0.7862

====epoch 79
Train Loss 22.529380329057496
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7918 test: 0.7661 | best val epoch -- val: 0.8136 test: 0.7862

====epoch 80
Train Loss 22.580936575075558
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7952 test: 0.7727 | best val epoch -- val: 0.8136 test: 0.7862

====epoch 81
Train Loss 22.163247887901683
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7870 test: 0.7662 | best val epoch -- val: 0.8136 test: 0.7862

====epoch 82
Train Loss 22.29149032379702
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7883 test: 0.7694 | best val epoch -- val: 0.8136 test: 0.7862

====epoch 83
Train Loss 22.2825920356296
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7950 test: 0.7715 | best val epoch -- val: 0.8136 test: 0.7862

====epoch 84
Train Loss 21.758497353852587
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7901 test: 0.7697 | best val epoch -- val: 0.8136 test: 0.7862

====epoch 85
Train Loss 21.810450885513198
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7929 test: 0.7724 | best val epoch -- val: 0.8136 test: 0.7862

====epoch 86
Train Loss 21.79578944441771
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8003 test: 0.7663 | best val epoch -- val: 0.8136 test: 0.7862

====epoch 87
Train Loss 21.38117048291865
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8020 test: 0.7717 | best val epoch -- val: 0.8136 test: 0.7862

====epoch 88
Train Loss 21.551332625824138
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7939 test: 0.7656 | best val epoch -- val: 0.8136 test: 0.7862

====epoch 89
Train Loss 21.26849830027154
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7990 test: 0.7642 | best val epoch -- val: 0.8136 test: 0.7862

====epoch 90
Train Loss 21.27142720539166
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7990 test: 0.7684 | best val epoch -- val: 0.8136 test: 0.7862

====epoch 91
Train Loss 21.37852963574503
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7995 test: 0.7733 | best val epoch -- val: 0.8136 test: 0.7862

====epoch 92
Train Loss 21.01538466231213
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7976 test: 0.7648 | best val epoch -- val: 0.8136 test: 0.7862

====epoch 93
Train Loss 20.723959375616996
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7993 test: 0.7685 | best val epoch -- val: 0.8136 test: 0.7862

====epoch 94
Train Loss 20.861620164051175
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7993 test: 0.7737 | best val epoch -- val: 0.8136 test: 0.7862

====epoch 95
Train Loss 20.738516720395904
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7892 test: 0.7748 | best val epoch -- val: 0.8136 test: 0.7862

====epoch 96
Train Loss 20.61748096665563
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7948 test: 0.7736 | best val epoch -- val: 0.8136 test: 0.7862

====epoch 97
Train Loss 20.23602555900576
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7886 test: 0.7681 | best val epoch -- val: 0.8136 test: 0.7862

====epoch 98
Train Loss 20.309330822242803
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7839 test: 0.7684 | best val epoch -- val: 0.8136 test: 0.7862

====epoch 99
Train Loss 20.422001603890983
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7912 test: 0.7674 | best val epoch -- val: 0.8136 test: 0.7862

====epoch 100
Train Loss 20.38679481157155
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7946 test: 0.7668 | best val epoch -- val: 0.8136 test: 0.7862

[15:08:02] WARNING: not removing hydrogen atom without neighbors
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.4.
2022-09-13 15:08:04.559 | INFO     | modules.masked_transformer_encoder:__init__:122 - number of parameters: 0.000000e+00
=========================================
batch_size = 32
d_model = 128
dataset = toxcast
decay = 0
device = 0
dim_feedforward = 512
eval_train = 0
filename =
gnn_JK = cat
gnn_dropout = 0.3
gnn_emb_dim = 300
gnn_num_layer = 5
gnn_residual = False
gnn_type = gin
gnn_virtual_node = False
graph_pooling = cls
input_model_file = models_graphtrans/graphtrans-sr-gcl.pth
lr = 0.0001
lr_scale = 1
max_input_len = 1000
nhead = 4
num_encoder_layers = 4
num_encoder_layers_masked = 0
num_workers = 0
pos_encoder = False
runseed = 0
seed = 12344
split = scaffold
transformer_activation = relu
transformer_dropout = 0.3
transformer_norm_input = True
transformer_prenorm = False
=========================================
toxcast
scaffold
Loaded GraphTrans from models_graphtrans/graphtrans-sr-gcl.pth
====epoch 1
Train Loss 90.60559479302873
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.4977 test: 0.4922 | best val epoch -- val: 0.4977 test: 0.4922

====epoch 2
Train Loss 52.64298376861674
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.5064 test: 0.4965 | best val epoch -- val: 0.5064 test: 0.4965

====epoch 3
Train Loss 49.27528252908216
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.5135 test: 0.5004 | best val epoch -- val: 0.5135 test: 0.5004

====epoch 4
Train Loss 48.31484243017122
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.5959 test: 0.5734 | best val epoch -- val: 0.5959 test: 0.5734

====epoch 5
Train Loss 45.696016474727145
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6162 test: 0.6075 | best val epoch -- val: 0.6162 test: 0.6075

====epoch 6
Train Loss 44.15366740833274
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6090 test: 0.6093 | best val epoch -- val: 0.6162 test: 0.6075

====epoch 7
Train Loss 42.8016428650418
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6231 test: 0.6206 | best val epoch -- val: 0.6231 test: 0.6206

====epoch 8
Train Loss 41.84289992185827
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6226 test: 0.6081 | best val epoch -- val: 0.6231 test: 0.6206

====epoch 9
Train Loss 41.67135544536689
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6289 test: 0.6088 | best val epoch -- val: 0.6289 test: 0.6088

====epoch 10
Train Loss 41.195606872268606
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6155 test: 0.6160 | best val epoch -- val: 0.6289 test: 0.6088

====epoch 11
Train Loss 40.60440832310298
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6310 test: 0.6270 | best val epoch -- val: 0.6310 test: 0.6270

====epoch 12
Train Loss 40.170505728617584
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6335 test: 0.6190 | best val epoch -- val: 0.6335 test: 0.6190

====epoch 13
Train Loss 40.34939344211862
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6378 test: 0.6206 | best val epoch -- val: 0.6378 test: 0.6206

====epoch 14
Train Loss 39.504474899817694
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6385 test: 0.6218 | best val epoch -- val: 0.6385 test: 0.6218

====epoch 15
Train Loss 39.30051396870858
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6488 test: 0.6238 | best val epoch -- val: 0.6488 test: 0.6238

====epoch 16
Train Loss 39.03212161439732
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6565 test: 0.6270 | best val epoch -- val: 0.6565 test: 0.6270

====epoch 17
Train Loss 38.6896639180812
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6580 test: 0.6254 | best val epoch -- val: 0.6580 test: 0.6254

====epoch 18
Train Loss 38.667184585794075
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6589 test: 0.6255 | best val epoch -- val: 0.6589 test: 0.6255

====epoch 19
Train Loss 38.44293288113031
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6558 test: 0.6216 | best val epoch -- val: 0.6589 test: 0.6255

====epoch 20
Train Loss 38.16352169520818
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6604 test: 0.6275 | best val epoch -- val: 0.6604 test: 0.6275

====epoch 21
Train Loss 38.217952538771264
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6531 test: 0.6213 | best val epoch -- val: 0.6604 test: 0.6275

====epoch 22
Train Loss 37.966544058247
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6613 test: 0.6240 | best val epoch -- val: 0.6613 test: 0.6240

====epoch 23
Train Loss 37.65039532843703
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6633 test: 0.6227 | best val epoch -- val: 0.6633 test: 0.6227

====epoch 24
Train Loss 37.33375113815374
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6625 test: 0.6230 | best val epoch -- val: 0.6633 test: 0.6227

====epoch 25
Train Loss 37.333779181156665
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6583 test: 0.6221 | best val epoch -- val: 0.6633 test: 0.6227

====epoch 26
Train Loss 36.891434636726366
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6598 test: 0.6243 | best val epoch -- val: 0.6633 test: 0.6227

====epoch 27
Train Loss 36.86628210487898
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6671 test: 0.6237 | best val epoch -- val: 0.6671 test: 0.6237

====epoch 28
Train Loss 36.967635400156176
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6710 test: 0.6222 | best val epoch -- val: 0.6710 test: 0.6222

====epoch 29
Train Loss 36.72118862884924
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6717 test: 0.6258 | best val epoch -- val: 0.6717 test: 0.6258

====epoch 30
Train Loss 36.71928078029231
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6667 test: 0.6263 | best val epoch -- val: 0.6717 test: 0.6258

====epoch 31
Train Loss 36.450492138189844
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6691 test: 0.6264 | best val epoch -- val: 0.6717 test: 0.6258

====epoch 32
Train Loss 36.32444399227282
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6730 test: 0.6279 | best val epoch -- val: 0.6730 test: 0.6279

====epoch 33
Train Loss 36.11890916093328
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6792 test: 0.6251 | best val epoch -- val: 0.6792 test: 0.6251

====epoch 34
Train Loss 36.167218634675564
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6751 test: 0.6230 | best val epoch -- val: 0.6792 test: 0.6251

====epoch 35
Train Loss 35.94678643117041
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6758 test: 0.6262 | best val epoch -- val: 0.6792 test: 0.6251

====epoch 36
Train Loss 35.724805422484565
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6789 test: 0.6313 | best val epoch -- val: 0.6792 test: 0.6251

====epoch 37
Train Loss 35.68341302201696
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6735 test: 0.6297 | best val epoch -- val: 0.6792 test: 0.6251

====epoch 38
Train Loss 35.730261670964374
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6796 test: 0.6312 | best val epoch -- val: 0.6796 test: 0.6312

====epoch 39
Train Loss 35.52411464563169
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6793 test: 0.6389 | best val epoch -- val: 0.6796 test: 0.6312

====epoch 40
Train Loss 35.65545220236196
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6850 test: 0.6414 | best val epoch -- val: 0.6850 test: 0.6414

====epoch 41
Train Loss 35.50299560191248
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6800 test: 0.6432 | best val epoch -- val: 0.6850 test: 0.6414

====epoch 42
Train Loss 35.27126899188726
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6851 test: 0.6373 | best val epoch -- val: 0.6851 test: 0.6373

====epoch 43
Train Loss 35.24400193941146
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6819 test: 0.6324 | best val epoch -- val: 0.6851 test: 0.6373

====epoch 44
Train Loss 34.869940463718514
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6845 test: 0.6429 | best val epoch -- val: 0.6851 test: 0.6373

====epoch 45
Train Loss 34.6162757067248
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6839 test: 0.6431 | best val epoch -- val: 0.6851 test: 0.6373

====epoch 46
Train Loss 34.87027451955329
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6831 test: 0.6357 | best val epoch -- val: 0.6851 test: 0.6373

====epoch 47
Train Loss 34.64804419726115
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6880 test: 0.6390 | best val epoch -- val: 0.6880 test: 0.6390

====epoch 48
Train Loss 34.70648808550581
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6908 test: 0.6418 | best val epoch -- val: 0.6908 test: 0.6418

====epoch 49
Train Loss 34.39084375179305
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6847 test: 0.6356 | best val epoch -- val: 0.6908 test: 0.6418

====epoch 50
Train Loss 34.35631655070767
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6857 test: 0.6469 | best val epoch -- val: 0.6908 test: 0.6418

====epoch 51
Train Loss 34.405570581738786
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6863 test: 0.6400 | best val epoch -- val: 0.6908 test: 0.6418

====epoch 52
Train Loss 34.24027513096881
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6885 test: 0.6345 | best val epoch -- val: 0.6908 test: 0.6418

====epoch 53
Train Loss 34.1972750295591
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6827 test: 0.6300 | best val epoch -- val: 0.6908 test: 0.6418

====epoch 54
Train Loss 33.892242243840954
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6878 test: 0.6336 | best val epoch -- val: 0.6908 test: 0.6418

====epoch 55
Train Loss 33.93595866356803
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6843 test: 0.6335 | best val epoch -- val: 0.6908 test: 0.6418

====epoch 56
Train Loss 33.94585286314708
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6823 test: 0.6398 | best val epoch -- val: 0.6908 test: 0.6418

====epoch 57
Train Loss 34.00812335677173
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6836 test: 0.6375 | best val epoch -- val: 0.6908 test: 0.6418

====epoch 58
Train Loss 33.82454749111238
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6829 test: 0.6392 | best val epoch -- val: 0.6908 test: 0.6418

====epoch 59
Train Loss 33.7225808494729
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6894 test: 0.6390 | best val epoch -- val: 0.6908 test: 0.6418

====epoch 60
Train Loss 33.57192094518874
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6858 test: 0.6343 | best val epoch -- val: 0.6908 test: 0.6418

====epoch 61
Train Loss 33.95403099197971
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6899 test: 0.6390 | best val epoch -- val: 0.6908 test: 0.6418

====epoch 62
Train Loss 33.54864821549519
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6878 test: 0.6384 | best val epoch -- val: 0.6908 test: 0.6418

====epoch 63
Train Loss 33.08123616561101
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6929 test: 0.6384 | best val epoch -- val: 0.6929 test: 0.6384

====epoch 64
Train Loss 33.25422871762463
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6893 test: 0.6363 | best val epoch -- val: 0.6929 test: 0.6384

====epoch 65
Train Loss 33.20430242891703
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6917 test: 0.6342 | best val epoch -- val: 0.6929 test: 0.6384

====epoch 66
Train Loss 33.37006345470826
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6938 test: 0.6344 | best val epoch -- val: 0.6938 test: 0.6344

====epoch 67
Train Loss 33.108144457910434
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6889 test: 0.6310 | best val epoch -- val: 0.6938 test: 0.6344

====epoch 68
Train Loss 33.105244323437084
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6890 test: 0.6318 | best val epoch -- val: 0.6938 test: 0.6344

====epoch 69
Train Loss 33.156626081700495
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6907 test: 0.6319 | best val epoch -- val: 0.6938 test: 0.6344

====epoch 70
Train Loss 32.80582248253447
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6829 test: 0.6288 | best val epoch -- val: 0.6938 test: 0.6344

====epoch 71
Train Loss 32.91383570532203
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6870 test: 0.6288 | best val epoch -- val: 0.6938 test: 0.6344

====epoch 72
Train Loss 32.96128067832196
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6956 test: 0.6449 | best val epoch -- val: 0.6956 test: 0.6449

====epoch 73
Train Loss 32.753570012444435
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6972 test: 0.6320 | best val epoch -- val: 0.6972 test: 0.6320

====epoch 74
Train Loss 32.617340381234435
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.7010 test: 0.6438 | best val epoch -- val: 0.7010 test: 0.6438

====epoch 75
Train Loss 32.63498368589845
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6994 test: 0.6466 | best val epoch -- val: 0.7010 test: 0.6438

====epoch 76
Train Loss 32.36858982750636
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6993 test: 0.6441 | best val epoch -- val: 0.7010 test: 0.6438

====epoch 77
Train Loss 32.41603317336276
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6973 test: 0.6394 | best val epoch -- val: 0.7010 test: 0.6438

====epoch 78
Train Loss 32.13686838500361
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6940 test: 0.6354 | best val epoch -- val: 0.7010 test: 0.6438

====epoch 79
Train Loss 32.26856865235234
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6943 test: 0.6386 | best val epoch -- val: 0.7010 test: 0.6438

====epoch 80
Train Loss 32.22560535923435
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6962 test: 0.6349 | best val epoch -- val: 0.7010 test: 0.6438

====epoch 81
Train Loss 31.94173907615716
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6978 test: 0.6420 | best val epoch -- val: 0.7010 test: 0.6438

====epoch 82
Train Loss 31.988930463517924
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6963 test: 0.6354 | best val epoch -- val: 0.7010 test: 0.6438

====epoch 83
Train Loss 31.829574628817543
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6942 test: 0.6376 | best val epoch -- val: 0.7010 test: 0.6438

====epoch 84
Train Loss 32.16909610945695
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6930 test: 0.6324 | best val epoch -- val: 0.7010 test: 0.6438

====epoch 85
Train Loss 32.07775278717054
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6956 test: 0.6444 | best val epoch -- val: 0.7010 test: 0.6438

====epoch 86
Train Loss 31.918645175833163
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6950 test: 0.6383 | best val epoch -- val: 0.7010 test: 0.6438

====epoch 87
Train Loss 31.91200565706707
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6938 test: 0.6418 | best val epoch -- val: 0.7010 test: 0.6438

====epoch 88
Train Loss 31.535757299563944
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6985 test: 0.6392 | best val epoch -- val: 0.7010 test: 0.6438

====epoch 89
Train Loss 31.578528845478438
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6977 test: 0.6403 | best val epoch -- val: 0.7010 test: 0.6438

====epoch 90
Train Loss 31.84605687265602
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.7061 test: 0.6343 | best val epoch -- val: 0.7061 test: 0.6343

====epoch 91
Train Loss 31.675679710956153
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.7006 test: 0.6404 | best val epoch -- val: 0.7061 test: 0.6343

====epoch 92
Train Loss 31.468097642660588
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.7035 test: 0.6457 | best val epoch -- val: 0.7061 test: 0.6343

====epoch 93
Train Loss 31.37102197744108
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.7063 test: 0.6406 | best val epoch -- val: 0.7063 test: 0.6406

====epoch 94
Train Loss 31.27161978612176
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.7059 test: 0.6436 | best val epoch -- val: 0.7063 test: 0.6406

====epoch 95
Train Loss 31.441135742868042
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6980 test: 0.6363 | best val epoch -- val: 0.7063 test: 0.6406

====epoch 96
Train Loss 31.608235639535703
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.7073 test: 0.6600 | best val epoch -- val: 0.7073 test: 0.6600

====epoch 97
Train Loss 31.474022394761423
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.7060 test: 0.6459 | best val epoch -- val: 0.7073 test: 0.6600

====epoch 98
Train Loss 31.305697703499646
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.7057 test: 0.6469 | best val epoch -- val: 0.7073 test: 0.6600

====epoch 99
Train Loss 31.26548741459212
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6972 test: 0.6509 | best val epoch -- val: 0.7073 test: 0.6600

====epoch 100
Train Loss 31.08709592162938
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.7020 test: 0.6480 | best val epoch -- val: 0.7073 test: 0.6600

[15:23:46] WARNING: not removing hydrogen atom without neighbors
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.4.
2022-09-13 15:23:47.693 | INFO     | modules.masked_transformer_encoder:__init__:122 - number of parameters: 0.000000e+00
=========================================
batch_size = 32
d_model = 128
dataset = toxcast
decay = 0
device = 0
dim_feedforward = 512
eval_train = 0
filename =
gnn_JK = cat
gnn_dropout = 0.3
gnn_emb_dim = 300
gnn_num_layer = 5
gnn_residual = False
gnn_type = gin
gnn_virtual_node = False
graph_pooling = cls
input_model_file = models_graphtrans/graphtrans-sr-gcl.pth
lr = 0.0001
lr_scale = 1
max_input_len = 1000
nhead = 4
num_encoder_layers = 4
num_encoder_layers_masked = 0
num_workers = 0
pos_encoder = False
runseed = 1
seed = 12344
split = scaffold
transformer_activation = relu
transformer_dropout = 0.3
transformer_norm_input = True
transformer_prenorm = False
=========================================
toxcast
scaffold
Loaded GraphTrans from models_graphtrans/graphtrans-sr-gcl.pth
====epoch 1
Train Loss 94.83200078490339
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.5231 test: 0.5005 | best val epoch -- val: 0.5231 test: 0.5005

====epoch 2
Train Loss 53.32156478859524
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.5159 test: 0.5033 | best val epoch -- val: 0.5231 test: 0.5005

====epoch 3
Train Loss 49.47551646003359
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.5063 test: 0.5069 | best val epoch -- val: 0.5231 test: 0.5005

====epoch 4
Train Loss 48.95893592184955
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.5055 test: 0.5166 | best val epoch -- val: 0.5231 test: 0.5005

====epoch 5
Train Loss 47.442529714584374
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.5944 test: 0.5775 | best val epoch -- val: 0.5944 test: 0.5775

====epoch 6
Train Loss 44.993160240595024
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6134 test: 0.6142 | best val epoch -- val: 0.6134 test: 0.6142

====epoch 7
Train Loss 43.47370866315903
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6284 test: 0.6240 | best val epoch -- val: 0.6284 test: 0.6240

====epoch 8
Train Loss 42.42245268271124
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6298 test: 0.6304 | best val epoch -- val: 0.6298 test: 0.6304

====epoch 9
Train Loss 42.160096294241804
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6251 test: 0.6206 | best val epoch -- val: 0.6298 test: 0.6304

====epoch 10
Train Loss 41.49809630672419
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6346 test: 0.6285 | best val epoch -- val: 0.6346 test: 0.6285

====epoch 11
Train Loss 41.14690835961331
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6368 test: 0.6287 | best val epoch -- val: 0.6368 test: 0.6287

====epoch 12
Train Loss 40.567682108861256
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6363 test: 0.6239 | best val epoch -- val: 0.6368 test: 0.6287

====epoch 13
Train Loss 40.03837932856024
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6419 test: 0.6315 | best val epoch -- val: 0.6419 test: 0.6315

====epoch 14
Train Loss 39.88071382544942
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6394 test: 0.6286 | best val epoch -- val: 0.6419 test: 0.6315

====epoch 15
Train Loss 39.759755019010825
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6449 test: 0.6295 | best val epoch -- val: 0.6449 test: 0.6295

====epoch 16
Train Loss 39.231692828861235
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6523 test: 0.6314 | best val epoch -- val: 0.6523 test: 0.6314

====epoch 17
Train Loss 39.05050247045068
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6509 test: 0.6259 | best val epoch -- val: 0.6523 test: 0.6314

====epoch 18
Train Loss 38.9553931240818
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6599 test: 0.6376 | best val epoch -- val: 0.6599 test: 0.6376

====epoch 19
Train Loss 38.437244926270715
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6521 test: 0.6252 | best val epoch -- val: 0.6599 test: 0.6376

====epoch 20
Train Loss 38.161651550001956
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6594 test: 0.6353 | best val epoch -- val: 0.6599 test: 0.6376

====epoch 21
Train Loss 38.173512346275274
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6645 test: 0.6310 | best val epoch -- val: 0.6645 test: 0.6310

====epoch 22
Train Loss 37.781129510174566
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6587 test: 0.6317 | best val epoch -- val: 0.6645 test: 0.6310

====epoch 23
Train Loss 37.83705896816265
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6627 test: 0.6438 | best val epoch -- val: 0.6645 test: 0.6310

====epoch 24
Train Loss 37.67483282832464
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6640 test: 0.6373 | best val epoch -- val: 0.6645 test: 0.6310

====epoch 25
Train Loss 37.17953193064601
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6668 test: 0.6319 | best val epoch -- val: 0.6668 test: 0.6319

====epoch 26
Train Loss 37.29187790603778
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6626 test: 0.6293 | best val epoch -- val: 0.6668 test: 0.6319

====epoch 27
Train Loss 37.11568554343028
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6619 test: 0.6249 | best val epoch -- val: 0.6668 test: 0.6319

====epoch 28
Train Loss 37.090544505637624
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6537 test: 0.6245 | best val epoch -- val: 0.6668 test: 0.6319

====epoch 29
Train Loss 36.75193591490448
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6561 test: 0.6314 | best val epoch -- val: 0.6668 test: 0.6319

====epoch 30
Train Loss 36.545498600124986
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6568 test: 0.6347 | best val epoch -- val: 0.6668 test: 0.6319

====epoch 31
Train Loss 36.257685765515774
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6651 test: 0.6318 | best val epoch -- val: 0.6668 test: 0.6319

====epoch 32
Train Loss 36.40467570601954
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6698 test: 0.6291 | best val epoch -- val: 0.6698 test: 0.6291

====epoch 33
Train Loss 36.08305924500851
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6685 test: 0.6287 | best val epoch -- val: 0.6698 test: 0.6291

====epoch 34
Train Loss 35.92092754292618
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6749 test: 0.6381 | best val epoch -- val: 0.6749 test: 0.6381

====epoch 35
Train Loss 36.02026953906484
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6751 test: 0.6348 | best val epoch -- val: 0.6751 test: 0.6348

====epoch 36
Train Loss 35.81575916379263
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6740 test: 0.6279 | best val epoch -- val: 0.6751 test: 0.6348

====epoch 37
Train Loss 35.644047343284555
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6725 test: 0.6329 | best val epoch -- val: 0.6751 test: 0.6348

====epoch 38
Train Loss 35.59137846904467
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6742 test: 0.6219 | best val epoch -- val: 0.6751 test: 0.6348

====epoch 39
Train Loss 35.42643747331414
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6756 test: 0.6307 | best val epoch -- val: 0.6756 test: 0.6307

====epoch 40
Train Loss 35.324405577058585
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6810 test: 0.6257 | best val epoch -- val: 0.6810 test: 0.6257

====epoch 41
Train Loss 35.23652079136848
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6837 test: 0.6274 | best val epoch -- val: 0.6837 test: 0.6274

====epoch 42
Train Loss 35.20806598763192
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6846 test: 0.6375 | best val epoch -- val: 0.6846 test: 0.6375

====epoch 43
Train Loss 35.13544467089919
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6843 test: 0.6319 | best val epoch -- val: 0.6846 test: 0.6375

====epoch 44
Train Loss 35.179052526632454
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6809 test: 0.6317 | best val epoch -- val: 0.6846 test: 0.6375

====epoch 45
Train Loss 34.80170351476911
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6844 test: 0.6374 | best val epoch -- val: 0.6846 test: 0.6375

====epoch 46
Train Loss 34.61136703108833
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6862 test: 0.6392 | best val epoch -- val: 0.6862 test: 0.6392

====epoch 47
Train Loss 34.767454593311136
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6841 test: 0.6331 | best val epoch -- val: 0.6862 test: 0.6392

====epoch 48
Train Loss 34.639108762485364
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6832 test: 0.6258 | best val epoch -- val: 0.6862 test: 0.6392

====epoch 49
Train Loss 34.43232047307539
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6764 test: 0.6273 | best val epoch -- val: 0.6862 test: 0.6392

====epoch 50
Train Loss 34.44212501444702
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6723 test: 0.6220 | best val epoch -- val: 0.6862 test: 0.6392

====epoch 51
Train Loss 34.21679276703524
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6795 test: 0.6292 | best val epoch -- val: 0.6862 test: 0.6392

====epoch 52
Train Loss 34.036979000082056
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6799 test: 0.6256 | best val epoch -- val: 0.6862 test: 0.6392

====epoch 53
Train Loss 34.283357711085266
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6753 test: 0.6289 | best val epoch -- val: 0.6862 test: 0.6392

====epoch 54
Train Loss 34.064366449545936
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6809 test: 0.6338 | best val epoch -- val: 0.6862 test: 0.6392

====epoch 55
Train Loss 34.195842125436826
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6863 test: 0.6349 | best val epoch -- val: 0.6863 test: 0.6349

====epoch 56
Train Loss 33.79762893946133
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6791 test: 0.6228 | best val epoch -- val: 0.6863 test: 0.6349

====epoch 57
Train Loss 33.83540286256652
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6829 test: 0.6279 | best val epoch -- val: 0.6863 test: 0.6349

====epoch 58
Train Loss 33.74520242796241
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6823 test: 0.6303 | best val epoch -- val: 0.6863 test: 0.6349

====epoch 59
Train Loss 33.680092339228395
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6869 test: 0.6307 | best val epoch -- val: 0.6869 test: 0.6307

====epoch 60
Train Loss 33.6336075521085
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6854 test: 0.6318 | best val epoch -- val: 0.6869 test: 0.6307

====epoch 61
Train Loss 33.36817835256958
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6905 test: 0.6290 | best val epoch -- val: 0.6905 test: 0.6290

====epoch 62
Train Loss 33.195161721638954
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6854 test: 0.6261 | best val epoch -- val: 0.6905 test: 0.6290

====epoch 63
Train Loss 33.336686412290106
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6899 test: 0.6372 | best val epoch -- val: 0.6905 test: 0.6290

====epoch 64
Train Loss 33.304491857524646
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6847 test: 0.6308 | best val epoch -- val: 0.6905 test: 0.6290

====epoch 65
Train Loss 33.38024300012613
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6916 test: 0.6378 | best val epoch -- val: 0.6916 test: 0.6378

====epoch 66
Train Loss 32.92871185063863
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6921 test: 0.6420 | best val epoch -- val: 0.6921 test: 0.6420

====epoch 67
Train Loss 32.88301286842421
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6888 test: 0.6375 | best val epoch -- val: 0.6921 test: 0.6420

====epoch 68
Train Loss 32.89431695488695
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6903 test: 0.6359 | best val epoch -- val: 0.6921 test: 0.6420

====epoch 69
Train Loss 33.004898274735474
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6850 test: 0.6418 | best val epoch -- val: 0.6921 test: 0.6420

====epoch 70
Train Loss 32.7121868387776
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6815 test: 0.6369 | best val epoch -- val: 0.6921 test: 0.6420

====epoch 71
Train Loss 32.71534058918746
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6849 test: 0.6351 | best val epoch -- val: 0.6921 test: 0.6420

====epoch 72
Train Loss 32.61986839166558
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6905 test: 0.6390 | best val epoch -- val: 0.6921 test: 0.6420

====epoch 73
Train Loss 32.66603298088446
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6924 test: 0.6411 | best val epoch -- val: 0.6924 test: 0.6411

====epoch 74
Train Loss 32.63438604153925
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6888 test: 0.6542 | best val epoch -- val: 0.6924 test: 0.6411

====epoch 75
Train Loss 32.70360316863075
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6803 test: 0.6410 | best val epoch -- val: 0.6924 test: 0.6411

====epoch 76
Train Loss 32.57640776971799
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6842 test: 0.6408 | best val epoch -- val: 0.6924 test: 0.6411

====epoch 77
Train Loss 32.48422955537139
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6823 test: 0.6382 | best val epoch -- val: 0.6924 test: 0.6411

====epoch 78
Train Loss 32.52040126899514
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6872 test: 0.6476 | best val epoch -- val: 0.6924 test: 0.6411

====epoch 79
Train Loss 32.28478273670982
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6859 test: 0.6433 | best val epoch -- val: 0.6924 test: 0.6411

====epoch 80
Train Loss 31.921745609916886
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6867 test: 0.6428 | best val epoch -- val: 0.6924 test: 0.6411

====epoch 81
Train Loss 32.45671675572959
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6913 test: 0.6439 | best val epoch -- val: 0.6924 test: 0.6411

====epoch 82
Train Loss 31.958335843133188
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6931 test: 0.6507 | best val epoch -- val: 0.6931 test: 0.6507

====epoch 83
Train Loss 32.04065713099392
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6919 test: 0.6513 | best val epoch -- val: 0.6931 test: 0.6507

====epoch 84
Train Loss 32.01294618006344
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6970 test: 0.6513 | best val epoch -- val: 0.6970 test: 0.6513

====epoch 85
Train Loss 31.778343095069474
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6970 test: 0.6492 | best val epoch -- val: 0.6970 test: 0.6492

====epoch 86
Train Loss 32.070794474659586
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6975 test: 0.6491 | best val epoch -- val: 0.6975 test: 0.6491

====epoch 87
Train Loss 31.986706181423745
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.7015 test: 0.6547 | best val epoch -- val: 0.7015 test: 0.6547

====epoch 88
Train Loss 31.80952030582317
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6923 test: 0.6495 | best val epoch -- val: 0.7015 test: 0.6547

====epoch 89
Train Loss 31.76357866392449
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6953 test: 0.6494 | best val epoch -- val: 0.7015 test: 0.6547

====epoch 90
Train Loss 31.72861480504575
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6970 test: 0.6534 | best val epoch -- val: 0.7015 test: 0.6547

====epoch 91
Train Loss 31.61848859383168
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6975 test: 0.6500 | best val epoch -- val: 0.7015 test: 0.6547

====epoch 92
Train Loss 31.59105252755171
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6965 test: 0.6536 | best val epoch -- val: 0.7015 test: 0.6547

====epoch 93
Train Loss 31.529066006486577
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6954 test: 0.6541 | best val epoch -- val: 0.7015 test: 0.6547

====epoch 94
Train Loss 31.46788650386454
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.7008 test: 0.6486 | best val epoch -- val: 0.7015 test: 0.6547

====epoch 95
Train Loss 31.17590621381885
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6969 test: 0.6433 | best val epoch -- val: 0.7015 test: 0.6547

====epoch 96
Train Loss 31.369943743434945
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.7035 test: 0.6506 | best val epoch -- val: 0.7035 test: 0.6506

====epoch 97
Train Loss 31.13657738788687
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.7001 test: 0.6512 | best val epoch -- val: 0.7035 test: 0.6506

====epoch 98
Train Loss 31.24037982391639
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.7052 test: 0.6540 | best val epoch -- val: 0.7052 test: 0.6540

====epoch 99
Train Loss 31.258935644827808
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6999 test: 0.6585 | best val epoch -- val: 0.7052 test: 0.6540

====epoch 100
Train Loss 31.025599243002326
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.7029 test: 0.6590 | best val epoch -- val: 0.7052 test: 0.6540

[15:39:35] WARNING: not removing hydrogen atom without neighbors
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.4.
2022-09-13 15:39:37.685 | INFO     | modules.masked_transformer_encoder:__init__:122 - number of parameters: 0.000000e+00
=========================================
batch_size = 32
d_model = 128
dataset = toxcast
decay = 0
device = 0
dim_feedforward = 512
eval_train = 0
filename =
gnn_JK = cat
gnn_dropout = 0.3
gnn_emb_dim = 300
gnn_num_layer = 5
gnn_residual = False
gnn_type = gin
gnn_virtual_node = False
graph_pooling = cls
input_model_file = models_graphtrans/graphtrans-sr-gcl.pth
lr = 0.0001
lr_scale = 1
max_input_len = 1000
nhead = 4
num_encoder_layers = 4
num_encoder_layers_masked = 0
num_workers = 0
pos_encoder = False
runseed = 2
seed = 12344
split = scaffold
transformer_activation = relu
transformer_dropout = 0.3
transformer_norm_input = True
transformer_prenorm = False
=========================================
toxcast
scaffold
Loaded GraphTrans from models_graphtrans/graphtrans-sr-gcl.pth
====epoch 1
Train Loss 93.37653083473735
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.5152 test: 0.5083 | best val epoch -- val: 0.5152 test: 0.5083

====epoch 2
Train Loss 52.82790946204471
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.5201 test: 0.5061 | best val epoch -- val: 0.5201 test: 0.5061

====epoch 3
Train Loss 49.49878814463347
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.5217 test: 0.5180 | best val epoch -- val: 0.5217 test: 0.5180

====epoch 4
Train Loss 48.76291974437551
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.5823 test: 0.5659 | best val epoch -- val: 0.5823 test: 0.5659

====epoch 5
Train Loss 46.32596683193195
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6356 test: 0.6007 | best val epoch -- val: 0.6356 test: 0.6007

====epoch 6
Train Loss 44.361817574752436
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6454 test: 0.6081 | best val epoch -- val: 0.6454 test: 0.6081

====epoch 7
Train Loss 43.210097289532044
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6368 test: 0.6034 | best val epoch -- val: 0.6454 test: 0.6081

====epoch 8
Train Loss 42.21886365608815
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6561 test: 0.6147 | best val epoch -- val: 0.6561 test: 0.6147

====epoch 9
Train Loss 41.3959996776138
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6533 test: 0.6149 | best val epoch -- val: 0.6561 test: 0.6147

====epoch 10
Train Loss 40.84159615251609
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6637 test: 0.6148 | best val epoch -- val: 0.6637 test: 0.6148

====epoch 11
Train Loss 40.76207809859012
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6633 test: 0.6125 | best val epoch -- val: 0.6637 test: 0.6148

====epoch 12
Train Loss 40.16780156911253
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6701 test: 0.6250 | best val epoch -- val: 0.6701 test: 0.6250

====epoch 13
Train Loss 39.886100214022974
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6757 test: 0.6243 | best val epoch -- val: 0.6757 test: 0.6243

====epoch 14
Train Loss 39.4497015087571
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6725 test: 0.6282 | best val epoch -- val: 0.6757 test: 0.6243

====epoch 15
Train Loss 39.314000284667884
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6683 test: 0.6274 | best val epoch -- val: 0.6757 test: 0.6243

====epoch 16
Train Loss 38.89673950912776
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6750 test: 0.6317 | best val epoch -- val: 0.6757 test: 0.6243

====epoch 17
Train Loss 38.646478294609196
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6784 test: 0.6344 | best val epoch -- val: 0.6784 test: 0.6344

====epoch 18
Train Loss 38.83561897456632
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6729 test: 0.6357 | best val epoch -- val: 0.6784 test: 0.6344

====epoch 19
Train Loss 38.13802964738504
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6780 test: 0.6387 | best val epoch -- val: 0.6784 test: 0.6344

====epoch 20
Train Loss 37.978721136719756
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6763 test: 0.6318 | best val epoch -- val: 0.6784 test: 0.6344

====epoch 21
Train Loss 38.05074690745675
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6714 test: 0.6250 | best val epoch -- val: 0.6784 test: 0.6344

====epoch 22
Train Loss 37.637386452738916
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6770 test: 0.6295 | best val epoch -- val: 0.6784 test: 0.6344

====epoch 23
Train Loss 37.89146454751059
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6741 test: 0.6289 | best val epoch -- val: 0.6784 test: 0.6344

====epoch 24
Train Loss 37.123812333260666
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6779 test: 0.6241 | best val epoch -- val: 0.6784 test: 0.6344

====epoch 25
Train Loss 37.028475432031904
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6753 test: 0.6238 | best val epoch -- val: 0.6784 test: 0.6344

====epoch 26
Train Loss 37.073226507648165
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6752 test: 0.6223 | best val epoch -- val: 0.6784 test: 0.6344

====epoch 27
Train Loss 36.804410933212864
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6741 test: 0.6282 | best val epoch -- val: 0.6784 test: 0.6344

====epoch 28
Train Loss 36.95052157198914
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6777 test: 0.6286 | best val epoch -- val: 0.6784 test: 0.6344

====epoch 29
Train Loss 36.73769390732089
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6776 test: 0.6317 | best val epoch -- val: 0.6784 test: 0.6344

====epoch 30
Train Loss 36.67638926544006
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6832 test: 0.6308 | best val epoch -- val: 0.6832 test: 0.6308

====epoch 31
Train Loss 36.39016383128304
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6818 test: 0.6338 | best val epoch -- val: 0.6832 test: 0.6308

====epoch 32
Train Loss 36.25798164088657
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6810 test: 0.6335 | best val epoch -- val: 0.6832 test: 0.6308

====epoch 33
Train Loss 36.144366747366654
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6778 test: 0.6292 | best val epoch -- val: 0.6832 test: 0.6308

====epoch 34
Train Loss 35.68450502436943
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6794 test: 0.6376 | best val epoch -- val: 0.6832 test: 0.6308

====epoch 35
Train Loss 35.62055995009916
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6809 test: 0.6341 | best val epoch -- val: 0.6832 test: 0.6308

====epoch 36
Train Loss 35.696057906104755
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6825 test: 0.6284 | best val epoch -- val: 0.6832 test: 0.6308

====epoch 37
Train Loss 35.599500723282986
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6807 test: 0.6290 | best val epoch -- val: 0.6832 test: 0.6308

====epoch 38
Train Loss 35.56607371488044
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6865 test: 0.6361 | best val epoch -- val: 0.6865 test: 0.6361

====epoch 39
Train Loss 35.19919554549557
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6785 test: 0.6314 | best val epoch -- val: 0.6865 test: 0.6361

====epoch 40
Train Loss 35.350432288535245
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6862 test: 0.6353 | best val epoch -- val: 0.6865 test: 0.6361

====epoch 41
Train Loss 35.364494329053514
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6903 test: 0.6453 | best val epoch -- val: 0.6903 test: 0.6453

====epoch 42
Train Loss 35.041549954035126
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6883 test: 0.6429 | best val epoch -- val: 0.6903 test: 0.6453

====epoch 43
Train Loss 34.98310998414857
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6948 test: 0.6451 | best val epoch -- val: 0.6948 test: 0.6451

====epoch 44
Train Loss 34.881124260317016
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6854 test: 0.6386 | best val epoch -- val: 0.6948 test: 0.6451

====epoch 45
Train Loss 34.832950666354854
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6851 test: 0.6408 | best val epoch -- val: 0.6948 test: 0.6451

====epoch 46
Train Loss 34.4857655603026
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6885 test: 0.6329 | best val epoch -- val: 0.6948 test: 0.6451

====epoch 47
Train Loss 34.72079410477701
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6804 test: 0.6383 | best val epoch -- val: 0.6948 test: 0.6451

====epoch 48
Train Loss 34.44283859631573
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6883 test: 0.6430 | best val epoch -- val: 0.6948 test: 0.6451

====epoch 49
Train Loss 34.444733108526385
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6902 test: 0.6420 | best val epoch -- val: 0.6948 test: 0.6451

====epoch 50
Train Loss 34.230179722152116
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6872 test: 0.6439 | best val epoch -- val: 0.6948 test: 0.6451

====epoch 51
Train Loss 34.28835133247045
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6869 test: 0.6477 | best val epoch -- val: 0.6948 test: 0.6451

====epoch 52
Train Loss 34.17662556931066
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6919 test: 0.6462 | best val epoch -- val: 0.6948 test: 0.6451

====epoch 53
Train Loss 34.02357078965435
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6874 test: 0.6429 | best val epoch -- val: 0.6948 test: 0.6451

====epoch 54
Train Loss 33.82841145175165
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6937 test: 0.6476 | best val epoch -- val: 0.6948 test: 0.6451

====epoch 55
Train Loss 33.886765399931484
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6870 test: 0.6473 | best val epoch -- val: 0.6948 test: 0.6451

====epoch 56
Train Loss 33.589340700992246
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6927 test: 0.6403 | best val epoch -- val: 0.6948 test: 0.6451

====epoch 57
Train Loss 33.78253358295857
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6924 test: 0.6448 | best val epoch -- val: 0.6948 test: 0.6451

====epoch 58
Train Loss 33.744213330270846
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6923 test: 0.6398 | best val epoch -- val: 0.6948 test: 0.6451

====epoch 59
Train Loss 33.70108800846381
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6897 test: 0.6430 | best val epoch -- val: 0.6948 test: 0.6451

====epoch 60
Train Loss 33.571781890041606
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6868 test: 0.6426 | best val epoch -- val: 0.6948 test: 0.6451

====epoch 61
Train Loss 33.66197962589079
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6910 test: 0.6456 | best val epoch -- val: 0.6948 test: 0.6451

====epoch 62
Train Loss 33.233027326519704
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6882 test: 0.6465 | best val epoch -- val: 0.6948 test: 0.6451

====epoch 63
Train Loss 33.20142462702525
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6896 test: 0.6438 | best val epoch -- val: 0.6948 test: 0.6451

====epoch 64
Train Loss 33.137025590795766
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6930 test: 0.6458 | best val epoch -- val: 0.6948 test: 0.6451

====epoch 65
Train Loss 32.99369299031976
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6873 test: 0.6449 | best val epoch -- val: 0.6948 test: 0.6451

====epoch 66
Train Loss 32.95106344196398
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6877 test: 0.6408 | best val epoch -- val: 0.6948 test: 0.6451

====epoch 67
Train Loss 33.29747475672433
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6990 test: 0.6505 | best val epoch -- val: 0.6990 test: 0.6505

====epoch 68
Train Loss 32.89513194737237
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6852 test: 0.6428 | best val epoch -- val: 0.6990 test: 0.6505

====epoch 69
Train Loss 32.96098415661029
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6950 test: 0.6502 | best val epoch -- val: 0.6990 test: 0.6505

====epoch 70
Train Loss 32.78058544034596
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6933 test: 0.6434 | best val epoch -- val: 0.6990 test: 0.6505

====epoch 71
Train Loss 32.79753775951932
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6946 test: 0.6514 | best val epoch -- val: 0.6990 test: 0.6505

====epoch 72
Train Loss 32.73365739686202
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.7032 test: 0.6491 | best val epoch -- val: 0.7032 test: 0.6491

====epoch 73
Train Loss 32.702052258117945
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6918 test: 0.6472 | best val epoch -- val: 0.7032 test: 0.6491

====epoch 74
Train Loss 32.37233451848403
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6994 test: 0.6604 | best val epoch -- val: 0.7032 test: 0.6491

====epoch 75
Train Loss 32.472177875036905
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.7003 test: 0.6524 | best val epoch -- val: 0.7032 test: 0.6491

====epoch 76
Train Loss 32.60738877255262
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6928 test: 0.6539 | best val epoch -- val: 0.7032 test: 0.6491

====epoch 77
Train Loss 32.45101290261542
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6994 test: 0.6572 | best val epoch -- val: 0.7032 test: 0.6491

====epoch 78
Train Loss 32.43138005797956
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6955 test: 0.6600 | best val epoch -- val: 0.7032 test: 0.6491

====epoch 79
Train Loss 32.24568331253869
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.7002 test: 0.6591 | best val epoch -- val: 0.7032 test: 0.6491

====epoch 80
Train Loss 31.875055661908352
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6953 test: 0.6546 | best val epoch -- val: 0.7032 test: 0.6491

====epoch 81
Train Loss 32.06604930232291
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6964 test: 0.6546 | best val epoch -- val: 0.7032 test: 0.6491

====epoch 82
Train Loss 32.112016561470156
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.7023 test: 0.6589 | best val epoch -- val: 0.7032 test: 0.6491

====epoch 83
Train Loss 32.06994793955099
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6942 test: 0.6537 | best val epoch -- val: 0.7032 test: 0.6491

====epoch 84
Train Loss 32.01239948708021
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6950 test: 0.6632 | best val epoch -- val: 0.7032 test: 0.6491

====epoch 85
Train Loss 31.95222268128495
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6946 test: 0.6525 | best val epoch -- val: 0.7032 test: 0.6491

====epoch 86
Train Loss 31.765638821920557
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6964 test: 0.6566 | best val epoch -- val: 0.7032 test: 0.6491

====epoch 87
Train Loss 31.824834437076944
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6981 test: 0.6576 | best val epoch -- val: 0.7032 test: 0.6491

====epoch 88
Train Loss 31.825544399474108
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6916 test: 0.6559 | best val epoch -- val: 0.7032 test: 0.6491

====epoch 89
Train Loss 32.00509544690021
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6809 test: 0.6499 | best val epoch -- val: 0.7032 test: 0.6491

====epoch 90
Train Loss 31.733403276010506
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6914 test: 0.6544 | best val epoch -- val: 0.7032 test: 0.6491

====epoch 91
Train Loss 31.609474125493037
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6921 test: 0.6560 | best val epoch -- val: 0.7032 test: 0.6491

====epoch 92
Train Loss 31.49210840957882
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6932 test: 0.6554 | best val epoch -- val: 0.7032 test: 0.6491

====epoch 93
Train Loss 31.498361530854496
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6908 test: 0.6589 | best val epoch -- val: 0.7032 test: 0.6491

====epoch 94
Train Loss 31.410728935683057
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.7011 test: 0.6594 | best val epoch -- val: 0.7032 test: 0.6491

====epoch 95
Train Loss 31.264732503158445
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6997 test: 0.6591 | best val epoch -- val: 0.7032 test: 0.6491

====epoch 96
Train Loss 31.42580453186091
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.7034 test: 0.6599 | best val epoch -- val: 0.7034 test: 0.6599

====epoch 97
Train Loss 31.25018390105993
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.7011 test: 0.6554 | best val epoch -- val: 0.7034 test: 0.6599

====epoch 98
Train Loss 31.26189064995903
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.7071 test: 0.6570 | best val epoch -- val: 0.7071 test: 0.6570

====epoch 99
Train Loss 31.12610804987662
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.7069 test: 0.6601 | best val epoch -- val: 0.7071 test: 0.6570

====epoch 100
Train Loss 30.926306006912146
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.7018 test: 0.6560 | best val epoch -- val: 0.7071 test: 0.6570

[15:55:30] WARNING: not removing hydrogen atom without neighbors
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.4.
2022-09-13 15:55:32.545 | INFO     | modules.masked_transformer_encoder:__init__:122 - number of parameters: 0.000000e+00
=========================================
batch_size = 32
d_model = 128
dataset = toxcast
decay = 0
device = 0
dim_feedforward = 512
eval_train = 0
filename =
gnn_JK = cat
gnn_dropout = 0.3
gnn_emb_dim = 300
gnn_num_layer = 5
gnn_residual = False
gnn_type = gin
gnn_virtual_node = False
graph_pooling = cls
input_model_file = models_graphtrans/graphtrans-sr-gcl.pth
lr = 0.0001
lr_scale = 1
max_input_len = 1000
nhead = 4
num_encoder_layers = 4
num_encoder_layers_masked = 0
num_workers = 0
pos_encoder = False
runseed = 3
seed = 12344
split = scaffold
transformer_activation = relu
transformer_dropout = 0.3
transformer_norm_input = True
transformer_prenorm = False
=========================================
toxcast
scaffold
Loaded GraphTrans from models_graphtrans/graphtrans-sr-gcl.pth
====epoch 1
Train Loss 91.81550925165071
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.5059 test: 0.5170 | best val epoch -- val: 0.5059 test: 0.5170

====epoch 2
Train Loss 52.450319303671286
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.5135 test: 0.5208 | best val epoch -- val: 0.5135 test: 0.5208

====epoch 3
Train Loss 49.460053818782264
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.5191 test: 0.5276 | best val epoch -- val: 0.5191 test: 0.5276

====epoch 4
Train Loss 48.15012124904831
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6084 test: 0.6091 | best val epoch -- val: 0.6084 test: 0.6091

====epoch 5
Train Loss 45.711567974993436
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6316 test: 0.6241 | best val epoch -- val: 0.6316 test: 0.6241

====epoch 6
Train Loss 43.77571952973889
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6400 test: 0.6326 | best val epoch -- val: 0.6400 test: 0.6326

====epoch 7
Train Loss 42.975398461797546
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6417 test: 0.6152 | best val epoch -- val: 0.6417 test: 0.6152

====epoch 8
Train Loss 42.079184771551006
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6413 test: 0.6220 | best val epoch -- val: 0.6417 test: 0.6152

====epoch 9
Train Loss 41.23959761790158
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6474 test: 0.6196 | best val epoch -- val: 0.6474 test: 0.6196

====epoch 10
Train Loss 41.04395490055889
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6512 test: 0.6202 | best val epoch -- val: 0.6512 test: 0.6202

====epoch 11
Train Loss 41.00437568303906
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6519 test: 0.6196 | best val epoch -- val: 0.6519 test: 0.6196

====epoch 12
Train Loss 40.259568092601775
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6538 test: 0.6306 | best val epoch -- val: 0.6538 test: 0.6306

====epoch 13
Train Loss 40.06752162768984
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6573 test: 0.6227 | best val epoch -- val: 0.6573 test: 0.6227

====epoch 14
Train Loss 39.70576492389632
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6591 test: 0.6270 | best val epoch -- val: 0.6591 test: 0.6270

====epoch 15
Train Loss 39.64594783886682
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6638 test: 0.6264 | best val epoch -- val: 0.6638 test: 0.6264

====epoch 16
Train Loss 39.18101039158793
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6723 test: 0.6143 | best val epoch -- val: 0.6723 test: 0.6143

====epoch 17
Train Loss 39.19501890418429
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6713 test: 0.6345 | best val epoch -- val: 0.6723 test: 0.6143

====epoch 18
Train Loss 38.79687045208503
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6649 test: 0.6319 | best val epoch -- val: 0.6723 test: 0.6143

====epoch 19
Train Loss 38.756297820523734
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6766 test: 0.6323 | best val epoch -- val: 0.6766 test: 0.6323

====epoch 20
Train Loss 38.12176256752315
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6676 test: 0.6288 | best val epoch -- val: 0.6766 test: 0.6323

====epoch 21
Train Loss 38.274469819617046
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6676 test: 0.6308 | best val epoch -- val: 0.6766 test: 0.6323

====epoch 22
Train Loss 38.103375873205586
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6761 test: 0.6350 | best val epoch -- val: 0.6766 test: 0.6323

====epoch 23
Train Loss 37.633013863996275
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6729 test: 0.6362 | best val epoch -- val: 0.6766 test: 0.6323

====epoch 24
Train Loss 37.60278032083193
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6782 test: 0.6305 | best val epoch -- val: 0.6782 test: 0.6305

====epoch 25
Train Loss 37.63886151143772
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6811 test: 0.6297 | best val epoch -- val: 0.6811 test: 0.6297

====epoch 26
Train Loss 37.11681664605511
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6833 test: 0.6328 | best val epoch -- val: 0.6833 test: 0.6328

====epoch 27
Train Loss 37.09002694485245
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6756 test: 0.6314 | best val epoch -- val: 0.6833 test: 0.6328

====epoch 28
Train Loss 36.84207868336497
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6782 test: 0.6299 | best val epoch -- val: 0.6833 test: 0.6328

====epoch 29
Train Loss 37.051048407821234
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6838 test: 0.6312 | best val epoch -- val: 0.6838 test: 0.6312

====epoch 30
Train Loss 36.958039765881274
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6897 test: 0.6290 | best val epoch -- val: 0.6897 test: 0.6290

====epoch 31
Train Loss 36.74578926164616
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6899 test: 0.6267 | best val epoch -- val: 0.6899 test: 0.6267

====epoch 32
Train Loss 36.581034767755995
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6830 test: 0.6313 | best val epoch -- val: 0.6899 test: 0.6267

====epoch 33
Train Loss 36.46457687243184
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6891 test: 0.6317 | best val epoch -- val: 0.6899 test: 0.6267

====epoch 34
Train Loss 36.01804686294013
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6883 test: 0.6354 | best val epoch -- val: 0.6899 test: 0.6267

====epoch 35
Train Loss 36.081442556824605
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6818 test: 0.6365 | best val epoch -- val: 0.6899 test: 0.6267

====epoch 36
Train Loss 35.699361078999324
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6836 test: 0.6311 | best val epoch -- val: 0.6899 test: 0.6267

====epoch 37
Train Loss 35.99216566483561
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6864 test: 0.6308 | best val epoch -- val: 0.6899 test: 0.6267

====epoch 38
Train Loss 35.63209416203753
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6856 test: 0.6366 | best val epoch -- val: 0.6899 test: 0.6267

====epoch 39
Train Loss 35.53722869693108
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6877 test: 0.6367 | best val epoch -- val: 0.6899 test: 0.6267

====epoch 40
Train Loss 35.55211883319974
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6872 test: 0.6351 | best val epoch -- val: 0.6899 test: 0.6267

====epoch 41
Train Loss 35.417534044957485
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6931 test: 0.6452 | best val epoch -- val: 0.6931 test: 0.6452

====epoch 42
Train Loss 35.17053457803938
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6946 test: 0.6408 | best val epoch -- val: 0.6946 test: 0.6408

====epoch 43
Train Loss 35.037397263701166
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6941 test: 0.6356 | best val epoch -- val: 0.6946 test: 0.6408

====epoch 44
Train Loss 35.238521746191495
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6878 test: 0.6343 | best val epoch -- val: 0.6946 test: 0.6408

====epoch 45
Train Loss 34.97487551311038
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6931 test: 0.6392 | best val epoch -- val: 0.6946 test: 0.6408

====epoch 46
Train Loss 34.582424693331035
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6903 test: 0.6411 | best val epoch -- val: 0.6946 test: 0.6408

====epoch 47
Train Loss 34.67882379026373
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6912 test: 0.6353 | best val epoch -- val: 0.6946 test: 0.6408

====epoch 48
Train Loss 34.44129558213397
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6917 test: 0.6355 | best val epoch -- val: 0.6946 test: 0.6408

====epoch 49
Train Loss 34.61166655768829
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6946 test: 0.6350 | best val epoch -- val: 0.6946 test: 0.6408

====epoch 50
Train Loss 34.4076494239149
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6980 test: 0.6424 | best val epoch -- val: 0.6980 test: 0.6424

====epoch 51
Train Loss 34.29841792540965
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6880 test: 0.6308 | best val epoch -- val: 0.6980 test: 0.6424

====epoch 52
Train Loss 34.45688061294769
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6970 test: 0.6416 | best val epoch -- val: 0.6980 test: 0.6424

====epoch 53
Train Loss 34.242011062701174
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6944 test: 0.6420 | best val epoch -- val: 0.6980 test: 0.6424

====epoch 54
Train Loss 34.164566947099324
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6891 test: 0.6360 | best val epoch -- val: 0.6980 test: 0.6424

====epoch 55
Train Loss 33.676391058887916
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6895 test: 0.6406 | best val epoch -- val: 0.6980 test: 0.6424

====epoch 56
Train Loss 34.14996755187856
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6925 test: 0.6420 | best val epoch -- val: 0.6980 test: 0.6424

====epoch 57
Train Loss 33.88364911496941
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6975 test: 0.6414 | best val epoch -- val: 0.6980 test: 0.6424

====epoch 58
Train Loss 33.73691902428948
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6927 test: 0.6400 | best val epoch -- val: 0.6980 test: 0.6424

====epoch 59
Train Loss 33.85029111217821
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6924 test: 0.6374 | best val epoch -- val: 0.6980 test: 0.6424

====epoch 60
Train Loss 33.53137827225102
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6945 test: 0.6321 | best val epoch -- val: 0.6980 test: 0.6424

====epoch 61
Train Loss 33.647232916369084
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6880 test: 0.6400 | best val epoch -- val: 0.6980 test: 0.6424

====epoch 62
Train Loss 33.46166771545476
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6896 test: 0.6381 | best val epoch -- val: 0.6980 test: 0.6424

====epoch 63
Train Loss 33.39954697881867
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6928 test: 0.6381 | best val epoch -- val: 0.6980 test: 0.6424

====epoch 64
Train Loss 33.33645001022098
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6892 test: 0.6344 | best val epoch -- val: 0.6980 test: 0.6424

====epoch 65
Train Loss 33.24296390165875
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6886 test: 0.6379 | best val epoch -- val: 0.6980 test: 0.6424

====epoch 66
Train Loss 33.231811910164815
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6936 test: 0.6391 | best val epoch -- val: 0.6980 test: 0.6424

====epoch 67
Train Loss 33.0313559385989
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6921 test: 0.6396 | best val epoch -- val: 0.6980 test: 0.6424

====epoch 68
Train Loss 33.24268398992749
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6868 test: 0.6366 | best val epoch -- val: 0.6980 test: 0.6424

====epoch 69
Train Loss 32.95554193296937
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6910 test: 0.6401 | best val epoch -- val: 0.6980 test: 0.6424

====epoch 70
Train Loss 32.76565290100133
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6927 test: 0.6416 | best val epoch -- val: 0.6980 test: 0.6424

====epoch 71
Train Loss 32.802019632293494
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6944 test: 0.6452 | best val epoch -- val: 0.6980 test: 0.6424

====epoch 72
Train Loss 32.70044777105465
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6917 test: 0.6404 | best val epoch -- val: 0.6980 test: 0.6424

====epoch 73
Train Loss 32.80069555925839
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6857 test: 0.6420 | best val epoch -- val: 0.6980 test: 0.6424

====epoch 74
Train Loss 32.48447533453254
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6842 test: 0.6387 | best val epoch -- val: 0.6980 test: 0.6424

====epoch 75
Train Loss 32.55291294008417
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6913 test: 0.6378 | best val epoch -- val: 0.6980 test: 0.6424

====epoch 76
Train Loss 32.51452745801253
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6872 test: 0.6432 | best val epoch -- val: 0.6980 test: 0.6424

====epoch 77
Train Loss 32.28362811190397
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6921 test: 0.6492 | best val epoch -- val: 0.6980 test: 0.6424

====epoch 78
Train Loss 32.43606774729002
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6924 test: 0.6520 | best val epoch -- val: 0.6980 test: 0.6424

====epoch 79
Train Loss 32.27305099090506
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6902 test: 0.6546 | best val epoch -- val: 0.6980 test: 0.6424

====epoch 80
Train Loss 32.07930498494702
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6926 test: 0.6461 | best val epoch -- val: 0.6980 test: 0.6424

====epoch 81
Train Loss 32.22318660858519
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6903 test: 0.6485 | best val epoch -- val: 0.6980 test: 0.6424

====epoch 82
Train Loss 32.3502458690417
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6847 test: 0.6509 | best val epoch -- val: 0.6980 test: 0.6424

====epoch 83
Train Loss 32.06887780487257
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6857 test: 0.6547 | best val epoch -- val: 0.6980 test: 0.6424

====epoch 84
Train Loss 31.944427980943384
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6907 test: 0.6530 | best val epoch -- val: 0.6980 test: 0.6424

====epoch 85
Train Loss 31.739550733253356
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6948 test: 0.6520 | best val epoch -- val: 0.6980 test: 0.6424

====epoch 86
Train Loss 32.00658375791173
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6888 test: 0.6515 | best val epoch -- val: 0.6980 test: 0.6424

====epoch 87
Train Loss 31.827323491452763
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6977 test: 0.6568 | best val epoch -- val: 0.6980 test: 0.6424

====epoch 88
Train Loss 32.15028120949515
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6889 test: 0.6513 | best val epoch -- val: 0.6980 test: 0.6424

====epoch 89
Train Loss 31.721843717031273
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6899 test: 0.6516 | best val epoch -- val: 0.6980 test: 0.6424

====epoch 90
Train Loss 31.586909064044878
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6954 test: 0.6535 | best val epoch -- val: 0.6980 test: 0.6424

====epoch 91
Train Loss 31.42101086662019
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6887 test: 0.6566 | best val epoch -- val: 0.6980 test: 0.6424

====epoch 92
Train Loss 31.525319546957572
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6899 test: 0.6484 | best val epoch -- val: 0.6980 test: 0.6424

====epoch 93
Train Loss 31.388270159308046
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6899 test: 0.6585 | best val epoch -- val: 0.6980 test: 0.6424

====epoch 94
Train Loss 31.483015947797035
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6905 test: 0.6604 | best val epoch -- val: 0.6980 test: 0.6424

====epoch 95
Train Loss 31.285753107691264
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6977 test: 0.6610 | best val epoch -- val: 0.6980 test: 0.6424

====epoch 96
Train Loss 31.462022427432473
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6945 test: 0.6545 | best val epoch -- val: 0.6980 test: 0.6424

====epoch 97
Train Loss 31.429731290571294
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6886 test: 0.6550 | best val epoch -- val: 0.6980 test: 0.6424

====epoch 98
Train Loss 31.397005806135773
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6903 test: 0.6508 | best val epoch -- val: 0.6980 test: 0.6424

====epoch 99
Train Loss 31.009340950083317
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.7008 test: 0.6615 | best val epoch -- val: 0.7008 test: 0.6615

====epoch 100
Train Loss 31.149638102762
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6933 test: 0.6570 | best val epoch -- val: 0.7008 test: 0.6615

[16:11:11] WARNING: not removing hydrogen atom without neighbors
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.4.
2022-09-13 16:11:12.703 | INFO     | modules.masked_transformer_encoder:__init__:122 - number of parameters: 0.000000e+00
=========================================
batch_size = 32
d_model = 128
dataset = toxcast
decay = 0
device = 0
dim_feedforward = 512
eval_train = 0
filename =
gnn_JK = cat
gnn_dropout = 0.3
gnn_emb_dim = 300
gnn_num_layer = 5
gnn_residual = False
gnn_type = gin
gnn_virtual_node = False
graph_pooling = cls
input_model_file = models_graphtrans/graphtrans-sr-gcl.pth
lr = 0.0001
lr_scale = 1
max_input_len = 1000
nhead = 4
num_encoder_layers = 4
num_encoder_layers_masked = 0
num_workers = 0
pos_encoder = False
runseed = 4
seed = 12344
split = scaffold
transformer_activation = relu
transformer_dropout = 0.3
transformer_norm_input = True
transformer_prenorm = False
=========================================
toxcast
scaffold
Loaded GraphTrans from models_graphtrans/graphtrans-sr-gcl.pth
====epoch 1
Train Loss 92.85269250589654
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.5107 test: 0.5144 | best val epoch -- val: 0.5107 test: 0.5144

====epoch 2
Train Loss 52.85760609138877
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.5090 test: 0.5128 | best val epoch -- val: 0.5107 test: 0.5144

====epoch 3
Train Loss 49.5281335566397
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.5154 test: 0.5158 | best val epoch -- val: 0.5154 test: 0.5158

====epoch 4
Train Loss 48.90685352625849
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.5302 test: 0.5267 | best val epoch -- val: 0.5302 test: 0.5267

====epoch 5
Train Loss 47.40010473619016
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6308 test: 0.6100 | best val epoch -- val: 0.6308 test: 0.6100

====epoch 6
Train Loss 45.206647891765506
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6261 test: 0.6130 | best val epoch -- val: 0.6308 test: 0.6100

====epoch 7
Train Loss 43.541742109368876
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6264 test: 0.6157 | best val epoch -- val: 0.6308 test: 0.6100

====epoch 8
Train Loss 42.74816182235355
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6218 test: 0.6285 | best val epoch -- val: 0.6308 test: 0.6100

====epoch 9
Train Loss 41.81281483004306
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6191 test: 0.6135 | best val epoch -- val: 0.6308 test: 0.6100

====epoch 10
Train Loss 41.38265913364775
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6286 test: 0.6125 | best val epoch -- val: 0.6308 test: 0.6100

====epoch 11
Train Loss 40.93701645429714
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6352 test: 0.6173 | best val epoch -- val: 0.6352 test: 0.6173

====epoch 12
Train Loss 40.7255045001245
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6291 test: 0.6156 | best val epoch -- val: 0.6352 test: 0.6173

====epoch 13
Train Loss 40.384597361606026
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6330 test: 0.6091 | best val epoch -- val: 0.6352 test: 0.6173

====epoch 14
Train Loss 40.237665388510415
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6285 test: 0.6172 | best val epoch -- val: 0.6352 test: 0.6173

====epoch 15
Train Loss 39.67285399254584
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6354 test: 0.6249 | best val epoch -- val: 0.6354 test: 0.6249

====epoch 16
Train Loss 39.778972935670446
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6370 test: 0.6183 | best val epoch -- val: 0.6370 test: 0.6183

====epoch 17
Train Loss 39.475384076443554
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6424 test: 0.6134 | best val epoch -- val: 0.6424 test: 0.6134

====epoch 18
Train Loss 39.03733905155251
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6442 test: 0.6132 | best val epoch -- val: 0.6442 test: 0.6132

====epoch 19
Train Loss 39.16015431594826
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6422 test: 0.6140 | best val epoch -- val: 0.6442 test: 0.6132

====epoch 20
Train Loss 38.5528268739078
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6462 test: 0.6141 | best val epoch -- val: 0.6462 test: 0.6141

====epoch 21
Train Loss 38.55895024324744
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6453 test: 0.6269 | best val epoch -- val: 0.6462 test: 0.6141

====epoch 22
Train Loss 38.57271943775187
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6520 test: 0.6276 | best val epoch -- val: 0.6520 test: 0.6276

====epoch 23
Train Loss 38.14171901175144
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6430 test: 0.6306 | best val epoch -- val: 0.6520 test: 0.6276

====epoch 24
Train Loss 38.042851455053984
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6564 test: 0.6242 | best val epoch -- val: 0.6564 test: 0.6242

====epoch 25
Train Loss 38.036353976816805
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6573 test: 0.6270 | best val epoch -- val: 0.6573 test: 0.6270

====epoch 26
Train Loss 37.63696404106613
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6609 test: 0.6237 | best val epoch -- val: 0.6609 test: 0.6237

====epoch 27
Train Loss 37.71443066944963
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6593 test: 0.6264 | best val epoch -- val: 0.6609 test: 0.6237

====epoch 28
Train Loss 37.31959824863738
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6559 test: 0.6359 | best val epoch -- val: 0.6609 test: 0.6237

====epoch 29
Train Loss 37.474023938026114
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6613 test: 0.6326 | best val epoch -- val: 0.6613 test: 0.6326

====epoch 30
Train Loss 37.12880776453992
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6579 test: 0.6333 | best val epoch -- val: 0.6613 test: 0.6326

====epoch 31
Train Loss 37.09339035508743
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6641 test: 0.6361 | best val epoch -- val: 0.6641 test: 0.6361

====epoch 32
Train Loss 36.65920817344981
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6696 test: 0.6354 | best val epoch -- val: 0.6696 test: 0.6354

====epoch 33
Train Loss 36.91421211142269
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6657 test: 0.6388 | best val epoch -- val: 0.6696 test: 0.6354

====epoch 34
Train Loss 36.50396133295447
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6616 test: 0.6283 | best val epoch -- val: 0.6696 test: 0.6354

====epoch 35
Train Loss 36.51844664239227
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6635 test: 0.6343 | best val epoch -- val: 0.6696 test: 0.6354

====epoch 36
Train Loss 36.474253285797865
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6597 test: 0.6319 | best val epoch -- val: 0.6696 test: 0.6354

====epoch 37
Train Loss 36.13327214307624
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6693 test: 0.6349 | best val epoch -- val: 0.6696 test: 0.6354

====epoch 38
Train Loss 35.86318140790776
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6677 test: 0.6401 | best val epoch -- val: 0.6696 test: 0.6354

====epoch 39
Train Loss 36.21804836266316
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6673 test: 0.6416 | best val epoch -- val: 0.6696 test: 0.6354

====epoch 40
Train Loss 36.038930403507976
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6695 test: 0.6417 | best val epoch -- val: 0.6696 test: 0.6354

====epoch 41
Train Loss 36.15357713143699
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6633 test: 0.6356 | best val epoch -- val: 0.6696 test: 0.6354

====epoch 42
Train Loss 35.78462373479818
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6746 test: 0.6367 | best val epoch -- val: 0.6746 test: 0.6367

====epoch 43
Train Loss 35.6921569535709
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6665 test: 0.6359 | best val epoch -- val: 0.6746 test: 0.6367

====epoch 44
Train Loss 35.61795925308037
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6726 test: 0.6434 | best val epoch -- val: 0.6746 test: 0.6367

====epoch 45
Train Loss 35.732933405674025
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6730 test: 0.6440 | best val epoch -- val: 0.6746 test: 0.6367

====epoch 46
Train Loss 35.1125641075904
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6652 test: 0.6337 | best val epoch -- val: 0.6746 test: 0.6367

====epoch 47
Train Loss 35.45896913783156
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6731 test: 0.6429 | best val epoch -- val: 0.6746 test: 0.6367

====epoch 48
Train Loss 35.28791482219345
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6765 test: 0.6425 | best val epoch -- val: 0.6765 test: 0.6425

====epoch 49
Train Loss 35.14060893658378
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6776 test: 0.6497 | best val epoch -- val: 0.6776 test: 0.6497

====epoch 50
Train Loss 35.05232496402435
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6696 test: 0.6416 | best val epoch -- val: 0.6776 test: 0.6497

====epoch 51
Train Loss 35.309849852135066
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6762 test: 0.6386 | best val epoch -- val: 0.6776 test: 0.6497

====epoch 52
Train Loss 34.90301142049874
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6776 test: 0.6416 | best val epoch -- val: 0.6776 test: 0.6497

====epoch 53
Train Loss 34.81344922323754
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6808 test: 0.6412 | best val epoch -- val: 0.6808 test: 0.6412

====epoch 54
Train Loss 34.495405902682805
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6764 test: 0.6400 | best val epoch -- val: 0.6808 test: 0.6412

====epoch 55
Train Loss 34.65166658666715
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6776 test: 0.6441 | best val epoch -- val: 0.6808 test: 0.6412

====epoch 56
Train Loss 34.6228867272512
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6792 test: 0.6449 | best val epoch -- val: 0.6808 test: 0.6412

====epoch 57
Train Loss 34.497051899582395
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6824 test: 0.6522 | best val epoch -- val: 0.6824 test: 0.6522

====epoch 58
Train Loss 34.20904391151402
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6871 test: 0.6490 | best val epoch -- val: 0.6871 test: 0.6490

====epoch 59
Train Loss 34.54007030791036
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6797 test: 0.6416 | best val epoch -- val: 0.6871 test: 0.6490

====epoch 60
Train Loss 34.21936851138403
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6762 test: 0.6371 | best val epoch -- val: 0.6871 test: 0.6490

====epoch 61
Train Loss 33.784570584496976
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6819 test: 0.6427 | best val epoch -- val: 0.6871 test: 0.6490

====epoch 62
Train Loss 34.016696115894185
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6825 test: 0.6451 | best val epoch -- val: 0.6871 test: 0.6490

====epoch 63
Train Loss 34.090140865368795
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6807 test: 0.6466 | best val epoch -- val: 0.6871 test: 0.6490

====epoch 64
Train Loss 33.86352230756188
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6809 test: 0.6454 | best val epoch -- val: 0.6871 test: 0.6490

====epoch 65
Train Loss 33.88984269009169
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6787 test: 0.6502 | best val epoch -- val: 0.6871 test: 0.6490

====epoch 66
Train Loss 33.5365984453417
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6823 test: 0.6439 | best val epoch -- val: 0.6871 test: 0.6490

====epoch 67
Train Loss 33.64390188050692
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6818 test: 0.6545 | best val epoch -- val: 0.6871 test: 0.6490

====epoch 68
Train Loss 33.65129127058514
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6788 test: 0.6483 | best val epoch -- val: 0.6871 test: 0.6490

====epoch 69
Train Loss 33.685734977106435
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6814 test: 0.6530 | best val epoch -- val: 0.6871 test: 0.6490

====epoch 70
Train Loss 33.35083185359509
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6803 test: 0.6512 | best val epoch -- val: 0.6871 test: 0.6490

====epoch 71
Train Loss 33.361965235061554
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6835 test: 0.6475 | best val epoch -- val: 0.6871 test: 0.6490

====epoch 72
Train Loss 33.024913000697815
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6849 test: 0.6472 | best val epoch -- val: 0.6871 test: 0.6490

====epoch 73
Train Loss 33.22377655983756
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6787 test: 0.6475 | best val epoch -- val: 0.6871 test: 0.6490

====epoch 74
Train Loss 33.09143878734864
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6786 test: 0.6500 | best val epoch -- val: 0.6871 test: 0.6490

====epoch 75
Train Loss 33.07410039798195
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6821 test: 0.6453 | best val epoch -- val: 0.6871 test: 0.6490

====epoch 76
Train Loss 32.80277487955912
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6826 test: 0.6505 | best val epoch -- val: 0.6871 test: 0.6490

====epoch 77
Train Loss 32.949666328315544
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6835 test: 0.6457 | best val epoch -- val: 0.6871 test: 0.6490

====epoch 78
Train Loss 32.74922127206362
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6801 test: 0.6451 | best val epoch -- val: 0.6871 test: 0.6490

====epoch 79
Train Loss 32.68814292735934
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6813 test: 0.6509 | best val epoch -- val: 0.6871 test: 0.6490

====epoch 80
Train Loss 32.582280048125014
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6837 test: 0.6506 | best val epoch -- val: 0.6871 test: 0.6490

====epoch 81
Train Loss 32.59027026619311
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6761 test: 0.6490 | best val epoch -- val: 0.6871 test: 0.6490

====epoch 82
Train Loss 32.595001583490784
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6788 test: 0.6489 | best val epoch -- val: 0.6871 test: 0.6490

====epoch 83
Train Loss 32.50452698878778
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6811 test: 0.6523 | best val epoch -- val: 0.6871 test: 0.6490

====epoch 84
Train Loss 32.45700568686711
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6744 test: 0.6499 | best val epoch -- val: 0.6871 test: 0.6490

====epoch 85
Train Loss 32.26304998102348
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6815 test: 0.6536 | best val epoch -- val: 0.6871 test: 0.6490

====epoch 86
Train Loss 32.28892324246164
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6812 test: 0.6538 | best val epoch -- val: 0.6871 test: 0.6490

====epoch 87
Train Loss 32.23310719089167
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6871 test: 0.6582 | best val epoch -- val: 0.6871 test: 0.6582

====epoch 88
Train Loss 32.21333486390167
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6881 test: 0.6609 | best val epoch -- val: 0.6881 test: 0.6609

====epoch 89
Train Loss 32.294312097473444
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6870 test: 0.6563 | best val epoch -- val: 0.6881 test: 0.6609

====epoch 90
Train Loss 32.13222261371178
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6915 test: 0.6647 | best val epoch -- val: 0.6915 test: 0.6647

====epoch 91
Train Loss 31.936312784744413
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6937 test: 0.6649 | best val epoch -- val: 0.6937 test: 0.6649

====epoch 92
Train Loss 32.03300514516123
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6942 test: 0.6584 | best val epoch -- val: 0.6942 test: 0.6584

====epoch 93
Train Loss 31.93010776667435
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6934 test: 0.6662 | best val epoch -- val: 0.6942 test: 0.6584

====epoch 94
Train Loss 31.975093340606996
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6959 test: 0.6660 | best val epoch -- val: 0.6959 test: 0.6660

====epoch 95
Train Loss 31.513240187151975
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6904 test: 0.6673 | best val epoch -- val: 0.6959 test: 0.6660

====epoch 96
Train Loss 31.90761119730163
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6816 test: 0.6564 | best val epoch -- val: 0.6959 test: 0.6660

====epoch 97
Train Loss 31.522004391051148
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6922 test: 0.6670 | best val epoch -- val: 0.6959 test: 0.6660

====epoch 98
Train Loss 31.365554311844292
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6876 test: 0.6608 | best val epoch -- val: 0.6959 test: 0.6660

====epoch 99
Train Loss 31.544349274600812
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6878 test: 0.6625 | best val epoch -- val: 0.6959 test: 0.6660

====epoch 100
Train Loss 31.562183531127058
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6999 test: 0.6702 | best val epoch -- val: 0.6999 test: 0.6702

[16:27:02] WARNING: not removing hydrogen atom without neighbors
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.4.
2022-09-13 16:27:04.185 | INFO     | modules.masked_transformer_encoder:__init__:122 - number of parameters: 0.000000e+00
=========================================
batch_size = 32
d_model = 128
dataset = toxcast
decay = 0
device = 0
dim_feedforward = 512
eval_train = 0
filename =
gnn_JK = cat
gnn_dropout = 0.3
gnn_emb_dim = 300
gnn_num_layer = 5
gnn_residual = False
gnn_type = gin
gnn_virtual_node = False
graph_pooling = cls
input_model_file = models_graphtrans/graphtrans-sr-gcl.pth
lr = 0.0001
lr_scale = 1
max_input_len = 1000
nhead = 4
num_encoder_layers = 4
num_encoder_layers_masked = 0
num_workers = 0
pos_encoder = False
runseed = 5
seed = 12344
split = scaffold
transformer_activation = relu
transformer_dropout = 0.3
transformer_norm_input = True
transformer_prenorm = False
=========================================
toxcast
scaffold
Loaded GraphTrans from models_graphtrans/graphtrans-sr-gcl.pth
====epoch 1
Train Loss 90.75898768530959
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.5172 test: 0.5060 | best val epoch -- val: 0.5172 test: 0.5060

====epoch 2
Train Loss 52.55924037206665
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.5238 test: 0.5110 | best val epoch -- val: 0.5238 test: 0.5110

====epoch 3
Train Loss 49.544881627991536
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.5159 test: 0.5165 | best val epoch -- val: 0.5238 test: 0.5110

====epoch 4
Train Loss 48.13329034312251
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.5977 test: 0.5690 | best val epoch -- val: 0.5977 test: 0.5690

====epoch 5
Train Loss 45.56047727235301
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6107 test: 0.5932 | best val epoch -- val: 0.6107 test: 0.5932

====epoch 6
Train Loss 43.884436153924526
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6279 test: 0.6136 | best val epoch -- val: 0.6279 test: 0.6136

====epoch 7
Train Loss 42.348985210381535
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6354 test: 0.6157 | best val epoch -- val: 0.6354 test: 0.6157

====epoch 8
Train Loss 42.14384228238596
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6436 test: 0.6128 | best val epoch -- val: 0.6436 test: 0.6128

====epoch 9
Train Loss 41.13247363873457
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6444 test: 0.6093 | best val epoch -- val: 0.6444 test: 0.6093

====epoch 10
Train Loss 40.875152382908105
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6491 test: 0.6128 | best val epoch -- val: 0.6491 test: 0.6128

====epoch 11
Train Loss 40.07151302257209
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6501 test: 0.6183 | best val epoch -- val: 0.6501 test: 0.6183

====epoch 12
Train Loss 40.04402789840055
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6549 test: 0.6262 | best val epoch -- val: 0.6549 test: 0.6262

====epoch 13
Train Loss 39.64847273156221
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6505 test: 0.6229 | best val epoch -- val: 0.6549 test: 0.6262

====epoch 14
Train Loss 39.875234127372885
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6489 test: 0.6232 | best val epoch -- val: 0.6549 test: 0.6262

====epoch 15
Train Loss 39.03992801535386
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6509 test: 0.6262 | best val epoch -- val: 0.6549 test: 0.6262

====epoch 16
Train Loss 38.75728816043796
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6597 test: 0.6273 | best val epoch -- val: 0.6597 test: 0.6273

====epoch 17
Train Loss 38.689083168077715
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6644 test: 0.6283 | best val epoch -- val: 0.6644 test: 0.6283

====epoch 18
Train Loss 38.48230123868063
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6668 test: 0.6272 | best val epoch -- val: 0.6668 test: 0.6272

====epoch 19
Train Loss 37.9869331573267
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6588 test: 0.6250 | best val epoch -- val: 0.6668 test: 0.6272

====epoch 20
Train Loss 37.82764479918507
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6648 test: 0.6321 | best val epoch -- val: 0.6668 test: 0.6272

====epoch 21
Train Loss 37.76579475141772
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6715 test: 0.6334 | best val epoch -- val: 0.6715 test: 0.6334

====epoch 22
Train Loss 37.538127289256764
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6667 test: 0.6328 | best val epoch -- val: 0.6715 test: 0.6334

====epoch 23
Train Loss 37.55022098036196
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6702 test: 0.6316 | best val epoch -- val: 0.6715 test: 0.6334

====epoch 24
Train Loss 37.500139451672204
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6667 test: 0.6248 | best val epoch -- val: 0.6715 test: 0.6334

====epoch 25
Train Loss 37.00001830321722
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6784 test: 0.6290 | best val epoch -- val: 0.6784 test: 0.6290

====epoch 26
Train Loss 37.11206167966829
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6739 test: 0.6270 | best val epoch -- val: 0.6784 test: 0.6290

====epoch 27
Train Loss 36.827957491285176
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6829 test: 0.6326 | best val epoch -- val: 0.6829 test: 0.6326

====epoch 28
Train Loss 36.47306995006277
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6780 test: 0.6244 | best val epoch -- val: 0.6829 test: 0.6326

====epoch 29
Train Loss 36.52321620737779
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6805 test: 0.6346 | best val epoch -- val: 0.6829 test: 0.6326

====epoch 30
Train Loss 36.45827450151192
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6745 test: 0.6307 | best val epoch -- val: 0.6829 test: 0.6326

====epoch 31
Train Loss 36.280517922010425
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6819 test: 0.6302 | best val epoch -- val: 0.6829 test: 0.6326

====epoch 32
Train Loss 36.24635381410971
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6842 test: 0.6356 | best val epoch -- val: 0.6842 test: 0.6356

====epoch 33
Train Loss 36.09105159420369
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6857 test: 0.6345 | best val epoch -- val: 0.6857 test: 0.6345

====epoch 34
Train Loss 35.89396974148905
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6800 test: 0.6407 | best val epoch -- val: 0.6857 test: 0.6345

====epoch 35
Train Loss 35.60779658991248
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6803 test: 0.6290 | best val epoch -- val: 0.6857 test: 0.6345

====epoch 36
Train Loss 35.81438806053938
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6862 test: 0.6439 | best val epoch -- val: 0.6862 test: 0.6439

====epoch 37
Train Loss 35.40203730422589
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6827 test: 0.6413 | best val epoch -- val: 0.6862 test: 0.6439

====epoch 38
Train Loss 35.53946740116754
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6766 test: 0.6340 | best val epoch -- val: 0.6862 test: 0.6439

====epoch 39
Train Loss 35.33544166138697
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6817 test: 0.6299 | best val epoch -- val: 0.6862 test: 0.6439

====epoch 40
Train Loss 35.32345717276509
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6837 test: 0.6350 | best val epoch -- val: 0.6862 test: 0.6439

====epoch 41
Train Loss 34.84803319304498
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6832 test: 0.6419 | best val epoch -- val: 0.6862 test: 0.6439

====epoch 42
Train Loss 35.036119268223956
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6815 test: 0.6368 | best val epoch -- val: 0.6862 test: 0.6439

====epoch 43
Train Loss 34.6965480764612
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6878 test: 0.6412 | best val epoch -- val: 0.6878 test: 0.6412

====epoch 44
Train Loss 34.73444620435001
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6867 test: 0.6397 | best val epoch -- val: 0.6878 test: 0.6412

====epoch 45
Train Loss 34.99087956365159
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6931 test: 0.6432 | best val epoch -- val: 0.6931 test: 0.6432

====epoch 46
Train Loss 34.622019635125106
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6898 test: 0.6399 | best val epoch -- val: 0.6931 test: 0.6432

====epoch 47
Train Loss 34.45817204078023
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6910 test: 0.6458 | best val epoch -- val: 0.6931 test: 0.6432

====epoch 48
Train Loss 34.3340978440348
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6889 test: 0.6397 | best val epoch -- val: 0.6931 test: 0.6432

====epoch 49
Train Loss 34.506982180969665
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6847 test: 0.6408 | best val epoch -- val: 0.6931 test: 0.6432

====epoch 50
Train Loss 34.092604507982685
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6893 test: 0.6422 | best val epoch -- val: 0.6931 test: 0.6432

====epoch 51
Train Loss 34.291180328982676
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6973 test: 0.6358 | best val epoch -- val: 0.6973 test: 0.6358

====epoch 52
Train Loss 33.93137086932669
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6886 test: 0.6346 | best val epoch -- val: 0.6973 test: 0.6358

====epoch 53
Train Loss 33.86583713418825
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6931 test: 0.6297 | best val epoch -- val: 0.6973 test: 0.6358

====epoch 54
Train Loss 33.89675737654632
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6902 test: 0.6309 | best val epoch -- val: 0.6973 test: 0.6358

====epoch 55
Train Loss 33.73294248414189
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6965 test: 0.6399 | best val epoch -- val: 0.6973 test: 0.6358

====epoch 56
Train Loss 34.049042838106175
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6961 test: 0.6427 | best val epoch -- val: 0.6973 test: 0.6358

====epoch 57
Train Loss 33.47109404765661
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6929 test: 0.6419 | best val epoch -- val: 0.6973 test: 0.6358

====epoch 58
Train Loss 33.621370392554006
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6975 test: 0.6431 | best val epoch -- val: 0.6975 test: 0.6431

====epoch 59
Train Loss 33.381840909124755
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6930 test: 0.6410 | best val epoch -- val: 0.6975 test: 0.6431

====epoch 60
Train Loss 33.65093814698842
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6870 test: 0.6421 | best val epoch -- val: 0.6975 test: 0.6431

====epoch 61
Train Loss 33.418335665886694
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6934 test: 0.6511 | best val epoch -- val: 0.6975 test: 0.6431

====epoch 62
Train Loss 33.30223793205665
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6923 test: 0.6489 | best val epoch -- val: 0.6975 test: 0.6431

====epoch 63
Train Loss 33.025383144985696
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6935 test: 0.6500 | best val epoch -- val: 0.6975 test: 0.6431

====epoch 64
Train Loss 32.806379787685664
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6900 test: 0.6420 | best val epoch -- val: 0.6975 test: 0.6431

====epoch 65
Train Loss 32.91391346228315
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6985 test: 0.6555 | best val epoch -- val: 0.6985 test: 0.6555

====epoch 66
Train Loss 33.10272784187432
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6977 test: 0.6505 | best val epoch -- val: 0.6985 test: 0.6555

====epoch 67
Train Loss 32.813931130739945
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6958 test: 0.6553 | best val epoch -- val: 0.6985 test: 0.6555

====epoch 68
Train Loss 32.721314509549444
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6917 test: 0.6488 | best val epoch -- val: 0.6985 test: 0.6555

====epoch 69
Train Loss 32.610364912899115
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6920 test: 0.6438 | best val epoch -- val: 0.6985 test: 0.6555

====epoch 70
Train Loss 32.73603817311956
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6929 test: 0.6522 | best val epoch -- val: 0.6985 test: 0.6555

====epoch 71
Train Loss 32.555597960737146
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6973 test: 0.6531 | best val epoch -- val: 0.6985 test: 0.6555

====epoch 72
Train Loss 32.606378333707916
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6945 test: 0.6503 | best val epoch -- val: 0.6985 test: 0.6555

====epoch 73
Train Loss 32.42745193452634
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.7043 test: 0.6562 | best val epoch -- val: 0.7043 test: 0.6562

====epoch 74
Train Loss 32.37130815057513
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.7003 test: 0.6524 | best val epoch -- val: 0.7043 test: 0.6562

====epoch 75
Train Loss 31.96589334254176
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6919 test: 0.6509 | best val epoch -- val: 0.7043 test: 0.6562

====epoch 76
Train Loss 32.07280947789695
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6916 test: 0.6512 | best val epoch -- val: 0.7043 test: 0.6562

====epoch 77
Train Loss 32.26449000153038
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6975 test: 0.6536 | best val epoch -- val: 0.7043 test: 0.6562

====epoch 78
Train Loss 32.0889768227518
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6954 test: 0.6495 | best val epoch -- val: 0.7043 test: 0.6562

====epoch 79
Train Loss 31.968117963446485
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6962 test: 0.6573 | best val epoch -- val: 0.7043 test: 0.6562

====epoch 80
Train Loss 32.05795454325484
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6953 test: 0.6534 | best val epoch -- val: 0.7043 test: 0.6562

====epoch 81
Train Loss 31.98788300548631
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6920 test: 0.6490 | best val epoch -- val: 0.7043 test: 0.6562

====epoch 82
Train Loss 31.696614126490267
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6956 test: 0.6496 | best val epoch -- val: 0.7043 test: 0.6562

====epoch 83
Train Loss 31.739047131387473
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6974 test: 0.6515 | best val epoch -- val: 0.7043 test: 0.6562

====epoch 84
Train Loss 31.74629885753541
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6954 test: 0.6560 | best val epoch -- val: 0.7043 test: 0.6562

====epoch 85
Train Loss 31.668282861699332
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6995 test: 0.6524 | best val epoch -- val: 0.7043 test: 0.6562

====epoch 86
Train Loss 31.617128979764537
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6945 test: 0.6476 | best val epoch -- val: 0.7043 test: 0.6562

====epoch 87
Train Loss 31.627288368609467
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6994 test: 0.6544 | best val epoch -- val: 0.7043 test: 0.6562

====epoch 88
Train Loss 31.5454417918679
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.7020 test: 0.6528 | best val epoch -- val: 0.7043 test: 0.6562

====epoch 89
Train Loss 31.37714451986821
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.7020 test: 0.6531 | best val epoch -- val: 0.7043 test: 0.6562

====epoch 90
Train Loss 31.503205870366262
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.7023 test: 0.6498 | best val epoch -- val: 0.7043 test: 0.6562

====epoch 91
Train Loss 31.28175171395442
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6957 test: 0.6547 | best val epoch -- val: 0.7043 test: 0.6562

====epoch 92
Train Loss 31.162810466716472
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6984 test: 0.6545 | best val epoch -- val: 0.7043 test: 0.6562

====epoch 93
Train Loss 31.25926199753066
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.7034 test: 0.6620 | best val epoch -- val: 0.7043 test: 0.6562

====epoch 94
Train Loss 31.156272397948978
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.7055 test: 0.6582 | best val epoch -- val: 0.7055 test: 0.6582

====epoch 95
Train Loss 31.160758690351727
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.7021 test: 0.6550 | best val epoch -- val: 0.7055 test: 0.6582

====epoch 96
Train Loss 31.01962449558902
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.7074 test: 0.6597 | best val epoch -- val: 0.7074 test: 0.6597

====epoch 97
Train Loss 31.09052432182281
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.7047 test: 0.6590 | best val epoch -- val: 0.7074 test: 0.6597

====epoch 98
Train Loss 30.956125776162065
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.7055 test: 0.6557 | best val epoch -- val: 0.7074 test: 0.6597

====epoch 99
Train Loss 30.91756541388181
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.7058 test: 0.6565 | best val epoch -- val: 0.7074 test: 0.6597

====epoch 100
Train Loss 30.7665428454658
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.7030 test: 0.6590 | best val epoch -- val: 0.7074 test: 0.6597

[16:42:56] WARNING: not removing hydrogen atom without neighbors
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.4.
2022-09-13 16:42:57.825 | INFO     | modules.masked_transformer_encoder:__init__:122 - number of parameters: 0.000000e+00
=========================================
batch_size = 32
d_model = 128
dataset = toxcast
decay = 0
device = 0
dim_feedforward = 512
eval_train = 0
filename =
gnn_JK = cat
gnn_dropout = 0.3
gnn_emb_dim = 300
gnn_num_layer = 5
gnn_residual = False
gnn_type = gin
gnn_virtual_node = False
graph_pooling = cls
input_model_file = models_graphtrans/graphtrans-sr-gcl.pth
lr = 0.0001
lr_scale = 1
max_input_len = 1000
nhead = 4
num_encoder_layers = 4
num_encoder_layers_masked = 0
num_workers = 0
pos_encoder = False
runseed = 6
seed = 12344
split = scaffold
transformer_activation = relu
transformer_dropout = 0.3
transformer_norm_input = True
transformer_prenorm = False
=========================================
toxcast
scaffold
Loaded GraphTrans from models_graphtrans/graphtrans-sr-gcl.pth
====epoch 1
Train Loss 91.918220275977
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.5242 test: 0.5076 | best val epoch -- val: 0.5242 test: 0.5076

====epoch 2
Train Loss 52.939688215774105
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.5235 test: 0.5043 | best val epoch -- val: 0.5242 test: 0.5076

====epoch 3
Train Loss 49.45616341886034
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.5358 test: 0.5175 | best val epoch -- val: 0.5358 test: 0.5175

====epoch 4
Train Loss 48.880926293192616
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.5575 test: 0.5356 | best val epoch -- val: 0.5575 test: 0.5356

====epoch 5
Train Loss 47.44139471606786
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6265 test: 0.5977 | best val epoch -- val: 0.6265 test: 0.5977

====epoch 6
Train Loss 45.082035834280084
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6208 test: 0.6204 | best val epoch -- val: 0.6265 test: 0.5977

====epoch 7
Train Loss 43.521703476366966
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6336 test: 0.6146 | best val epoch -- val: 0.6336 test: 0.6146

====epoch 8
Train Loss 42.434616088053396
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6352 test: 0.6216 | best val epoch -- val: 0.6352 test: 0.6216

====epoch 9
Train Loss 41.55624051598635
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6383 test: 0.6276 | best val epoch -- val: 0.6383 test: 0.6276

====epoch 10
Train Loss 41.34008468722534
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6436 test: 0.6184 | best val epoch -- val: 0.6436 test: 0.6184

====epoch 11
Train Loss 41.07130362312918
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6429 test: 0.6181 | best val epoch -- val: 0.6436 test: 0.6184

====epoch 12
Train Loss 40.36275107954041
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6492 test: 0.6232 | best val epoch -- val: 0.6492 test: 0.6232

====epoch 13
Train Loss 40.21913001423276
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6441 test: 0.6267 | best val epoch -- val: 0.6492 test: 0.6232

====epoch 14
Train Loss 40.08852105701926
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6487 test: 0.6220 | best val epoch -- val: 0.6492 test: 0.6232

====epoch 15
Train Loss 39.657528633087686
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6550 test: 0.6170 | best val epoch -- val: 0.6550 test: 0.6170

====epoch 16
Train Loss 39.427159844632875
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6582 test: 0.6201 | best val epoch -- val: 0.6582 test: 0.6201

====epoch 17
Train Loss 38.922934489073036
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6663 test: 0.6173 | best val epoch -- val: 0.6663 test: 0.6173

====epoch 18
Train Loss 38.92326264989722
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6625 test: 0.6237 | best val epoch -- val: 0.6663 test: 0.6173

====epoch 19
Train Loss 38.50921657149989
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6652 test: 0.6216 | best val epoch -- val: 0.6663 test: 0.6173

====epoch 20
Train Loss 38.359363199999834
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6676 test: 0.6183 | best val epoch -- val: 0.6676 test: 0.6183

====epoch 21
Train Loss 38.21896804572786
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6712 test: 0.6181 | best val epoch -- val: 0.6712 test: 0.6181

====epoch 22
Train Loss 38.096155207641324
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6688 test: 0.6204 | best val epoch -- val: 0.6712 test: 0.6181

====epoch 23
Train Loss 37.84373455058508
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6617 test: 0.6187 | best val epoch -- val: 0.6712 test: 0.6181

====epoch 24
Train Loss 37.99199364662643
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6610 test: 0.6174 | best val epoch -- val: 0.6712 test: 0.6181

====epoch 25
Train Loss 37.393755475592044
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6637 test: 0.6207 | best val epoch -- val: 0.6712 test: 0.6181

====epoch 26
Train Loss 37.5351837700035
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6667 test: 0.6190 | best val epoch -- val: 0.6712 test: 0.6181

====epoch 27
Train Loss 37.291400791316654
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6576 test: 0.6230 | best val epoch -- val: 0.6712 test: 0.6181

====epoch 28
Train Loss 37.34413434725119
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6643 test: 0.6186 | best val epoch -- val: 0.6712 test: 0.6181

====epoch 29
Train Loss 36.88716022300788
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6686 test: 0.6170 | best val epoch -- val: 0.6712 test: 0.6181

====epoch 30
Train Loss 36.86592970370005
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6681 test: 0.6171 | best val epoch -- val: 0.6712 test: 0.6181

====epoch 31
Train Loss 36.569920566050875
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6576 test: 0.6232 | best val epoch -- val: 0.6712 test: 0.6181

====epoch 32
Train Loss 36.30728858115984
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6681 test: 0.6194 | best val epoch -- val: 0.6712 test: 0.6181

====epoch 33
Train Loss 36.14771055299869
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6687 test: 0.6238 | best val epoch -- val: 0.6712 test: 0.6181

====epoch 34
Train Loss 36.22675291596127
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6680 test: 0.6218 | best val epoch -- val: 0.6712 test: 0.6181

====epoch 35
Train Loss 36.13442036044346
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6661 test: 0.6171 | best val epoch -- val: 0.6712 test: 0.6181

====epoch 36
Train Loss 35.98389690732096
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6810 test: 0.6210 | best val epoch -- val: 0.6810 test: 0.6210

====epoch 37
Train Loss 35.884625683221415
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6712 test: 0.6200 | best val epoch -- val: 0.6810 test: 0.6210

====epoch 38
Train Loss 35.79371269963876
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6732 test: 0.6196 | best val epoch -- val: 0.6810 test: 0.6210

====epoch 39
Train Loss 35.65462317368846
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6671 test: 0.6185 | best val epoch -- val: 0.6810 test: 0.6210

====epoch 40
Train Loss 35.483804724279985
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6739 test: 0.6158 | best val epoch -- val: 0.6810 test: 0.6210

====epoch 41
Train Loss 35.567022955620814
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6778 test: 0.6240 | best val epoch -- val: 0.6810 test: 0.6210

====epoch 42
Train Loss 35.389160739739694
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6773 test: 0.6209 | best val epoch -- val: 0.6810 test: 0.6210

====epoch 43
Train Loss 35.13049076082636
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6753 test: 0.6237 | best val epoch -- val: 0.6810 test: 0.6210

====epoch 44
Train Loss 35.236530522904104
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6737 test: 0.6243 | best val epoch -- val: 0.6810 test: 0.6210

====epoch 45
Train Loss 35.25010531367056
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6831 test: 0.6277 | best val epoch -- val: 0.6831 test: 0.6277

====epoch 46
Train Loss 35.025840305332615
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6758 test: 0.6299 | best val epoch -- val: 0.6831 test: 0.6277

====epoch 47
Train Loss 35.06247416500331
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6769 test: 0.6269 | best val epoch -- val: 0.6831 test: 0.6277

====epoch 48
Train Loss 34.69688142359772
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6735 test: 0.6213 | best val epoch -- val: 0.6831 test: 0.6277

====epoch 49
Train Loss 34.64061305041818
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6773 test: 0.6318 | best val epoch -- val: 0.6831 test: 0.6277

====epoch 50
Train Loss 34.59875233617965
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6753 test: 0.6270 | best val epoch -- val: 0.6831 test: 0.6277

====epoch 51
Train Loss 34.37354369756272
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6741 test: 0.6328 | best val epoch -- val: 0.6831 test: 0.6277

====epoch 52
Train Loss 34.47083444133268
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6758 test: 0.6323 | best val epoch -- val: 0.6831 test: 0.6277

====epoch 53
Train Loss 34.08872380734929
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6744 test: 0.6296 | best val epoch -- val: 0.6831 test: 0.6277

====epoch 54
Train Loss 34.13649189981323
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6760 test: 0.6342 | best val epoch -- val: 0.6831 test: 0.6277

====epoch 55
Train Loss 34.3506135196244
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6744 test: 0.6352 | best val epoch -- val: 0.6831 test: 0.6277

====epoch 56
Train Loss 34.10166695581025
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6753 test: 0.6304 | best val epoch -- val: 0.6831 test: 0.6277

====epoch 57
Train Loss 33.82544526578204
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6794 test: 0.6371 | best val epoch -- val: 0.6831 test: 0.6277

====epoch 58
Train Loss 33.90454472138888
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6740 test: 0.6315 | best val epoch -- val: 0.6831 test: 0.6277

====epoch 59
Train Loss 33.93392890568735
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6822 test: 0.6326 | best val epoch -- val: 0.6831 test: 0.6277

====epoch 60
Train Loss 33.79752639790073
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6754 test: 0.6356 | best val epoch -- val: 0.6831 test: 0.6277

====epoch 61
Train Loss 33.630986046620386
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6781 test: 0.6334 | best val epoch -- val: 0.6831 test: 0.6277

====epoch 62
Train Loss 33.70079344844674
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6804 test: 0.6343 | best val epoch -- val: 0.6831 test: 0.6277

====epoch 63
Train Loss 33.358092750906124
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6722 test: 0.6344 | best val epoch -- val: 0.6831 test: 0.6277

====epoch 64
Train Loss 33.177321559821905
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6740 test: 0.6363 | best val epoch -- val: 0.6831 test: 0.6277

====epoch 65
Train Loss 33.46973003457666
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6843 test: 0.6349 | best val epoch -- val: 0.6843 test: 0.6349

====epoch 66
Train Loss 33.1558232784496
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6844 test: 0.6394 | best val epoch -- val: 0.6844 test: 0.6394

====epoch 67
Train Loss 33.39977614432921
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6792 test: 0.6354 | best val epoch -- val: 0.6844 test: 0.6394

====epoch 68
Train Loss 33.09170543984857
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6870 test: 0.6335 | best val epoch -- val: 0.6870 test: 0.6335

====epoch 69
Train Loss 33.05096107000413
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6859 test: 0.6388 | best val epoch -- val: 0.6870 test: 0.6335

====epoch 70
Train Loss 33.11775260889106
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6786 test: 0.6372 | best val epoch -- val: 0.6870 test: 0.6335

====epoch 71
Train Loss 32.95592010986942
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6842 test: 0.6382 | best val epoch -- val: 0.6870 test: 0.6335

====epoch 72
Train Loss 32.80451701243724
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6799 test: 0.6377 | best val epoch -- val: 0.6870 test: 0.6335

====epoch 73
Train Loss 32.87478469281356
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6858 test: 0.6373 | best val epoch -- val: 0.6870 test: 0.6335

====epoch 74
Train Loss 32.724858833952645
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6842 test: 0.6401 | best val epoch -- val: 0.6870 test: 0.6335

====epoch 75
Train Loss 32.606114251701506
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6832 test: 0.6417 | best val epoch -- val: 0.6870 test: 0.6335

====epoch 76
Train Loss 32.601196555172024
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6766 test: 0.6345 | best val epoch -- val: 0.6870 test: 0.6335

====epoch 77
Train Loss 32.545710315768126
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6803 test: 0.6420 | best val epoch -- val: 0.6870 test: 0.6335

====epoch 78
Train Loss 32.572643575823896
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6876 test: 0.6466 | best val epoch -- val: 0.6876 test: 0.6466

====epoch 79
Train Loss 32.430299560322084
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6846 test: 0.6481 | best val epoch -- val: 0.6876 test: 0.6466

====epoch 80
Train Loss 32.32363397344998
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6869 test: 0.6447 | best val epoch -- val: 0.6876 test: 0.6466

====epoch 81
Train Loss 32.08907491029606
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6853 test: 0.6530 | best val epoch -- val: 0.6876 test: 0.6466

====epoch 82
Train Loss 32.228928889816764
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6842 test: 0.6536 | best val epoch -- val: 0.6876 test: 0.6466

====epoch 83
Train Loss 32.255098387493916
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6844 test: 0.6476 | best val epoch -- val: 0.6876 test: 0.6466

====epoch 84
Train Loss 31.919258350244345
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6848 test: 0.6495 | best val epoch -- val: 0.6876 test: 0.6466

====epoch 85
Train Loss 32.0169721380728
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6866 test: 0.6543 | best val epoch -- val: 0.6876 test: 0.6466

====epoch 86
Train Loss 32.216949974059766
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6839 test: 0.6467 | best val epoch -- val: 0.6876 test: 0.6466

====epoch 87
Train Loss 31.966604137140198
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6842 test: 0.6454 | best val epoch -- val: 0.6876 test: 0.6466

====epoch 88
Train Loss 31.814749625575107
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6902 test: 0.6482 | best val epoch -- val: 0.6902 test: 0.6482

====epoch 89
Train Loss 31.980071597260253
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6872 test: 0.6507 | best val epoch -- val: 0.6902 test: 0.6482

====epoch 90
Train Loss 31.743683171494663
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6903 test: 0.6481 | best val epoch -- val: 0.6903 test: 0.6481

====epoch 91
Train Loss 31.64477706024447
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6916 test: 0.6501 | best val epoch -- val: 0.6916 test: 0.6501

====epoch 92
Train Loss 31.521539445675053
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6968 test: 0.6484 | best val epoch -- val: 0.6968 test: 0.6484

====epoch 93
Train Loss 31.49249668380644
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6873 test: 0.6529 | best val epoch -- val: 0.6968 test: 0.6484

====epoch 94
Train Loss 31.576258856557736
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6887 test: 0.6484 | best val epoch -- val: 0.6968 test: 0.6484

====epoch 95
Train Loss 31.574769505195725
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6858 test: 0.6456 | best val epoch -- val: 0.6968 test: 0.6484

====epoch 96
Train Loss 31.546920959031876
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6880 test: 0.6527 | best val epoch -- val: 0.6968 test: 0.6484

====epoch 97
Train Loss 31.02455992947352
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6944 test: 0.6487 | best val epoch -- val: 0.6968 test: 0.6484

====epoch 98
Train Loss 31.132954719347417
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6903 test: 0.6487 | best val epoch -- val: 0.6968 test: 0.6484

====epoch 99
Train Loss 31.218590685635494
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6894 test: 0.6549 | best val epoch -- val: 0.6968 test: 0.6484

====epoch 100
Train Loss 30.95311574443502
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6883 test: 0.6513 | best val epoch -- val: 0.6968 test: 0.6484

[16:58:45] WARNING: not removing hydrogen atom without neighbors
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.4.
2022-09-13 16:58:47.040 | INFO     | modules.masked_transformer_encoder:__init__:122 - number of parameters: 0.000000e+00
=========================================
batch_size = 32
d_model = 128
dataset = toxcast
decay = 0
device = 0
dim_feedforward = 512
eval_train = 0
filename =
gnn_JK = cat
gnn_dropout = 0.3
gnn_emb_dim = 300
gnn_num_layer = 5
gnn_residual = False
gnn_type = gin
gnn_virtual_node = False
graph_pooling = cls
input_model_file = models_graphtrans/graphtrans-sr-gcl.pth
lr = 0.0001
lr_scale = 1
max_input_len = 1000
nhead = 4
num_encoder_layers = 4
num_encoder_layers_masked = 0
num_workers = 0
pos_encoder = False
runseed = 7
seed = 12344
split = scaffold
transformer_activation = relu
transformer_dropout = 0.3
transformer_norm_input = True
transformer_prenorm = False
=========================================
toxcast
scaffold
Loaded GraphTrans from models_graphtrans/graphtrans-sr-gcl.pth
====epoch 1
Train Loss 90.79733902963106
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.5245 test: 0.5093 | best val epoch -- val: 0.5245 test: 0.5093

====epoch 2
Train Loss 52.62017092896928
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.5287 test: 0.5128 | best val epoch -- val: 0.5287 test: 0.5128

====epoch 3
Train Loss 49.43921547324615
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.5235 test: 0.5289 | best val epoch -- val: 0.5287 test: 0.5128

====epoch 4
Train Loss 48.90587911727314
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.5775 test: 0.5836 | best val epoch -- val: 0.5775 test: 0.5836

====epoch 5
Train Loss 46.264719201082706
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6262 test: 0.6124 | best val epoch -- val: 0.6262 test: 0.6124

====epoch 6
Train Loss 44.498110338481126
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6370 test: 0.6229 | best val epoch -- val: 0.6370 test: 0.6229

====epoch 7
Train Loss 42.808130651729115
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6400 test: 0.6230 | best val epoch -- val: 0.6400 test: 0.6230

====epoch 8
Train Loss 42.33014289632273
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6370 test: 0.6219 | best val epoch -- val: 0.6400 test: 0.6230

====epoch 9
Train Loss 41.80798721499233
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6428 test: 0.6288 | best val epoch -- val: 0.6428 test: 0.6288

====epoch 10
Train Loss 41.05999455180474
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6535 test: 0.6328 | best val epoch -- val: 0.6535 test: 0.6328

====epoch 11
Train Loss 40.90309984818
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6570 test: 0.6278 | best val epoch -- val: 0.6570 test: 0.6278

====epoch 12
Train Loss 40.63180248886891
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6528 test: 0.6271 | best val epoch -- val: 0.6570 test: 0.6278

====epoch 13
Train Loss 40.078217706557254
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6496 test: 0.6229 | best val epoch -- val: 0.6570 test: 0.6278

====epoch 14
Train Loss 39.610373043276645
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6608 test: 0.6293 | best val epoch -- val: 0.6608 test: 0.6293

====epoch 15
Train Loss 39.57588951107365
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6566 test: 0.6318 | best val epoch -- val: 0.6608 test: 0.6293

====epoch 16
Train Loss 39.50026973350216
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6540 test: 0.6272 | best val epoch -- val: 0.6608 test: 0.6293

====epoch 17
Train Loss 39.156491203252884
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6570 test: 0.6330 | best val epoch -- val: 0.6608 test: 0.6293

====epoch 18
Train Loss 38.79221788567017
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6538 test: 0.6366 | best val epoch -- val: 0.6608 test: 0.6293

====epoch 19
Train Loss 38.393410945000916
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6560 test: 0.6402 | best val epoch -- val: 0.6608 test: 0.6293

====epoch 20
Train Loss 38.448838031610265
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6677 test: 0.6395 | best val epoch -- val: 0.6677 test: 0.6395

====epoch 21
Train Loss 37.93722579626102
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6576 test: 0.6426 | best val epoch -- val: 0.6677 test: 0.6395

====epoch 22
Train Loss 38.05328147217571
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6644 test: 0.6361 | best val epoch -- val: 0.6677 test: 0.6395

====epoch 23
Train Loss 38.24093100554354
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6655 test: 0.6389 | best val epoch -- val: 0.6677 test: 0.6395

====epoch 24
Train Loss 37.79083495821064
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6736 test: 0.6383 | best val epoch -- val: 0.6736 test: 0.6383

====epoch 25
Train Loss 37.57020052204876
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6727 test: 0.6332 | best val epoch -- val: 0.6736 test: 0.6383

====epoch 26
Train Loss 37.225339983302284
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6726 test: 0.6357 | best val epoch -- val: 0.6736 test: 0.6383

====epoch 27
Train Loss 37.12522104459299
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6621 test: 0.6344 | best val epoch -- val: 0.6736 test: 0.6383

====epoch 28
Train Loss 37.08097878659889
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6683 test: 0.6351 | best val epoch -- val: 0.6736 test: 0.6383

====epoch 29
Train Loss 36.907392683047874
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6695 test: 0.6428 | best val epoch -- val: 0.6736 test: 0.6383

====epoch 30
Train Loss 36.587045833292194
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6723 test: 0.6396 | best val epoch -- val: 0.6736 test: 0.6383

====epoch 31
Train Loss 36.5855823707998
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6753 test: 0.6425 | best val epoch -- val: 0.6753 test: 0.6425

====epoch 32
Train Loss 36.47387729665607
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6684 test: 0.6360 | best val epoch -- val: 0.6753 test: 0.6425

====epoch 33
Train Loss 36.22070588212451
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6684 test: 0.6311 | best val epoch -- val: 0.6753 test: 0.6425

====epoch 34
Train Loss 36.154361870196055
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6743 test: 0.6382 | best val epoch -- val: 0.6753 test: 0.6425

====epoch 35
Train Loss 36.41054681898422
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6743 test: 0.6389 | best val epoch -- val: 0.6753 test: 0.6425

====epoch 36
Train Loss 36.1179001047095
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6748 test: 0.6380 | best val epoch -- val: 0.6753 test: 0.6425

====epoch 37
Train Loss 35.93041523530218
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6774 test: 0.6341 | best val epoch -- val: 0.6774 test: 0.6341

====epoch 38
Train Loss 35.92485202044116
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6736 test: 0.6346 | best val epoch -- val: 0.6774 test: 0.6341

====epoch 39
Train Loss 35.81201476993662
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6751 test: 0.6391 | best val epoch -- val: 0.6774 test: 0.6341

====epoch 40
Train Loss 35.60002949065649
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6829 test: 0.6417 | best val epoch -- val: 0.6829 test: 0.6417

====epoch 41
Train Loss 35.55372447451959
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6808 test: 0.6395 | best val epoch -- val: 0.6829 test: 0.6417

====epoch 42
Train Loss 35.27660813340775
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6833 test: 0.6308 | best val epoch -- val: 0.6833 test: 0.6308

====epoch 43
Train Loss 35.20314651895861
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6740 test: 0.6304 | best val epoch -- val: 0.6833 test: 0.6308

====epoch 44
Train Loss 35.17718252871395
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6867 test: 0.6312 | best val epoch -- val: 0.6867 test: 0.6312

====epoch 45
Train Loss 34.977557789057784
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6818 test: 0.6387 | best val epoch -- val: 0.6867 test: 0.6312

====epoch 46
Train Loss 35.010623252226786
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6820 test: 0.6368 | best val epoch -- val: 0.6867 test: 0.6312

====epoch 47
Train Loss 34.7708888554785
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6824 test: 0.6334 | best val epoch -- val: 0.6867 test: 0.6312

====epoch 48
Train Loss 35.09878088404269
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6833 test: 0.6321 | best val epoch -- val: 0.6867 test: 0.6312

====epoch 49
Train Loss 34.70195368305932
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6816 test: 0.6367 | best val epoch -- val: 0.6867 test: 0.6312

====epoch 50
Train Loss 34.48857079856563
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6823 test: 0.6362 | best val epoch -- val: 0.6867 test: 0.6312

====epoch 51
Train Loss 34.61017474264015
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6919 test: 0.6365 | best val epoch -- val: 0.6919 test: 0.6365

====epoch 52
Train Loss 34.557209950214
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6885 test: 0.6402 | best val epoch -- val: 0.6919 test: 0.6365

====epoch 53
Train Loss 34.24799036529961
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6834 test: 0.6387 | best val epoch -- val: 0.6919 test: 0.6365

====epoch 54
Train Loss 34.116862648417104
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6905 test: 0.6381 | best val epoch -- val: 0.6919 test: 0.6365

====epoch 55
Train Loss 34.0437618275209
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6848 test: 0.6394 | best val epoch -- val: 0.6919 test: 0.6365

====epoch 56
Train Loss 34.062732142600794
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6947 test: 0.6405 | best val epoch -- val: 0.6947 test: 0.6405

====epoch 57
Train Loss 34.17203724901912
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6974 test: 0.6445 | best val epoch -- val: 0.6974 test: 0.6445

====epoch 58
Train Loss 33.72045278032781
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6988 test: 0.6448 | best val epoch -- val: 0.6988 test: 0.6448

====epoch 59
Train Loss 33.93978296115808
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6850 test: 0.6422 | best val epoch -- val: 0.6988 test: 0.6448

====epoch 60
Train Loss 33.80444723783935
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6908 test: 0.6437 | best val epoch -- val: 0.6988 test: 0.6448

====epoch 61
Train Loss 33.7758162549941
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6887 test: 0.6425 | best val epoch -- val: 0.6988 test: 0.6448

====epoch 62
Train Loss 33.60669617732354
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6931 test: 0.6466 | best val epoch -- val: 0.6988 test: 0.6448

====epoch 63
Train Loss 33.3994106376157
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6942 test: 0.6471 | best val epoch -- val: 0.6988 test: 0.6448

====epoch 64
Train Loss 33.558841695792275
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6875 test: 0.6381 | best val epoch -- val: 0.6988 test: 0.6448

====epoch 65
Train Loss 33.26984962438218
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6905 test: 0.6494 | best val epoch -- val: 0.6988 test: 0.6448

====epoch 66
Train Loss 33.46095526724541
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6960 test: 0.6472 | best val epoch -- val: 0.6988 test: 0.6448

====epoch 67
Train Loss 33.306646001278686
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6918 test: 0.6431 | best val epoch -- val: 0.6988 test: 0.6448

====epoch 68
Train Loss 33.08665098292444
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6923 test: 0.6350 | best val epoch -- val: 0.6988 test: 0.6448

====epoch 69
Train Loss 33.093414055097355
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6945 test: 0.6376 | best val epoch -- val: 0.6988 test: 0.6448

====epoch 70
Train Loss 33.0243700188041
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6923 test: 0.6397 | best val epoch -- val: 0.6988 test: 0.6448

====epoch 71
Train Loss 32.99519443494678
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6905 test: 0.6428 | best val epoch -- val: 0.6988 test: 0.6448

====epoch 72
Train Loss 32.63913807529358
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6970 test: 0.6477 | best val epoch -- val: 0.6988 test: 0.6448

====epoch 73
Train Loss 32.87301496550641
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6903 test: 0.6373 | best val epoch -- val: 0.6988 test: 0.6448

====epoch 74
Train Loss 32.760326081938445
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6978 test: 0.6459 | best val epoch -- val: 0.6988 test: 0.6448

====epoch 75
Train Loss 32.503336515399795
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6905 test: 0.6475 | best val epoch -- val: 0.6988 test: 0.6448

====epoch 76
Train Loss 32.48791230866729
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6904 test: 0.6407 | best val epoch -- val: 0.6988 test: 0.6448

====epoch 77
Train Loss 32.58450875124918
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6908 test: 0.6451 | best val epoch -- val: 0.6988 test: 0.6448

====epoch 78
Train Loss 32.18747499692706
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6896 test: 0.6448 | best val epoch -- val: 0.6988 test: 0.6448

====epoch 79
Train Loss 32.33375007809064
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6894 test: 0.6459 | best val epoch -- val: 0.6988 test: 0.6448

====epoch 80
Train Loss 32.328401363707705
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6998 test: 0.6661 | best val epoch -- val: 0.6998 test: 0.6661

====epoch 81
Train Loss 32.17901109560399
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6914 test: 0.6484 | best val epoch -- val: 0.6998 test: 0.6661

====epoch 82
Train Loss 32.09622739257016
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6940 test: 0.6448 | best val epoch -- val: 0.6998 test: 0.6661

====epoch 83
Train Loss 31.908504888146084
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6981 test: 0.6433 | best val epoch -- val: 0.6998 test: 0.6661

====epoch 84
Train Loss 32.0331433193804
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6978 test: 0.6527 | best val epoch -- val: 0.6998 test: 0.6661

====epoch 85
Train Loss 31.772653478309334
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6952 test: 0.6527 | best val epoch -- val: 0.6998 test: 0.6661

====epoch 86
Train Loss 32.088914067649256
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6932 test: 0.6568 | best val epoch -- val: 0.6998 test: 0.6661

====epoch 87
Train Loss 31.78540609260448
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6977 test: 0.6482 | best val epoch -- val: 0.6998 test: 0.6661

====epoch 88
Train Loss 31.621605422185862
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6947 test: 0.6521 | best val epoch -- val: 0.6998 test: 0.6661

====epoch 89
Train Loss 31.707773005425434
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6951 test: 0.6514 | best val epoch -- val: 0.6998 test: 0.6661

====epoch 90
Train Loss 31.841023747023534
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6897 test: 0.6473 | best val epoch -- val: 0.6998 test: 0.6661

====epoch 91
Train Loss 31.748644098007873
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6874 test: 0.6547 | best val epoch -- val: 0.6998 test: 0.6661

====epoch 92
Train Loss 31.567404054223807
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6889 test: 0.6556 | best val epoch -- val: 0.6998 test: 0.6661

====epoch 93
Train Loss 31.510261931118706
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6938 test: 0.6579 | best val epoch -- val: 0.6998 test: 0.6661

====epoch 94
Train Loss 31.40944377291832
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6874 test: 0.6532 | best val epoch -- val: 0.6998 test: 0.6661

====epoch 95
Train Loss 31.53007771149258
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6913 test: 0.6524 | best val epoch -- val: 0.6998 test: 0.6661

====epoch 96
Train Loss 31.193091958592685
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6947 test: 0.6609 | best val epoch -- val: 0.6998 test: 0.6661

====epoch 97
Train Loss 31.05541123059344
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6940 test: 0.6554 | best val epoch -- val: 0.6998 test: 0.6661

====epoch 98
Train Loss 31.309672573751673
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6883 test: 0.6554 | best val epoch -- val: 0.6998 test: 0.6661

====epoch 99
Train Loss 31.281030663698687
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6985 test: 0.6616 | best val epoch -- val: 0.6998 test: 0.6661

====epoch 100
Train Loss 31.21229431667217
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6991 test: 0.6543 | best val epoch -- val: 0.6998 test: 0.6661

[17:14:39] WARNING: not removing hydrogen atom without neighbors
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.4.
2022-09-13 17:14:41.470 | INFO     | modules.masked_transformer_encoder:__init__:122 - number of parameters: 0.000000e+00
=========================================
batch_size = 32
d_model = 128
dataset = toxcast
decay = 0
device = 0
dim_feedforward = 512
eval_train = 0
filename =
gnn_JK = cat
gnn_dropout = 0.3
gnn_emb_dim = 300
gnn_num_layer = 5
gnn_residual = False
gnn_type = gin
gnn_virtual_node = False
graph_pooling = cls
input_model_file = models_graphtrans/graphtrans-sr-gcl.pth
lr = 0.0001
lr_scale = 1
max_input_len = 1000
nhead = 4
num_encoder_layers = 4
num_encoder_layers_masked = 0
num_workers = 0
pos_encoder = False
runseed = 8
seed = 12344
split = scaffold
transformer_activation = relu
transformer_dropout = 0.3
transformer_norm_input = True
transformer_prenorm = False
=========================================
toxcast
scaffold
Loaded GraphTrans from models_graphtrans/graphtrans-sr-gcl.pth
====epoch 1
Train Loss 92.08623343198478
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.5165 test: 0.5135 | best val epoch -- val: 0.5165 test: 0.5135

====epoch 2
Train Loss 52.945082840958854
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.5137 test: 0.5187 | best val epoch -- val: 0.5165 test: 0.5135

====epoch 3
Train Loss 49.55135435004389
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.5238 test: 0.5296 | best val epoch -- val: 0.5238 test: 0.5296

====epoch 4
Train Loss 48.72034470792235
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.5850 test: 0.5827 | best val epoch -- val: 0.5850 test: 0.5827

====epoch 5
Train Loss 46.52113457817815
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6199 test: 0.6091 | best val epoch -- val: 0.6199 test: 0.6091

====epoch 6
Train Loss 44.32312760926511
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6369 test: 0.6271 | best val epoch -- val: 0.6369 test: 0.6271

====epoch 7
Train Loss 43.06390625937364
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6348 test: 0.6226 | best val epoch -- val: 0.6369 test: 0.6271

====epoch 8
Train Loss 42.05469803580696
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6412 test: 0.6252 | best val epoch -- val: 0.6412 test: 0.6252

====epoch 9
Train Loss 41.50202951763781
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6347 test: 0.6209 | best val epoch -- val: 0.6412 test: 0.6252

====epoch 10
Train Loss 41.0362430132037
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6415 test: 0.6182 | best val epoch -- val: 0.6415 test: 0.6182

====epoch 11
Train Loss 40.64814656018536
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6479 test: 0.6153 | best val epoch -- val: 0.6479 test: 0.6153

====epoch 12
Train Loss 40.49434032928832
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6546 test: 0.6185 | best val epoch -- val: 0.6546 test: 0.6185

====epoch 13
Train Loss 40.283417850026055
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6544 test: 0.6316 | best val epoch -- val: 0.6546 test: 0.6185

====epoch 14
Train Loss 39.7800243387238
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6509 test: 0.6250 | best val epoch -- val: 0.6546 test: 0.6185

====epoch 15
Train Loss 39.37086816039852
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6519 test: 0.6268 | best val epoch -- val: 0.6546 test: 0.6185

====epoch 16
Train Loss 39.27372357999172
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6578 test: 0.6234 | best val epoch -- val: 0.6578 test: 0.6234

====epoch 17
Train Loss 39.04099543998482
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6576 test: 0.6323 | best val epoch -- val: 0.6578 test: 0.6234

====epoch 18
Train Loss 38.74106627591401
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6645 test: 0.6313 | best val epoch -- val: 0.6645 test: 0.6313

====epoch 19
Train Loss 38.50598746906613
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6627 test: 0.6299 | best val epoch -- val: 0.6645 test: 0.6313

====epoch 20
Train Loss 38.4710861557138
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6559 test: 0.6264 | best val epoch -- val: 0.6645 test: 0.6313

====epoch 21
Train Loss 38.06218166205082
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6571 test: 0.6295 | best val epoch -- val: 0.6645 test: 0.6313

====epoch 22
Train Loss 37.77567492457674
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6609 test: 0.6259 | best val epoch -- val: 0.6645 test: 0.6313

====epoch 23
Train Loss 37.63701381182164
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6628 test: 0.6178 | best val epoch -- val: 0.6645 test: 0.6313

====epoch 24
Train Loss 37.24773550529136
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6615 test: 0.6221 | best val epoch -- val: 0.6645 test: 0.6313

====epoch 25
Train Loss 37.26353264825776
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6578 test: 0.6116 | best val epoch -- val: 0.6645 test: 0.6313

====epoch 26
Train Loss 37.25104059355991
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6650 test: 0.6214 | best val epoch -- val: 0.6650 test: 0.6214

====epoch 27
Train Loss 37.107235065020454
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6697 test: 0.6218 | best val epoch -- val: 0.6697 test: 0.6218

====epoch 28
Train Loss 36.89335838198613
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6641 test: 0.6231 | best val epoch -- val: 0.6697 test: 0.6218

====epoch 29
Train Loss 36.56231388662047
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6581 test: 0.6287 | best val epoch -- val: 0.6697 test: 0.6218

====epoch 30
Train Loss 36.15167729932092
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6631 test: 0.6210 | best val epoch -- val: 0.6697 test: 0.6218

====epoch 31
Train Loss 36.4710027205654
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6717 test: 0.6234 | best val epoch -- val: 0.6717 test: 0.6234

====epoch 32
Train Loss 36.56730447988106
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6559 test: 0.6170 | best val epoch -- val: 0.6717 test: 0.6234

====epoch 33
Train Loss 36.346914531594535
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6642 test: 0.6129 | best val epoch -- val: 0.6717 test: 0.6234

====epoch 34
Train Loss 36.10611807555358
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6610 test: 0.6203 | best val epoch -- val: 0.6717 test: 0.6234

====epoch 35
Train Loss 35.86348124452781
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6704 test: 0.6267 | best val epoch -- val: 0.6717 test: 0.6234

====epoch 36
Train Loss 35.82974177806458
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6658 test: 0.6220 | best val epoch -- val: 0.6717 test: 0.6234

====epoch 37
Train Loss 35.84436916710507
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6646 test: 0.6235 | best val epoch -- val: 0.6717 test: 0.6234

====epoch 38
Train Loss 35.636444500366
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6645 test: 0.6257 | best val epoch -- val: 0.6717 test: 0.6234

====epoch 39
Train Loss 35.421305407607996
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6618 test: 0.6199 | best val epoch -- val: 0.6717 test: 0.6234

====epoch 40
Train Loss 35.535497644308414
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6706 test: 0.6199 | best val epoch -- val: 0.6717 test: 0.6234

====epoch 41
Train Loss 35.1936723099149
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6695 test: 0.6192 | best val epoch -- val: 0.6717 test: 0.6234

====epoch 42
Train Loss 35.00644764030278
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6756 test: 0.6204 | best val epoch -- val: 0.6756 test: 0.6204

====epoch 43
Train Loss 34.974489843831584
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6730 test: 0.6148 | best val epoch -- val: 0.6756 test: 0.6204

====epoch 44
Train Loss 35.17585391774229
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6775 test: 0.6270 | best val epoch -- val: 0.6775 test: 0.6270

====epoch 45
Train Loss 34.9546402710677
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6770 test: 0.6219 | best val epoch -- val: 0.6775 test: 0.6270

====epoch 46
Train Loss 34.75831853237895
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6786 test: 0.6241 | best val epoch -- val: 0.6786 test: 0.6241

====epoch 47
Train Loss 34.67833945925386
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6801 test: 0.6266 | best val epoch -- val: 0.6801 test: 0.6266

====epoch 48
Train Loss 34.381656143261694
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6756 test: 0.6228 | best val epoch -- val: 0.6801 test: 0.6266

====epoch 49
Train Loss 34.672158470326245
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6758 test: 0.6205 | best val epoch -- val: 0.6801 test: 0.6266

====epoch 50
Train Loss 34.450243262891725
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6766 test: 0.6284 | best val epoch -- val: 0.6801 test: 0.6266

====epoch 51
Train Loss 34.186598592231995
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6748 test: 0.6306 | best val epoch -- val: 0.6801 test: 0.6266

====epoch 52
Train Loss 34.22266932972351
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6729 test: 0.6289 | best val epoch -- val: 0.6801 test: 0.6266

====epoch 53
Train Loss 34.16851609632609
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6748 test: 0.6241 | best val epoch -- val: 0.6801 test: 0.6266

====epoch 54
Train Loss 34.14221305720561
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6802 test: 0.6300 | best val epoch -- val: 0.6802 test: 0.6300

====epoch 55
Train Loss 34.01669442438168
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6772 test: 0.6220 | best val epoch -- val: 0.6802 test: 0.6300

====epoch 56
Train Loss 33.968615730851624
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6749 test: 0.6266 | best val epoch -- val: 0.6802 test: 0.6300

====epoch 57
Train Loss 33.96693826202277
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6795 test: 0.6261 | best val epoch -- val: 0.6802 test: 0.6300

====epoch 58
Train Loss 33.75506450326135
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6770 test: 0.6334 | best val epoch -- val: 0.6802 test: 0.6300

====epoch 59
Train Loss 33.87140885831017
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6870 test: 0.6466 | best val epoch -- val: 0.6870 test: 0.6466

====epoch 60
Train Loss 33.41825532367502
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6752 test: 0.6293 | best val epoch -- val: 0.6870 test: 0.6466

====epoch 61
Train Loss 33.489751022864034
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6807 test: 0.6315 | best val epoch -- val: 0.6870 test: 0.6466

====epoch 62
Train Loss 33.63399039770004
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6848 test: 0.6316 | best val epoch -- val: 0.6870 test: 0.6466

====epoch 63
Train Loss 33.113512422046234
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6836 test: 0.6363 | best val epoch -- val: 0.6870 test: 0.6466

====epoch 64
Train Loss 33.150350593614846
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6866 test: 0.6344 | best val epoch -- val: 0.6870 test: 0.6466

====epoch 65
Train Loss 33.648982963574
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6797 test: 0.6355 | best val epoch -- val: 0.6870 test: 0.6466

====epoch 66
Train Loss 32.98971547729493
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6861 test: 0.6348 | best val epoch -- val: 0.6870 test: 0.6466

====epoch 67
Train Loss 32.61247264161712
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6823 test: 0.6380 | best val epoch -- val: 0.6870 test: 0.6466

====epoch 68
Train Loss 32.99635415236098
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6831 test: 0.6365 | best val epoch -- val: 0.6870 test: 0.6466

====epoch 69
Train Loss 32.70408694737366
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6836 test: 0.6354 | best val epoch -- val: 0.6870 test: 0.6466

====epoch 70
Train Loss 32.81852754368863
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6821 test: 0.6370 | best val epoch -- val: 0.6870 test: 0.6466

====epoch 71
Train Loss 32.76668876008918
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6780 test: 0.6379 | best val epoch -- val: 0.6870 test: 0.6466

====epoch 72
Train Loss 32.81398536402701
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6802 test: 0.6394 | best val epoch -- val: 0.6870 test: 0.6466

====epoch 73
Train Loss 32.59269761806833
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6838 test: 0.6420 | best val epoch -- val: 0.6870 test: 0.6466

====epoch 74
Train Loss 32.573016183563226
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6819 test: 0.6417 | best val epoch -- val: 0.6870 test: 0.6466

====epoch 75
Train Loss 32.3733645743284
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6843 test: 0.6379 | best val epoch -- val: 0.6870 test: 0.6466

====epoch 76
Train Loss 32.37783150460404
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6811 test: 0.6423 | best val epoch -- val: 0.6870 test: 0.6466

====epoch 77
Train Loss 32.39611336023132
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6802 test: 0.6448 | best val epoch -- val: 0.6870 test: 0.6466

====epoch 78
Train Loss 32.29561905172774
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6764 test: 0.6458 | best val epoch -- val: 0.6870 test: 0.6466

====epoch 79
Train Loss 32.08685975640286
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6723 test: 0.6413 | best val epoch -- val: 0.6870 test: 0.6466

====epoch 80
Train Loss 32.21505000999822
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6846 test: 0.6443 | best val epoch -- val: 0.6870 test: 0.6466

====epoch 81
Train Loss 32.13926594416252
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6832 test: 0.6425 | best val epoch -- val: 0.6870 test: 0.6466

====epoch 82
Train Loss 32.070924702866456
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6822 test: 0.6457 | best val epoch -- val: 0.6870 test: 0.6466

====epoch 83
Train Loss 31.84031084826034
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6840 test: 0.6441 | best val epoch -- val: 0.6870 test: 0.6466

====epoch 84
Train Loss 31.79006470455737
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6826 test: 0.6512 | best val epoch -- val: 0.6870 test: 0.6466

====epoch 85
Train Loss 31.914591948693417
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6773 test: 0.6505 | best val epoch -- val: 0.6870 test: 0.6466

====epoch 86
Train Loss 31.734270272911846
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6870 test: 0.6536 | best val epoch -- val: 0.6870 test: 0.6536

====epoch 87
Train Loss 31.663827587021814
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6946 test: 0.6535 | best val epoch -- val: 0.6946 test: 0.6535

====epoch 88
Train Loss 31.67291453424037
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6775 test: 0.6471 | best val epoch -- val: 0.6946 test: 0.6535

====epoch 89
Train Loss 31.633629419897662
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6814 test: 0.6507 | best val epoch -- val: 0.6946 test: 0.6535

====epoch 90
Train Loss 31.61005333815547
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6863 test: 0.6531 | best val epoch -- val: 0.6946 test: 0.6535

====epoch 91
Train Loss 31.593388032193506
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6783 test: 0.6524 | best val epoch -- val: 0.6946 test: 0.6535

====epoch 92
Train Loss 31.552779911788473
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6912 test: 0.6513 | best val epoch -- val: 0.6946 test: 0.6535

====epoch 93
Train Loss 31.48115892403497
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6844 test: 0.6535 | best val epoch -- val: 0.6946 test: 0.6535

====epoch 94
Train Loss 31.44882108561814
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6956 test: 0.6518 | best val epoch -- val: 0.6956 test: 0.6518

====epoch 95
Train Loss 31.304747639887577
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6854 test: 0.6502 | best val epoch -- val: 0.6956 test: 0.6518

====epoch 96
Train Loss 31.207515267090464
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6950 test: 0.6582 | best val epoch -- val: 0.6956 test: 0.6518

====epoch 97
Train Loss 31.146565403112547
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6872 test: 0.6576 | best val epoch -- val: 0.6956 test: 0.6518

====epoch 98
Train Loss 30.97650049609325
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6906 test: 0.6525 | best val epoch -- val: 0.6956 test: 0.6518

====epoch 99
Train Loss 31.216704378870638
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6928 test: 0.6584 | best val epoch -- val: 0.6956 test: 0.6518

====epoch 100
Train Loss 31.060077744022905
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6823 test: 0.6579 | best val epoch -- val: 0.6956 test: 0.6518

[17:30:29] WARNING: not removing hydrogen atom without neighbors
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.4.
2022-09-13 17:30:31.530 | INFO     | modules.masked_transformer_encoder:__init__:122 - number of parameters: 0.000000e+00
=========================================
batch_size = 32
d_model = 128
dataset = toxcast
decay = 0
device = 0
dim_feedforward = 512
eval_train = 0
filename =
gnn_JK = cat
gnn_dropout = 0.3
gnn_emb_dim = 300
gnn_num_layer = 5
gnn_residual = False
gnn_type = gin
gnn_virtual_node = False
graph_pooling = cls
input_model_file = models_graphtrans/graphtrans-sr-gcl.pth
lr = 0.0001
lr_scale = 1
max_input_len = 1000
nhead = 4
num_encoder_layers = 4
num_encoder_layers_masked = 0
num_workers = 0
pos_encoder = False
runseed = 9
seed = 12344
split = scaffold
transformer_activation = relu
transformer_dropout = 0.3
transformer_norm_input = True
transformer_prenorm = False
=========================================
toxcast
scaffold
Loaded GraphTrans from models_graphtrans/graphtrans-sr-gcl.pth
====epoch 1
Train Loss 90.90826837266367
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.4988 test: 0.5038 | best val epoch -- val: 0.4988 test: 0.5038

====epoch 2
Train Loss 52.68891606984874
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.5064 test: 0.5058 | best val epoch -- val: 0.5064 test: 0.5058

====epoch 3
Train Loss 49.47780598500604
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.5153 test: 0.5115 | best val epoch -- val: 0.5153 test: 0.5115

====epoch 4
Train Loss 47.943229804107
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6085 test: 0.5935 | best val epoch -- val: 0.6085 test: 0.5935

====epoch 5
Train Loss 45.31108551497388
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6328 test: 0.6094 | best val epoch -- val: 0.6328 test: 0.6094

====epoch 6
Train Loss 44.01311476151336
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6280 test: 0.6161 | best val epoch -- val: 0.6328 test: 0.6094

====epoch 7
Train Loss 42.8335649872009
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6382 test: 0.6186 | best val epoch -- val: 0.6382 test: 0.6186

====epoch 8
Train Loss 42.022929704687044
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6353 test: 0.6200 | best val epoch -- val: 0.6382 test: 0.6186

====epoch 9
Train Loss 41.463049793695205
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6338 test: 0.6126 | best val epoch -- val: 0.6382 test: 0.6186

====epoch 10
Train Loss 41.306649580494515
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6280 test: 0.6206 | best val epoch -- val: 0.6382 test: 0.6186

====epoch 11
Train Loss 40.67488473900681
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6508 test: 0.6195 | best val epoch -- val: 0.6508 test: 0.6195

====epoch 12
Train Loss 40.581890900370944
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6454 test: 0.6170 | best val epoch -- val: 0.6508 test: 0.6195

====epoch 13
Train Loss 40.17045654106073
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6461 test: 0.6259 | best val epoch -- val: 0.6508 test: 0.6195

====epoch 14
Train Loss 39.72822004471435
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6495 test: 0.6251 | best val epoch -- val: 0.6508 test: 0.6195

====epoch 15
Train Loss 39.63899347334388
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6471 test: 0.6197 | best val epoch -- val: 0.6508 test: 0.6195

====epoch 16
Train Loss 39.561040846277294
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6497 test: 0.6195 | best val epoch -- val: 0.6508 test: 0.6195

====epoch 17
Train Loss 39.26485918113446
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6503 test: 0.6255 | best val epoch -- val: 0.6508 test: 0.6195

====epoch 18
Train Loss 39.045824166728785
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6582 test: 0.6274 | best val epoch -- val: 0.6582 test: 0.6274

====epoch 19
Train Loss 38.970157988995794
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6557 test: 0.6200 | best val epoch -- val: 0.6582 test: 0.6274

====epoch 20
Train Loss 38.364187451201374
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6567 test: 0.6199 | best val epoch -- val: 0.6582 test: 0.6274

====epoch 21
Train Loss 38.20259875190464
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6574 test: 0.6222 | best val epoch -- val: 0.6582 test: 0.6274

====epoch 22
Train Loss 38.18605980931354
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6600 test: 0.6200 | best val epoch -- val: 0.6600 test: 0.6200

====epoch 23
Train Loss 37.744680458303016
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6660 test: 0.6257 | best val epoch -- val: 0.6660 test: 0.6257

====epoch 24
Train Loss 37.424975439006644
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6619 test: 0.6202 | best val epoch -- val: 0.6660 test: 0.6257

====epoch 25
Train Loss 37.48992481766109
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6647 test: 0.6215 | best val epoch -- val: 0.6660 test: 0.6257

====epoch 26
Train Loss 37.24389620797331
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6577 test: 0.6233 | best val epoch -- val: 0.6660 test: 0.6257

====epoch 27
Train Loss 37.19848154910741
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6735 test: 0.6307 | best val epoch -- val: 0.6735 test: 0.6307

====epoch 28
Train Loss 36.93224860934207
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6697 test: 0.6239 | best val epoch -- val: 0.6735 test: 0.6307

====epoch 29
Train Loss 36.87042636715478
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6701 test: 0.6162 | best val epoch -- val: 0.6735 test: 0.6307

====epoch 30
Train Loss 36.675414440521884
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6652 test: 0.6181 | best val epoch -- val: 0.6735 test: 0.6307

====epoch 31
Train Loss 36.388034290423015
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6724 test: 0.6294 | best val epoch -- val: 0.6735 test: 0.6307

====epoch 32
Train Loss 36.443079161222194
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6742 test: 0.6318 | best val epoch -- val: 0.6742 test: 0.6318

====epoch 33
Train Loss 36.314637987039845
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6720 test: 0.6309 | best val epoch -- val: 0.6742 test: 0.6318

====epoch 34
Train Loss 36.20905282839942
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6759 test: 0.6308 | best val epoch -- val: 0.6759 test: 0.6308

====epoch 35
Train Loss 36.207150565423355
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6778 test: 0.6314 | best val epoch -- val: 0.6778 test: 0.6314

====epoch 36
Train Loss 35.977005028474025
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6801 test: 0.6312 | best val epoch -- val: 0.6801 test: 0.6312

====epoch 37
Train Loss 35.79330532549892
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6697 test: 0.6212 | best val epoch -- val: 0.6801 test: 0.6312

====epoch 38
Train Loss 35.861235675298424
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6765 test: 0.6209 | best val epoch -- val: 0.6801 test: 0.6312

====epoch 39
Train Loss 35.512922929101045
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6819 test: 0.6231 | best val epoch -- val: 0.6819 test: 0.6231

====epoch 40
Train Loss 35.33893387742847
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6749 test: 0.6242 | best val epoch -- val: 0.6819 test: 0.6231

====epoch 41
Train Loss 35.39644675581632
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6793 test: 0.6218 | best val epoch -- val: 0.6819 test: 0.6231

====epoch 42
Train Loss 35.14601518723169
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6785 test: 0.6241 | best val epoch -- val: 0.6819 test: 0.6231

====epoch 43
Train Loss 35.01089968399278
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6815 test: 0.6273 | best val epoch -- val: 0.6819 test: 0.6231

====epoch 44
Train Loss 35.47019184792065
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6861 test: 0.6261 | best val epoch -- val: 0.6861 test: 0.6261

====epoch 45
Train Loss 34.91691188258257
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6864 test: 0.6287 | best val epoch -- val: 0.6864 test: 0.6287

====epoch 46
Train Loss 34.84659411962461
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6870 test: 0.6323 | best val epoch -- val: 0.6870 test: 0.6323

====epoch 47
Train Loss 34.83339899358138
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6814 test: 0.6307 | best val epoch -- val: 0.6870 test: 0.6323

====epoch 48
Train Loss 34.49005205011293
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6881 test: 0.6334 | best val epoch -- val: 0.6881 test: 0.6334

====epoch 49
Train Loss 34.61924231807022
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6863 test: 0.6330 | best val epoch -- val: 0.6881 test: 0.6334

====epoch 50
Train Loss 34.37629846867785
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6852 test: 0.6295 | best val epoch -- val: 0.6881 test: 0.6334

====epoch 51
Train Loss 34.560095532688706
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6899 test: 0.6348 | best val epoch -- val: 0.6899 test: 0.6348

====epoch 52
Train Loss 34.273418975299414
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6885 test: 0.6333 | best val epoch -- val: 0.6899 test: 0.6348

====epoch 53
Train Loss 33.997730970878166
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6908 test: 0.6362 | best val epoch -- val: 0.6908 test: 0.6362

====epoch 54
Train Loss 34.22306113121021
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6872 test: 0.6332 | best val epoch -- val: 0.6908 test: 0.6362

====epoch 55
Train Loss 34.206417850269666
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6893 test: 0.6357 | best val epoch -- val: 0.6908 test: 0.6362

====epoch 56
Train Loss 33.76567206082259
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6899 test: 0.6375 | best val epoch -- val: 0.6908 test: 0.6362

====epoch 57
Train Loss 34.13323068556541
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6938 test: 0.6445 | best val epoch -- val: 0.6938 test: 0.6445

====epoch 58
Train Loss 33.76513558918008
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6871 test: 0.6457 | best val epoch -- val: 0.6938 test: 0.6445

====epoch 59
Train Loss 33.55943398687121
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6925 test: 0.6419 | best val epoch -- val: 0.6938 test: 0.6445

====epoch 60
Train Loss 33.493933866491396
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6922 test: 0.6375 | best val epoch -- val: 0.6938 test: 0.6445

====epoch 61
Train Loss 33.11457618608881
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6877 test: 0.6356 | best val epoch -- val: 0.6938 test: 0.6445

====epoch 62
Train Loss 33.24952973994176
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6918 test: 0.6395 | best val epoch -- val: 0.6938 test: 0.6445

====epoch 63
Train Loss 33.366030672829666
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6920 test: 0.6359 | best val epoch -- val: 0.6938 test: 0.6445

====epoch 64
Train Loss 33.42347013924234
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6901 test: 0.6381 | best val epoch -- val: 0.6938 test: 0.6445

====epoch 65
Train Loss 33.065300279209836
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6909 test: 0.6361 | best val epoch -- val: 0.6938 test: 0.6445

====epoch 66
Train Loss 33.148158174398
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6958 test: 0.6480 | best val epoch -- val: 0.6958 test: 0.6480

====epoch 67
Train Loss 33.070961965947575
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6977 test: 0.6420 | best val epoch -- val: 0.6977 test: 0.6420

====epoch 68
Train Loss 33.22140652885962
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6900 test: 0.6407 | best val epoch -- val: 0.6977 test: 0.6420

====epoch 69
Train Loss 32.91479035402939
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6912 test: 0.6407 | best val epoch -- val: 0.6977 test: 0.6420

====epoch 70
Train Loss 32.8424515746124
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6842 test: 0.6387 | best val epoch -- val: 0.6977 test: 0.6420

====epoch 71
Train Loss 32.70057302627753
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6957 test: 0.6446 | best val epoch -- val: 0.6977 test: 0.6420

====epoch 72
Train Loss 32.75125236234293
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6976 test: 0.6436 | best val epoch -- val: 0.6977 test: 0.6420

====epoch 73
Train Loss 32.61691657259835
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6911 test: 0.6455 | best val epoch -- val: 0.6977 test: 0.6420

====epoch 74
Train Loss 32.51480488206872
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6932 test: 0.6459 | best val epoch -- val: 0.6977 test: 0.6420

====epoch 75
Train Loss 32.63239260832381
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6936 test: 0.6473 | best val epoch -- val: 0.6977 test: 0.6420

====epoch 76
Train Loss 32.55762626298421
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6930 test: 0.6426 | best val epoch -- val: 0.6977 test: 0.6420

====epoch 77
Train Loss 32.47702155912902
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6953 test: 0.6448 | best val epoch -- val: 0.6977 test: 0.6420

====epoch 78
Train Loss 32.59310079559941
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6981 test: 0.6504 | best val epoch -- val: 0.6981 test: 0.6504

====epoch 79
Train Loss 32.37695421950379
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.7021 test: 0.6503 | best val epoch -- val: 0.7021 test: 0.6503

====epoch 80
Train Loss 32.308951935903536
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.7049 test: 0.6479 | best val epoch -- val: 0.7049 test: 0.6479

====epoch 81
Train Loss 32.224505841138566
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6961 test: 0.6458 | best val epoch -- val: 0.7049 test: 0.6479

====epoch 82
Train Loss 32.21530350098846
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.7013 test: 0.6510 | best val epoch -- val: 0.7049 test: 0.6479

====epoch 83
Train Loss 31.88000878815293
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.7006 test: 0.6588 | best val epoch -- val: 0.7049 test: 0.6479

====epoch 84
Train Loss 31.90198160856282
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6987 test: 0.6447 | best val epoch -- val: 0.7049 test: 0.6479

====epoch 85
Train Loss 31.989577978696587
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.7064 test: 0.6577 | best val epoch -- val: 0.7064 test: 0.6577

====epoch 86
Train Loss 31.941413227345794
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.7013 test: 0.6512 | best val epoch -- val: 0.7064 test: 0.6577

====epoch 87
Train Loss 31.91294202893388
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.7014 test: 0.6566 | best val epoch -- val: 0.7064 test: 0.6577

====epoch 88
Train Loss 31.738495053268835
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.7016 test: 0.6470 | best val epoch -- val: 0.7064 test: 0.6577

====epoch 89
Train Loss 31.95384469208452
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.7004 test: 0.6530 | best val epoch -- val: 0.7064 test: 0.6577

====epoch 90
Train Loss 31.612788387206255
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.7017 test: 0.6511 | best val epoch -- val: 0.7064 test: 0.6577

====epoch 91
Train Loss 31.62296856220835
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6950 test: 0.6477 | best val epoch -- val: 0.7064 test: 0.6577

====epoch 92
Train Loss 31.386929655351874
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.7015 test: 0.6526 | best val epoch -- val: 0.7064 test: 0.6577

====epoch 93
Train Loss 31.705356061231097
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6999 test: 0.6525 | best val epoch -- val: 0.7064 test: 0.6577

====epoch 94
Train Loss 31.362130692321625
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6965 test: 0.6450 | best val epoch -- val: 0.7064 test: 0.6577

====epoch 95
Train Loss 31.49619429719442
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.7005 test: 0.6564 | best val epoch -- val: 0.7064 test: 0.6577

====epoch 96
Train Loss 31.480156915077092
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.7025 test: 0.6566 | best val epoch -- val: 0.7064 test: 0.6577

====epoch 97
Train Loss 31.183397139706567
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.7010 test: 0.6592 | best val epoch -- val: 0.7064 test: 0.6577

====epoch 98
Train Loss 31.23211268356124
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.6991 test: 0.6559 | best val epoch -- val: 0.7064 test: 0.6577

====epoch 99
Train Loss 31.126173660557534
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.7044 test: 0.6549 | best val epoch -- val: 0.7064 test: 0.6577

====epoch 100
Train Loss 30.912970552237002
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.011345
Some target is missing!
Missing ratio: 0.011345
train: 0.0000 val: 0.7057 test: 0.6553 | best val epoch -- val: 0.7064 test: 0.6577

2022-09-13 17:46:20.366 | INFO     | modules.masked_transformer_encoder:__init__:122 - number of parameters: 0.000000e+00
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.4.
=========================================
batch_size = 32
d_model = 128
dataset = bace
decay = 0
device = 0
dim_feedforward = 512
eval_train = 0
filename =
gnn_JK = cat
gnn_dropout = 0.3
gnn_emb_dim = 300
gnn_num_layer = 5
gnn_residual = False
gnn_type = gin
gnn_virtual_node = False
graph_pooling = cls
input_model_file = models_graphtrans/graphtrans-sr-gcl.pth
lr = 0.0001
lr_scale = 1
max_input_len = 1000
nhead = 4
num_encoder_layers = 4
num_encoder_layers_masked = 0
num_workers = 0
pos_encoder = False
runseed = 0
seed = 12344
split = scaffold
transformer_activation = relu
transformer_dropout = 0.3
transformer_norm_input = True
transformer_prenorm = False
=========================================
bace
scaffold
Loaded GraphTrans from models_graphtrans/graphtrans-sr-gcl.pth
====epoch 1
Train Loss 26.057848055935665
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6095 test: 0.5295 | best val epoch -- val: 0.6095 test: 0.5295

====epoch 2
Train Loss 25.730394329150474
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.5462 test: 0.7020 | best val epoch -- val: 0.6095 test: 0.5295

====epoch 3
Train Loss 24.347542455804614
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.4853 test: 0.6688 | best val epoch -- val: 0.6095 test: 0.5295

====epoch 4
Train Loss 24.128092469109166
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.4864 test: 0.6541 | best val epoch -- val: 0.6095 test: 0.5295

====epoch 5
Train Loss 23.23563501506433
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.5656 test: 0.6715 | best val epoch -- val: 0.6095 test: 0.5295

====epoch 6
Train Loss 20.807863263049423
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6271 test: 0.7284 | best val epoch -- val: 0.6271 test: 0.7284

====epoch 7
Train Loss 19.156257471980833
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6766 test: 0.7621 | best val epoch -- val: 0.6766 test: 0.7621

====epoch 8
Train Loss 18.386434155865125
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6799 test: 0.7847 | best val epoch -- val: 0.6799 test: 0.7847

====epoch 9
Train Loss 17.255540007556686
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7022 test: 0.8146 | best val epoch -- val: 0.7022 test: 0.8146

====epoch 10
Train Loss 16.72362651355105
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6868 test: 0.7882 | best val epoch -- val: 0.7022 test: 0.8146

====epoch 11
Train Loss 17.10089239909044
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6795 test: 0.7920 | best val epoch -- val: 0.7022 test: 0.8146

====epoch 12
Train Loss 15.473369860332841
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6901 test: 0.8181 | best val epoch -- val: 0.7022 test: 0.8146

====epoch 13
Train Loss 15.636543285044908
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7040 test: 0.8059 | best val epoch -- val: 0.7040 test: 0.8059

====epoch 14
Train Loss 15.906933788763093
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7179 test: 0.8235 | best val epoch -- val: 0.7179 test: 0.8235

====epoch 15
Train Loss 15.75211054544575
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6952 test: 0.8195 | best val epoch -- val: 0.7179 test: 0.8235

====epoch 16
Train Loss 15.156751451564567
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7095 test: 0.8313 | best val epoch -- val: 0.7179 test: 0.8235

====epoch 17
Train Loss 14.85414085528914
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7062 test: 0.8139 | best val epoch -- val: 0.7179 test: 0.8235

====epoch 18
Train Loss 14.681202939297727
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7033 test: 0.8284 | best val epoch -- val: 0.7179 test: 0.8235

====epoch 19
Train Loss 14.59200036995384
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6938 test: 0.8221 | best val epoch -- val: 0.7179 test: 0.8235

====epoch 20
Train Loss 14.290990415317328
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7037 test: 0.8268 | best val epoch -- val: 0.7179 test: 0.8235

====epoch 21
Train Loss 14.609422319678128
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6575 test: 0.8117 | best val epoch -- val: 0.7179 test: 0.8235

====epoch 22
Train Loss 13.7995394463153
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6678 test: 0.8193 | best val epoch -- val: 0.7179 test: 0.8235

====epoch 23
Train Loss 14.201131206527764
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6813 test: 0.8263 | best val epoch -- val: 0.7179 test: 0.8235

====epoch 24
Train Loss 14.248144624247491
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6861 test: 0.8061 | best val epoch -- val: 0.7179 test: 0.8235

====epoch 25
Train Loss 13.328752523697837
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7106 test: 0.8139 | best val epoch -- val: 0.7179 test: 0.8235

====epoch 26
Train Loss 12.949283427388595
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7201 test: 0.8190 | best val epoch -- val: 0.7201 test: 0.8190

====epoch 27
Train Loss 13.246138500780217
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7037 test: 0.8139 | best val epoch -- val: 0.7201 test: 0.8190

====epoch 28
Train Loss 12.823566531139921
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7150 test: 0.8153 | best val epoch -- val: 0.7201 test: 0.8190

====epoch 29
Train Loss 13.115374000925614
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7128 test: 0.8148 | best val epoch -- val: 0.7201 test: 0.8190

====epoch 30
Train Loss 13.415293843245223
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7212 test: 0.8053 | best val epoch -- val: 0.7212 test: 0.8053

====epoch 31
Train Loss 13.017947353095785
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7029 test: 0.8132 | best val epoch -- val: 0.7212 test: 0.8053

====epoch 32
Train Loss 12.899656247161117
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7370 test: 0.8171 | best val epoch -- val: 0.7370 test: 0.8171

====epoch 33
Train Loss 12.907880073925558
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7234 test: 0.8119 | best val epoch -- val: 0.7370 test: 0.8171

====epoch 34
Train Loss 12.31158115039412
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6956 test: 0.8263 | best val epoch -- val: 0.7370 test: 0.8171

====epoch 35
Train Loss 12.818247316788463
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7147 test: 0.8053 | best val epoch -- val: 0.7370 test: 0.8171

====epoch 36
Train Loss 12.1479763767616
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7267 test: 0.8188 | best val epoch -- val: 0.7370 test: 0.8171

====epoch 37
Train Loss 12.421290036025047
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7143 test: 0.7939 | best val epoch -- val: 0.7370 test: 0.8171

====epoch 38
Train Loss 12.152872988774652
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7040 test: 0.7983 | best val epoch -- val: 0.7370 test: 0.8171

====epoch 39
Train Loss 12.11689989374727
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7267 test: 0.7908 | best val epoch -- val: 0.7370 test: 0.8171

====epoch 40
Train Loss 11.198405608759215
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7055 test: 0.7903 | best val epoch -- val: 0.7370 test: 0.8171

====epoch 41
Train Loss 11.837586335931132
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6835 test: 0.7833 | best val epoch -- val: 0.7370 test: 0.8171

====epoch 42
Train Loss 11.863266943335317
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7117 test: 0.8148 | best val epoch -- val: 0.7370 test: 0.8171

====epoch 43
Train Loss 11.35432744038001
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7172 test: 0.8086 | best val epoch -- val: 0.7370 test: 0.8171

====epoch 44
Train Loss 11.347655174842233
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7136 test: 0.7762 | best val epoch -- val: 0.7370 test: 0.8171

====epoch 45
Train Loss 11.570493399404862
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7143 test: 0.7936 | best val epoch -- val: 0.7370 test: 0.8171

====epoch 46
Train Loss 10.575557300476556
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7132 test: 0.7804 | best val epoch -- val: 0.7370 test: 0.8171

====epoch 47
Train Loss 10.70742732258636
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7084 test: 0.7879 | best val epoch -- val: 0.7370 test: 0.8171

====epoch 48
Train Loss 11.311065785867155
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7216 test: 0.7736 | best val epoch -- val: 0.7370 test: 0.8171

====epoch 49
Train Loss 10.588319101434688
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6886 test: 0.7590 | best val epoch -- val: 0.7370 test: 0.8171

====epoch 50
Train Loss 10.699168982743956
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7011 test: 0.7792 | best val epoch -- val: 0.7370 test: 0.8171


2022-09-13 17:49:15.887 | INFO     | modules.masked_transformer_encoder:__init__:122 - number of parameters: 0.000000e+00
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.4.
=========================================
batch_size = 32
d_model = 128
dataset = bace
decay = 0
device = 0
dim_feedforward = 512
eval_train = 0
filename =
gnn_JK = cat
gnn_dropout = 0.3
gnn_emb_dim = 300
gnn_num_layer = 5
gnn_residual = False
gnn_type = gin
gnn_virtual_node = False
graph_pooling = cls
input_model_file = models_graphtrans/graphtrans-sr-gcl.pth
lr = 0.0001
lr_scale = 1
max_input_len = 1000
nhead = 4
num_encoder_layers = 4
num_encoder_layers_masked = 0
num_workers = 0
pos_encoder = False
runseed = 1
seed = 12344
split = scaffold
transformer_activation = relu
transformer_dropout = 0.3
transformer_norm_input = True
transformer_prenorm = False
=========================================
bace
scaffold
Loaded GraphTrans from models_graphtrans/graphtrans-sr-gcl.pth
====epoch 1
Train Loss 26.23785714037998
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.4846 test: 0.4921 | best val epoch -- val: 0.4846 test: 0.4921

====epoch 2
Train Loss 25.31565590544243
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.5216 test: 0.6660 | best val epoch -- val: 0.5216 test: 0.6660

====epoch 3
Train Loss 23.622658983965458
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.5934 test: 0.7173 | best val epoch -- val: 0.5934 test: 0.7173

====epoch 4
Train Loss 22.182389979446334
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6216 test: 0.7240 | best val epoch -- val: 0.6216 test: 0.7240

====epoch 5
Train Loss 20.090612877681153
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6440 test: 0.7484 | best val epoch -- val: 0.6440 test: 0.7484

====epoch 6
Train Loss 18.333694536499515
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6780 test: 0.7675 | best val epoch -- val: 0.6780 test: 0.7675

====epoch 7
Train Loss 17.578604441825792
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6619 test: 0.7780 | best val epoch -- val: 0.6780 test: 0.7675

====epoch 8
Train Loss 16.97360386418792
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6502 test: 0.8030 | best val epoch -- val: 0.6780 test: 0.7675

====epoch 9
Train Loss 15.93850868796027
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6777 test: 0.8053 | best val epoch -- val: 0.6780 test: 0.7675

====epoch 10
Train Loss 16.199303645203326
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6656 test: 0.8002 | best val epoch -- val: 0.6780 test: 0.7675

====epoch 11
Train Loss 16.228832262921088
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6861 test: 0.8032 | best val epoch -- val: 0.6861 test: 0.8032

====epoch 12
Train Loss 16.071982440142715
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6744 test: 0.7906 | best val epoch -- val: 0.6861 test: 0.8032

====epoch 13
Train Loss 15.424621537550886
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6780 test: 0.7934 | best val epoch -- val: 0.6861 test: 0.8032

====epoch 14
Train Loss 15.02736849611906
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6897 test: 0.8035 | best val epoch -- val: 0.6897 test: 0.8035

====epoch 15
Train Loss 15.309039641266276
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6872 test: 0.7962 | best val epoch -- val: 0.6897 test: 0.8035

====epoch 16
Train Loss 14.791645739868759
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6890 test: 0.8016 | best val epoch -- val: 0.6897 test: 0.8035

====epoch 17
Train Loss 14.574931829970776
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7044 test: 0.8051 | best val epoch -- val: 0.7044 test: 0.8051

====epoch 18
Train Loss 14.119671885640162
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6795 test: 0.8000 | best val epoch -- val: 0.7044 test: 0.8051

====epoch 19
Train Loss 13.95427320515364
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6780 test: 0.8096 | best val epoch -- val: 0.7044 test: 0.8051

====epoch 20
Train Loss 14.12143652713064
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6941 test: 0.8059 | best val epoch -- val: 0.7044 test: 0.8051

====epoch 21
Train Loss 13.228823657531414
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6912 test: 0.8212 | best val epoch -- val: 0.7044 test: 0.8051

====epoch 22
Train Loss 13.80500101149843
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6788 test: 0.8145 | best val epoch -- val: 0.7044 test: 0.8051

====epoch 23
Train Loss 14.346011135344506
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6945 test: 0.8141 | best val epoch -- val: 0.7044 test: 0.8051

====epoch 24
Train Loss 13.536244551442083
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6927 test: 0.8240 | best val epoch -- val: 0.7044 test: 0.8051

====epoch 25
Train Loss 13.591435819773272
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6912 test: 0.8089 | best val epoch -- val: 0.7044 test: 0.8051

====epoch 26
Train Loss 13.158383835646264
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6846 test: 0.8110 | best val epoch -- val: 0.7044 test: 0.8051

====epoch 27
Train Loss 12.884529674560534
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6857 test: 0.8072 | best val epoch -- val: 0.7044 test: 0.8051

====epoch 28
Train Loss 12.89230015606321
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6868 test: 0.8089 | best val epoch -- val: 0.7044 test: 0.8051

====epoch 29
Train Loss 12.36599365792563
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6788 test: 0.8235 | best val epoch -- val: 0.7044 test: 0.8051

====epoch 30
Train Loss 12.81833029118042
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6879 test: 0.8235 | best val epoch -- val: 0.7044 test: 0.8051

====epoch 31
Train Loss 12.260896490198732
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6729 test: 0.8181 | best val epoch -- val: 0.7044 test: 0.8051

====epoch 32
Train Loss 12.198887657339293
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6634 test: 0.8117 | best val epoch -- val: 0.7044 test: 0.8051

====epoch 33
Train Loss 12.541180319578325
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6905 test: 0.8268 | best val epoch -- val: 0.7044 test: 0.8051

====epoch 34
Train Loss 12.077210962061418
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6659 test: 0.8162 | best val epoch -- val: 0.7044 test: 0.8051

====epoch 35
Train Loss 12.721827539067691
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6828 test: 0.8192 | best val epoch -- val: 0.7044 test: 0.8051

====epoch 36
Train Loss 11.63034820567124
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7103 test: 0.8185 | best val epoch -- val: 0.7103 test: 0.8185

====epoch 37
Train Loss 12.154750162403603
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6729 test: 0.8098 | best val epoch -- val: 0.7103 test: 0.8185

====epoch 38
Train Loss 12.01725546974594
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6875 test: 0.8040 | best val epoch -- val: 0.7103 test: 0.8185

====epoch 39
Train Loss 11.389742831439033
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6546 test: 0.8051 | best val epoch -- val: 0.7103 test: 0.8185

====epoch 40
Train Loss 12.389193136643696
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6784 test: 0.8007 | best val epoch -- val: 0.7103 test: 0.8185

====epoch 41
Train Loss 11.556877972166097
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6828 test: 0.8065 | best val epoch -- val: 0.7103 test: 0.8185

====epoch 42
Train Loss 11.272053935771513
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6919 test: 0.8179 | best val epoch -- val: 0.7103 test: 0.8185

====epoch 43
Train Loss 10.8750048268388
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6802 test: 0.8101 | best val epoch -- val: 0.7103 test: 0.8185

====epoch 44
Train Loss 11.014772127198393
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6648 test: 0.8028 | best val epoch -- val: 0.7103 test: 0.8185

====epoch 45
Train Loss 11.608090007732889
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7040 test: 0.7933 | best val epoch -- val: 0.7103 test: 0.8185

====epoch 46
Train Loss 11.753587269160652
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6842 test: 0.7861 | best val epoch -- val: 0.7103 test: 0.8185

====epoch 47
Train Loss 10.927746996771724
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6751 test: 0.8186 | best val epoch -- val: 0.7103 test: 0.8185

====epoch 48
Train Loss 10.401135114311154
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6886 test: 0.8159 | best val epoch -- val: 0.7103 test: 0.8185

====epoch 49
Train Loss 10.584934150851177
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6784 test: 0.8089 | best val epoch -- val: 0.7103 test: 0.8185

====epoch 50
Train Loss 10.46558756425133
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6832 test: 0.7920 | best val epoch -- val: 0.7103 test: 0.8185

2022-09-13 17:52:00.343 | INFO     | modules.masked_transformer_encoder:__init__:122 - number of parameters: 0.000000e+00
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.4.
=========================================
batch_size = 32
d_model = 128
dataset = bace
decay = 0
device = 0
dim_feedforward = 512
eval_train = 0
filename =
gnn_JK = cat
gnn_dropout = 0.3
gnn_emb_dim = 300
gnn_num_layer = 5
gnn_residual = False
gnn_type = gin
gnn_virtual_node = False
graph_pooling = cls
input_model_file = models_graphtrans/graphtrans-sr-gcl.pth
lr = 0.0001
lr_scale = 1
max_input_len = 1000
nhead = 4
num_encoder_layers = 4
num_encoder_layers_masked = 0
num_workers = 0
pos_encoder = False
runseed = 2
seed = 12344
split = scaffold
transformer_activation = relu
transformer_dropout = 0.3
transformer_norm_input = True
transformer_prenorm = False
=========================================
bace
scaffold
Loaded GraphTrans from models_graphtrans/graphtrans-sr-gcl.pth
====epoch 1
Train Loss 26.73602145281797
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.4824 test: 0.6540 | best val epoch -- val: 0.4824 test: 0.6540

====epoch 2
Train Loss 25.80312021335336
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.4963 test: 0.6472 | best val epoch -- val: 0.4963 test: 0.6472

====epoch 3
Train Loss 25.166552221066404
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.5575 test: 0.7406 | best val epoch -- val: 0.5575 test: 0.7406

====epoch 4
Train Loss 23.530085984674855
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.5531 test: 0.7501 | best val epoch -- val: 0.5575 test: 0.7406

====epoch 5
Train Loss 22.61172976402657
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6125 test: 0.7235 | best val epoch -- val: 0.6125 test: 0.7235

====epoch 6
Train Loss 21.374567487993453
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6308 test: 0.7254 | best val epoch -- val: 0.6308 test: 0.7254

====epoch 7
Train Loss 19.115808583658453
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6769 test: 0.7920 | best val epoch -- val: 0.6769 test: 0.7920

====epoch 8
Train Loss 17.99436710723907
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6465 test: 0.8086 | best val epoch -- val: 0.6769 test: 0.7920

====epoch 9
Train Loss 16.463759755537172
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6564 test: 0.8037 | best val epoch -- val: 0.6769 test: 0.7920

====epoch 10
Train Loss 17.173854103590408
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6982 test: 0.8207 | best val epoch -- val: 0.6982 test: 0.8207

====epoch 11
Train Loss 16.500912382651975
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6744 test: 0.8357 | best val epoch -- val: 0.6982 test: 0.8207

====epoch 12
Train Loss 15.302668779279417
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6557 test: 0.8322 | best val epoch -- val: 0.6982 test: 0.8207

====epoch 13
Train Loss 15.333877938568474
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6495 test: 0.8138 | best val epoch -- val: 0.6982 test: 0.8207

====epoch 14
Train Loss 15.173525204706399
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6766 test: 0.8298 | best val epoch -- val: 0.6982 test: 0.8207

====epoch 15
Train Loss 15.807282812638329
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6707 test: 0.8320 | best val epoch -- val: 0.6982 test: 0.8207

====epoch 16
Train Loss 15.425485332097775
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6832 test: 0.8244 | best val epoch -- val: 0.6982 test: 0.8207

====epoch 17
Train Loss 14.377500920017667
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6846 test: 0.8200 | best val epoch -- val: 0.6982 test: 0.8207

====epoch 18
Train Loss 14.421039423464158
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6842 test: 0.8117 | best val epoch -- val: 0.6982 test: 0.8207

====epoch 19
Train Loss 14.650626368679601
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6696 test: 0.7806 | best val epoch -- val: 0.6982 test: 0.8207

====epoch 20
Train Loss 13.64201967451855
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7022 test: 0.8228 | best val epoch -- val: 0.7022 test: 0.8228

====epoch 21
Train Loss 13.22074955216596
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7300 test: 0.8329 | best val epoch -- val: 0.7300 test: 0.8329

====epoch 22
Train Loss 14.259975835892686
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7194 test: 0.8206 | best val epoch -- val: 0.7300 test: 0.8329

====epoch 23
Train Loss 14.298211837109108
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7000 test: 0.8317 | best val epoch -- val: 0.7300 test: 0.8329

====epoch 24
Train Loss 14.25535313691119
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7282 test: 0.8186 | best val epoch -- val: 0.7300 test: 0.8329

====epoch 25
Train Loss 13.07749713166969
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7286 test: 0.8258 | best val epoch -- val: 0.7300 test: 0.8329

====epoch 26
Train Loss 13.421380024992013
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7220 test: 0.8166 | best val epoch -- val: 0.7300 test: 0.8329

====epoch 27
Train Loss 13.201334937558027
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7128 test: 0.8256 | best val epoch -- val: 0.7300 test: 0.8329

====epoch 28
Train Loss 13.703494049019104
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6927 test: 0.8035 | best val epoch -- val: 0.7300 test: 0.8329

====epoch 29
Train Loss 12.982689346524982
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6974 test: 0.8186 | best val epoch -- val: 0.7300 test: 0.8329

====epoch 30
Train Loss 12.882609221593084
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6952 test: 0.8266 | best val epoch -- val: 0.7300 test: 0.8329

====epoch 31
Train Loss 12.80885427693187
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6864 test: 0.8150 | best val epoch -- val: 0.7300 test: 0.8329

====epoch 32
Train Loss 12.285519908061156
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7110 test: 0.8119 | best val epoch -- val: 0.7300 test: 0.8329

====epoch 33
Train Loss 12.025768233983248
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6901 test: 0.8035 | best val epoch -- val: 0.7300 test: 0.8329

====epoch 34
Train Loss 12.485694856056737
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7165 test: 0.8115 | best val epoch -- val: 0.7300 test: 0.8329

====epoch 35
Train Loss 11.884872979649822
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7114 test: 0.8266 | best val epoch -- val: 0.7300 test: 0.8329

====epoch 36
Train Loss 12.144435905807962
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7161 test: 0.8103 | best val epoch -- val: 0.7300 test: 0.8329

====epoch 37
Train Loss 11.571188747722028
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6927 test: 0.8049 | best val epoch -- val: 0.7300 test: 0.8329

====epoch 38
Train Loss 12.843755951126766
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7084 test: 0.8089 | best val epoch -- val: 0.7300 test: 0.8329

====epoch 39
Train Loss 11.82906227016079
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7136 test: 0.8160 | best val epoch -- val: 0.7300 test: 0.8329

====epoch 40
Train Loss 11.582965867084086
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7121 test: 0.8136 | best val epoch -- val: 0.7300 test: 0.8329

====epoch 41
Train Loss 11.367108971898036
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6993 test: 0.8141 | best val epoch -- val: 0.7300 test: 0.8329

====epoch 42
Train Loss 10.819173666181534
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7106 test: 0.8028 | best val epoch -- val: 0.7300 test: 0.8329

====epoch 43
Train Loss 11.22920148140595
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7245 test: 0.8082 | best val epoch -- val: 0.7300 test: 0.8329

====epoch 44
Train Loss 11.281954337058158
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7139 test: 0.8061 | best val epoch -- val: 0.7300 test: 0.8329

====epoch 45
Train Loss 10.78308988032694
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7073 test: 0.7999 | best val epoch -- val: 0.7300 test: 0.8329

====epoch 46
Train Loss 10.95166007713486
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7018 test: 0.7936 | best val epoch -- val: 0.7300 test: 0.8329

====epoch 47
Train Loss 10.794306701020863
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7176 test: 0.8059 | best val epoch -- val: 0.7300 test: 0.8329

====epoch 48
Train Loss 10.500693696363646
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6967 test: 0.8112 | best val epoch -- val: 0.7300 test: 0.8329

====epoch 49
Train Loss 10.928207372915406
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7066 test: 0.8066 | best val epoch -- val: 0.7300 test: 0.8329

====epoch 50
Train Loss 10.584337550150355
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7088 test: 0.7964 | best val epoch -- val: 0.7300 test: 0.8329

2022-09-13 17:54:46.203 | INFO     | modules.masked_transformer_encoder:__init__:122 - number of parameters: 0.000000e+00
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.4.
=========================================
batch_size = 32
d_model = 128
dataset = bace
decay = 0
device = 0
dim_feedforward = 512
eval_train = 0
filename =
gnn_JK = cat
gnn_dropout = 0.3
gnn_emb_dim = 300
gnn_num_layer = 5
gnn_residual = False
gnn_type = gin
gnn_virtual_node = False
graph_pooling = cls
input_model_file = models_graphtrans/graphtrans-sr-gcl.pth
lr = 0.0001
lr_scale = 1
max_input_len = 1000
nhead = 4
num_encoder_layers = 4
num_encoder_layers_masked = 0
num_workers = 0
pos_encoder = False
runseed = 3
seed = 12344
split = scaffold
transformer_activation = relu
transformer_dropout = 0.3
transformer_norm_input = True
transformer_prenorm = False
=========================================
bace
scaffold
Loaded GraphTrans from models_graphtrans/graphtrans-sr-gcl.pth
====epoch 1
Train Loss 26.859927668504504
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.4139 test: 0.4693 | best val epoch -- val: 0.4139 test: 0.4693

====epoch 2
Train Loss 24.99257869451441
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.4949 test: 0.6013 | best val epoch -- val: 0.4949 test: 0.6013

====epoch 3
Train Loss 24.688100122886915
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.5703 test: 0.6225 | best val epoch -- val: 0.5703 test: 0.6225

====epoch 4
Train Loss 23.666899859084598
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6227 test: 0.6498 | best val epoch -- val: 0.6227 test: 0.6498

====epoch 5
Train Loss 21.90058737856129
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6436 test: 0.7027 | best val epoch -- val: 0.6436 test: 0.7027

====epoch 6
Train Loss 19.692608636292363
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6560 test: 0.7173 | best val epoch -- val: 0.6560 test: 0.7173

====epoch 7
Train Loss 18.49310444130796
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6484 test: 0.7585 | best val epoch -- val: 0.6560 test: 0.7173

====epoch 8
Train Loss 16.787867571797694
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6707 test: 0.7545 | best val epoch -- val: 0.6707 test: 0.7545

====epoch 9
Train Loss 17.065626177461823
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6692 test: 0.7654 | best val epoch -- val: 0.6707 test: 0.7545

====epoch 10
Train Loss 16.639427521477984
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6758 test: 0.7731 | best val epoch -- val: 0.6758 test: 0.7731

====epoch 11
Train Loss 16.93748934122157
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6762 test: 0.7877 | best val epoch -- val: 0.6762 test: 0.7877

====epoch 12
Train Loss 15.772338727161456
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6612 test: 0.7722 | best val epoch -- val: 0.6762 test: 0.7877

====epoch 13
Train Loss 15.217883444833701
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6667 test: 0.7988 | best val epoch -- val: 0.6762 test: 0.7877

====epoch 14
Train Loss 15.104388976545597
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6637 test: 0.7802 | best val epoch -- val: 0.6762 test: 0.7877

====epoch 15
Train Loss 14.538911724308056
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6908 test: 0.7793 | best val epoch -- val: 0.6908 test: 0.7793

====epoch 16
Train Loss 15.128794561759655
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6623 test: 0.7884 | best val epoch -- val: 0.6908 test: 0.7793

====epoch 17
Train Loss 14.479133312079357
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7125 test: 0.8054 | best val epoch -- val: 0.7125 test: 0.8054

====epoch 18
Train Loss 14.821049338909285
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6971 test: 0.7990 | best val epoch -- val: 0.7125 test: 0.8054

====epoch 19
Train Loss 13.715667995340263
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6978 test: 0.7826 | best val epoch -- val: 0.7125 test: 0.8054

====epoch 20
Train Loss 14.852415709769838
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6861 test: 0.7995 | best val epoch -- val: 0.7125 test: 0.8054

====epoch 21
Train Loss 14.497922376397472
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6993 test: 0.7927 | best val epoch -- val: 0.7125 test: 0.8054

====epoch 22
Train Loss 13.968164077860381
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6853 test: 0.7790 | best val epoch -- val: 0.7125 test: 0.8054

====epoch 23
Train Loss 13.542626271114617
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6886 test: 0.8056 | best val epoch -- val: 0.7125 test: 0.8054

====epoch 24
Train Loss 13.906127141661365
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7000 test: 0.7905 | best val epoch -- val: 0.7125 test: 0.8054

====epoch 25
Train Loss 13.579488041191281
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7040 test: 0.8150 | best val epoch -- val: 0.7125 test: 0.8054

====epoch 26
Train Loss 14.04482534632796
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7070 test: 0.8103 | best val epoch -- val: 0.7125 test: 0.8054

====epoch 27
Train Loss 13.296947895765937
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7121 test: 0.8047 | best val epoch -- val: 0.7125 test: 0.8054

====epoch 28
Train Loss 13.371698453301137
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7044 test: 0.8061 | best val epoch -- val: 0.7125 test: 0.8054

====epoch 29
Train Loss 13.260531304157837
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7139 test: 0.7960 | best val epoch -- val: 0.7139 test: 0.7960

====epoch 30
Train Loss 13.415563143790001
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7183 test: 0.8051 | best val epoch -- val: 0.7183 test: 0.8051

====epoch 31
Train Loss 13.061663501531136
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6905 test: 0.7999 | best val epoch -- val: 0.7183 test: 0.8051

====epoch 32
Train Loss 13.348178880247016
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7040 test: 0.8131 | best val epoch -- val: 0.7183 test: 0.8051

====epoch 33
Train Loss 12.599687467464767
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7125 test: 0.7986 | best val epoch -- val: 0.7183 test: 0.8051

====epoch 34
Train Loss 12.431534884244211
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7110 test: 0.7917 | best val epoch -- val: 0.7183 test: 0.8051

====epoch 35
Train Loss 11.951207157534046
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6989 test: 0.8138 | best val epoch -- val: 0.7183 test: 0.8051

====epoch 36
Train Loss 11.561109609988362
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7026 test: 0.7926 | best val epoch -- val: 0.7183 test: 0.8051

====epoch 37
Train Loss 11.791208436652084
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7150 test: 0.7988 | best val epoch -- val: 0.7183 test: 0.8051

====epoch 38
Train Loss 12.149334923637841
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7048 test: 0.8063 | best val epoch -- val: 0.7183 test: 0.8051

====epoch 39
Train Loss 11.118862353316562
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6908 test: 0.8223 | best val epoch -- val: 0.7183 test: 0.8051

====epoch 40
Train Loss 11.044881567901209
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6879 test: 0.8322 | best val epoch -- val: 0.7183 test: 0.8051

====epoch 41
Train Loss 11.757799060999767
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7044 test: 0.8103 | best val epoch -- val: 0.7183 test: 0.8051

====epoch 42
Train Loss 12.23022397360888
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7084 test: 0.8105 | best val epoch -- val: 0.7183 test: 0.8051

====epoch 43
Train Loss 11.755447174298622
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7176 test: 0.8002 | best val epoch -- val: 0.7183 test: 0.8051

====epoch 44
Train Loss 11.323522737485591
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7172 test: 0.8028 | best val epoch -- val: 0.7183 test: 0.8051

====epoch 45
Train Loss 11.205409176004418
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7205 test: 0.7976 | best val epoch -- val: 0.7205 test: 0.7976

====epoch 46
Train Loss 11.33392146918683
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7128 test: 0.7908 | best val epoch -- val: 0.7205 test: 0.7976

====epoch 47
Train Loss 10.676630430574303
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7055 test: 0.7933 | best val epoch -- val: 0.7205 test: 0.7976

====epoch 48
Train Loss 10.812691157813562
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7055 test: 0.7837 | best val epoch -- val: 0.7205 test: 0.7976

====epoch 49
Train Loss 11.33335217474183
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7139 test: 0.7950 | best val epoch -- val: 0.7205 test: 0.7976

====epoch 50
Train Loss 10.078155556957398
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7209 test: 0.8026 | best val epoch -- val: 0.7209 test: 0.8026

2022-09-13 17:57:34.956 | INFO     | modules.masked_transformer_encoder:__init__:122 - number of parameters: 0.000000e+00
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.4.
=========================================
batch_size = 32
d_model = 128
dataset = bace
decay = 0
device = 0
dim_feedforward = 512
eval_train = 0
filename =
gnn_JK = cat
gnn_dropout = 0.3
gnn_emb_dim = 300
gnn_num_layer = 5
gnn_residual = False
gnn_type = gin
gnn_virtual_node = False
graph_pooling = cls
input_model_file = models_graphtrans/graphtrans-sr-gcl.pth
lr = 0.0001
lr_scale = 1
max_input_len = 1000
nhead = 4
num_encoder_layers = 4
num_encoder_layers_masked = 0
num_workers = 0
pos_encoder = False
runseed = 4
seed = 12344
split = scaffold
transformer_activation = relu
transformer_dropout = 0.3
transformer_norm_input = True
transformer_prenorm = False
=========================================
bace
scaffold
Loaded GraphTrans from models_graphtrans/graphtrans-sr-gcl.pth
====epoch 1
Train Loss 26.660225195048138
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.4088 test: 0.5872 | best val epoch -- val: 0.4088 test: 0.5872

====epoch 2
Train Loss 25.840206208389677
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.4590 test: 0.6286 | best val epoch -- val: 0.4590 test: 0.6286

====epoch 3
Train Loss 24.38837725679169
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.5267 test: 0.6700 | best val epoch -- val: 0.5267 test: 0.6700

====epoch 4
Train Loss 22.901249229389677
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.5575 test: 0.7087 | best val epoch -- val: 0.5575 test: 0.7087

====epoch 5
Train Loss 21.17621573910658
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6103 test: 0.7312 | best val epoch -- val: 0.6103 test: 0.7312

====epoch 6
Train Loss 20.005603717736353
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6762 test: 0.7479 | best val epoch -- val: 0.6762 test: 0.7479

====epoch 7
Train Loss 18.63639990960513
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6842 test: 0.7713 | best val epoch -- val: 0.6842 test: 0.7713

====epoch 8
Train Loss 17.814856221486437
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6978 test: 0.7840 | best val epoch -- val: 0.6978 test: 0.7840

====epoch 9
Train Loss 17.099262194808507
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7040 test: 0.8097 | best val epoch -- val: 0.7040 test: 0.8097

====epoch 10
Train Loss 16.548206965857688
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6780 test: 0.7910 | best val epoch -- val: 0.7040 test: 0.8097

====epoch 11
Train Loss 16.183538120013306
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6982 test: 0.7953 | best val epoch -- val: 0.7040 test: 0.8097

====epoch 12
Train Loss 16.128740614553397
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6766 test: 0.7889 | best val epoch -- val: 0.7040 test: 0.8097

====epoch 13
Train Loss 15.900892388679981
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6956 test: 0.7983 | best val epoch -- val: 0.7040 test: 0.8097

====epoch 14
Train Loss 15.034299290900778
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7022 test: 0.8230 | best val epoch -- val: 0.7040 test: 0.8097

====epoch 15
Train Loss 15.133702578958161
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6850 test: 0.8166 | best val epoch -- val: 0.7040 test: 0.8097

====epoch 16
Train Loss 15.367465236264927
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6897 test: 0.8063 | best val epoch -- val: 0.7040 test: 0.8097

====epoch 17
Train Loss 14.353167438372898
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6769 test: 0.8053 | best val epoch -- val: 0.7040 test: 0.8097

====epoch 18
Train Loss 14.079986230548473
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6729 test: 0.8152 | best val epoch -- val: 0.7040 test: 0.8097

====epoch 19
Train Loss 14.716856677465524
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6766 test: 0.8051 | best val epoch -- val: 0.7040 test: 0.8097

====epoch 20
Train Loss 14.468750989047873
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6656 test: 0.8246 | best val epoch -- val: 0.7040 test: 0.8097

====epoch 21
Train Loss 13.216089810339058
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6736 test: 0.8164 | best val epoch -- val: 0.7040 test: 0.8097

====epoch 22
Train Loss 14.511632095110265
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6711 test: 0.8252 | best val epoch -- val: 0.7040 test: 0.8097

====epoch 23
Train Loss 13.721018152319454
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6674 test: 0.8286 | best val epoch -- val: 0.7040 test: 0.8097

====epoch 24
Train Loss 13.314462873462954
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6714 test: 0.8219 | best val epoch -- val: 0.7040 test: 0.8097

====epoch 25
Train Loss 13.36728969124339
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6744 test: 0.8226 | best val epoch -- val: 0.7040 test: 0.8097

====epoch 26
Train Loss 13.612520532794413
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6890 test: 0.8239 | best val epoch -- val: 0.7040 test: 0.8097

====epoch 27
Train Loss 12.992099734897456
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6766 test: 0.7920 | best val epoch -- val: 0.7040 test: 0.8097

====epoch 28
Train Loss 13.597065118377827
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6733 test: 0.8065 | best val epoch -- val: 0.7040 test: 0.8097

====epoch 29
Train Loss 13.3203236528879
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6601 test: 0.8197 | best val epoch -- val: 0.7040 test: 0.8097

====epoch 30
Train Loss 13.364850742755484
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6586 test: 0.8188 | best val epoch -- val: 0.7040 test: 0.8097

====epoch 31
Train Loss 13.265116817235523
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6718 test: 0.8066 | best val epoch -- val: 0.7040 test: 0.8097

====epoch 32
Train Loss 13.042482264047539
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6667 test: 0.8080 | best val epoch -- val: 0.7040 test: 0.8097

====epoch 33
Train Loss 11.800254096066869
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6667 test: 0.7979 | best val epoch -- val: 0.7040 test: 0.8097

====epoch 34
Train Loss 13.029686732004498
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6821 test: 0.8122 | best val epoch -- val: 0.7040 test: 0.8097

====epoch 35
Train Loss 12.588783372587613
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6766 test: 0.8143 | best val epoch -- val: 0.7040 test: 0.8097

====epoch 36
Train Loss 12.351373318024
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6795 test: 0.8216 | best val epoch -- val: 0.7040 test: 0.8097

====epoch 37
Train Loss 12.25165061863866
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6714 test: 0.8206 | best val epoch -- val: 0.7040 test: 0.8097

====epoch 38
Train Loss 12.051170705112119
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6901 test: 0.8093 | best val epoch -- val: 0.7040 test: 0.8097

====epoch 39
Train Loss 11.90041789221375
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6729 test: 0.8242 | best val epoch -- val: 0.7040 test: 0.8097

====epoch 40
Train Loss 12.327159637857234
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6733 test: 0.7929 | best val epoch -- val: 0.7040 test: 0.8097

====epoch 41
Train Loss 12.214399720019701
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6941 test: 0.8070 | best val epoch -- val: 0.7040 test: 0.8097

====epoch 42
Train Loss 11.396521304381256
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6744 test: 0.8134 | best val epoch -- val: 0.7040 test: 0.8097

====epoch 43
Train Loss 11.809982729582126
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6949 test: 0.8018 | best val epoch -- val: 0.7040 test: 0.8097

====epoch 44
Train Loss 11.283520482571223
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6930 test: 0.8033 | best val epoch -- val: 0.7040 test: 0.8097

====epoch 45
Train Loss 11.058593913343932
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6967 test: 0.7922 | best val epoch -- val: 0.7040 test: 0.8097

====epoch 46
Train Loss 11.497577066989997
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6868 test: 0.7922 | best val epoch -- val: 0.7040 test: 0.8097

====epoch 47
Train Loss 11.47062228354992
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6751 test: 0.7880 | best val epoch -- val: 0.7040 test: 0.8097

====epoch 48
Train Loss 11.82335569005306
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6923 test: 0.7879 | best val epoch -- val: 0.7040 test: 0.8097

====epoch 49
Train Loss 10.785461511610315
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6839 test: 0.7978 | best val epoch -- val: 0.7040 test: 0.8097

====epoch 50
Train Loss 11.212864480407355
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6905 test: 0.7976 | best val epoch -- val: 0.7040 test: 0.8097

2022-09-13 18:00:24.778 | INFO     | modules.masked_transformer_encoder:__init__:122 - number of parameters: 0.000000e+00
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.4.
=========================================
batch_size = 32
d_model = 128
dataset = bace
decay = 0
device = 0
dim_feedforward = 512
eval_train = 0
filename =
gnn_JK = cat
gnn_dropout = 0.3
gnn_emb_dim = 300
gnn_num_layer = 5
gnn_residual = False
gnn_type = gin
gnn_virtual_node = False
graph_pooling = cls
input_model_file = models_graphtrans/graphtrans-sr-gcl.pth
lr = 0.0001
lr_scale = 1
max_input_len = 1000
nhead = 4
num_encoder_layers = 4
num_encoder_layers_masked = 0
num_workers = 0
pos_encoder = False
runseed = 5
seed = 12344
split = scaffold
transformer_activation = relu
transformer_dropout = 0.3
transformer_norm_input = True
transformer_prenorm = False
=========================================
bace
scaffold
Loaded GraphTrans from models_graphtrans/graphtrans-sr-gcl.pth
====epoch 1
Train Loss 26.37491940928755
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6429 test: 0.5557 | best val epoch -- val: 0.6429 test: 0.5557

====epoch 2
Train Loss 25.817312311211285
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7117 test: 0.6427 | best val epoch -- val: 0.7117 test: 0.6427

====epoch 3
Train Loss 24.39935349428381
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6729 test: 0.7380 | best val epoch -- val: 0.7117 test: 0.6427

====epoch 4
Train Loss 24.141373087304448
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6099 test: 0.7486 | best val epoch -- val: 0.7117 test: 0.6427

====epoch 5
Train Loss 22.59664034108901
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6220 test: 0.7470 | best val epoch -- val: 0.7117 test: 0.6427

====epoch 6
Train Loss 20.774982369439982
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7132 test: 0.7755 | best val epoch -- val: 0.7132 test: 0.7755

====epoch 7
Train Loss 18.188488680003307
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7103 test: 0.7966 | best val epoch -- val: 0.7132 test: 0.7755

====epoch 8
Train Loss 18.28290917493847
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7212 test: 0.8068 | best val epoch -- val: 0.7212 test: 0.8068

====epoch 9
Train Loss 16.807867219117576
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6875 test: 0.8113 | best val epoch -- val: 0.7212 test: 0.8068

====epoch 10
Train Loss 16.602439486939748
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6956 test: 0.8159 | best val epoch -- val: 0.7212 test: 0.8068

====epoch 11
Train Loss 16.10343819396201
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7179 test: 0.8119 | best val epoch -- val: 0.7212 test: 0.8068

====epoch 12
Train Loss 16.117169003038047
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7033 test: 0.8129 | best val epoch -- val: 0.7212 test: 0.8068

====epoch 13
Train Loss 16.657214736107424
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7004 test: 0.8110 | best val epoch -- val: 0.7212 test: 0.8068

====epoch 14
Train Loss 15.645096494192684
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6832 test: 0.8251 | best val epoch -- val: 0.7212 test: 0.8068

====epoch 15
Train Loss 15.138143389128745
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7073 test: 0.8101 | best val epoch -- val: 0.7212 test: 0.8068

====epoch 16
Train Loss 14.746257238175692
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7150 test: 0.8094 | best val epoch -- val: 0.7212 test: 0.8068

====epoch 17
Train Loss 15.27427733970698
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7278 test: 0.8303 | best val epoch -- val: 0.7278 test: 0.8303

====epoch 18
Train Loss 15.120521369668092
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7147 test: 0.8016 | best val epoch -- val: 0.7278 test: 0.8303

====epoch 19
Train Loss 14.207587587622742
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7059 test: 0.8259 | best val epoch -- val: 0.7278 test: 0.8303

====epoch 20
Train Loss 14.822838956402048
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7059 test: 0.8258 | best val epoch -- val: 0.7278 test: 0.8303

====epoch 21
Train Loss 14.232303159551687
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7220 test: 0.8185 | best val epoch -- val: 0.7278 test: 0.8303

====epoch 22
Train Loss 13.597434280426436
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7114 test: 0.8146 | best val epoch -- val: 0.7278 test: 0.8303

====epoch 23
Train Loss 13.49019111803618
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6996 test: 0.8202 | best val epoch -- val: 0.7278 test: 0.8303

====epoch 24
Train Loss 14.044590662054267
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7081 test: 0.8155 | best val epoch -- val: 0.7278 test: 0.8303

====epoch 25
Train Loss 14.203553394289976
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6996 test: 0.8059 | best val epoch -- val: 0.7278 test: 0.8303

====epoch 26
Train Loss 13.738498771938643
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7154 test: 0.8014 | best val epoch -- val: 0.7278 test: 0.8303

====epoch 27
Train Loss 13.76224311853658
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7147 test: 0.7922 | best val epoch -- val: 0.7278 test: 0.8303

====epoch 28
Train Loss 13.420208826071024
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7300 test: 0.8091 | best val epoch -- val: 0.7300 test: 0.8091

====epoch 29
Train Loss 12.402553851628602
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7077 test: 0.8061 | best val epoch -- val: 0.7300 test: 0.8091

====epoch 30
Train Loss 13.102848146278689
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7311 test: 0.8124 | best val epoch -- val: 0.7311 test: 0.8124

====epoch 31
Train Loss 12.9703796399377
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7161 test: 0.8117 | best val epoch -- val: 0.7311 test: 0.8124

====epoch 32
Train Loss 12.691844271417276
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7128 test: 0.8059 | best val epoch -- val: 0.7311 test: 0.8124

====epoch 33
Train Loss 11.810260277709563
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7004 test: 0.8093 | best val epoch -- val: 0.7311 test: 0.8124

====epoch 34
Train Loss 12.899389291156844
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7234 test: 0.8025 | best val epoch -- val: 0.7311 test: 0.8124

====epoch 35
Train Loss 12.288819161803891
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6923 test: 0.8066 | best val epoch -- val: 0.7311 test: 0.8124

====epoch 36
Train Loss 12.249570982381773
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6751 test: 0.8200 | best val epoch -- val: 0.7311 test: 0.8124

====epoch 37
Train Loss 12.043591313589392
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6927 test: 0.8127 | best val epoch -- val: 0.7311 test: 0.8124

====epoch 38
Train Loss 11.71106870632178
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7062 test: 0.8166 | best val epoch -- val: 0.7311 test: 0.8124

====epoch 39
Train Loss 11.966943280946639
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7062 test: 0.8033 | best val epoch -- val: 0.7311 test: 0.8124

====epoch 40
Train Loss 11.831224247010182
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6894 test: 0.7967 | best val epoch -- val: 0.7311 test: 0.8124

====epoch 41
Train Loss 11.668557915360653
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6974 test: 0.8049 | best val epoch -- val: 0.7311 test: 0.8124

====epoch 42
Train Loss 12.341567192957553
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7062 test: 0.7979 | best val epoch -- val: 0.7311 test: 0.8124

====epoch 43
Train Loss 11.467531825181116
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6938 test: 0.7978 | best val epoch -- val: 0.7311 test: 0.8124

====epoch 44
Train Loss 11.797958687419259
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7286 test: 0.8226 | best val epoch -- val: 0.7311 test: 0.8124

====epoch 45
Train Loss 12.140881099943622
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7183 test: 0.8157 | best val epoch -- val: 0.7311 test: 0.8124

====epoch 46
Train Loss 11.564274357193577
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7048 test: 0.8018 | best val epoch -- val: 0.7311 test: 0.8124

====epoch 47
Train Loss 11.317545735409155
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7125 test: 0.7983 | best val epoch -- val: 0.7311 test: 0.8124

====epoch 48
Train Loss 11.345882151823302
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6872 test: 0.8021 | best val epoch -- val: 0.7311 test: 0.8124

====epoch 49
Train Loss 11.186670958597263
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6978 test: 0.8061 | best val epoch -- val: 0.7311 test: 0.8124

====epoch 50
Train Loss 10.906609534481305
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7000 test: 0.7858 | best val epoch -- val: 0.7311 test: 0.8124

WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.4.
2022-09-13 18:03:12.773 | INFO     | modules.masked_transformer_encoder:__init__:122 - number of parameters: 0.000000e+00
=========================================
batch_size = 32
d_model = 128
dataset = bace
decay = 0
device = 0
dim_feedforward = 512
eval_train = 0
filename =
gnn_JK = cat
gnn_dropout = 0.3
gnn_emb_dim = 300
gnn_num_layer = 5
gnn_residual = False
gnn_type = gin
gnn_virtual_node = False
graph_pooling = cls
input_model_file = models_graphtrans/graphtrans-sr-gcl.pth
lr = 0.0001
lr_scale = 1
max_input_len = 1000
nhead = 4
num_encoder_layers = 4
num_encoder_layers_masked = 0
num_workers = 0
pos_encoder = False
runseed = 6
seed = 12344
split = scaffold
transformer_activation = relu
transformer_dropout = 0.3
transformer_norm_input = True
transformer_prenorm = False
=========================================
bace
scaffold
Loaded GraphTrans from models_graphtrans/graphtrans-sr-gcl.pth
====epoch 1
Train Loss 27.018143338796342
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.3498 test: 0.5528 | best val epoch -- val: 0.3498 test: 0.5528

====epoch 2
Train Loss 26.19131244231151
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.4557 test: 0.5302 | best val epoch -- val: 0.4557 test: 0.5302

====epoch 3
Train Loss 24.941623919151073
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.5725 test: 0.5496 | best val epoch -- val: 0.5725 test: 0.5496

====epoch 4
Train Loss 24.672469136980595
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6612 test: 0.6458 | best val epoch -- val: 0.6612 test: 0.6458

====epoch 5
Train Loss 23.11411128376069
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6385 test: 0.6901 | best val epoch -- val: 0.6612 test: 0.6458

====epoch 6
Train Loss 20.136837031921083
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6652 test: 0.7188 | best val epoch -- val: 0.6652 test: 0.7188

====epoch 7
Train Loss 19.89215355765021
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6560 test: 0.7513 | best val epoch -- val: 0.6652 test: 0.7188

====epoch 8
Train Loss 18.49474908536106
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6905 test: 0.7727 | best val epoch -- val: 0.6905 test: 0.7727

====epoch 9
Train Loss 17.293844396338567
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6780 test: 0.7946 | best val epoch -- val: 0.6905 test: 0.7727

====epoch 10
Train Loss 16.75688217420841
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6718 test: 0.7799 | best val epoch -- val: 0.6905 test: 0.7727

====epoch 11
Train Loss 16.380254629203783
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6839 test: 0.7844 | best val epoch -- val: 0.6905 test: 0.7727

====epoch 12
Train Loss 16.448196072879334
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6993 test: 0.7866 | best val epoch -- val: 0.6993 test: 0.7866

====epoch 13
Train Loss 15.911879807925738
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6714 test: 0.7807 | best val epoch -- val: 0.6993 test: 0.7866

====epoch 14
Train Loss 15.451239763972618
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6993 test: 0.7832 | best val epoch -- val: 0.6993 test: 0.7832

====epoch 15
Train Loss 15.39832425308211
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6868 test: 0.7919 | best val epoch -- val: 0.6993 test: 0.7832

====epoch 16
Train Loss 15.146029749184745
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6685 test: 0.8112 | best val epoch -- val: 0.6993 test: 0.7832

====epoch 17
Train Loss 15.308482107789208
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6564 test: 0.8155 | best val epoch -- val: 0.6993 test: 0.7832

====epoch 18
Train Loss 14.324090126434582
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6751 test: 0.8049 | best val epoch -- val: 0.6993 test: 0.7832

====epoch 19
Train Loss 14.502881368478564
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6842 test: 0.8360 | best val epoch -- val: 0.6993 test: 0.7832

====epoch 20
Train Loss 14.777635446638278
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6685 test: 0.8120 | best val epoch -- val: 0.6993 test: 0.7832

====epoch 21
Train Loss 14.513807604831467
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6626 test: 0.7964 | best val epoch -- val: 0.6993 test: 0.7832

====epoch 22
Train Loss 14.678032162353587
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6758 test: 0.8019 | best val epoch -- val: 0.6993 test: 0.7832

====epoch 23
Train Loss 13.957565118915413
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6784 test: 0.8115 | best val epoch -- val: 0.6993 test: 0.7832

====epoch 24
Train Loss 13.54468080916342
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6842 test: 0.8190 | best val epoch -- val: 0.6993 test: 0.7832

====epoch 25
Train Loss 13.426430303846821
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6934 test: 0.7879 | best val epoch -- val: 0.6993 test: 0.7832

====epoch 26
Train Loss 13.74032889584207
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6923 test: 0.8214 | best val epoch -- val: 0.6993 test: 0.7832

====epoch 27
Train Loss 13.605825093388384
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6864 test: 0.8183 | best val epoch -- val: 0.6993 test: 0.7832

====epoch 28
Train Loss 13.955077506339807
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6828 test: 0.8219 | best val epoch -- val: 0.6993 test: 0.7832

====epoch 29
Train Loss 12.850092997564039
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6850 test: 0.8143 | best val epoch -- val: 0.6993 test: 0.7832

====epoch 30
Train Loss 12.99513099558112
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6897 test: 0.8172 | best val epoch -- val: 0.6993 test: 0.7832

====epoch 31
Train Loss 13.28777289442901
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6795 test: 0.8141 | best val epoch -- val: 0.6993 test: 0.7832

====epoch 32
Train Loss 12.83951100794409
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6751 test: 0.8218 | best val epoch -- val: 0.6993 test: 0.7832

====epoch 33
Train Loss 12.802945388019635
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6905 test: 0.8258 | best val epoch -- val: 0.6993 test: 0.7832

====epoch 34
Train Loss 12.851236838769205
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6718 test: 0.8212 | best val epoch -- val: 0.6993 test: 0.7832

====epoch 35
Train Loss 12.218891835514182
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6755 test: 0.7999 | best val epoch -- val: 0.6993 test: 0.7832

====epoch 36
Train Loss 12.414063622023948
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6663 test: 0.8282 | best val epoch -- val: 0.6993 test: 0.7832

====epoch 37
Train Loss 12.326106305729526
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6879 test: 0.8211 | best val epoch -- val: 0.6993 test: 0.7832

====epoch 38
Train Loss 12.573764439198705
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6722 test: 0.8310 | best val epoch -- val: 0.6993 test: 0.7832

====epoch 39
Train Loss 12.11084664303023
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6883 test: 0.8291 | best val epoch -- val: 0.6993 test: 0.7832

====epoch 40
Train Loss 12.15200858645841
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7073 test: 0.8273 | best val epoch -- val: 0.7073 test: 0.8273

====epoch 41
Train Loss 11.582513795444543
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7033 test: 0.8289 | best val epoch -- val: 0.7073 test: 0.8273

====epoch 42
Train Loss 12.249121289156676
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6857 test: 0.8084 | best val epoch -- val: 0.7073 test: 0.8273

====epoch 43
Train Loss 12.199415390671833
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7026 test: 0.8252 | best val epoch -- val: 0.7073 test: 0.8273

====epoch 44
Train Loss 11.349897545294159
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6883 test: 0.8193 | best val epoch -- val: 0.7073 test: 0.8273

====epoch 45
Train Loss 11.314884206683974
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6872 test: 0.8204 | best val epoch -- val: 0.7073 test: 0.8273

====epoch 46
Train Loss 11.796136054371663
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7066 test: 0.8127 | best val epoch -- val: 0.7073 test: 0.8273

====epoch 47
Train Loss 11.783313190199602
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6993 test: 0.8171 | best val epoch -- val: 0.7073 test: 0.8273

====epoch 48
Train Loss 11.519357092760236
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6890 test: 0.8044 | best val epoch -- val: 0.7073 test: 0.8273

====epoch 49
Train Loss 11.20008130553883
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6901 test: 0.8099 | best val epoch -- val: 0.7073 test: 0.8273

====epoch 50
Train Loss 11.229688118159565
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7007 test: 0.8072 | best val epoch -- val: 0.7073 test: 0.8273

WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.4.
2022-09-13 18:06:02.464 | INFO     | modules.masked_transformer_encoder:__init__:122 - number of parameters: 0.000000e+00
=========================================
batch_size = 32
d_model = 128
dataset = bace
decay = 0
device = 0
dim_feedforward = 512
eval_train = 0
filename =
gnn_JK = cat
gnn_dropout = 0.3
gnn_emb_dim = 300
gnn_num_layer = 5
gnn_residual = False
gnn_type = gin
gnn_virtual_node = False
graph_pooling = cls
input_model_file = models_graphtrans/graphtrans-sr-gcl.pth
lr = 0.0001
lr_scale = 1
max_input_len = 1000
nhead = 4
num_encoder_layers = 4
num_encoder_layers_masked = 0
num_workers = 0
pos_encoder = False
runseed = 7
seed = 12344
split = scaffold
transformer_activation = relu
transformer_dropout = 0.3
transformer_norm_input = True
transformer_prenorm = False
=========================================
bace
scaffold
Loaded GraphTrans from models_graphtrans/graphtrans-sr-gcl.pth
====epoch 1
Train Loss 26.645871622669834
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.4073 test: 0.5399 | best val epoch -- val: 0.4073 test: 0.5399

====epoch 2
Train Loss 25.444242373168862
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7099 test: 0.7007 | best val epoch -- val: 0.7099 test: 0.7007

====epoch 3
Train Loss 24.270875488013164
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7132 test: 0.7122 | best val epoch -- val: 0.7132 test: 0.7122

====epoch 4
Train Loss 23.305012836079246
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6846 test: 0.7268 | best val epoch -- val: 0.7132 test: 0.7122

====epoch 5
Train Loss 20.716646994661893
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6612 test: 0.7519 | best val epoch -- val: 0.7132 test: 0.7122

====epoch 6
Train Loss 19.177799560570147
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6802 test: 0.7992 | best val epoch -- val: 0.7132 test: 0.7122

====epoch 7
Train Loss 17.30385916399732
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6784 test: 0.7915 | best val epoch -- val: 0.7132 test: 0.7122

====epoch 8
Train Loss 17.84193334364434
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6623 test: 0.7938 | best val epoch -- val: 0.7132 test: 0.7122

====epoch 9
Train Loss 16.450205925323655
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6788 test: 0.7639 | best val epoch -- val: 0.7132 test: 0.7122

====epoch 10
Train Loss 16.30673188193539
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6729 test: 0.7660 | best val epoch -- val: 0.7132 test: 0.7122

====epoch 11
Train Loss 15.748777419607036
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6901 test: 0.7844 | best val epoch -- val: 0.7132 test: 0.7122

====epoch 12
Train Loss 15.040419122138784
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6890 test: 0.8061 | best val epoch -- val: 0.7132 test: 0.7122

====epoch 13
Train Loss 15.649184155073524
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6832 test: 0.7872 | best val epoch -- val: 0.7132 test: 0.7122

====epoch 14
Train Loss 15.517732826646156
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6751 test: 0.7656 | best val epoch -- val: 0.7132 test: 0.7122

====epoch 15
Train Loss 15.37559205275422
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6960 test: 0.7959 | best val epoch -- val: 0.7132 test: 0.7122

====epoch 16
Train Loss 15.130093888524314
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6996 test: 0.8059 | best val epoch -- val: 0.7132 test: 0.7122

====epoch 17
Train Loss 13.814072652834053
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6967 test: 0.7870 | best val epoch -- val: 0.7132 test: 0.7122

====epoch 18
Train Loss 14.190812546972506
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6806 test: 0.7962 | best val epoch -- val: 0.7132 test: 0.7122

====epoch 19
Train Loss 14.138538527710423
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6949 test: 0.8235 | best val epoch -- val: 0.7132 test: 0.7122

====epoch 20
Train Loss 13.890021979870019
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6938 test: 0.8108 | best val epoch -- val: 0.7132 test: 0.7122

====epoch 21
Train Loss 14.075880835414596
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7011 test: 0.8277 | best val epoch -- val: 0.7132 test: 0.7122

====epoch 22
Train Loss 13.57886879312139
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7062 test: 0.8094 | best val epoch -- val: 0.7132 test: 0.7122

====epoch 23
Train Loss 13.661778619648334
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6927 test: 0.7934 | best val epoch -- val: 0.7132 test: 0.7122

====epoch 24
Train Loss 12.89151700563738
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7026 test: 0.7957 | best val epoch -- val: 0.7132 test: 0.7122

====epoch 25
Train Loss 13.652421556063352
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6806 test: 0.8218 | best val epoch -- val: 0.7132 test: 0.7122

====epoch 26
Train Loss 12.688537582253522
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6945 test: 0.7960 | best val epoch -- val: 0.7132 test: 0.7122

====epoch 27
Train Loss 13.821032016862919
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7125 test: 0.8204 | best val epoch -- val: 0.7132 test: 0.7122

====epoch 28
Train Loss 13.413116096098769
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7095 test: 0.8200 | best val epoch -- val: 0.7132 test: 0.7122

====epoch 29
Train Loss 13.092471130093612
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7022 test: 0.8089 | best val epoch -- val: 0.7132 test: 0.7122

====epoch 30
Train Loss 12.776582700143937
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7037 test: 0.8249 | best val epoch -- val: 0.7132 test: 0.7122

====epoch 31
Train Loss 12.544716950167825
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7081 test: 0.8146 | best val epoch -- val: 0.7132 test: 0.7122

====epoch 32
Train Loss 12.979333758570647
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7139 test: 0.8039 | best val epoch -- val: 0.7139 test: 0.8039

====epoch 33
Train Loss 12.489343492067391
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6967 test: 0.8072 | best val epoch -- val: 0.7139 test: 0.8039

====epoch 34
Train Loss 12.111154500766846
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7004 test: 0.8169 | best val epoch -- val: 0.7139 test: 0.8039

====epoch 35
Train Loss 12.508610454545552
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6993 test: 0.8240 | best val epoch -- val: 0.7139 test: 0.8039

====epoch 36
Train Loss 11.730298778648507
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7165 test: 0.7962 | best val epoch -- val: 0.7165 test: 0.7962

====epoch 37
Train Loss 11.252471061475726
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7194 test: 0.8138 | best val epoch -- val: 0.7194 test: 0.8138

====epoch 38
Train Loss 11.778862988553255
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6901 test: 0.8042 | best val epoch -- val: 0.7194 test: 0.8138

====epoch 39
Train Loss 11.88980045096771
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7037 test: 0.8150 | best val epoch -- val: 0.7194 test: 0.8138

====epoch 40
Train Loss 11.752633876123951
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7018 test: 0.8166 | best val epoch -- val: 0.7194 test: 0.8138

====epoch 41
Train Loss 11.20199517774018
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6960 test: 0.8023 | best val epoch -- val: 0.7194 test: 0.8138

====epoch 42
Train Loss 12.366563057843198
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7117 test: 0.7799 | best val epoch -- val: 0.7194 test: 0.8138

====epoch 43
Train Loss 11.107224792703208
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7136 test: 0.7969 | best val epoch -- val: 0.7194 test: 0.8138

====epoch 44
Train Loss 11.03183788998235
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7073 test: 0.7990 | best val epoch -- val: 0.7194 test: 0.8138

====epoch 45
Train Loss 10.64471353609946
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7081 test: 0.7988 | best val epoch -- val: 0.7194 test: 0.8138

====epoch 46
Train Loss 11.15968266545106
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7147 test: 0.7979 | best val epoch -- val: 0.7194 test: 0.8138

====epoch 47
Train Loss 10.457315342235496
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7304 test: 0.8030 | best val epoch -- val: 0.7304 test: 0.8030

====epoch 48
Train Loss 10.192303920351875
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7128 test: 0.7983 | best val epoch -- val: 0.7304 test: 0.8030

====epoch 49
Train Loss 10.969010896471163
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7190 test: 0.7840 | best val epoch -- val: 0.7304 test: 0.8030

====epoch 50
Train Loss 10.901239534301686
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7231 test: 0.7974 | best val epoch -- val: 0.7304 test: 0.8030

2022-09-13 18:08:54.802 | INFO     | modules.masked_transformer_encoder:__init__:122 - number of parameters: 0.000000e+00
=========================================
batch_size = 32
d_model = 128
dataset = bace
decay = 0
device = 0
dim_feedforward = 512
eval_train = 0
filename =
gnn_JK = cat
gnn_dropout = 0.3
gnn_emb_dim = 300
gnn_num_layer = 5
gnn_residual = False
gnn_type = gin
gnn_virtual_node = False
graph_pooling = cls
input_model_file = models_graphtrans/graphtrans-sr-gcl.pth
lr = 0.0001
lr_scale = 1
max_input_len = 1000
nhead = 4
num_encoder_layers = 4
num_encoder_layers_masked = 0
num_workers = 0
pos_encoder = False
runseed = 8
seed = 12344
split = scaffold
transformer_activation = relu
transformer_dropout = 0.3
transformer_norm_input = True
transformer_prenorm = False
=========================================
bace
scaffold
Loaded GraphTrans from models_graphtrans/graphtrans-sr-gcl.pth
====epoch 1
Train Loss 26.529386056493706
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.4282 test: 0.4851 | best val epoch -- val: 0.4282 test: 0.4851

====epoch 2
Train Loss 25.451457338666597
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6352 test: 0.7072 | best val epoch -- val: 0.6352 test: 0.7072

====epoch 3
Train Loss 24.75037425365032
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.5927 test: 0.7009 | best val epoch -- val: 0.6352 test: 0.7072

====epoch 4
Train Loss 22.902663980231143
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6527 test: 0.7209 | best val epoch -- val: 0.6527 test: 0.7209

====epoch 5
Train Loss 21.092493685466902
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6359 test: 0.7194 | best val epoch -- val: 0.6527 test: 0.7209

====epoch 6
Train Loss 19.31851555746125
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6575 test: 0.7359 | best val epoch -- val: 0.6575 test: 0.7359

====epoch 7
Train Loss 18.190450444829096
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6462 test: 0.7649 | best val epoch -- val: 0.6575 test: 0.7359

====epoch 8
Train Loss 17.480538825470134
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6630 test: 0.7920 | best val epoch -- val: 0.6630 test: 0.7920

====epoch 9
Train Loss 17.07109183528679
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6645 test: 0.7825 | best val epoch -- val: 0.6645 test: 0.7825

====epoch 10
Train Loss 15.923739934193238
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6568 test: 0.7955 | best val epoch -- val: 0.6645 test: 0.7825

====epoch 11
Train Loss 15.867930404451341
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6586 test: 0.7823 | best val epoch -- val: 0.6645 test: 0.7825

====epoch 12
Train Loss 16.030914746863694
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6689 test: 0.7799 | best val epoch -- val: 0.6689 test: 0.7799

====epoch 13
Train Loss 15.719425338138475
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6842 test: 0.7931 | best val epoch -- val: 0.6842 test: 0.7931

====epoch 14
Train Loss 15.06713775768404
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6879 test: 0.7967 | best val epoch -- val: 0.6879 test: 0.7967

====epoch 15
Train Loss 15.45033711658446
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6828 test: 0.7840 | best val epoch -- val: 0.6879 test: 0.7967

====epoch 16
Train Loss 15.10192779590108
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6934 test: 0.8021 | best val epoch -- val: 0.6934 test: 0.8021

====epoch 17
Train Loss 14.815865761836227
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7150 test: 0.7981 | best val epoch -- val: 0.7150 test: 0.7981

====epoch 18
Train Loss 14.579430176525719
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6897 test: 0.7908 | best val epoch -- val: 0.7150 test: 0.7981

====epoch 19
Train Loss 14.542370032299296
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6835 test: 0.8007 | best val epoch -- val: 0.7150 test: 0.7981

====epoch 20
Train Loss 14.003233000658597
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6916 test: 0.7986 | best val epoch -- val: 0.7150 test: 0.7981

====epoch 21
Train Loss 13.34162386660165
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6960 test: 0.8080 | best val epoch -- val: 0.7150 test: 0.7981

====epoch 22
Train Loss 13.995923565380355
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7051 test: 0.8079 | best val epoch -- val: 0.7150 test: 0.7981

====epoch 23
Train Loss 13.978095225647948
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6982 test: 0.8106 | best val epoch -- val: 0.7150 test: 0.7981

====epoch 24
Train Loss 13.425994392640902
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7062 test: 0.8080 | best val epoch -- val: 0.7150 test: 0.7981

====epoch 25
Train Loss 13.174047734398547
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7062 test: 0.8127 | best val epoch -- val: 0.7150 test: 0.7981

====epoch 26
Train Loss 12.453079132014194
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7161 test: 0.8251 | best val epoch -- val: 0.7161 test: 0.8251

====epoch 27
Train Loss 13.542958906777317
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7143 test: 0.8206 | best val epoch -- val: 0.7161 test: 0.8251

====epoch 28
Train Loss 13.234969538976365
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7147 test: 0.8087 | best val epoch -- val: 0.7161 test: 0.8251

====epoch 29
Train Loss 13.040976352319847
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7147 test: 0.7926 | best val epoch -- val: 0.7161 test: 0.8251

====epoch 30
Train Loss 12.70188488244739
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7117 test: 0.8004 | best val epoch -- val: 0.7161 test: 0.8251

====epoch 31
Train Loss 12.41479295779894
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6993 test: 0.8159 | best val epoch -- val: 0.7161 test: 0.8251

====epoch 32
Train Loss 12.254935159795682
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7062 test: 0.8186 | best val epoch -- val: 0.7161 test: 0.8251

====epoch 33
Train Loss 12.49601458069122
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7132 test: 0.8181 | best val epoch -- val: 0.7161 test: 0.8251

====epoch 34
Train Loss 12.589100195926669
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7103 test: 0.8186 | best val epoch -- val: 0.7161 test: 0.8251

====epoch 35
Train Loss 12.44928106101834
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7070 test: 0.8073 | best val epoch -- val: 0.7161 test: 0.8251

====epoch 36
Train Loss 12.143491553139576
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6912 test: 0.8134 | best val epoch -- val: 0.7161 test: 0.8251

====epoch 37
Train Loss 12.213460782824646
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7026 test: 0.8099 | best val epoch -- val: 0.7161 test: 0.8251

====epoch 38
Train Loss 12.049483362993099
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6996 test: 0.8179 | best val epoch -- val: 0.7161 test: 0.8251

====epoch 39
Train Loss 11.668240455168178
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6982 test: 0.8112 | best val epoch -- val: 0.7161 test: 0.8251

====epoch 40
Train Loss 11.964231009981388
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6919 test: 0.8160 | best val epoch -- val: 0.7161 test: 0.8251

====epoch 41
Train Loss 11.969047181351447
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6930 test: 0.8082 | best val epoch -- val: 0.7161 test: 0.8251

====epoch 42
Train Loss 12.21843383608011
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7128 test: 0.8065 | best val epoch -- val: 0.7161 test: 0.8251

====epoch 43
Train Loss 11.777854378848422
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7081 test: 0.8242 | best val epoch -- val: 0.7161 test: 0.8251

====epoch 44
Train Loss 11.713992482259291
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7022 test: 0.8106 | best val epoch -- val: 0.7161 test: 0.8251

====epoch 45
Train Loss 12.04432477357028
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7059 test: 0.8146 | best val epoch -- val: 0.7161 test: 0.8251

====epoch 46
Train Loss 11.20757773317701
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7051 test: 0.8099 | best val epoch -- val: 0.7161 test: 0.8251

====epoch 47
Train Loss 10.704908482556206
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6930 test: 0.8082 | best val epoch -- val: 0.7161 test: 0.8251

====epoch 48
Train Loss 10.817942590267412
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6996 test: 0.8089 | best val epoch -- val: 0.7161 test: 0.8251

====epoch 49
Train Loss 10.725996290350269
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7018 test: 0.8026 | best val epoch -- val: 0.7161 test: 0.8251

====epoch 50
Train Loss 10.858752154079472
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6989 test: 0.8138 | best val epoch -- val: 0.7161 test: 0.8251

2022-09-13 18:15:29.766 | INFO     | modules.masked_transformer_encoder:__init__:122 - number of parameters: 0.000000e+00
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.4.
=========================================
batch_size = 32
d_model = 128
dataset = bace
decay = 0
device = 0
dim_feedforward = 512
eval_train = 0
filename =
gnn_JK = cat
gnn_dropout = 0.3
gnn_emb_dim = 300
gnn_num_layer = 5
gnn_residual = False
gnn_type = gin
gnn_virtual_node = False
graph_pooling = cls
input_model_file = models_graphtrans/graphtrans-sr-gcl.pth
lr = 0.0001
lr_scale = 1
max_input_len = 1000
nhead = 4
num_encoder_layers = 4
num_encoder_layers_masked = 0
num_workers = 0
pos_encoder = False
runseed = 9
seed = 12344
split = scaffold
transformer_activation = relu
transformer_dropout = 0.3
transformer_norm_input = True
transformer_prenorm = False
=========================================
bace
scaffold
Loaded GraphTrans from models_graphtrans/graphtrans-sr-gcl.pth
====epoch 1
Train Loss 26.1860204376771
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.2769 test: 0.5013 | best val epoch -- val: 0.2769 test: 0.5013

====epoch 2
Train Loss 25.02124496841491
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.4502 test: 0.6413 | best val epoch -- val: 0.4502 test: 0.6413

====epoch 3
Train Loss 23.473232291922873
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.5967 test: 0.7359 | best val epoch -- val: 0.5967 test: 0.7359

====epoch 4
Train Loss 21.637788458619617
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6311 test: 0.7489 | best val epoch -- val: 0.6311 test: 0.7489

====epoch 5
Train Loss 19.900535948192946
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6542 test: 0.7818 | best val epoch -- val: 0.6542 test: 0.7818

====epoch 6
Train Loss 18.771559420015443
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6495 test: 0.7906 | best val epoch -- val: 0.6542 test: 0.7818

====epoch 7
Train Loss 17.71530386150102
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6641 test: 0.8152 | best val epoch -- val: 0.6641 test: 0.8152

====epoch 8
Train Loss 16.73990889638301
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6410 test: 0.8053 | best val epoch -- val: 0.6641 test: 0.8152

====epoch 9
Train Loss 16.498670737501236
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6725 test: 0.8047 | best val epoch -- val: 0.6725 test: 0.8047

====epoch 10
Train Loss 15.918937557189627
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6788 test: 0.8313 | best val epoch -- val: 0.6788 test: 0.8313

====epoch 11
Train Loss 15.282524456731526
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7070 test: 0.8268 | best val epoch -- val: 0.7070 test: 0.8268

====epoch 12
Train Loss 15.886787110303382
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6908 test: 0.8181 | best val epoch -- val: 0.7070 test: 0.8268

====epoch 13
Train Loss 14.623079192230133
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6575 test: 0.8080 | best val epoch -- val: 0.7070 test: 0.8268

====epoch 14
Train Loss 15.530297480244226
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6828 test: 0.8202 | best val epoch -- val: 0.7070 test: 0.8268

====epoch 15
Train Loss 14.500072540830082
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6751 test: 0.8230 | best val epoch -- val: 0.7070 test: 0.8268

====epoch 16
Train Loss 14.401767150501762
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6612 test: 0.8075 | best val epoch -- val: 0.7070 test: 0.8268

====epoch 17
Train Loss 15.427518676506635
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6875 test: 0.8282 | best val epoch -- val: 0.7070 test: 0.8268

====epoch 18
Train Loss 14.287982216009759
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6821 test: 0.8099 | best val epoch -- val: 0.7070 test: 0.8268

====epoch 19
Train Loss 14.07027934743956
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6806 test: 0.8115 | best val epoch -- val: 0.7070 test: 0.8268

====epoch 20
Train Loss 14.098255264552744
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6802 test: 0.8176 | best val epoch -- val: 0.7070 test: 0.8268

====epoch 21
Train Loss 13.736210958686176
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7150 test: 0.8093 | best val epoch -- val: 0.7150 test: 0.8093

====epoch 22
Train Loss 14.322833093067086
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7092 test: 0.8103 | best val epoch -- val: 0.7150 test: 0.8093

====epoch 23
Train Loss 13.225227291561737
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7066 test: 0.8160 | best val epoch -- val: 0.7150 test: 0.8093

====epoch 24
Train Loss 13.38328926838332
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7103 test: 0.8139 | best val epoch -- val: 0.7150 test: 0.8093

====epoch 25
Train Loss 13.939104499533693
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7147 test: 0.8246 | best val epoch -- val: 0.7150 test: 0.8093

====epoch 26
Train Loss 13.504938660894029
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7044 test: 0.8167 | best val epoch -- val: 0.7150 test: 0.8093

====epoch 27
Train Loss 13.482263391209315
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6923 test: 0.8360 | best val epoch -- val: 0.7150 test: 0.8093

====epoch 28
Train Loss 13.608553959486779
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7040 test: 0.8258 | best val epoch -- val: 0.7150 test: 0.8093

====epoch 29
Train Loss 12.215301525718093
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6982 test: 0.8192 | best val epoch -- val: 0.7150 test: 0.8093

====epoch 30
Train Loss 12.475199980199065
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6978 test: 0.8166 | best val epoch -- val: 0.7150 test: 0.8093

====epoch 31
Train Loss 12.997178115695478
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6978 test: 0.8359 | best val epoch -- val: 0.7150 test: 0.8093

====epoch 32
Train Loss 12.08131862839176
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6908 test: 0.8306 | best val epoch -- val: 0.7150 test: 0.8093

====epoch 33
Train Loss 12.312832783806918
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6919 test: 0.8332 | best val epoch -- val: 0.7150 test: 0.8093

====epoch 34
Train Loss 12.594142729731178
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6890 test: 0.8371 | best val epoch -- val: 0.7150 test: 0.8093

====epoch 35
Train Loss 12.047666503788939
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6875 test: 0.8265 | best val epoch -- val: 0.7150 test: 0.8093

====epoch 36
Train Loss 11.405672732686005
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6711 test: 0.8315 | best val epoch -- val: 0.7150 test: 0.8093

====epoch 37
Train Loss 12.466176057934673
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6879 test: 0.8072 | best val epoch -- val: 0.7150 test: 0.8093

====epoch 38
Train Loss 11.932450900969476
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7110 test: 0.8065 | best val epoch -- val: 0.7150 test: 0.8093

====epoch 39
Train Loss 11.256665237756001
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6952 test: 0.8059 | best val epoch -- val: 0.7150 test: 0.8093

====epoch 40
Train Loss 11.204516737382052
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7077 test: 0.8134 | best val epoch -- val: 0.7150 test: 0.8093

====epoch 41
Train Loss 11.04408625738557
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6875 test: 0.8129 | best val epoch -- val: 0.7150 test: 0.8093

====epoch 42
Train Loss 11.667941031115681
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7073 test: 0.8047 | best val epoch -- val: 0.7150 test: 0.8093

====epoch 43
Train Loss 12.035143856727254
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6952 test: 0.8167 | best val epoch -- val: 0.7150 test: 0.8093

====epoch 44
Train Loss 10.654598934060596
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7040 test: 0.8051 | best val epoch -- val: 0.7150 test: 0.8093

====epoch 45
Train Loss 10.92133038253649
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7066 test: 0.8033 | best val epoch -- val: 0.7150 test: 0.8093

====epoch 46
Train Loss 11.374985940044098
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7125 test: 0.8032 | best val epoch -- val: 0.7150 test: 0.8093

====epoch 47
Train Loss 11.661570269141102
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7051 test: 0.8054 | best val epoch -- val: 0.7150 test: 0.8093

====epoch 48
Train Loss 10.109880678749787
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7059 test: 0.7936 | best val epoch -- val: 0.7150 test: 0.8093

====epoch 49
Train Loss 10.340619372287822
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6989 test: 0.8094 | best val epoch -- val: 0.7150 test: 0.8093

====epoch 50
Train Loss 10.331520059080452
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6985 test: 0.8044 | best val epoch -- val: 0.7150 test: 0.8093

[18:18:17] WARNING: not removing hydrogen atom without neighbors
[18:18:17] WARNING: not removing hydrogen atom without neighbors
[18:18:17] WARNING: not removing hydrogen atom without neighbors
[18:18:17] WARNING: not removing hydrogen atom without neighbors
[18:18:17] WARNING: not removing hydrogen atom without neighbors
[18:18:17] WARNING: not removing hydrogen atom without neighbors
[18:18:17] WARNING: not removing hydrogen atom without neighbors
[18:18:17] WARNING: not removing hydrogen atom without neighbors
[18:18:17] WARNING: not removing hydrogen atom without neighbors
[18:18:17] WARNING: not removing hydrogen atom without neighbors
[18:18:17] WARNING: not removing hydrogen atom without neighbors
[18:18:17] WARNING: not removing hydrogen atom without neighbors
[18:18:17] WARNING: not removing hydrogen atom without neighbors
[18:18:17] WARNING: not removing hydrogen atom without neighbors
[18:18:17] WARNING: not removing hydrogen atom without neighbors
[18:18:17] Conflicting single bond directions around double bond at index 1.
[18:18:17]   BondStereo set to STEREONONE and single bond directions set to NONE.
[18:18:17] WARNING: not removing hydrogen atom without neighbors
[18:18:17] WARNING: not removing hydrogen atom without neighbors
[18:18:17] WARNING: not removing hydrogen atom without neighbors
[18:18:17] WARNING: not removing hydrogen atom without neighbors
[18:18:17] WARNING: not removing hydrogen atom without neighbors
[18:18:17] WARNING: not removing hydrogen atom without neighbors
[18:18:17] WARNING: not removing hydrogen atom without neighbors
[18:18:17] WARNING: not removing hydrogen atom without neighbors
[18:18:17] WARNING: not removing hydrogen atom without neighbors
[18:18:17] WARNING: not removing hydrogen atom without neighbors
[18:18:17] WARNING: not removing hydrogen atom without neighbors
[18:18:17] WARNING: not removing hydrogen atom without neighbors
[18:18:18] WARNING: not removing hydrogen atom without neighbors
[18:18:18] WARNING: not removing hydrogen atom without neighbors
[18:18:18] WARNING: not removing hydrogen atom without neighbors
[18:18:18] WARNING: not removing hydrogen atom without neighbors
[18:18:18] WARNING: not removing hydrogen atom without neighbors
[18:18:18] WARNING: not removing hydrogen atom without neighbors
[18:18:18] WARNING: not removing hydrogen atom without neighbors
[18:18:18] WARNING: not removing hydrogen atom without neighbors
[18:18:18] WARNING: not removing hydrogen atom without neighbors
[18:18:18] WARNING: not removing hydrogen atom without neighbors
[18:18:18] WARNING: not removing hydrogen atom without neighbors
[18:18:18] WARNING: not removing hydrogen atom without neighbors
[18:18:18] WARNING: not removing hydrogen atom without neighbors
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.4.
2022-09-13 18:18:18.302 | INFO     | modules.masked_transformer_encoder:__init__:122 - number of parameters: 0.000000e+00
=========================================
batch_size = 32
d_model = 128
dataset = bbbp
decay = 0
device = 0
dim_feedforward = 512
eval_train = 0
filename =
gnn_JK = cat
gnn_dropout = 0.3
gnn_emb_dim = 300
gnn_num_layer = 5
gnn_residual = False
gnn_type = gin
gnn_virtual_node = False
graph_pooling = cls
input_model_file = models_graphtrans/graphtrans-sr-gcl.pth
lr = 0.0001
lr_scale = 1
max_input_len = 1000
nhead = 4
num_encoder_layers = 4
num_encoder_layers_masked = 0
num_workers = 0
pos_encoder = False
runseed = 0
seed = 12344
split = scaffold
transformer_activation = relu
transformer_dropout = 0.3
transformer_norm_input = True
transformer_prenorm = False
=========================================
bbbp
scaffold
Loaded GraphTrans from models_graphtrans/graphtrans-sr-gcl.pth
====epoch 1
Train Loss 24.687868408272326
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.5398 test: 0.4931 | best val epoch -- val: 0.5398 test: 0.4931

====epoch 2
Train Loss 20.99302936758482
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8832 test: 0.5998 | best val epoch -- val: 0.8832 test: 0.5998

====epoch 3
Train Loss 18.991890312063926
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9023 test: 0.6270 | best val epoch -- val: 0.9023 test: 0.6270

====epoch 4
Train Loss 16.736638698856275
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9000 test: 0.6307 | best val epoch -- val: 0.9023 test: 0.6270

====epoch 5
Train Loss 14.867799825462582
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9020 test: 0.6628 | best val epoch -- val: 0.9023 test: 0.6270

====epoch 6
Train Loss 13.989801426943448
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9014 test: 0.6779 | best val epoch -- val: 0.9023 test: 0.6270

====epoch 7
Train Loss 12.866274035631662
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9007 test: 0.6897 | best val epoch -- val: 0.9023 test: 0.6270

====epoch 8
Train Loss 11.88460477218923
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9000 test: 0.6981 | best val epoch -- val: 0.9023 test: 0.6270

====epoch 9
Train Loss 11.23226899642378
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9142 test: 0.7103 | best val epoch -- val: 0.9142 test: 0.7103

====epoch 10
Train Loss 10.90515882849234
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9148 test: 0.7098 | best val epoch -- val: 0.9148 test: 0.7098

====epoch 11
Train Loss 10.531667008164847
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9292 test: 0.7196 | best val epoch -- val: 0.9292 test: 0.7196

====epoch 12
Train Loss 9.929665432976892
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9145 test: 0.7173 | best val epoch -- val: 0.9292 test: 0.7196

====epoch 13
Train Loss 10.265518304187841
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8995 test: 0.7092 | best val epoch -- val: 0.9292 test: 0.7196

====epoch 14
Train Loss 10.150563806001152
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9028 test: 0.7188 | best val epoch -- val: 0.9292 test: 0.7196

====epoch 15
Train Loss 9.639024312509232
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9205 test: 0.7206 | best val epoch -- val: 0.9292 test: 0.7196

====epoch 16
Train Loss 9.293929555119863
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9165 test: 0.7235 | best val epoch -- val: 0.9292 test: 0.7196

====epoch 17
Train Loss 9.241264549481121
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9077 test: 0.7173 | best val epoch -- val: 0.9292 test: 0.7196

====epoch 18
Train Loss 8.201099917276796
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9175 test: 0.7233 | best val epoch -- val: 0.9292 test: 0.7196

====epoch 19
Train Loss 8.75998468164144
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9140 test: 0.7211 | best val epoch -- val: 0.9292 test: 0.7196

====epoch 20
Train Loss 8.483623874188092
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9139 test: 0.7156 | best val epoch -- val: 0.9292 test: 0.7196

====epoch 21
Train Loss 8.404833865638334
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9148 test: 0.7160 | best val epoch -- val: 0.9292 test: 0.7196

====epoch 22
Train Loss 8.637155242311879
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9077 test: 0.7138 | best val epoch -- val: 0.9292 test: 0.7196

====epoch 23
Train Loss 8.780478586858658
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8951 test: 0.7215 | best val epoch -- val: 0.9292 test: 0.7196

====epoch 24
Train Loss 7.794872461867064
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9011 test: 0.7241 | best val epoch -- val: 0.9292 test: 0.7196

====epoch 25
Train Loss 8.52070938801925
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9158 test: 0.7235 | best val epoch -- val: 0.9292 test: 0.7196

====epoch 26
Train Loss 8.279442710469016
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8915 test: 0.7187 | best val epoch -- val: 0.9292 test: 0.7196

====epoch 27
Train Loss 8.203645437400434
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8971 test: 0.7177 | best val epoch -- val: 0.9292 test: 0.7196

====epoch 28
Train Loss 7.558312925507954
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9212 test: 0.7230 | best val epoch -- val: 0.9292 test: 0.7196

====epoch 29
Train Loss 7.503031484490636
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8897 test: 0.7084 | best val epoch -- val: 0.9292 test: 0.7196

====epoch 30
Train Loss 7.457769816339332
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9002 test: 0.7087 | best val epoch -- val: 0.9292 test: 0.7196

====epoch 31
Train Loss 7.053194188281037
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8870 test: 0.7079 | best val epoch -- val: 0.9292 test: 0.7196

====epoch 32
Train Loss 6.729383656515556
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8976 test: 0.7189 | best val epoch -- val: 0.9292 test: 0.7196

====epoch 33
Train Loss 7.246859434601955
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8941 test: 0.7141 | best val epoch -- val: 0.9292 test: 0.7196

====epoch 34
Train Loss 6.64244022764373
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9008 test: 0.7196 | best val epoch -- val: 0.9292 test: 0.7196

====epoch 35
Train Loss 6.333488693303623
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8867 test: 0.7041 | best val epoch -- val: 0.9292 test: 0.7196

====epoch 36
Train Loss 6.5566251038599574
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9030 test: 0.7175 | best val epoch -- val: 0.9292 test: 0.7196

====epoch 37
Train Loss 6.316146876460176
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8963 test: 0.7083 | best val epoch -- val: 0.9292 test: 0.7196

====epoch 38
Train Loss 6.212929061047354
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9045 test: 0.7173 | best val epoch -- val: 0.9292 test: 0.7196

====epoch 39
Train Loss 6.126502736659419
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8958 test: 0.7031 | best val epoch -- val: 0.9292 test: 0.7196

====epoch 40
Train Loss 5.974376699734661
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8770 test: 0.7004 | best val epoch -- val: 0.9292 test: 0.7196

====epoch 41
Train Loss 5.85318189445748
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8762 test: 0.7045 | best val epoch -- val: 0.9292 test: 0.7196

====epoch 42
Train Loss 5.337225897220204
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8941 test: 0.7136 | best val epoch -- val: 0.9292 test: 0.7196

====epoch 43
Train Loss 6.189952219073778
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9010 test: 0.7156 | best val epoch -- val: 0.9292 test: 0.7196

====epoch 44
Train Loss 5.263207537104775
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8893 test: 0.7136 | best val epoch -- val: 0.9292 test: 0.7196

====epoch 45
Train Loss 6.093712519543646
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8996 test: 0.7188 | best val epoch -- val: 0.9292 test: 0.7196

====epoch 46
Train Loss 5.983946363971324
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9021 test: 0.7230 | best val epoch -- val: 0.9292 test: 0.7196

====epoch 47
Train Loss 6.183627216180488
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9058 test: 0.7195 | best val epoch -- val: 0.9292 test: 0.7196

====epoch 48
Train Loss 5.608368836156768
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8940 test: 0.7133 | best val epoch -- val: 0.9292 test: 0.7196

====epoch 49
Train Loss 5.431553084770298
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8917 test: 0.7156 | best val epoch -- val: 0.9292 test: 0.7196

====epoch 50
Train Loss 4.936033133011771
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8745 test: 0.7171 | best val epoch -- val: 0.9292 test: 0.7196

====epoch 51
Train Loss 5.519887345500045
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8970 test: 0.7208 | best val epoch -- val: 0.9292 test: 0.7196

====epoch 52
Train Loss 5.210505217096279
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8807 test: 0.7211 | best val epoch -- val: 0.9292 test: 0.7196

====epoch 53
Train Loss 5.686167955200843
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8999 test: 0.7150 | best val epoch -- val: 0.9292 test: 0.7196

====epoch 54
Train Loss 4.685510183855403
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8983 test: 0.7169 | best val epoch -- val: 0.9292 test: 0.7196

====epoch 55
Train Loss 4.6598591061518935
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9021 test: 0.7194 | best val epoch -- val: 0.9292 test: 0.7196

====epoch 56
Train Loss 5.050595206857409
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9032 test: 0.7116 | best val epoch -- val: 0.9292 test: 0.7196

====epoch 57
Train Loss 4.896498238656544
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9080 test: 0.7104 | best val epoch -- val: 0.9292 test: 0.7196

====epoch 58
Train Loss 4.872633990055417
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8898 test: 0.7070 | best val epoch -- val: 0.9292 test: 0.7196

====epoch 59
Train Loss 5.0476861085277385
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8826 test: 0.7094 | best val epoch -- val: 0.9292 test: 0.7196

====epoch 60
Train Loss 4.446176215597724
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8981 test: 0.7078 | best val epoch -- val: 0.9292 test: 0.7196

====epoch 61
Train Loss 4.739332006752088
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8865 test: 0.7169 | best val epoch -- val: 0.9292 test: 0.7196

====epoch 62
Train Loss 4.199644767547811
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8937 test: 0.7195 | best val epoch -- val: 0.9292 test: 0.7196

====epoch 63
Train Loss 3.5166267705783607
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8767 test: 0.7126 | best val epoch -- val: 0.9292 test: 0.7196

====epoch 64
Train Loss 4.511296120182053
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8874 test: 0.7099 | best val epoch -- val: 0.9292 test: 0.7196

====epoch 65
Train Loss 4.764258506786471
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9001 test: 0.7192 | best val epoch -- val: 0.9292 test: 0.7196

====epoch 66
Train Loss 4.335074441260181
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8972 test: 0.7073 | best val epoch -- val: 0.9292 test: 0.7196

====epoch 67
Train Loss 4.6772418973849845
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9047 test: 0.7137 | best val epoch -- val: 0.9292 test: 0.7196

====epoch 68
Train Loss 4.670880854485291
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9044 test: 0.7176 | best val epoch -- val: 0.9292 test: 0.7196

====epoch 69
Train Loss 4.005906395334515
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8880 test: 0.7129 | best val epoch -- val: 0.9292 test: 0.7196

====epoch 70
Train Loss 4.181141043794595
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8963 test: 0.7044 | best val epoch -- val: 0.9292 test: 0.7196

====epoch 71
Train Loss 3.706724499749732
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8858 test: 0.6981 | best val epoch -- val: 0.9292 test: 0.7196

====epoch 72
Train Loss 4.845920006448382
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9003 test: 0.7075 | best val epoch -- val: 0.9292 test: 0.7196

====epoch 73
Train Loss 4.263609423167915
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8860 test: 0.6956 | best val epoch -- val: 0.9292 test: 0.7196

====epoch 74
Train Loss 3.393670606868707
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9039 test: 0.6949 | best val epoch -- val: 0.9292 test: 0.7196

====epoch 75
Train Loss 4.1586372642850105
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9072 test: 0.6977 | best val epoch -- val: 0.9292 test: 0.7196

====epoch 76
Train Loss 3.4432152109811205
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9111 test: 0.6997 | best val epoch -- val: 0.9292 test: 0.7196

====epoch 77
Train Loss 3.6052914007671903
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9080 test: 0.7095 | best val epoch -- val: 0.9292 test: 0.7196

====epoch 78
Train Loss 3.8168343737964627
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8851 test: 0.7086 | best val epoch -- val: 0.9292 test: 0.7196

====epoch 79
Train Loss 3.332494436513887
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9061 test: 0.6988 | best val epoch -- val: 0.9292 test: 0.7196

====epoch 80
Train Loss 4.047434997387177
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8976 test: 0.7065 | best val epoch -- val: 0.9292 test: 0.7196

====epoch 81
Train Loss 3.7240093369605862
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9105 test: 0.7018 | best val epoch -- val: 0.9292 test: 0.7196

====epoch 82
Train Loss 3.5642793518132985
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8851 test: 0.7005 | best val epoch -- val: 0.9292 test: 0.7196

====epoch 83
Train Loss 3.5602458495415408
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8960 test: 0.6927 | best val epoch -- val: 0.9292 test: 0.7196

====epoch 84
Train Loss 3.1903068838450324
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8947 test: 0.7079 | best val epoch -- val: 0.9292 test: 0.7196

====epoch 85
Train Loss 3.23726215969662
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9096 test: 0.7119 | best val epoch -- val: 0.9292 test: 0.7196

====epoch 86
Train Loss 3.1758315493711122
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8887 test: 0.7052 | best val epoch -- val: 0.9292 test: 0.7196

====epoch 87
Train Loss 3.432987324724737
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8969 test: 0.6980 | best val epoch -- val: 0.9292 test: 0.7196

====epoch 88
Train Loss 3.2347305633267394
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8969 test: 0.6910 | best val epoch -- val: 0.9292 test: 0.7196

====epoch 89
Train Loss 3.3489225755085084
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8713 test: 0.6980 | best val epoch -- val: 0.9292 test: 0.7196

====epoch 90
Train Loss 3.2515469483590973
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8677 test: 0.6905 | best val epoch -- val: 0.9292 test: 0.7196

====epoch 91
Train Loss 2.8288085471267523
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8567 test: 0.6925 | best val epoch -- val: 0.9292 test: 0.7196

====epoch 92
Train Loss 3.07693275286675
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8596 test: 0.6823 | best val epoch -- val: 0.9292 test: 0.7196

====epoch 93
Train Loss 3.0570390040032795
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8942 test: 0.7022 | best val epoch -- val: 0.9292 test: 0.7196

====epoch 94
Train Loss 3.156367206616435
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8712 test: 0.6780 | best val epoch -- val: 0.9292 test: 0.7196

====epoch 95
Train Loss 3.2735985453063194
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8768 test: 0.6810 | best val epoch -- val: 0.9292 test: 0.7196

====epoch 96
Train Loss 3.3111634828747913
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8584 test: 0.6620 | best val epoch -- val: 0.9292 test: 0.7196

====epoch 97
Train Loss 3.115669176395183
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8771 test: 0.6701 | best val epoch -- val: 0.9292 test: 0.7196

====epoch 98
Train Loss 3.072175154751748
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8682 test: 0.6611 | best val epoch -- val: 0.9292 test: 0.7196

====epoch 99
Train Loss 2.484228021290535
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8898 test: 0.6670 | best val epoch -- val: 0.9292 test: 0.7196

====epoch 100
Train Loss 2.839034332411683
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8878 test: 0.6746 | best val epoch -- val: 0.9292 test: 0.7196

[18:21:53] WARNING: not removing hydrogen atom without neighbors
[18:21:53] WARNING: not removing hydrogen atom without neighbors
[18:21:53] WARNING: not removing hydrogen atom without neighbors
[18:21:53] WARNING: not removing hydrogen atom without neighbors
[18:21:53] WARNING: not removing hydrogen atom without neighbors
[18:21:53] WARNING: not removing hydrogen atom without neighbors
[18:21:53] WARNING: not removing hydrogen atom without neighbors
[18:21:53] WARNING: not removing hydrogen atom without neighbors
[18:21:53] WARNING: not removing hydrogen atom without neighbors
[18:21:53] WARNING: not removing hydrogen atom without neighbors
[18:21:53] WARNING: not removing hydrogen atom without neighbors
[18:21:53] WARNING: not removing hydrogen atom without neighbors
[18:21:53] WARNING: not removing hydrogen atom without neighbors
[18:21:53] WARNING: not removing hydrogen atom without neighbors
[18:21:53] WARNING: not removing hydrogen atom without neighbors
[18:21:53] Conflicting single bond directions around double bond at index 1.
[18:21:53]   BondStereo set to STEREONONE and single bond directions set to NONE.
[18:21:53] WARNING: not removing hydrogen atom without neighbors
[18:21:53] WARNING: not removing hydrogen atom without neighbors
[18:21:53] WARNING: not removing hydrogen atom without neighbors
[18:21:53] WARNING: not removing hydrogen atom without neighbors
[18:21:53] WARNING: not removing hydrogen atom without neighbors
[18:21:53] WARNING: not removing hydrogen atom without neighbors
[18:21:53] WARNING: not removing hydrogen atom without neighbors
[18:21:53] WARNING: not removing hydrogen atom without neighbors
[18:21:53] WARNING: not removing hydrogen atom without neighbors
[18:21:53] WARNING: not removing hydrogen atom without neighbors
[18:21:53] WARNING: not removing hydrogen atom without neighbors
[18:21:53] WARNING: not removing hydrogen atom without neighbors
[18:21:53] WARNING: not removing hydrogen atom without neighbors
[18:21:53] WARNING: not removing hydrogen atom without neighbors
[18:21:53] WARNING: not removing hydrogen atom without neighbors
[18:21:53] WARNING: not removing hydrogen atom without neighbors
[18:21:53] WARNING: not removing hydrogen atom without neighbors
[18:21:53] WARNING: not removing hydrogen atom without neighbors
[18:21:53] WARNING: not removing hydrogen atom without neighbors
[18:21:53] WARNING: not removing hydrogen atom without neighbors
[18:21:53] WARNING: not removing hydrogen atom without neighbors
[18:21:53] WARNING: not removing hydrogen atom without neighbors
[18:21:53] WARNING: not removing hydrogen atom without neighbors
[18:21:53] WARNING: not removing hydrogen atom without neighbors
[18:21:53] WARNING: not removing hydrogen atom without neighbors
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.4.
2022-09-13 18:21:54.033 | INFO     | modules.masked_transformer_encoder:__init__:122 - number of parameters: 0.000000e+00
=========================================
batch_size = 32
d_model = 128
dataset = bbbp
decay = 0
device = 0
dim_feedforward = 512
eval_train = 0
filename =
gnn_JK = cat
gnn_dropout = 0.3
gnn_emb_dim = 300
gnn_num_layer = 5
gnn_residual = False
gnn_type = gin
gnn_virtual_node = False
graph_pooling = cls
input_model_file = models_graphtrans/graphtrans-sr-gcl.pth
lr = 0.0001
lr_scale = 1
max_input_len = 1000
nhead = 4
num_encoder_layers = 4
num_encoder_layers_masked = 0
num_workers = 0
pos_encoder = False
runseed = 1
seed = 12344
split = scaffold
transformer_activation = relu
transformer_dropout = 0.3
transformer_norm_input = True
transformer_prenorm = False
=========================================
bbbp
scaffold
Loaded GraphTrans from models_graphtrans/graphtrans-sr-gcl.pth
====epoch 1
Train Loss 25.435869940885805
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6456 test: 0.5156 | best val epoch -- val: 0.6456 test: 0.5156

====epoch 2
Train Loss 20.963046886516718
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8791 test: 0.6101 | best val epoch -- val: 0.8791 test: 0.6101

====epoch 3
Train Loss 18.510081712531054
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9178 test: 0.6344 | best val epoch -- val: 0.9178 test: 0.6344

====epoch 4
Train Loss 16.160364679517603
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9067 test: 0.6354 | best val epoch -- val: 0.9178 test: 0.6344

====epoch 5
Train Loss 14.307750960911644
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9212 test: 0.6661 | best val epoch -- val: 0.9212 test: 0.6661

====epoch 6
Train Loss 13.248270163400749
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9294 test: 0.6743 | best val epoch -- val: 0.9294 test: 0.6743

====epoch 7
Train Loss 12.939006971246984
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9289 test: 0.6916 | best val epoch -- val: 0.9294 test: 0.6743

====epoch 8
Train Loss 11.613254626122147
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9269 test: 0.7043 | best val epoch -- val: 0.9294 test: 0.6743

====epoch 9
Train Loss 11.593787317221246
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9248 test: 0.7104 | best val epoch -- val: 0.9294 test: 0.6743

====epoch 10
Train Loss 11.153712600337514
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9319 test: 0.7291 | best val epoch -- val: 0.9319 test: 0.7291

====epoch 11
Train Loss 11.016472398476834
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9287 test: 0.7309 | best val epoch -- val: 0.9319 test: 0.7291

====epoch 12
Train Loss 10.276667789550586
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9361 test: 0.7324 | best val epoch -- val: 0.9361 test: 0.7324

====epoch 13
Train Loss 9.653917606986978
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9405 test: 0.7275 | best val epoch -- val: 0.9405 test: 0.7275

====epoch 14
Train Loss 9.839040814430405
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9284 test: 0.7315 | best val epoch -- val: 0.9405 test: 0.7275

====epoch 15
Train Loss 9.510760184461839
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9352 test: 0.7238 | best val epoch -- val: 0.9405 test: 0.7275

====epoch 16
Train Loss 8.93426637620575
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9327 test: 0.7261 | best val epoch -- val: 0.9405 test: 0.7275

====epoch 17
Train Loss 9.212462234204315
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9311 test: 0.7258 | best val epoch -- val: 0.9405 test: 0.7275

====epoch 18
Train Loss 8.885657597088214
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9354 test: 0.7273 | best val epoch -- val: 0.9405 test: 0.7275

====epoch 19
Train Loss 9.113489153453635
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9289 test: 0.7259 | best val epoch -- val: 0.9405 test: 0.7275

====epoch 20
Train Loss 8.090111728400544
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9229 test: 0.7284 | best val epoch -- val: 0.9405 test: 0.7275

====epoch 21
Train Loss 8.41596437446083
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9232 test: 0.7268 | best val epoch -- val: 0.9405 test: 0.7275

====epoch 22
Train Loss 8.199425353140716
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9271 test: 0.7267 | best val epoch -- val: 0.9405 test: 0.7275

====epoch 23
Train Loss 8.288988937662726
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9282 test: 0.7386 | best val epoch -- val: 0.9405 test: 0.7275

====epoch 24
Train Loss 7.606933055494388
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9299 test: 0.7364 | best val epoch -- val: 0.9405 test: 0.7275

====epoch 25
Train Loss 8.252817239340974
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9313 test: 0.7365 | best val epoch -- val: 0.9405 test: 0.7275

====epoch 26
Train Loss 7.062383490539798
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9244 test: 0.7252 | best val epoch -- val: 0.9405 test: 0.7275

====epoch 27
Train Loss 7.836750292439339
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9227 test: 0.7253 | best val epoch -- val: 0.9405 test: 0.7275

====epoch 28
Train Loss 6.741205694070225
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9207 test: 0.7122 | best val epoch -- val: 0.9405 test: 0.7275

====epoch 29
Train Loss 7.0675438384653315
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9374 test: 0.7242 | best val epoch -- val: 0.9405 test: 0.7275

====epoch 30
Train Loss 7.516128244338344
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9318 test: 0.7163 | best val epoch -- val: 0.9405 test: 0.7275

====epoch 31
Train Loss 7.3249531441434
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9160 test: 0.7109 | best val epoch -- val: 0.9405 test: 0.7275

====epoch 32
Train Loss 6.712348417310948
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9246 test: 0.7108 | best val epoch -- val: 0.9405 test: 0.7275

====epoch 33
Train Loss 6.886954827835549
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9171 test: 0.7068 | best val epoch -- val: 0.9405 test: 0.7275

====epoch 34
Train Loss 6.649252809917809
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9274 test: 0.7092 | best val epoch -- val: 0.9405 test: 0.7275

====epoch 35
Train Loss 6.235499877624958
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9242 test: 0.7060 | best val epoch -- val: 0.9405 test: 0.7275

====epoch 36
Train Loss 6.393960717523823
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9285 test: 0.7143 | best val epoch -- val: 0.9405 test: 0.7275

====epoch 37
Train Loss 6.429648662100184
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9257 test: 0.7006 | best val epoch -- val: 0.9405 test: 0.7275

====epoch 38
Train Loss 6.083047438049912
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9265 test: 0.6929 | best val epoch -- val: 0.9405 test: 0.7275

====epoch 39
Train Loss 6.142007242041029
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9282 test: 0.6966 | best val epoch -- val: 0.9405 test: 0.7275

====epoch 40
Train Loss 5.742350692294886
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9233 test: 0.6986 | best val epoch -- val: 0.9405 test: 0.7275

====epoch 41
Train Loss 6.9525745437540865
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9198 test: 0.6827 | best val epoch -- val: 0.9405 test: 0.7275

====epoch 42
Train Loss 6.005575870226073
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9189 test: 0.6892 | best val epoch -- val: 0.9405 test: 0.7275

====epoch 43
Train Loss 5.676414666082649
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9200 test: 0.6950 | best val epoch -- val: 0.9405 test: 0.7275

====epoch 44
Train Loss 5.661012705475985
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9294 test: 0.7123 | best val epoch -- val: 0.9405 test: 0.7275

====epoch 45
Train Loss 5.341607886026828
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9140 test: 0.6943 | best val epoch -- val: 0.9405 test: 0.7275

====epoch 46
Train Loss 5.63615069514438
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9142 test: 0.6945 | best val epoch -- val: 0.9405 test: 0.7275

====epoch 47
Train Loss 5.757244188513791
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9215 test: 0.7148 | best val epoch -- val: 0.9405 test: 0.7275

====epoch 48
Train Loss 5.347582729105268
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9245 test: 0.7034 | best val epoch -- val: 0.9405 test: 0.7275

====epoch 49
Train Loss 5.564415425864393
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9240 test: 0.6961 | best val epoch -- val: 0.9405 test: 0.7275

====epoch 50
Train Loss 5.270635750067545
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9255 test: 0.7125 | best val epoch -- val: 0.9405 test: 0.7275

====epoch 51
Train Loss 5.328877043653251
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9186 test: 0.7065 | best val epoch -- val: 0.9405 test: 0.7275

====epoch 52
Train Loss 5.773879062092068
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9201 test: 0.6949 | best val epoch -- val: 0.9405 test: 0.7275

====epoch 53
Train Loss 5.833646150725729
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9227 test: 0.6943 | best val epoch -- val: 0.9405 test: 0.7275

====epoch 54
Train Loss 5.386139339495768
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9278 test: 0.7100 | best val epoch -- val: 0.9405 test: 0.7275

====epoch 55
Train Loss 5.288157718283656
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9178 test: 0.6781 | best val epoch -- val: 0.9405 test: 0.7275

====epoch 56
Train Loss 4.970618914806824
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9229 test: 0.6863 | best val epoch -- val: 0.9405 test: 0.7275

====epoch 57
Train Loss 4.907906372318163
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9288 test: 0.6931 | best val epoch -- val: 0.9405 test: 0.7275

====epoch 58
Train Loss 5.080254887534635
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9030 test: 0.6861 | best val epoch -- val: 0.9405 test: 0.7275

====epoch 59
Train Loss 4.615348954034444
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9086 test: 0.6687 | best val epoch -- val: 0.9405 test: 0.7275

====epoch 60
Train Loss 4.500217479492929
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8916 test: 0.6705 | best val epoch -- val: 0.9405 test: 0.7275

====epoch 61
Train Loss 4.559186709164975
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9099 test: 0.6709 | best val epoch -- val: 0.9405 test: 0.7275

====epoch 62
Train Loss 4.188476173824763
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9076 test: 0.6805 | best val epoch -- val: 0.9405 test: 0.7275

====epoch 63
Train Loss 4.063080773970764
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9119 test: 0.6851 | best val epoch -- val: 0.9405 test: 0.7275

====epoch 64
Train Loss 4.984797681434292
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9236 test: 0.6909 | best val epoch -- val: 0.9405 test: 0.7275

====epoch 65
Train Loss 4.213595287320807
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9031 test: 0.6845 | best val epoch -- val: 0.9405 test: 0.7275

====epoch 66
Train Loss 4.501041723869599
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8933 test: 0.6671 | best val epoch -- val: 0.9405 test: 0.7275

====epoch 67
Train Loss 4.481354248664906
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9210 test: 0.6886 | best val epoch -- val: 0.9405 test: 0.7275

====epoch 68
Train Loss 4.396664922357485
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9194 test: 0.6819 | best val epoch -- val: 0.9405 test: 0.7275

====epoch 69
Train Loss 4.6386932304151145
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9157 test: 0.6878 | best val epoch -- val: 0.9405 test: 0.7275

====epoch 70
Train Loss 4.1295729316448195
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9049 test: 0.6761 | best val epoch -- val: 0.9405 test: 0.7275

====epoch 71
Train Loss 4.201562620957997
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9137 test: 0.6874 | best val epoch -- val: 0.9405 test: 0.7275

====epoch 72
Train Loss 3.7288330674487473
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9220 test: 0.6976 | best val epoch -- val: 0.9405 test: 0.7275

====epoch 73
Train Loss 4.153544274248009
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9035 test: 0.6833 | best val epoch -- val: 0.9405 test: 0.7275

====epoch 74
Train Loss 3.843071379966744
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9077 test: 0.6674 | best val epoch -- val: 0.9405 test: 0.7275

====epoch 75
Train Loss 4.1657819269528735
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9158 test: 0.6840 | best val epoch -- val: 0.9405 test: 0.7275

====epoch 76
Train Loss 3.865180442542446
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9191 test: 0.6844 | best val epoch -- val: 0.9405 test: 0.7275

====epoch 77
Train Loss 3.9430444686491053
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9076 test: 0.6778 | best val epoch -- val: 0.9405 test: 0.7275

====epoch 78
Train Loss 3.717843582987079
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9132 test: 0.6776 | best val epoch -- val: 0.9405 test: 0.7275

====epoch 79
Train Loss 4.090627806654483
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9125 test: 0.6698 | best val epoch -- val: 0.9405 test: 0.7275

====epoch 80
Train Loss 3.3025936662100364
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9114 test: 0.6675 | best val epoch -- val: 0.9405 test: 0.7275

====epoch 81
Train Loss 3.043298583654538
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9057 test: 0.6566 | best val epoch -- val: 0.9405 test: 0.7275

====epoch 82
Train Loss 3.4375647204920656
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8860 test: 0.6435 | best val epoch -- val: 0.9405 test: 0.7275

====epoch 83
Train Loss 4.341799171283131
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8790 test: 0.6464 | best val epoch -- val: 0.9405 test: 0.7275

====epoch 84
Train Loss 3.736899198234123
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8962 test: 0.6675 | best val epoch -- val: 0.9405 test: 0.7275

====epoch 85
Train Loss 3.7400927099151184
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8872 test: 0.6591 | best val epoch -- val: 0.9405 test: 0.7275

====epoch 86
Train Loss 4.159422443035657
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8957 test: 0.6616 | best val epoch -- val: 0.9405 test: 0.7275

====epoch 87
Train Loss 3.357445139695104
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8906 test: 0.6577 | best val epoch -- val: 0.9405 test: 0.7275

====epoch 88
Train Loss 3.0705470465607476
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9092 test: 0.6613 | best val epoch -- val: 0.9405 test: 0.7275

====epoch 89
Train Loss 3.876791307372139
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8965 test: 0.6593 | best val epoch -- val: 0.9405 test: 0.7275

====epoch 90
Train Loss 2.959787525708808
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8972 test: 0.6555 | best val epoch -- val: 0.9405 test: 0.7275

====epoch 91
Train Loss 3.2413862672627762
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8998 test: 0.6612 | best val epoch -- val: 0.9405 test: 0.7275

====epoch 92
Train Loss 2.7850248769714736
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9019 test: 0.6540 | best val epoch -- val: 0.9405 test: 0.7275

====epoch 93
Train Loss 3.076344855580097
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8851 test: 0.6561 | best val epoch -- val: 0.9405 test: 0.7275

====epoch 94
Train Loss 3.1485921188863024
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9016 test: 0.6589 | best val epoch -- val: 0.9405 test: 0.7275

====epoch 95
Train Loss 2.7576233261981993
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8986 test: 0.6644 | best val epoch -- val: 0.9405 test: 0.7275

====epoch 96
Train Loss 2.7788614174350954
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9162 test: 0.6714 | best val epoch -- val: 0.9405 test: 0.7275

====epoch 97
Train Loss 3.6065916304078263
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8997 test: 0.6682 | best val epoch -- val: 0.9405 test: 0.7275

====epoch 98
Train Loss 3.0267276489418578
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9063 test: 0.6702 | best val epoch -- val: 0.9405 test: 0.7275

====epoch 99
Train Loss 3.3052619241637986
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8868 test: 0.6550 | best val epoch -- val: 0.9405 test: 0.7275

====epoch 100
Train Loss 3.168690813828522
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9032 test: 0.6597 | best val epoch -- val: 0.9405 test: 0.7275

[18:25:08] WARNING: not removing hydrogen atom without neighbors
[18:25:08] WARNING: not removing hydrogen atom without neighbors
[18:25:08] WARNING: not removing hydrogen atom without neighbors
[18:25:08] WARNING: not removing hydrogen atom without neighbors
[18:25:08] WARNING: not removing hydrogen atom without neighbors
[18:25:08] WARNING: not removing hydrogen atom without neighbors
[18:25:08] WARNING: not removing hydrogen atom without neighbors
[18:25:08] WARNING: not removing hydrogen atom without neighbors
[18:25:08] WARNING: not removing hydrogen atom without neighbors
[18:25:08] WARNING: not removing hydrogen atom without neighbors
[18:25:08] WARNING: not removing hydrogen atom without neighbors
[18:25:08] WARNING: not removing hydrogen atom without neighbors
[18:25:08] WARNING: not removing hydrogen atom without neighbors
[18:25:08] WARNING: not removing hydrogen atom without neighbors
[18:25:08] WARNING: not removing hydrogen atom without neighbors
[18:25:08] Conflicting single bond directions around double bond at index 1.
[18:25:08]   BondStereo set to STEREONONE and single bond directions set to NONE.
[18:25:08] WARNING: not removing hydrogen atom without neighbors
[18:25:08] WARNING: not removing hydrogen atom without neighbors
[18:25:08] WARNING: not removing hydrogen atom without neighbors
[18:25:08] WARNING: not removing hydrogen atom without neighbors
[18:25:08] WARNING: not removing hydrogen atom without neighbors
[18:25:08] WARNING: not removing hydrogen atom without neighbors
[18:25:08] WARNING: not removing hydrogen atom without neighbors
[18:25:09] WARNING: not removing hydrogen atom without neighbors
[18:25:09] WARNING: not removing hydrogen atom without neighbors
[18:25:09] WARNING: not removing hydrogen atom without neighbors
[18:25:09] WARNING: not removing hydrogen atom without neighbors
[18:25:09] WARNING: not removing hydrogen atom without neighbors
[18:25:09] WARNING: not removing hydrogen atom without neighbors
[18:25:09] WARNING: not removing hydrogen atom without neighbors
[18:25:09] WARNING: not removing hydrogen atom without neighbors
[18:25:09] WARNING: not removing hydrogen atom without neighbors
[18:25:09] WARNING: not removing hydrogen atom without neighbors
[18:25:09] WARNING: not removing hydrogen atom without neighbors
[18:25:09] WARNING: not removing hydrogen atom without neighbors
[18:25:09] WARNING: not removing hydrogen atom without neighbors
[18:25:09] WARNING: not removing hydrogen atom without neighbors
[18:25:09] WARNING: not removing hydrogen atom without neighbors
[18:25:09] WARNING: not removing hydrogen atom without neighbors
[18:25:09] WARNING: not removing hydrogen atom without neighbors
[18:25:09] WARNING: not removing hydrogen atom without neighbors
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.4.
2022-09-13 18:25:09.356 | INFO     | modules.masked_transformer_encoder:__init__:122 - number of parameters: 0.000000e+00
=========================================
batch_size = 32
d_model = 128
dataset = bbbp
decay = 0
device = 0
dim_feedforward = 512
eval_train = 0
filename =
gnn_JK = cat
gnn_dropout = 0.3
gnn_emb_dim = 300
gnn_num_layer = 5
gnn_residual = False
gnn_type = gin
gnn_virtual_node = False
graph_pooling = cls
input_model_file = models_graphtrans/graphtrans-sr-gcl.pth
lr = 0.0001
lr_scale = 1
max_input_len = 1000
nhead = 4
num_encoder_layers = 4
num_encoder_layers_masked = 0
num_workers = 0
pos_encoder = False
runseed = 2
seed = 12344
split = scaffold
transformer_activation = relu
transformer_dropout = 0.3
transformer_norm_input = True
transformer_prenorm = False
=========================================
bbbp
scaffold
Loaded GraphTrans from models_graphtrans/graphtrans-sr-gcl.pth
====epoch 1
Train Loss 23.430433271436023
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7560 test: 0.5321 | best val epoch -- val: 0.7560 test: 0.5321

====epoch 2
Train Loss 20.48655643550899
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8991 test: 0.5889 | best val epoch -- val: 0.8991 test: 0.5889

====epoch 3
Train Loss 17.811611289525846
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8995 test: 0.6087 | best val epoch -- val: 0.8995 test: 0.6087

====epoch 4
Train Loss 16.18890151143779
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8949 test: 0.6304 | best val epoch -- val: 0.8995 test: 0.6087

====epoch 5
Train Loss 15.023891334549958
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9014 test: 0.6569 | best val epoch -- val: 0.9014 test: 0.6569

====epoch 6
Train Loss 13.31682833218079
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9088 test: 0.6729 | best val epoch -- val: 0.9088 test: 0.6729

====epoch 7
Train Loss 12.35155013755305
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9066 test: 0.6773 | best val epoch -- val: 0.9088 test: 0.6729

====epoch 8
Train Loss 11.404497634775787
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9030 test: 0.6791 | best val epoch -- val: 0.9088 test: 0.6729

====epoch 9
Train Loss 11.279918403875273
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8994 test: 0.6940 | best val epoch -- val: 0.9088 test: 0.6729

====epoch 10
Train Loss 10.84085675097625
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9012 test: 0.6939 | best val epoch -- val: 0.9088 test: 0.6729

====epoch 11
Train Loss 10.94058253984262
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8992 test: 0.6948 | best val epoch -- val: 0.9088 test: 0.6729

====epoch 12
Train Loss 10.46386026005652
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9034 test: 0.6952 | best val epoch -- val: 0.9088 test: 0.6729

====epoch 13
Train Loss 11.026726676715672
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8983 test: 0.7047 | best val epoch -- val: 0.9088 test: 0.6729

====epoch 14
Train Loss 9.873297092747045
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8916 test: 0.7042 | best val epoch -- val: 0.9088 test: 0.6729

====epoch 15
Train Loss 10.18117708097338
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9111 test: 0.7177 | best val epoch -- val: 0.9111 test: 0.7177

====epoch 16
Train Loss 9.403017374123788
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8886 test: 0.6926 | best val epoch -- val: 0.9111 test: 0.7177

====epoch 17
Train Loss 9.240183306349568
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9269 test: 0.7116 | best val epoch -- val: 0.9269 test: 0.7116

====epoch 18
Train Loss 8.856795397151938
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9142 test: 0.7038 | best val epoch -- val: 0.9269 test: 0.7116

====epoch 19
Train Loss 8.765366621530468
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9231 test: 0.7185 | best val epoch -- val: 0.9269 test: 0.7116

====epoch 20
Train Loss 8.753398182051193
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9112 test: 0.7032 | best val epoch -- val: 0.9269 test: 0.7116

====epoch 21
Train Loss 8.543575375749935
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9216 test: 0.7074 | best val epoch -- val: 0.9269 test: 0.7116

====epoch 22
Train Loss 8.280545208870357
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9207 test: 0.7094 | best val epoch -- val: 0.9269 test: 0.7116

====epoch 23
Train Loss 8.132825618014502
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9055 test: 0.7003 | best val epoch -- val: 0.9269 test: 0.7116

====epoch 24
Train Loss 7.611734925143554
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9080 test: 0.7041 | best val epoch -- val: 0.9269 test: 0.7116

====epoch 25
Train Loss 7.777895469187326
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9178 test: 0.7194 | best val epoch -- val: 0.9269 test: 0.7116

====epoch 26
Train Loss 7.982937109262113
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8911 test: 0.6929 | best val epoch -- val: 0.9269 test: 0.7116

====epoch 27
Train Loss 8.27139711256234
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9217 test: 0.7090 | best val epoch -- val: 0.9269 test: 0.7116

====epoch 28
Train Loss 7.219412103477755
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9140 test: 0.7133 | best val epoch -- val: 0.9269 test: 0.7116

====epoch 29
Train Loss 7.378105257071907
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9188 test: 0.7230 | best val epoch -- val: 0.9269 test: 0.7116

====epoch 30
Train Loss 6.88696441784677
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9021 test: 0.7186 | best val epoch -- val: 0.9269 test: 0.7116

====epoch 31
Train Loss 6.927383434304602
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9170 test: 0.7157 | best val epoch -- val: 0.9269 test: 0.7116

====epoch 32
Train Loss 6.4823775396897165
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9115 test: 0.7113 | best val epoch -- val: 0.9269 test: 0.7116

====epoch 33
Train Loss 6.325481452036503
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9318 test: 0.7137 | best val epoch -- val: 0.9318 test: 0.7137

====epoch 34
Train Loss 6.767799219228662
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9125 test: 0.7171 | best val epoch -- val: 0.9318 test: 0.7137

====epoch 35
Train Loss 5.969669418751405
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9239 test: 0.7142 | best val epoch -- val: 0.9318 test: 0.7137

====epoch 36
Train Loss 6.66193265124711
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9121 test: 0.7079 | best val epoch -- val: 0.9318 test: 0.7137

====epoch 37
Train Loss 6.219370876700692
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9162 test: 0.7163 | best val epoch -- val: 0.9318 test: 0.7137

====epoch 38
Train Loss 5.550891412726011
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9121 test: 0.7133 | best val epoch -- val: 0.9318 test: 0.7137

====epoch 39
Train Loss 6.160731009682389
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9127 test: 0.7050 | best val epoch -- val: 0.9318 test: 0.7137

====epoch 40
Train Loss 6.826435140816889
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9021 test: 0.7025 | best val epoch -- val: 0.9318 test: 0.7137

====epoch 41
Train Loss 5.41572239803072
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9071 test: 0.7148 | best val epoch -- val: 0.9318 test: 0.7137

====epoch 42
Train Loss 5.644677528130736
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9056 test: 0.7127 | best val epoch -- val: 0.9318 test: 0.7137

====epoch 43
Train Loss 5.431195803541081
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9185 test: 0.7046 | best val epoch -- val: 0.9318 test: 0.7137

====epoch 44
Train Loss 5.323756480049801
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9053 test: 0.7042 | best val epoch -- val: 0.9318 test: 0.7137

====epoch 45
Train Loss 5.256465441149575
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9136 test: 0.6938 | best val epoch -- val: 0.9318 test: 0.7137

====epoch 46
Train Loss 5.802660917624553
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9093 test: 0.7032 | best val epoch -- val: 0.9318 test: 0.7137

====epoch 47
Train Loss 5.232084520810824
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9194 test: 0.7052 | best val epoch -- val: 0.9318 test: 0.7137

====epoch 48
Train Loss 5.061075768109907
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9064 test: 0.7070 | best val epoch -- val: 0.9318 test: 0.7137

====epoch 49
Train Loss 5.231258443206361
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9078 test: 0.7041 | best val epoch -- val: 0.9318 test: 0.7137

====epoch 50
Train Loss 5.437946106741217
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9080 test: 0.7049 | best val epoch -- val: 0.9318 test: 0.7137

====epoch 51
Train Loss 5.042746403767899
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8955 test: 0.7062 | best val epoch -- val: 0.9318 test: 0.7137

====epoch 52
Train Loss 5.595931337077615
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9042 test: 0.6980 | best val epoch -- val: 0.9318 test: 0.7137

====epoch 53
Train Loss 5.025587903824241
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9103 test: 0.7071 | best val epoch -- val: 0.9318 test: 0.7137

====epoch 54
Train Loss 4.853661755926101
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9017 test: 0.7052 | best val epoch -- val: 0.9318 test: 0.7137

====epoch 55
Train Loss 4.376060646882938
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9159 test: 0.6971 | best val epoch -- val: 0.9318 test: 0.7137

====epoch 56
Train Loss 4.865524577379129
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9167 test: 0.6952 | best val epoch -- val: 0.9318 test: 0.7137

====epoch 57
Train Loss 4.935138831830772
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9088 test: 0.6851 | best val epoch -- val: 0.9318 test: 0.7137

====epoch 58
Train Loss 5.105850343210234
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9081 test: 0.6801 | best val epoch -- val: 0.9318 test: 0.7137

====epoch 59
Train Loss 3.85522013678734
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9100 test: 0.6880 | best val epoch -- val: 0.9318 test: 0.7137

====epoch 60
Train Loss 4.741123002068626
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9061 test: 0.6876 | best val epoch -- val: 0.9318 test: 0.7137

====epoch 61
Train Loss 4.534813397687155
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9008 test: 0.6875 | best val epoch -- val: 0.9318 test: 0.7137

====epoch 62
Train Loss 4.5598313174115805
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9013 test: 0.6929 | best val epoch -- val: 0.9318 test: 0.7137

====epoch 63
Train Loss 4.478995029227873
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9072 test: 0.7006 | best val epoch -- val: 0.9318 test: 0.7137

====epoch 64
Train Loss 4.585217781158252
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9151 test: 0.6975 | best val epoch -- val: 0.9318 test: 0.7137

====epoch 65
Train Loss 4.18959573089628
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8937 test: 0.6914 | best val epoch -- val: 0.9318 test: 0.7137

====epoch 66
Train Loss 4.170799822412861
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9057 test: 0.6866 | best val epoch -- val: 0.9318 test: 0.7137

====epoch 67
Train Loss 4.246649757352615
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9109 test: 0.6798 | best val epoch -- val: 0.9318 test: 0.7137

====epoch 68
Train Loss 3.6350644840985473
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9124 test: 0.6729 | best val epoch -- val: 0.9318 test: 0.7137

====epoch 69
Train Loss 3.9391222816962252
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9111 test: 0.6844 | best val epoch -- val: 0.9318 test: 0.7137

====epoch 70
Train Loss 3.2634890905058644
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9050 test: 0.6818 | best val epoch -- val: 0.9318 test: 0.7137

====epoch 71
Train Loss 4.32074747504829
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9089 test: 0.6786 | best val epoch -- val: 0.9318 test: 0.7137

====epoch 72
Train Loss 4.291629533142949
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9104 test: 0.6982 | best val epoch -- val: 0.9318 test: 0.7137

====epoch 73
Train Loss 3.6878447254614315
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8984 test: 0.6919 | best val epoch -- val: 0.9318 test: 0.7137

====epoch 74
Train Loss 3.442558670312282
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9042 test: 0.6854 | best val epoch -- val: 0.9318 test: 0.7137

====epoch 75
Train Loss 3.558271884799049
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8860 test: 0.6769 | best val epoch -- val: 0.9318 test: 0.7137

====epoch 76
Train Loss 3.582548505467512
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9055 test: 0.6652 | best val epoch -- val: 0.9318 test: 0.7137

====epoch 77
Train Loss 3.9444659463903147
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9101 test: 0.6891 | best val epoch -- val: 0.9318 test: 0.7137

====epoch 78
Train Loss 3.8586556333530844
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9097 test: 0.6987 | best val epoch -- val: 0.9318 test: 0.7137

====epoch 79
Train Loss 3.3501764589825416
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9123 test: 0.6846 | best val epoch -- val: 0.9318 test: 0.7137

====epoch 80
Train Loss 3.842679035355315
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9159 test: 0.6836 | best val epoch -- val: 0.9318 test: 0.7137

====epoch 81
Train Loss 3.658110883078793
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9087 test: 0.6925 | best val epoch -- val: 0.9318 test: 0.7137

====epoch 82
Train Loss 3.7334433764083568
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9049 test: 0.6850 | best val epoch -- val: 0.9318 test: 0.7137

====epoch 83
Train Loss 2.926771289099316
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8937 test: 0.6670 | best val epoch -- val: 0.9318 test: 0.7137

====epoch 84
Train Loss 3.646531330402231
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9089 test: 0.6807 | best val epoch -- val: 0.9318 test: 0.7137

====epoch 85
Train Loss 3.638799121358216
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8971 test: 0.6850 | best val epoch -- val: 0.9318 test: 0.7137

====epoch 86
Train Loss 3.8308789255280353
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9203 test: 0.6900 | best val epoch -- val: 0.9318 test: 0.7137

====epoch 87
Train Loss 3.774802133812354
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8994 test: 0.6832 | best val epoch -- val: 0.9318 test: 0.7137

====epoch 88
Train Loss 3.287769532914652
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8932 test: 0.6738 | best val epoch -- val: 0.9318 test: 0.7137

====epoch 89
Train Loss 2.8926859200580037
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9087 test: 0.6794 | best val epoch -- val: 0.9318 test: 0.7137

====epoch 90
Train Loss 3.3431957598288977
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8926 test: 0.6715 | best val epoch -- val: 0.9318 test: 0.7137

====epoch 91
Train Loss 3.033390358179881
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8963 test: 0.6734 | best val epoch -- val: 0.9318 test: 0.7137

====epoch 92
Train Loss 2.8426132070732395
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9013 test: 0.6787 | best val epoch -- val: 0.9318 test: 0.7137

====epoch 93
Train Loss 2.992604449604636
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8846 test: 0.6694 | best val epoch -- val: 0.9318 test: 0.7137

====epoch 94
Train Loss 2.970135502084558
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8790 test: 0.6661 | best val epoch -- val: 0.9318 test: 0.7137

====epoch 95
Train Loss 2.70974936232429
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8761 test: 0.6550 | best val epoch -- val: 0.9318 test: 0.7137

====epoch 96
Train Loss 2.845884086604749
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8836 test: 0.6459 | best val epoch -- val: 0.9318 test: 0.7137

====epoch 97
Train Loss 2.9544452372467074
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8954 test: 0.6608 | best val epoch -- val: 0.9318 test: 0.7137

====epoch 98
Train Loss 3.0105299261038208
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8743 test: 0.6453 | best val epoch -- val: 0.9318 test: 0.7137

====epoch 99
Train Loss 2.259369622050771
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8768 test: 0.6420 | best val epoch -- val: 0.9318 test: 0.7137

====epoch 100
Train Loss 3.1993845850257037
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8504 test: 0.6245 | best val epoch -- val: 0.9318 test: 0.7137

[18:28:35] WARNING: not removing hydrogen atom without neighbors
[18:28:35] WARNING: not removing hydrogen atom without neighbors
[18:28:35] WARNING: not removing hydrogen atom without neighbors
[18:28:35] WARNING: not removing hydrogen atom without neighbors
[18:28:35] WARNING: not removing hydrogen atom without neighbors
[18:28:35] WARNING: not removing hydrogen atom without neighbors
[18:28:35] WARNING: not removing hydrogen atom without neighbors
[18:28:35] WARNING: not removing hydrogen atom without neighbors
[18:28:35] WARNING: not removing hydrogen atom without neighbors
[18:28:35] WARNING: not removing hydrogen atom without neighbors
[18:28:35] WARNING: not removing hydrogen atom without neighbors
[18:28:35] WARNING: not removing hydrogen atom without neighbors
[18:28:35] WARNING: not removing hydrogen atom without neighbors
[18:28:35] WARNING: not removing hydrogen atom without neighbors
[18:28:35] WARNING: not removing hydrogen atom without neighbors
[18:28:35] Conflicting single bond directions around double bond at index 1.
[18:28:35]   BondStereo set to STEREONONE and single bond directions set to NONE.
[18:28:35] WARNING: not removing hydrogen atom without neighbors
[18:28:35] WARNING: not removing hydrogen atom without neighbors
[18:28:35] WARNING: not removing hydrogen atom without neighbors
[18:28:35] WARNING: not removing hydrogen atom without neighbors
[18:28:35] WARNING: not removing hydrogen atom without neighbors
[18:28:35] WARNING: not removing hydrogen atom without neighbors
[18:28:35] WARNING: not removing hydrogen atom without neighbors
[18:28:35] WARNING: not removing hydrogen atom without neighbors
[18:28:35] WARNING: not removing hydrogen atom without neighbors
[18:28:35] WARNING: not removing hydrogen atom without neighbors
[18:28:35] WARNING: not removing hydrogen atom without neighbors
[18:28:35] WARNING: not removing hydrogen atom without neighbors
[18:28:35] WARNING: not removing hydrogen atom without neighbors
[18:28:35] WARNING: not removing hydrogen atom without neighbors
[18:28:35] WARNING: not removing hydrogen atom without neighbors
[18:28:35] WARNING: not removing hydrogen atom without neighbors
[18:28:35] WARNING: not removing hydrogen atom without neighbors
[18:28:35] WARNING: not removing hydrogen atom without neighbors
[18:28:35] WARNING: not removing hydrogen atom without neighbors
[18:28:35] WARNING: not removing hydrogen atom without neighbors
[18:28:35] WARNING: not removing hydrogen atom without neighbors
[18:28:35] WARNING: not removing hydrogen atom without neighbors
[18:28:35] WARNING: not removing hydrogen atom without neighbors
[18:28:35] WARNING: not removing hydrogen atom without neighbors
[18:28:35] WARNING: not removing hydrogen atom without neighbors
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.4.
2022-09-13 18:28:35.924 | INFO     | modules.masked_transformer_encoder:__init__:122 - number of parameters: 0.000000e+00
=========================================
batch_size = 32
d_model = 128
dataset = bbbp
decay = 0
device = 0
dim_feedforward = 512
eval_train = 0
filename =
gnn_JK = cat
gnn_dropout = 0.3
gnn_emb_dim = 300
gnn_num_layer = 5
gnn_residual = False
gnn_type = gin
gnn_virtual_node = False
graph_pooling = cls
input_model_file = models_graphtrans/graphtrans-sr-gcl.pth
lr = 0.0001
lr_scale = 1
max_input_len = 1000
nhead = 4
num_encoder_layers = 4
num_encoder_layers_masked = 0
num_workers = 0
pos_encoder = False
runseed = 3
seed = 12344
split = scaffold
transformer_activation = relu
transformer_dropout = 0.3
transformer_norm_input = True
transformer_prenorm = False
=========================================
bbbp
scaffold
Loaded GraphTrans from models_graphtrans/graphtrans-sr-gcl.pth
====epoch 1
Train Loss 23.900332089669455
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6471 test: 0.5930 | best val epoch -- val: 0.6471 test: 0.5930

====epoch 2
Train Loss 21.422951307554683
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8664 test: 0.6413 | best val epoch -- val: 0.8664 test: 0.6413

====epoch 3
Train Loss 19.05296522011422
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8926 test: 0.6282 | best val epoch -- val: 0.8926 test: 0.6282

====epoch 4
Train Loss 16.690879954103657
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9194 test: 0.6396 | best val epoch -- val: 0.9194 test: 0.6396

====epoch 5
Train Loss 14.724274605093278
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9201 test: 0.6712 | best val epoch -- val: 0.9201 test: 0.6712

====epoch 6
Train Loss 13.421241769291369
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9312 test: 0.6846 | best val epoch -- val: 0.9312 test: 0.6846

====epoch 7
Train Loss 12.510825399280638
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9227 test: 0.6867 | best val epoch -- val: 0.9312 test: 0.6846

====epoch 8
Train Loss 12.037957521874668
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9267 test: 0.6909 | best val epoch -- val: 0.9312 test: 0.6846

====epoch 9
Train Loss 11.815536522655108
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9145 test: 0.7080 | best val epoch -- val: 0.9312 test: 0.6846

====epoch 10
Train Loss 11.173410669329952
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9308 test: 0.7265 | best val epoch -- val: 0.9312 test: 0.6846

====epoch 11
Train Loss 11.184579020507918
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9278 test: 0.7178 | best val epoch -- val: 0.9312 test: 0.6846

====epoch 12
Train Loss 9.763618989598566
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9375 test: 0.7312 | best val epoch -- val: 0.9375 test: 0.7312

====epoch 13
Train Loss 9.96880486599708
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9261 test: 0.7330 | best val epoch -- val: 0.9375 test: 0.7312

====epoch 14
Train Loss 10.42356584721873
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9403 test: 0.7344 | best val epoch -- val: 0.9403 test: 0.7344

====epoch 15
Train Loss 9.895622046946366
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9378 test: 0.7239 | best val epoch -- val: 0.9403 test: 0.7344

====epoch 16
Train Loss 10.014280077265326
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9323 test: 0.7339 | best val epoch -- val: 0.9403 test: 0.7344

====epoch 17
Train Loss 8.625678857261612
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9332 test: 0.7402 | best val epoch -- val: 0.9403 test: 0.7344

====epoch 18
Train Loss 9.34129759300537
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9347 test: 0.7351 | best val epoch -- val: 0.9403 test: 0.7344

====epoch 19
Train Loss 8.790038335539808
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9254 test: 0.7349 | best val epoch -- val: 0.9403 test: 0.7344

====epoch 20
Train Loss 8.799423384720626
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9267 test: 0.7392 | best val epoch -- val: 0.9403 test: 0.7344

====epoch 21
Train Loss 8.96222098209492
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9362 test: 0.7412 | best val epoch -- val: 0.9403 test: 0.7344

====epoch 22
Train Loss 8.335356706149145
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9392 test: 0.7426 | best val epoch -- val: 0.9403 test: 0.7344

====epoch 23
Train Loss 7.705306922636972
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9446 test: 0.7403 | best val epoch -- val: 0.9446 test: 0.7403

====epoch 24
Train Loss 7.783263057735641
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9370 test: 0.7422 | best val epoch -- val: 0.9446 test: 0.7403

====epoch 25
Train Loss 7.719651671155144
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9382 test: 0.7392 | best val epoch -- val: 0.9446 test: 0.7403

====epoch 26
Train Loss 7.779739908197734
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9307 test: 0.7445 | best val epoch -- val: 0.9446 test: 0.7403

====epoch 27
Train Loss 7.388172606921124
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9257 test: 0.7324 | best val epoch -- val: 0.9446 test: 0.7403

====epoch 28
Train Loss 7.339972403130164
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9369 test: 0.7352 | best val epoch -- val: 0.9446 test: 0.7403

====epoch 29
Train Loss 7.6931589557637
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9386 test: 0.7373 | best val epoch -- val: 0.9446 test: 0.7403

====epoch 30
Train Loss 7.391367077499473
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9289 test: 0.7288 | best val epoch -- val: 0.9446 test: 0.7403

====epoch 31
Train Loss 7.302051293055027
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9308 test: 0.7256 | best val epoch -- val: 0.9446 test: 0.7403

====epoch 32
Train Loss 6.817735109787193
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9410 test: 0.7390 | best val epoch -- val: 0.9446 test: 0.7403

====epoch 33
Train Loss 6.460143609978158
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9166 test: 0.7217 | best val epoch -- val: 0.9446 test: 0.7403

====epoch 34
Train Loss 6.604426450272573
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9413 test: 0.7491 | best val epoch -- val: 0.9446 test: 0.7403

====epoch 35
Train Loss 6.969719112630537
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9209 test: 0.7327 | best val epoch -- val: 0.9446 test: 0.7403

====epoch 36
Train Loss 6.150833082066344
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9183 test: 0.7354 | best val epoch -- val: 0.9446 test: 0.7403

====epoch 37
Train Loss 6.3380833857949215
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8993 test: 0.7210 | best val epoch -- val: 0.9446 test: 0.7403

====epoch 38
Train Loss 6.93351818397177
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9251 test: 0.7203 | best val epoch -- val: 0.9446 test: 0.7403

====epoch 39
Train Loss 6.092098887999117
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9218 test: 0.7287 | best val epoch -- val: 0.9446 test: 0.7403

====epoch 40
Train Loss 6.2930583503608934
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8847 test: 0.7130 | best val epoch -- val: 0.9446 test: 0.7403

====epoch 41
Train Loss 6.178242606286044
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8937 test: 0.7260 | best val epoch -- val: 0.9446 test: 0.7403

====epoch 42
Train Loss 6.475850265674812
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8990 test: 0.7231 | best val epoch -- val: 0.9446 test: 0.7403

====epoch 43
Train Loss 6.193082859091853
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9068 test: 0.7293 | best val epoch -- val: 0.9446 test: 0.7403

====epoch 44
Train Loss 5.816669017124752
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9062 test: 0.7351 | best val epoch -- val: 0.9446 test: 0.7403

====epoch 45
Train Loss 5.865541711462186
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8934 test: 0.7287 | best val epoch -- val: 0.9446 test: 0.7403

====epoch 46
Train Loss 5.246106737262904
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9106 test: 0.7167 | best val epoch -- val: 0.9446 test: 0.7403

====epoch 47
Train Loss 5.729553701675094
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8989 test: 0.7236 | best val epoch -- val: 0.9446 test: 0.7403

====epoch 48
Train Loss 5.617893691970771
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8945 test: 0.7347 | best val epoch -- val: 0.9446 test: 0.7403

====epoch 49
Train Loss 5.355465803068068
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9034 test: 0.7251 | best val epoch -- val: 0.9446 test: 0.7403

====epoch 50
Train Loss 5.1348765869492885
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8953 test: 0.7306 | best val epoch -- val: 0.9446 test: 0.7403

====epoch 51
Train Loss 5.03882576918862
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9016 test: 0.7342 | best val epoch -- val: 0.9446 test: 0.7403

====epoch 52
Train Loss 5.24268088859585
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8935 test: 0.7218 | best val epoch -- val: 0.9446 test: 0.7403

====epoch 53
Train Loss 5.378047587699037
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9050 test: 0.7243 | best val epoch -- val: 0.9446 test: 0.7403

====epoch 54
Train Loss 4.884754833049118
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9103 test: 0.7327 | best val epoch -- val: 0.9446 test: 0.7403

====epoch 55
Train Loss 5.336818609989855
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9074 test: 0.7386 | best val epoch -- val: 0.9446 test: 0.7403

====epoch 56
Train Loss 4.704629604705981
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8928 test: 0.7219 | best val epoch -- val: 0.9446 test: 0.7403

====epoch 57
Train Loss 5.018141905511248
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8764 test: 0.7204 | best val epoch -- val: 0.9446 test: 0.7403

====epoch 58
Train Loss 5.036657428019956
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8898 test: 0.7210 | best val epoch -- val: 0.9446 test: 0.7403

====epoch 59
Train Loss 5.412275104884867
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8976 test: 0.7284 | best val epoch -- val: 0.9446 test: 0.7403

====epoch 60
Train Loss 4.3295080837922
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8940 test: 0.7241 | best val epoch -- val: 0.9446 test: 0.7403

====epoch 61
Train Loss 4.519421761282096
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8899 test: 0.7246 | best val epoch -- val: 0.9446 test: 0.7403

====epoch 62
Train Loss 4.122210286037397
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8961 test: 0.7240 | best val epoch -- val: 0.9446 test: 0.7403

====epoch 63
Train Loss 4.486950321474198
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9121 test: 0.7197 | best val epoch -- val: 0.9446 test: 0.7403

====epoch 64
Train Loss 4.360142731436389
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8991 test: 0.7151 | best val epoch -- val: 0.9446 test: 0.7403

====epoch 65
Train Loss 4.320746365386161
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9094 test: 0.7125 | best val epoch -- val: 0.9446 test: 0.7403

====epoch 66
Train Loss 4.057333067053702
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8997 test: 0.7213 | best val epoch -- val: 0.9446 test: 0.7403

====epoch 67
Train Loss 4.266796673461498
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8868 test: 0.7245 | best val epoch -- val: 0.9446 test: 0.7403

====epoch 68
Train Loss 4.442998147115272
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9077 test: 0.7245 | best val epoch -- val: 0.9446 test: 0.7403

====epoch 69
Train Loss 5.357505628223285
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9063 test: 0.7205 | best val epoch -- val: 0.9446 test: 0.7403

====epoch 70
Train Loss 3.956389294288436
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8934 test: 0.7174 | best val epoch -- val: 0.9446 test: 0.7403

====epoch 71
Train Loss 3.9325113534813076
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8895 test: 0.7247 | best val epoch -- val: 0.9446 test: 0.7403

====epoch 72
Train Loss 3.911226740601799
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8966 test: 0.7159 | best val epoch -- val: 0.9446 test: 0.7403

====epoch 73
Train Loss 3.511275367295788
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8978 test: 0.7160 | best val epoch -- val: 0.9446 test: 0.7403

====epoch 74
Train Loss 4.59668450442539
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8947 test: 0.7253 | best val epoch -- val: 0.9446 test: 0.7403

====epoch 75
Train Loss 4.060775440990848
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8937 test: 0.7149 | best val epoch -- val: 0.9446 test: 0.7403

====epoch 76
Train Loss 3.8051688880402064
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8877 test: 0.7216 | best val epoch -- val: 0.9446 test: 0.7403

====epoch 77
Train Loss 3.514397618947093
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8880 test: 0.7106 | best val epoch -- val: 0.9446 test: 0.7403

====epoch 78
Train Loss 3.3423626384988596
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8954 test: 0.7073 | best val epoch -- val: 0.9446 test: 0.7403

====epoch 79
Train Loss 3.8740664504187268
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8846 test: 0.7036 | best val epoch -- val: 0.9446 test: 0.7403

====epoch 80
Train Loss 3.686744525402489
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8935 test: 0.6962 | best val epoch -- val: 0.9446 test: 0.7403

====epoch 81
Train Loss 3.7796771161955145
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8824 test: 0.7060 | best val epoch -- val: 0.9446 test: 0.7403

====epoch 82
Train Loss 3.6839852556901618
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8906 test: 0.7256 | best val epoch -- val: 0.9446 test: 0.7403

====epoch 83
Train Loss 2.9709667530657113
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8901 test: 0.7122 | best val epoch -- val: 0.9446 test: 0.7403

====epoch 84
Train Loss 3.226708407835007
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8973 test: 0.7170 | best val epoch -- val: 0.9446 test: 0.7403

====epoch 85
Train Loss 3.0025760618418316
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8774 test: 0.7143 | best val epoch -- val: 0.9446 test: 0.7403

====epoch 86
Train Loss 3.743582388581676
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8977 test: 0.7081 | best val epoch -- val: 0.9446 test: 0.7403

====epoch 87
Train Loss 3.7063655625986396
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8857 test: 0.7159 | best val epoch -- val: 0.9446 test: 0.7403

====epoch 88
Train Loss 2.9723582504520047
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8710 test: 0.7165 | best val epoch -- val: 0.9446 test: 0.7403

====epoch 89
Train Loss 3.262863474900898
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8747 test: 0.7203 | best val epoch -- val: 0.9446 test: 0.7403

====epoch 90
Train Loss 3.121575280049517
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8818 test: 0.7252 | best val epoch -- val: 0.9446 test: 0.7403

====epoch 91
Train Loss 3.248398347182928
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8828 test: 0.7326 | best val epoch -- val: 0.9446 test: 0.7403

====epoch 92
Train Loss 2.709728217611273
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8927 test: 0.7249 | best val epoch -- val: 0.9446 test: 0.7403

====epoch 93
Train Loss 2.9268825893009396
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8870 test: 0.7061 | best val epoch -- val: 0.9446 test: 0.7403

====epoch 94
Train Loss 2.9256588833939605
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8846 test: 0.7060 | best val epoch -- val: 0.9446 test: 0.7403

====epoch 95
Train Loss 2.925521988999421
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9002 test: 0.7215 | best val epoch -- val: 0.9446 test: 0.7403

====epoch 96
Train Loss 2.780575609109036
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8833 test: 0.7351 | best val epoch -- val: 0.9446 test: 0.7403

====epoch 97
Train Loss 2.9026644026834734
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8948 test: 0.7269 | best val epoch -- val: 0.9446 test: 0.7403

====epoch 98
Train Loss 2.7809390523558513
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8835 test: 0.7205 | best val epoch -- val: 0.9446 test: 0.7403

====epoch 99
Train Loss 2.680859899612023
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8816 test: 0.7034 | best val epoch -- val: 0.9446 test: 0.7403

====epoch 100
Train Loss 2.8910621809780603
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8748 test: 0.7226 | best val epoch -- val: 0.9446 test: 0.7403

[18:31:45] WARNING: not removing hydrogen atom without neighbors
[18:31:45] WARNING: not removing hydrogen atom without neighbors
[18:31:45] WARNING: not removing hydrogen atom without neighbors
[18:31:45] WARNING: not removing hydrogen atom without neighbors
[18:31:45] WARNING: not removing hydrogen atom without neighbors
[18:31:45] WARNING: not removing hydrogen atom without neighbors
[18:31:45] WARNING: not removing hydrogen atom without neighbors
[18:31:45] WARNING: not removing hydrogen atom without neighbors
[18:31:45] WARNING: not removing hydrogen atom without neighbors
[18:31:46] WARNING: not removing hydrogen atom without neighbors
[18:31:46] WARNING: not removing hydrogen atom without neighbors
[18:31:46] WARNING: not removing hydrogen atom without neighbors
[18:31:46] WARNING: not removing hydrogen atom without neighbors
[18:31:46] WARNING: not removing hydrogen atom without neighbors
[18:31:46] WARNING: not removing hydrogen atom without neighbors
[18:31:46] Conflicting single bond directions around double bond at index 1.
[18:31:46]   BondStereo set to STEREONONE and single bond directions set to NONE.
[18:31:46] WARNING: not removing hydrogen atom without neighbors
[18:31:46] WARNING: not removing hydrogen atom without neighbors
[18:31:46] WARNING: not removing hydrogen atom without neighbors
[18:31:46] WARNING: not removing hydrogen atom without neighbors
[18:31:46] WARNING: not removing hydrogen atom without neighbors
[18:31:46] WARNING: not removing hydrogen atom without neighbors
[18:31:46] WARNING: not removing hydrogen atom without neighbors
[18:31:46] WARNING: not removing hydrogen atom without neighbors
[18:31:46] WARNING: not removing hydrogen atom without neighbors
[18:31:46] WARNING: not removing hydrogen atom without neighbors
[18:31:46] WARNING: not removing hydrogen atom without neighbors
[18:31:46] WARNING: not removing hydrogen atom without neighbors
[18:31:46] WARNING: not removing hydrogen atom without neighbors
[18:31:46] WARNING: not removing hydrogen atom without neighbors
[18:31:46] WARNING: not removing hydrogen atom without neighbors
[18:31:46] WARNING: not removing hydrogen atom without neighbors
[18:31:46] WARNING: not removing hydrogen atom without neighbors
[18:31:46] WARNING: not removing hydrogen atom without neighbors
[18:31:46] WARNING: not removing hydrogen atom without neighbors
[18:31:46] WARNING: not removing hydrogen atom without neighbors
[18:31:46] WARNING: not removing hydrogen atom without neighbors
[18:31:46] WARNING: not removing hydrogen atom without neighbors
[18:31:46] WARNING: not removing hydrogen atom without neighbors
[18:31:46] WARNING: not removing hydrogen atom without neighbors
[18:31:46] WARNING: not removing hydrogen atom without neighbors
2022-09-13 18:31:46.500 | INFO     | modules.masked_transformer_encoder:__init__:122 - number of parameters: 0.000000e+00
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.4.
=========================================
batch_size = 32
d_model = 128
dataset = bbbp
decay = 0
device = 0
dim_feedforward = 512
eval_train = 0
filename =
gnn_JK = cat
gnn_dropout = 0.3
gnn_emb_dim = 300
gnn_num_layer = 5
gnn_residual = False
gnn_type = gin
gnn_virtual_node = False
graph_pooling = cls
input_model_file = models_graphtrans/graphtrans-sr-gcl.pth
lr = 0.0001
lr_scale = 1
max_input_len = 1000
nhead = 4
num_encoder_layers = 4
num_encoder_layers_masked = 0
num_workers = 0
pos_encoder = False
runseed = 4
seed = 12344
split = scaffold
transformer_activation = relu
transformer_dropout = 0.3
transformer_norm_input = True
transformer_prenorm = False
=========================================
bbbp
scaffold
Loaded GraphTrans from models_graphtrans/graphtrans-sr-gcl.pth
====epoch 1
Train Loss 25.029340618631803
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.4970 test: 0.4785 | best val epoch -- val: 0.4970 test: 0.4785

====epoch 2
Train Loss 21.50391175845691
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7518 test: 0.5755 | best val epoch -- val: 0.7518 test: 0.5755

====epoch 3
Train Loss 20.042867648021247
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9029 test: 0.6184 | best val epoch -- val: 0.9029 test: 0.6184

====epoch 4
Train Loss 16.96168342988144
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9223 test: 0.6535 | best val epoch -- val: 0.9223 test: 0.6535

====epoch 5
Train Loss 14.514676461335
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9264 test: 0.6986 | best val epoch -- val: 0.9264 test: 0.6986

====epoch 6
Train Loss 13.671405432831833
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9394 test: 0.6998 | best val epoch -- val: 0.9394 test: 0.6998

====epoch 7
Train Loss 12.41816543370913
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9394 test: 0.7010 | best val epoch -- val: 0.9394 test: 0.7010

====epoch 8
Train Loss 11.332229544980965
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9399 test: 0.7209 | best val epoch -- val: 0.9399 test: 0.7209

====epoch 9
Train Loss 11.125948512665113
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9194 test: 0.7153 | best val epoch -- val: 0.9399 test: 0.7209

====epoch 10
Train Loss 10.606696020075843
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9413 test: 0.7152 | best val epoch -- val: 0.9413 test: 0.7152

====epoch 11
Train Loss 10.523509622589783
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9218 test: 0.7257 | best val epoch -- val: 0.9413 test: 0.7152

====epoch 12
Train Loss 9.880837211503565
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9303 test: 0.7239 | best val epoch -- val: 0.9413 test: 0.7152

====epoch 13
Train Loss 9.790449459501898
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9238 test: 0.7279 | best val epoch -- val: 0.9413 test: 0.7152

====epoch 14
Train Loss 9.370411560836551
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9240 test: 0.7266 | best val epoch -- val: 0.9413 test: 0.7152

====epoch 15
Train Loss 9.085253736050447
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9236 test: 0.7188 | best val epoch -- val: 0.9413 test: 0.7152

====epoch 16
Train Loss 9.774973556480802
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9104 test: 0.7215 | best val epoch -- val: 0.9413 test: 0.7152

====epoch 17
Train Loss 8.157245088517158
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9071 test: 0.7262 | best val epoch -- val: 0.9413 test: 0.7152

====epoch 18
Train Loss 8.991656405570863
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9252 test: 0.7236 | best val epoch -- val: 0.9413 test: 0.7152

====epoch 19
Train Loss 8.136975668303897
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9160 test: 0.7345 | best val epoch -- val: 0.9413 test: 0.7152

====epoch 20
Train Loss 8.387077099206884
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9260 test: 0.7437 | best val epoch -- val: 0.9413 test: 0.7152

====epoch 21
Train Loss 8.497882645256475
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9329 test: 0.7418 | best val epoch -- val: 0.9413 test: 0.7152

====epoch 22
Train Loss 7.943747795276484
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9272 test: 0.7353 | best val epoch -- val: 0.9413 test: 0.7152

====epoch 23
Train Loss 8.251218185939937
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9215 test: 0.7296 | best val epoch -- val: 0.9413 test: 0.7152

====epoch 24
Train Loss 7.731190190803519
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9268 test: 0.7335 | best val epoch -- val: 0.9413 test: 0.7152

====epoch 25
Train Loss 7.286038914867009
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9366 test: 0.7379 | best val epoch -- val: 0.9413 test: 0.7152

====epoch 26
Train Loss 7.523807802567146
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9170 test: 0.7311 | best val epoch -- val: 0.9413 test: 0.7152

====epoch 27
Train Loss 7.05964567803449
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9216 test: 0.7377 | best val epoch -- val: 0.9413 test: 0.7152

====epoch 28
Train Loss 7.122134022045882
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9215 test: 0.7394 | best val epoch -- val: 0.9413 test: 0.7152

====epoch 29
Train Loss 6.856369985102343
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9195 test: 0.7335 | best val epoch -- val: 0.9413 test: 0.7152

====epoch 30
Train Loss 7.0249972531284515
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9200 test: 0.7305 | best val epoch -- val: 0.9413 test: 0.7152

====epoch 31
Train Loss 6.513024396047528
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9280 test: 0.7206 | best val epoch -- val: 0.9413 test: 0.7152

====epoch 32
Train Loss 6.7128698700844485
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9303 test: 0.7219 | best val epoch -- val: 0.9413 test: 0.7152

====epoch 33
Train Loss 6.458625487401912
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9018 test: 0.7144 | best val epoch -- val: 0.9413 test: 0.7152

====epoch 34
Train Loss 6.2013821594135985
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9108 test: 0.7184 | best val epoch -- val: 0.9413 test: 0.7152

====epoch 35
Train Loss 5.845518236077782
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9127 test: 0.7248 | best val epoch -- val: 0.9413 test: 0.7152

====epoch 36
Train Loss 6.652188625950066
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9076 test: 0.7213 | best val epoch -- val: 0.9413 test: 0.7152

====epoch 37
Train Loss 6.341171205654775
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9021 test: 0.7297 | best val epoch -- val: 0.9413 test: 0.7152

====epoch 38
Train Loss 5.361307711510926
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9038 test: 0.7356 | best val epoch -- val: 0.9413 test: 0.7152

====epoch 39
Train Loss 6.41368219074005
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8915 test: 0.7138 | best val epoch -- val: 0.9413 test: 0.7152

====epoch 40
Train Loss 5.79908647990307
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8900 test: 0.7137 | best val epoch -- val: 0.9413 test: 0.7152

====epoch 41
Train Loss 5.594977883054156
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8630 test: 0.7113 | best val epoch -- val: 0.9413 test: 0.7152

====epoch 42
Train Loss 5.810721577512904
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8720 test: 0.7052 | best val epoch -- val: 0.9413 test: 0.7152

====epoch 43
Train Loss 5.994377241812982
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9173 test: 0.7169 | best val epoch -- val: 0.9413 test: 0.7152

====epoch 44
Train Loss 5.566572059154721
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9205 test: 0.7309 | best val epoch -- val: 0.9413 test: 0.7152

====epoch 45
Train Loss 5.339359220762475
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9144 test: 0.7232 | best val epoch -- val: 0.9413 test: 0.7152

====epoch 46
Train Loss 5.697812952522887
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8996 test: 0.7236 | best val epoch -- val: 0.9413 test: 0.7152

====epoch 47
Train Loss 5.453522972580278
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9057 test: 0.7151 | best val epoch -- val: 0.9413 test: 0.7152

====epoch 48
Train Loss 5.34037927389349
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8859 test: 0.7044 | best val epoch -- val: 0.9413 test: 0.7152

====epoch 49
Train Loss 5.132209737871025
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8873 test: 0.7038 | best val epoch -- val: 0.9413 test: 0.7152

====epoch 50
Train Loss 5.352277738015924
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8967 test: 0.7033 | best val epoch -- val: 0.9413 test: 0.7152

====epoch 51
Train Loss 4.938386778768866
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8946 test: 0.7082 | best val epoch -- val: 0.9413 test: 0.7152

====epoch 52
Train Loss 4.784019292057536
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9057 test: 0.7054 | best val epoch -- val: 0.9413 test: 0.7152

====epoch 53
Train Loss 5.274333980855839
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8630 test: 0.6852 | best val epoch -- val: 0.9413 test: 0.7152

====epoch 54
Train Loss 5.321889621755556
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8941 test: 0.7061 | best val epoch -- val: 0.9413 test: 0.7152

====epoch 55
Train Loss 4.829204464953833
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8723 test: 0.6942 | best val epoch -- val: 0.9413 test: 0.7152

====epoch 56
Train Loss 4.924640955636268
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9244 test: 0.7258 | best val epoch -- val: 0.9413 test: 0.7152

====epoch 57
Train Loss 4.962797887002
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8948 test: 0.7084 | best val epoch -- val: 0.9413 test: 0.7152

====epoch 58
Train Loss 4.662406532750429
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8967 test: 0.7173 | best val epoch -- val: 0.9413 test: 0.7152

====epoch 59
Train Loss 4.32785698985836
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9126 test: 0.7158 | best val epoch -- val: 0.9413 test: 0.7152

====epoch 60
Train Loss 4.250070425627287
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9088 test: 0.7149 | best val epoch -- val: 0.9413 test: 0.7152

====epoch 61
Train Loss 4.406042792699844
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9168 test: 0.7238 | best val epoch -- val: 0.9413 test: 0.7152

====epoch 62
Train Loss 3.9785785447048325
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8901 test: 0.7067 | best val epoch -- val: 0.9413 test: 0.7152

====epoch 63
Train Loss 3.9074894117107517
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8943 test: 0.7235 | best val epoch -- val: 0.9413 test: 0.7152

====epoch 64
Train Loss 4.923885774506042
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8659 test: 0.7089 | best val epoch -- val: 0.9413 test: 0.7152

====epoch 65
Train Loss 4.021132663600301
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8891 test: 0.7079 | best val epoch -- val: 0.9413 test: 0.7152

====epoch 66
Train Loss 4.498382657956447
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8692 test: 0.6988 | best val epoch -- val: 0.9413 test: 0.7152

====epoch 67
Train Loss 3.9813780446779137
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8925 test: 0.7151 | best val epoch -- val: 0.9413 test: 0.7152

====epoch 68
Train Loss 4.012736933631573
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9093 test: 0.7114 | best val epoch -- val: 0.9413 test: 0.7152

====epoch 69
Train Loss 3.763896661997775
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8602 test: 0.6941 | best val epoch -- val: 0.9413 test: 0.7152

====epoch 70
Train Loss 4.1962695160972405
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9155 test: 0.7177 | best val epoch -- val: 0.9413 test: 0.7152

====epoch 71
Train Loss 4.554109652231251
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8910 test: 0.7135 | best val epoch -- val: 0.9413 test: 0.7152

====epoch 72
Train Loss 3.9369310999272717
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8625 test: 0.6851 | best val epoch -- val: 0.9413 test: 0.7152

====epoch 73
Train Loss 3.3232603814381636
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8654 test: 0.6891 | best val epoch -- val: 0.9413 test: 0.7152

====epoch 74
Train Loss 4.069859662642952
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9068 test: 0.7119 | best val epoch -- val: 0.9413 test: 0.7152

====epoch 75
Train Loss 3.820989664414969
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9043 test: 0.7148 | best val epoch -- val: 0.9413 test: 0.7152

====epoch 76
Train Loss 3.3739078508551428
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8899 test: 0.7207 | best val epoch -- val: 0.9413 test: 0.7152

====epoch 77
Train Loss 3.15375793834331
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8986 test: 0.7021 | best val epoch -- val: 0.9413 test: 0.7152

====epoch 78
Train Loss 3.5459670338240104
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8665 test: 0.6933 | best val epoch -- val: 0.9413 test: 0.7152

====epoch 79
Train Loss 3.7938750761643836
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9016 test: 0.7189 | best val epoch -- val: 0.9413 test: 0.7152

====epoch 80
Train Loss 2.9327169883421758
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9198 test: 0.7123 | best val epoch -- val: 0.9413 test: 0.7152

====epoch 81
Train Loss 3.725430092943042
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9145 test: 0.7045 | best val epoch -- val: 0.9413 test: 0.7152

====epoch 82
Train Loss 3.402350569417848
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9008 test: 0.6984 | best val epoch -- val: 0.9413 test: 0.7152

====epoch 83
Train Loss 2.9153558843147414
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8940 test: 0.6968 | best val epoch -- val: 0.9413 test: 0.7152

====epoch 84
Train Loss 3.5271437683157214
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8931 test: 0.6999 | best val epoch -- val: 0.9413 test: 0.7152

====epoch 85
Train Loss 3.488149338268425
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8889 test: 0.6927 | best val epoch -- val: 0.9413 test: 0.7152

====epoch 86
Train Loss 3.3915332615745677
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8819 test: 0.6939 | best val epoch -- val: 0.9413 test: 0.7152

====epoch 87
Train Loss 2.8785876051026547
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8832 test: 0.6896 | best val epoch -- val: 0.9413 test: 0.7152

====epoch 88
Train Loss 3.2438624991591762
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8523 test: 0.6693 | best val epoch -- val: 0.9413 test: 0.7152

====epoch 89
Train Loss 2.7682566607072023
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8722 test: 0.6877 | best val epoch -- val: 0.9413 test: 0.7152

====epoch 90
Train Loss 3.0040834976448125
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8980 test: 0.7062 | best val epoch -- val: 0.9413 test: 0.7152

====epoch 91
Train Loss 3.166276897974758
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9005 test: 0.7044 | best val epoch -- val: 0.9413 test: 0.7152

====epoch 92
Train Loss 3.204220910857732
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8951 test: 0.7152 | best val epoch -- val: 0.9413 test: 0.7152

====epoch 93
Train Loss 2.493681323134846
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8962 test: 0.7075 | best val epoch -- val: 0.9413 test: 0.7152

====epoch 94
Train Loss 2.729317945856677
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8851 test: 0.6952 | best val epoch -- val: 0.9413 test: 0.7152

====epoch 95
Train Loss 2.2137462386086066
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8691 test: 0.6882 | best val epoch -- val: 0.9413 test: 0.7152

====epoch 96
Train Loss 2.693674222574799
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8911 test: 0.6944 | best val epoch -- val: 0.9413 test: 0.7152

====epoch 97
Train Loss 2.9859673435994507
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8822 test: 0.6984 | best val epoch -- val: 0.9413 test: 0.7152

====epoch 98
Train Loss 2.5868917276831747
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8848 test: 0.6989 | best val epoch -- val: 0.9413 test: 0.7152

====epoch 99
Train Loss 2.868681506383865
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8922 test: 0.6938 | best val epoch -- val: 0.9413 test: 0.7152

====epoch 100
Train Loss 2.364902896244629
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8967 test: 0.6916 | best val epoch -- val: 0.9413 test: 0.7152

[18:35:09] WARNING: not removing hydrogen atom without neighbors
[18:35:09] WARNING: not removing hydrogen atom without neighbors
[18:35:09] WARNING: not removing hydrogen atom without neighbors
[18:35:09] WARNING: not removing hydrogen atom without neighbors
[18:35:09] WARNING: not removing hydrogen atom without neighbors
[18:35:09] WARNING: not removing hydrogen atom without neighbors
[18:35:09] WARNING: not removing hydrogen atom without neighbors
[18:35:09] WARNING: not removing hydrogen atom without neighbors
[18:35:09] WARNING: not removing hydrogen atom without neighbors
[18:35:09] WARNING: not removing hydrogen atom without neighbors
[18:35:09] WARNING: not removing hydrogen atom without neighbors
[18:35:09] WARNING: not removing hydrogen atom without neighbors
[18:35:09] WARNING: not removing hydrogen atom without neighbors
[18:35:09] WARNING: not removing hydrogen atom without neighbors
[18:35:09] WARNING: not removing hydrogen atom without neighbors
[18:35:09] Conflicting single bond directions around double bond at index 1.
[18:35:09]   BondStereo set to STEREONONE and single bond directions set to NONE.
[18:35:09] WARNING: not removing hydrogen atom without neighbors
[18:35:09] WARNING: not removing hydrogen atom without neighbors
[18:35:09] WARNING: not removing hydrogen atom without neighbors
[18:35:09] WARNING: not removing hydrogen atom without neighbors
[18:35:09] WARNING: not removing hydrogen atom without neighbors
[18:35:09] WARNING: not removing hydrogen atom without neighbors
[18:35:09] WARNING: not removing hydrogen atom without neighbors
[18:35:09] WARNING: not removing hydrogen atom without neighbors
[18:35:09] WARNING: not removing hydrogen atom without neighbors
[18:35:09] WARNING: not removing hydrogen atom without neighbors
[18:35:09] WARNING: not removing hydrogen atom without neighbors
[18:35:09] WARNING: not removing hydrogen atom without neighbors
[18:35:09] WARNING: not removing hydrogen atom without neighbors
[18:35:09] WARNING: not removing hydrogen atom without neighbors
[18:35:09] WARNING: not removing hydrogen atom without neighbors
[18:35:09] WARNING: not removing hydrogen atom without neighbors
[18:35:09] WARNING: not removing hydrogen atom without neighbors
[18:35:09] WARNING: not removing hydrogen atom without neighbors
[18:35:09] WARNING: not removing hydrogen atom without neighbors
[18:35:09] WARNING: not removing hydrogen atom without neighbors
[18:35:09] WARNING: not removing hydrogen atom without neighbors
[18:35:09] WARNING: not removing hydrogen atom without neighbors
[18:35:09] WARNING: not removing hydrogen atom without neighbors
[18:35:09] WARNING: not removing hydrogen atom without neighbors
[18:35:09] WARNING: not removing hydrogen atom without neighbors
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.4.
2022-09-13 18:35:09.925 | INFO     | modules.masked_transformer_encoder:__init__:122 - number of parameters: 0.000000e+00
=========================================
batch_size = 32
d_model = 128
dataset = bbbp
decay = 0
device = 0
dim_feedforward = 512
eval_train = 0
filename =
gnn_JK = cat
gnn_dropout = 0.3
gnn_emb_dim = 300
gnn_num_layer = 5
gnn_residual = False
gnn_type = gin
gnn_virtual_node = False
graph_pooling = cls
input_model_file = models_graphtrans/graphtrans-sr-gcl.pth
lr = 0.0001
lr_scale = 1
max_input_len = 1000
nhead = 4
num_encoder_layers = 4
num_encoder_layers_masked = 0
num_workers = 0
pos_encoder = False
runseed = 5
seed = 12344
split = scaffold
transformer_activation = relu
transformer_dropout = 0.3
transformer_norm_input = True
transformer_prenorm = False
=========================================
bbbp
scaffold
Loaded GraphTrans from models_graphtrans/graphtrans-sr-gcl.pth
====epoch 1
Train Loss 24.43483397494667
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7454 test: 0.5548 | best val epoch -- val: 0.7454 test: 0.5548

====epoch 2
Train Loss 20.934045436311216
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8622 test: 0.5897 | best val epoch -- val: 0.8622 test: 0.5897

====epoch 3
Train Loss 18.0456359399012
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9077 test: 0.6205 | best val epoch -- val: 0.9077 test: 0.6205

====epoch 4
Train Loss 16.245206426776505
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9247 test: 0.6412 | best val epoch -- val: 0.9247 test: 0.6412

====epoch 5
Train Loss 14.614906739562796
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9367 test: 0.6698 | best val epoch -- val: 0.9367 test: 0.6698

====epoch 6
Train Loss 12.905745829113483
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9267 test: 0.6965 | best val epoch -- val: 0.9367 test: 0.6698

====epoch 7
Train Loss 12.45358294402924
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9434 test: 0.6975 | best val epoch -- val: 0.9434 test: 0.6975

====epoch 8
Train Loss 11.901757536549388
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9356 test: 0.6955 | best val epoch -- val: 0.9434 test: 0.6975

====epoch 9
Train Loss 11.268660681649202
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9357 test: 0.6976 | best val epoch -- val: 0.9434 test: 0.6975

====epoch 10
Train Loss 11.0969544691414
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9399 test: 0.6989 | best val epoch -- val: 0.9434 test: 0.6975

====epoch 11
Train Loss 10.690751791831447
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9363 test: 0.7052 | best val epoch -- val: 0.9434 test: 0.6975

====epoch 12
Train Loss 10.45721373323523
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9385 test: 0.7093 | best val epoch -- val: 0.9434 test: 0.6975

====epoch 13
Train Loss 10.450719362802111
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9447 test: 0.7164 | best val epoch -- val: 0.9447 test: 0.7164

====epoch 14
Train Loss 9.563157583814444
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9402 test: 0.7140 | best val epoch -- val: 0.9447 test: 0.7164

====epoch 15
Train Loss 9.257728576412898
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9460 test: 0.7093 | best val epoch -- val: 0.9460 test: 0.7093

====epoch 16
Train Loss 8.650487388122718
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9396 test: 0.6918 | best val epoch -- val: 0.9460 test: 0.7093

====epoch 17
Train Loss 9.300962759077603
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9461 test: 0.6916 | best val epoch -- val: 0.9461 test: 0.6916

====epoch 18
Train Loss 8.676970176713464
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9435 test: 0.7099 | best val epoch -- val: 0.9461 test: 0.6916

====epoch 19
Train Loss 9.402659737422383
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9439 test: 0.7087 | best val epoch -- val: 0.9461 test: 0.6916

====epoch 20
Train Loss 8.531210154104878
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9439 test: 0.7090 | best val epoch -- val: 0.9461 test: 0.6916

====epoch 21
Train Loss 8.48744641762123
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9478 test: 0.7137 | best val epoch -- val: 0.9478 test: 0.7137

====epoch 22
Train Loss 8.603468803162743
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9421 test: 0.7127 | best val epoch -- val: 0.9478 test: 0.7137

====epoch 23
Train Loss 8.203824916904303
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9492 test: 0.7125 | best val epoch -- val: 0.9492 test: 0.7125

====epoch 24
Train Loss 7.749821307676907
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9428 test: 0.7109 | best val epoch -- val: 0.9492 test: 0.7125

====epoch 25
Train Loss 7.74257804015049
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9390 test: 0.7060 | best val epoch -- val: 0.9492 test: 0.7125

====epoch 26
Train Loss 8.120661128104855
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9437 test: 0.7101 | best val epoch -- val: 0.9492 test: 0.7125

====epoch 27
Train Loss 7.652881761076095
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9348 test: 0.7133 | best val epoch -- val: 0.9492 test: 0.7125

====epoch 28
Train Loss 6.813135528768765
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9306 test: 0.7135 | best val epoch -- val: 0.9492 test: 0.7125

====epoch 29
Train Loss 7.064872777324826
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9384 test: 0.7181 | best val epoch -- val: 0.9492 test: 0.7125

====epoch 30
Train Loss 6.780196753579256
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9141 test: 0.7017 | best val epoch -- val: 0.9492 test: 0.7125

====epoch 31
Train Loss 7.007340819401353
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9030 test: 0.6943 | best val epoch -- val: 0.9492 test: 0.7125

====epoch 32
Train Loss 6.245217234739824
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9359 test: 0.7013 | best val epoch -- val: 0.9492 test: 0.7125

====epoch 33
Train Loss 6.856024172525219
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9268 test: 0.7011 | best val epoch -- val: 0.9492 test: 0.7125

====epoch 34
Train Loss 6.285205756937171
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9243 test: 0.7084 | best val epoch -- val: 0.9492 test: 0.7125

====epoch 35
Train Loss 6.47785439714782
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9250 test: 0.7082 | best val epoch -- val: 0.9492 test: 0.7125

====epoch 36
Train Loss 6.8400569017496755
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9204 test: 0.7006 | best val epoch -- val: 0.9492 test: 0.7125

====epoch 37
Train Loss 6.320821280955646
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9110 test: 0.6967 | best val epoch -- val: 0.9492 test: 0.7125

====epoch 38
Train Loss 6.598829638958266
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9120 test: 0.6912 | best val epoch -- val: 0.9492 test: 0.7125

====epoch 39
Train Loss 6.472814896133921
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9244 test: 0.7049 | best val epoch -- val: 0.9492 test: 0.7125

====epoch 40
Train Loss 6.470309859064477
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9244 test: 0.7095 | best val epoch -- val: 0.9492 test: 0.7125

====epoch 41
Train Loss 6.17271502261394
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9241 test: 0.6996 | best val epoch -- val: 0.9492 test: 0.7125

====epoch 42
Train Loss 5.724422671610196
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9162 test: 0.7012 | best val epoch -- val: 0.9492 test: 0.7125

====epoch 43
Train Loss 6.54449359699006
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9342 test: 0.7002 | best val epoch -- val: 0.9492 test: 0.7125

====epoch 44
Train Loss 6.110399291859083
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9336 test: 0.7056 | best val epoch -- val: 0.9492 test: 0.7125

====epoch 45
Train Loss 5.510007624132169
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9276 test: 0.6866 | best val epoch -- val: 0.9492 test: 0.7125

====epoch 46
Train Loss 6.330834608657013
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9262 test: 0.6943 | best val epoch -- val: 0.9492 test: 0.7125

====epoch 47
Train Loss 5.700024092168322
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9236 test: 0.6834 | best val epoch -- val: 0.9492 test: 0.7125

====epoch 48
Train Loss 5.185085588469477
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9183 test: 0.6997 | best val epoch -- val: 0.9492 test: 0.7125

====epoch 49
Train Loss 5.463247979712684
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9157 test: 0.6943 | best val epoch -- val: 0.9492 test: 0.7125

====epoch 50
Train Loss 5.464567770686577
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9077 test: 0.6912 | best val epoch -- val: 0.9492 test: 0.7125

====epoch 51
Train Loss 5.611460197518881
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9236 test: 0.6956 | best val epoch -- val: 0.9492 test: 0.7125

====epoch 52
Train Loss 5.291192531615549
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9217 test: 0.6968 | best val epoch -- val: 0.9492 test: 0.7125

====epoch 53
Train Loss 5.096262089600308
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9121 test: 0.7040 | best val epoch -- val: 0.9492 test: 0.7125

====epoch 54
Train Loss 5.664585406150222
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9205 test: 0.7004 | best val epoch -- val: 0.9492 test: 0.7125

====epoch 55
Train Loss 4.701711774422786
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9178 test: 0.7041 | best val epoch -- val: 0.9492 test: 0.7125

====epoch 56
Train Loss 5.032175600994037
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9158 test: 0.6944 | best val epoch -- val: 0.9492 test: 0.7125

====epoch 57
Train Loss 5.047459710906317
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9171 test: 0.7040 | best val epoch -- val: 0.9492 test: 0.7125

====epoch 58
Train Loss 4.612177469244607
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9080 test: 0.6935 | best val epoch -- val: 0.9492 test: 0.7125

====epoch 59
Train Loss 4.18224629743919
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9104 test: 0.7005 | best val epoch -- val: 0.9492 test: 0.7125

====epoch 60
Train Loss 4.541046125013938
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9108 test: 0.6957 | best val epoch -- val: 0.9492 test: 0.7125

====epoch 61
Train Loss 4.560596923010617
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9044 test: 0.6900 | best val epoch -- val: 0.9492 test: 0.7125

====epoch 62
Train Loss 4.678240679825459
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9184 test: 0.6983 | best val epoch -- val: 0.9492 test: 0.7125

====epoch 63
Train Loss 3.897766425436066
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8949 test: 0.6880 | best val epoch -- val: 0.9492 test: 0.7125

====epoch 64
Train Loss 4.444388499717524
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9081 test: 0.6905 | best val epoch -- val: 0.9492 test: 0.7125

====epoch 65
Train Loss 4.20132614985696
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8831 test: 0.6628 | best val epoch -- val: 0.9492 test: 0.7125

====epoch 66
Train Loss 4.48181534564877
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8909 test: 0.6846 | best val epoch -- val: 0.9492 test: 0.7125

====epoch 67
Train Loss 3.7406104641358873
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8778 test: 0.6650 | best val epoch -- val: 0.9492 test: 0.7125

====epoch 68
Train Loss 4.588381896606426
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8966 test: 0.6808 | best val epoch -- val: 0.9492 test: 0.7125

====epoch 69
Train Loss 4.077342466340868
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8837 test: 0.6872 | best val epoch -- val: 0.9492 test: 0.7125

====epoch 70
Train Loss 3.821523509788206
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8946 test: 0.6916 | best val epoch -- val: 0.9492 test: 0.7125

====epoch 71
Train Loss 4.395937918222716
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8648 test: 0.6786 | best val epoch -- val: 0.9492 test: 0.7125

====epoch 72
Train Loss 4.035944965205683
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8942 test: 0.6844 | best val epoch -- val: 0.9492 test: 0.7125

====epoch 73
Train Loss 3.637887288913385
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8683 test: 0.6649 | best val epoch -- val: 0.9492 test: 0.7125

====epoch 74
Train Loss 3.7831450723463647
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8786 test: 0.6936 | best val epoch -- val: 0.9492 test: 0.7125

====epoch 75
Train Loss 4.214150732731632
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8901 test: 0.6887 | best val epoch -- val: 0.9492 test: 0.7125

====epoch 76
Train Loss 3.931951389858805
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8860 test: 0.6656 | best val epoch -- val: 0.9492 test: 0.7125

====epoch 77
Train Loss 3.477209603142498
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8978 test: 0.6884 | best val epoch -- val: 0.9492 test: 0.7125

====epoch 78
Train Loss 3.5572896104947636
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9079 test: 0.6814 | best val epoch -- val: 0.9492 test: 0.7125

====epoch 79
Train Loss 4.369834794039786
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9009 test: 0.6828 | best val epoch -- val: 0.9492 test: 0.7125

====epoch 80
Train Loss 4.0059012828623715
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8988 test: 0.6852 | best val epoch -- val: 0.9492 test: 0.7125

====epoch 81
Train Loss 3.636257670156841
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8934 test: 0.6833 | best val epoch -- val: 0.9492 test: 0.7125

====epoch 82
Train Loss 3.5165604760369855
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9090 test: 0.6826 | best val epoch -- val: 0.9492 test: 0.7125

====epoch 83
Train Loss 3.8114034263862857
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8922 test: 0.6766 | best val epoch -- val: 0.9492 test: 0.7125

====epoch 84
Train Loss 3.437072878799742
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8886 test: 0.6658 | best val epoch -- val: 0.9492 test: 0.7125

====epoch 85
Train Loss 3.286953293883749
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8729 test: 0.6572 | best val epoch -- val: 0.9492 test: 0.7125

====epoch 86
Train Loss 3.753595322941232
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9004 test: 0.6802 | best val epoch -- val: 0.9492 test: 0.7125

====epoch 87
Train Loss 2.9552795045737623
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8810 test: 0.6715 | best val epoch -- val: 0.9492 test: 0.7125

====epoch 88
Train Loss 3.410103807892609
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8782 test: 0.6841 | best val epoch -- val: 0.9492 test: 0.7125

====epoch 89
Train Loss 3.309001855809769
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8790 test: 0.6700 | best val epoch -- val: 0.9492 test: 0.7125

====epoch 90
Train Loss 3.451539567896806
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8600 test: 0.6485 | best val epoch -- val: 0.9492 test: 0.7125

====epoch 91
Train Loss 3.4916624805220926
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8872 test: 0.6727 | best val epoch -- val: 0.9492 test: 0.7125

====epoch 92
Train Loss 2.9610834649938704
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8879 test: 0.6805 | best val epoch -- val: 0.9492 test: 0.7125

====epoch 93
Train Loss 2.9467353192474133
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8701 test: 0.6675 | best val epoch -- val: 0.9492 test: 0.7125

====epoch 94
Train Loss 3.2986183363544184
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8914 test: 0.6843 | best val epoch -- val: 0.9492 test: 0.7125

====epoch 95
Train Loss 2.847854984621629
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8683 test: 0.6589 | best val epoch -- val: 0.9492 test: 0.7125

====epoch 96
Train Loss 2.848359518246548
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8578 test: 0.6374 | best val epoch -- val: 0.9492 test: 0.7125

====epoch 97
Train Loss 2.9526138126090204
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8929 test: 0.6776 | best val epoch -- val: 0.9492 test: 0.7125

====epoch 98
Train Loss 3.0759193316002778
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8803 test: 0.6565 | best val epoch -- val: 0.9492 test: 0.7125

====epoch 99
Train Loss 3.157582488113166
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8940 test: 0.6720 | best val epoch -- val: 0.9492 test: 0.7125

====epoch 100
Train Loss 2.6561064882565755
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8885 test: 0.6723 | best val epoch -- val: 0.9492 test: 0.7125

[18:38:30] WARNING: not removing hydrogen atom without neighbors
[18:38:30] WARNING: not removing hydrogen atom without neighbors
[18:38:30] WARNING: not removing hydrogen atom without neighbors
[18:38:30] WARNING: not removing hydrogen atom without neighbors
[18:38:30] WARNING: not removing hydrogen atom without neighbors
[18:38:30] WARNING: not removing hydrogen atom without neighbors
[18:38:30] WARNING: not removing hydrogen atom without neighbors
[18:38:30] WARNING: not removing hydrogen atom without neighbors
[18:38:30] WARNING: not removing hydrogen atom without neighbors
[18:38:30] WARNING: not removing hydrogen atom without neighbors
[18:38:30] WARNING: not removing hydrogen atom without neighbors
[18:38:30] WARNING: not removing hydrogen atom without neighbors
[18:38:30] WARNING: not removing hydrogen atom without neighbors
[18:38:30] WARNING: not removing hydrogen atom without neighbors
[18:38:30] WARNING: not removing hydrogen atom without neighbors
[18:38:30] Conflicting single bond directions around double bond at index 1.
[18:38:30]   BondStereo set to STEREONONE and single bond directions set to NONE.
[18:38:30] WARNING: not removing hydrogen atom without neighbors
[18:38:30] WARNING: not removing hydrogen atom without neighbors
[18:38:30] WARNING: not removing hydrogen atom without neighbors
[18:38:30] WARNING: not removing hydrogen atom without neighbors
[18:38:30] WARNING: not removing hydrogen atom without neighbors
[18:38:30] WARNING: not removing hydrogen atom without neighbors
[18:38:30] WARNING: not removing hydrogen atom without neighbors
[18:38:30] WARNING: not removing hydrogen atom without neighbors
[18:38:30] WARNING: not removing hydrogen atom without neighbors
[18:38:30] WARNING: not removing hydrogen atom without neighbors
[18:38:30] WARNING: not removing hydrogen atom without neighbors
[18:38:30] WARNING: not removing hydrogen atom without neighbors
[18:38:30] WARNING: not removing hydrogen atom without neighbors
[18:38:30] WARNING: not removing hydrogen atom without neighbors
[18:38:30] WARNING: not removing hydrogen atom without neighbors
[18:38:30] WARNING: not removing hydrogen atom without neighbors
[18:38:30] WARNING: not removing hydrogen atom without neighbors
[18:38:30] WARNING: not removing hydrogen atom without neighbors
[18:38:30] WARNING: not removing hydrogen atom without neighbors
[18:38:30] WARNING: not removing hydrogen atom without neighbors
[18:38:30] WARNING: not removing hydrogen atom without neighbors
[18:38:30] WARNING: not removing hydrogen atom without neighbors
[18:38:30] WARNING: not removing hydrogen atom without neighbors
[18:38:30] WARNING: not removing hydrogen atom without neighbors
[18:38:30] WARNING: not removing hydrogen atom without neighbors
2022-09-13 18:38:30.986 | INFO     | modules.masked_transformer_encoder:__init__:122 - number of parameters: 0.000000e+00
=========================================
batch_size = 32
d_model = 128
dataset = bbbp
decay = 0
device = 0
dim_feedforward = 512
eval_train = 0
filename =
gnn_JK = cat
gnn_dropout = 0.3
gnn_emb_dim = 300
gnn_num_layer = 5
gnn_residual = False
gnn_type = gin
gnn_virtual_node = False
graph_pooling = cls
input_model_file = models_graphtrans/graphtrans-sr-gcl.pth
lr = 0.0001
lr_scale = 1
max_input_len = 1000
nhead = 4
num_encoder_layers = 4
num_encoder_layers_masked = 0
num_workers = 0
pos_encoder = False
runseed = 6
seed = 12344
split = scaffold
transformer_activation = relu
transformer_dropout = 0.3
transformer_norm_input = True
transformer_prenorm = False
=========================================
bbbp
scaffold
Loaded GraphTrans from models_graphtrans/graphtrans-sr-gcl.pth
====epoch 1
Train Loss 23.914407353565387
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6948 test: 0.5266 | best val epoch -- val: 0.6948 test: 0.5266

====epoch 2
Train Loss 20.281701994513266
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8892 test: 0.6098 | best val epoch -- val: 0.8892 test: 0.6098

====epoch 3
Train Loss 17.8489606829248
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8930 test: 0.6361 | best val epoch -- val: 0.8930 test: 0.6361

====epoch 4
Train Loss 16.122112484348
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9000 test: 0.6399 | best val epoch -- val: 0.9000 test: 0.6399

====epoch 5
Train Loss 14.038388114062652
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9009 test: 0.6511 | best val epoch -- val: 0.9009 test: 0.6511

====epoch 6
Train Loss 13.241713345935796
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9097 test: 0.6634 | best val epoch -- val: 0.9097 test: 0.6634

====epoch 7
Train Loss 12.373315629862761
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9043 test: 0.6738 | best val epoch -- val: 0.9097 test: 0.6634

====epoch 8
Train Loss 11.959434625124743
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9154 test: 0.6700 | best val epoch -- val: 0.9154 test: 0.6700

====epoch 9
Train Loss 11.138705522305989
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9097 test: 0.6835 | best val epoch -- val: 0.9154 test: 0.6700

====epoch 10
Train Loss 10.783795124907646
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9262 test: 0.6939 | best val epoch -- val: 0.9262 test: 0.6939

====epoch 11
Train Loss 10.631298823237056
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9235 test: 0.6855 | best val epoch -- val: 0.9262 test: 0.6939

====epoch 12
Train Loss 9.797442846077221
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9283 test: 0.6996 | best val epoch -- val: 0.9283 test: 0.6996

====epoch 13
Train Loss 10.11945372328408
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9284 test: 0.7032 | best val epoch -- val: 0.9284 test: 0.7032

====epoch 14
Train Loss 9.653251294880153
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9314 test: 0.7259 | best val epoch -- val: 0.9314 test: 0.7259

====epoch 15
Train Loss 9.011860476291728
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9201 test: 0.7035 | best val epoch -- val: 0.9314 test: 0.7259

====epoch 16
Train Loss 9.828955637895247
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9153 test: 0.6884 | best val epoch -- val: 0.9314 test: 0.7259

====epoch 17
Train Loss 9.772435743190641
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9070 test: 0.6946 | best val epoch -- val: 0.9314 test: 0.7259

====epoch 18
Train Loss 9.010213273512615
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8888 test: 0.7093 | best val epoch -- val: 0.9314 test: 0.7259

====epoch 19
Train Loss 8.649259487448447
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9175 test: 0.7140 | best val epoch -- val: 0.9314 test: 0.7259

====epoch 20
Train Loss 8.514270048202084
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9108 test: 0.6980 | best val epoch -- val: 0.9314 test: 0.7259

====epoch 21
Train Loss 8.380083236637088
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8997 test: 0.6904 | best val epoch -- val: 0.9314 test: 0.7259

====epoch 22
Train Loss 7.939253776216354
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8953 test: 0.6970 | best val epoch -- val: 0.9314 test: 0.7259

====epoch 23
Train Loss 8.129571887148547
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9200 test: 0.7165 | best val epoch -- val: 0.9314 test: 0.7259

====epoch 24
Train Loss 8.419113042417123
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9187 test: 0.7187 | best val epoch -- val: 0.9314 test: 0.7259

====epoch 25
Train Loss 7.509315161755568
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9167 test: 0.7166 | best val epoch -- val: 0.9314 test: 0.7259

====epoch 26
Train Loss 7.580325651552455
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9226 test: 0.7121 | best val epoch -- val: 0.9314 test: 0.7259

====epoch 27
Train Loss 7.087573500868273
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9108 test: 0.7123 | best val epoch -- val: 0.9314 test: 0.7259

====epoch 28
Train Loss 7.891255823089014
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9079 test: 0.7093 | best val epoch -- val: 0.9314 test: 0.7259

====epoch 29
Train Loss 6.931808583685679
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9274 test: 0.7122 | best val epoch -- val: 0.9314 test: 0.7259

====epoch 30
Train Loss 6.97259580226542
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8936 test: 0.6872 | best val epoch -- val: 0.9314 test: 0.7259

====epoch 31
Train Loss 6.568643304740607
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9058 test: 0.7043 | best val epoch -- val: 0.9314 test: 0.7259

====epoch 32
Train Loss 7.128978431275597
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9122 test: 0.7102 | best val epoch -- val: 0.9314 test: 0.7259

====epoch 33
Train Loss 6.799629319739424
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9081 test: 0.6933 | best val epoch -- val: 0.9314 test: 0.7259

====epoch 34
Train Loss 7.096024236869618
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9177 test: 0.7103 | best val epoch -- val: 0.9314 test: 0.7259

====epoch 35
Train Loss 6.516571873421748
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8983 test: 0.6906 | best val epoch -- val: 0.9314 test: 0.7259

====epoch 36
Train Loss 6.275530013007202
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9194 test: 0.7001 | best val epoch -- val: 0.9314 test: 0.7259

====epoch 37
Train Loss 6.143227057427785
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8900 test: 0.6906 | best val epoch -- val: 0.9314 test: 0.7259

====epoch 38
Train Loss 5.0783938516735505
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9198 test: 0.7055 | best val epoch -- val: 0.9314 test: 0.7259

====epoch 39
Train Loss 6.041445621303726
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8922 test: 0.7027 | best val epoch -- val: 0.9314 test: 0.7259

====epoch 40
Train Loss 5.970317810528758
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9102 test: 0.7009 | best val epoch -- val: 0.9314 test: 0.7259

====epoch 41
Train Loss 5.755643891965863
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8990 test: 0.6798 | best val epoch -- val: 0.9314 test: 0.7259

====epoch 42
Train Loss 5.75116689104901
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9113 test: 0.6983 | best val epoch -- val: 0.9314 test: 0.7259

====epoch 43
Train Loss 5.430685055643195
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9107 test: 0.6891 | best val epoch -- val: 0.9314 test: 0.7259

====epoch 44
Train Loss 5.589780288230633
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9120 test: 0.6849 | best val epoch -- val: 0.9314 test: 0.7259

====epoch 45
Train Loss 5.5789035489487855
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9052 test: 0.6971 | best val epoch -- val: 0.9314 test: 0.7259

====epoch 46
Train Loss 5.501306971867913
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9207 test: 0.6979 | best val epoch -- val: 0.9314 test: 0.7259

====epoch 47
Train Loss 5.12966333070421
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9144 test: 0.6961 | best val epoch -- val: 0.9314 test: 0.7259

====epoch 48
Train Loss 5.334302719298977
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9089 test: 0.6934 | best val epoch -- val: 0.9314 test: 0.7259

====epoch 49
Train Loss 5.439166222767904
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8904 test: 0.6851 | best val epoch -- val: 0.9314 test: 0.7259

====epoch 50
Train Loss 4.800241147399803
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8982 test: 0.6787 | best val epoch -- val: 0.9314 test: 0.7259

====epoch 51
Train Loss 5.047120557406315
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9053 test: 0.6901 | best val epoch -- val: 0.9314 test: 0.7259

====epoch 52
Train Loss 5.143345572946369
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9063 test: 0.6831 | best val epoch -- val: 0.9314 test: 0.7259

====epoch 53
Train Loss 4.475944386954532
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9067 test: 0.6855 | best val epoch -- val: 0.9314 test: 0.7259

====epoch 54
Train Loss 4.58659629060952
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9148 test: 0.6864 | best val epoch -- val: 0.9314 test: 0.7259

====epoch 55
Train Loss 4.618658041242404
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9021 test: 0.6721 | best val epoch -- val: 0.9314 test: 0.7259

====epoch 56
Train Loss 5.208213178669829
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8943 test: 0.6780 | best val epoch -- val: 0.9314 test: 0.7259

====epoch 57
Train Loss 4.7542333828894625
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9106 test: 0.6813 | best val epoch -- val: 0.9314 test: 0.7259

====epoch 58
Train Loss 4.006531166728716
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9132 test: 0.6805 | best val epoch -- val: 0.9314 test: 0.7259

====epoch 59
Train Loss 4.6775791590823745
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8999 test: 0.6785 | best val epoch -- val: 0.9314 test: 0.7259

====epoch 60
Train Loss 4.778168211775631
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9038 test: 0.6861 | best val epoch -- val: 0.9314 test: 0.7259

====epoch 61
Train Loss 4.9159962397565256
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8864 test: 0.6761 | best val epoch -- val: 0.9314 test: 0.7259

====epoch 62
Train Loss 4.5043394420524345
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8985 test: 0.6734 | best val epoch -- val: 0.9314 test: 0.7259

====epoch 63
Train Loss 4.611219553101454
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9088 test: 0.6894 | best val epoch -- val: 0.9314 test: 0.7259

====epoch 64
Train Loss 3.7586034051575594
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9131 test: 0.6892 | best val epoch -- val: 0.9314 test: 0.7259

====epoch 65
Train Loss 4.061488759739727
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8979 test: 0.6654 | best val epoch -- val: 0.9314 test: 0.7259

====epoch 66
Train Loss 4.455655537036084
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9121 test: 0.6933 | best val epoch -- val: 0.9314 test: 0.7259

====epoch 67
Train Loss 4.0547110031608025
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9075 test: 0.6857 | best val epoch -- val: 0.9314 test: 0.7259

====epoch 68
Train Loss 3.3129616533001065
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8957 test: 0.6785 | best val epoch -- val: 0.9314 test: 0.7259

====epoch 69
Train Loss 4.205041210560432
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8879 test: 0.6782 | best val epoch -- val: 0.9314 test: 0.7259

====epoch 70
Train Loss 4.037892980511895
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8996 test: 0.6817 | best val epoch -- val: 0.9314 test: 0.7259

====epoch 71
Train Loss 4.014588767773498
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8941 test: 0.6750 | best val epoch -- val: 0.9314 test: 0.7259

====epoch 72
Train Loss 3.2724254606277374
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8905 test: 0.6780 | best val epoch -- val: 0.9314 test: 0.7259

====epoch 73
Train Loss 3.4154284730073026
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8906 test: 0.6756 | best val epoch -- val: 0.9314 test: 0.7259

====epoch 74
Train Loss 3.6147685050583163
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8918 test: 0.6850 | best val epoch -- val: 0.9314 test: 0.7259

====epoch 75
Train Loss 3.648714130806656
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9021 test: 0.6859 | best val epoch -- val: 0.9314 test: 0.7259

====epoch 76
Train Loss 3.375813052309067
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9026 test: 0.6739 | best val epoch -- val: 0.9314 test: 0.7259

====epoch 77
Train Loss 3.315611969711418
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8763 test: 0.6700 | best val epoch -- val: 0.9314 test: 0.7259

====epoch 78
Train Loss 3.167405320035293
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8745 test: 0.6704 | best val epoch -- val: 0.9314 test: 0.7259

====epoch 79
Train Loss 2.6472612715630337
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8771 test: 0.6692 | best val epoch -- val: 0.9314 test: 0.7259

====epoch 80
Train Loss 3.4095178616156865
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8960 test: 0.6736 | best val epoch -- val: 0.9314 test: 0.7259

====epoch 81
Train Loss 3.916779556745644
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9022 test: 0.6708 | best val epoch -- val: 0.9314 test: 0.7259

====epoch 82
Train Loss 2.76188859687026
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8804 test: 0.6661 | best val epoch -- val: 0.9314 test: 0.7259

====epoch 83
Train Loss 3.2285903108740714
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8635 test: 0.6690 | best val epoch -- val: 0.9314 test: 0.7259

====epoch 84
Train Loss 2.9485492754115232
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8794 test: 0.6603 | best val epoch -- val: 0.9314 test: 0.7259

====epoch 85
Train Loss 3.7833089371189503
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8612 test: 0.6546 | best val epoch -- val: 0.9314 test: 0.7259

====epoch 86
Train Loss 3.663382005442466
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8906 test: 0.6606 | best val epoch -- val: 0.9314 test: 0.7259

====epoch 87
Train Loss 3.003032402817057
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8853 test: 0.6626 | best val epoch -- val: 0.9314 test: 0.7259

====epoch 88
Train Loss 3.1126771135558413
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8927 test: 0.6638 | best val epoch -- val: 0.9314 test: 0.7259

====epoch 89
Train Loss 3.424392433249627
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8945 test: 0.6638 | best val epoch -- val: 0.9314 test: 0.7259

====epoch 90
Train Loss 2.831889448469492
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8704 test: 0.6561 | best val epoch -- val: 0.9314 test: 0.7259

====epoch 91
Train Loss 2.5470403260021257
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8616 test: 0.6506 | best val epoch -- val: 0.9314 test: 0.7259

====epoch 92
Train Loss 3.4202560960282864
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8711 test: 0.6509 | best val epoch -- val: 0.9314 test: 0.7259

====epoch 93
Train Loss 2.936196846853099
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8470 test: 0.6461 | best val epoch -- val: 0.9314 test: 0.7259

====epoch 94
Train Loss 3.021749636816116
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8837 test: 0.6695 | best val epoch -- val: 0.9314 test: 0.7259

====epoch 95
Train Loss 2.890580272827978
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8707 test: 0.6663 | best val epoch -- val: 0.9314 test: 0.7259

====epoch 96
Train Loss 2.920860596867701
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8709 test: 0.6676 | best val epoch -- val: 0.9314 test: 0.7259

====epoch 97
Train Loss 3.179685041219358
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8796 test: 0.6705 | best val epoch -- val: 0.9314 test: 0.7259

====epoch 98
Train Loss 2.6089723758510757
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8844 test: 0.6642 | best val epoch -- val: 0.9314 test: 0.7259

====epoch 99
Train Loss 2.747237912747274
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8757 test: 0.6692 | best val epoch -- val: 0.9314 test: 0.7259

====epoch 100
Train Loss 2.4017093088645285
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8592 test: 0.6558 | best val epoch -- val: 0.9314 test: 0.7259

WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.4.
[18:42:55] WARNING: not removing hydrogen atom without neighbors
[18:42:55] WARNING: not removing hydrogen atom without neighbors
[18:42:55] WARNING: not removing hydrogen atom without neighbors
[18:42:55] WARNING: not removing hydrogen atom without neighbors
[18:42:55] WARNING: not removing hydrogen atom without neighbors
[18:42:55] WARNING: not removing hydrogen atom without neighbors
[18:42:55] WARNING: not removing hydrogen atom without neighbors
[18:42:55] WARNING: not removing hydrogen atom without neighbors
[18:42:55] WARNING: not removing hydrogen atom without neighbors
[18:42:55] WARNING: not removing hydrogen atom without neighbors
[18:42:55] WARNING: not removing hydrogen atom without neighbors
[18:42:55] WARNING: not removing hydrogen atom without neighbors
[18:42:55] WARNING: not removing hydrogen atom without neighbors
[18:42:55] WARNING: not removing hydrogen atom without neighbors
[18:42:55] WARNING: not removing hydrogen atom without neighbors
[18:42:55] Conflicting single bond directions around double bond at index 1.
[18:42:55]   BondStereo set to STEREONONE and single bond directions set to NONE.
[18:42:55] WARNING: not removing hydrogen atom without neighbors
[18:42:55] WARNING: not removing hydrogen atom without neighbors
[18:42:55] WARNING: not removing hydrogen atom without neighbors
[18:42:55] WARNING: not removing hydrogen atom without neighbors
[18:42:55] WARNING: not removing hydrogen atom without neighbors
[18:42:55] WARNING: not removing hydrogen atom without neighbors
[18:42:55] WARNING: not removing hydrogen atom without neighbors
[18:42:55] WARNING: not removing hydrogen atom without neighbors
[18:42:55] WARNING: not removing hydrogen atom without neighbors
[18:42:55] WARNING: not removing hydrogen atom without neighbors
[18:42:55] WARNING: not removing hydrogen atom without neighbors
[18:42:55] WARNING: not removing hydrogen atom without neighbors
[18:42:55] WARNING: not removing hydrogen atom without neighbors
[18:42:55] WARNING: not removing hydrogen atom without neighbors
[18:42:55] WARNING: not removing hydrogen atom without neighbors
[18:42:56] WARNING: not removing hydrogen atom without neighbors
[18:42:56] WARNING: not removing hydrogen atom without neighbors
[18:42:56] WARNING: not removing hydrogen atom without neighbors
[18:42:56] WARNING: not removing hydrogen atom without neighbors
[18:42:56] WARNING: not removing hydrogen atom without neighbors
[18:42:56] WARNING: not removing hydrogen atom without neighbors
[18:42:56] WARNING: not removing hydrogen atom without neighbors
[18:42:56] WARNING: not removing hydrogen atom without neighbors
[18:42:56] WARNING: not removing hydrogen atom without neighbors
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.4.
[18:42:56] WARNING: not removing hydrogen atom without neighbors
2022-09-13 18:42:56.198 | INFO     | modules.masked_transformer_encoder:__init__:122 - number of parameters: 0.000000e+00
=========================================
batch_size = 32
d_model = 128
dataset = bbbp
decay = 0
device = 0
dim_feedforward = 512
eval_train = 0
filename =
gnn_JK = cat
gnn_dropout = 0.3
gnn_emb_dim = 300
gnn_num_layer = 5
gnn_residual = False
gnn_type = gin
gnn_virtual_node = False
graph_pooling = cls
input_model_file = models_graphtrans/graphtrans-sr-gcl.pth
lr = 0.0001
lr_scale = 1
max_input_len = 1000
nhead = 4
num_encoder_layers = 4
num_encoder_layers_masked = 0
num_workers = 0
pos_encoder = False
runseed = 7
seed = 12344
split = scaffold
transformer_activation = relu
transformer_dropout = 0.3
transformer_norm_input = True
transformer_prenorm = False
=========================================
bbbp
scaffold
Loaded GraphTrans from models_graphtrans/graphtrans-sr-gcl.pth
====epoch 1
Train Loss 24.57766973249895
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.5739 test: 0.5248 | best val epoch -- val: 0.5739 test: 0.5248

====epoch 2
Train Loss 20.68637679504887
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8438 test: 0.5974 | best val epoch -- val: 0.8438 test: 0.5974

====epoch 3
Train Loss 18.313151605118083
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9008 test: 0.6260 | best val epoch -- val: 0.9008 test: 0.6260

====epoch 4
Train Loss 16.026576019299238
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9021 test: 0.6402 | best val epoch -- val: 0.9021 test: 0.6402

====epoch 5
Train Loss 14.515786587412448
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9066 test: 0.6518 | best val epoch -- val: 0.9066 test: 0.6518

====epoch 6
Train Loss 13.039520384872716
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9038 test: 0.6686 | best val epoch -- val: 0.9066 test: 0.6518

====epoch 7
Train Loss 12.19081254596423
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8681 test: 0.6739 | best val epoch -- val: 0.9066 test: 0.6518

====epoch 8
Train Loss 11.76991562342772
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9105 test: 0.6847 | best val epoch -- val: 0.9105 test: 0.6847

====epoch 9
Train Loss 11.484208821678617
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8966 test: 0.6899 | best val epoch -- val: 0.9105 test: 0.6847

====epoch 10
Train Loss 10.670650611171201
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8981 test: 0.7017 | best val epoch -- val: 0.9105 test: 0.6847

====epoch 11
Train Loss 11.391628677676723
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9092 test: 0.7005 | best val epoch -- val: 0.9105 test: 0.6847

====epoch 12
Train Loss 10.213001302779844
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9088 test: 0.7157 | best val epoch -- val: 0.9105 test: 0.6847

====epoch 13
Train Loss 10.169800163690093
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8803 test: 0.7010 | best val epoch -- val: 0.9105 test: 0.6847

====epoch 14
Train Loss 9.950247622087689
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8954 test: 0.7111 | best val epoch -- val: 0.9105 test: 0.6847

====epoch 15
Train Loss 9.432245327191339
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8725 test: 0.7058 | best val epoch -- val: 0.9105 test: 0.6847

====epoch 16
Train Loss 9.810570877000405
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9006 test: 0.7166 | best val epoch -- val: 0.9105 test: 0.6847

====epoch 17
Train Loss 9.214712441370231
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8934 test: 0.7122 | best val epoch -- val: 0.9105 test: 0.6847

====epoch 18
Train Loss 9.154839174960426
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9038 test: 0.7188 | best val epoch -- val: 0.9105 test: 0.6847

====epoch 19
Train Loss 8.481102714093593
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8986 test: 0.7216 | best val epoch -- val: 0.9105 test: 0.6847

====epoch 20
Train Loss 8.073616793960303
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8990 test: 0.7244 | best val epoch -- val: 0.9105 test: 0.6847

====epoch 21
Train Loss 8.745666653944669
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8876 test: 0.7309 | best val epoch -- val: 0.9105 test: 0.6847

====epoch 22
Train Loss 9.01939509269421
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8889 test: 0.7332 | best val epoch -- val: 0.9105 test: 0.6847

====epoch 23
Train Loss 8.175961524261554
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8976 test: 0.7144 | best val epoch -- val: 0.9105 test: 0.6847

====epoch 24
Train Loss 7.817535837199938
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9033 test: 0.7178 | best val epoch -- val: 0.9105 test: 0.6847

====epoch 25
Train Loss 7.768713752153261
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9081 test: 0.7251 | best val epoch -- val: 0.9105 test: 0.6847

====epoch 26
Train Loss 7.660387392293487
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8978 test: 0.7163 | best val epoch -- val: 0.9105 test: 0.6847

====epoch 27
Train Loss 7.169596072811649
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9072 test: 0.7188 | best val epoch -- val: 0.9105 test: 0.6847

====epoch 28
Train Loss 7.681387454644597
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9118 test: 0.7133 | best val epoch -- val: 0.9118 test: 0.7133

====epoch 29
Train Loss 7.516937980528415
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9116 test: 0.7168 | best val epoch -- val: 0.9118 test: 0.7133

====epoch 30
Train Loss 7.4163259326231845
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9094 test: 0.7264 | best val epoch -- val: 0.9118 test: 0.7133

====epoch 31
Train Loss 6.964203722221212
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9045 test: 0.7177 | best val epoch -- val: 0.9118 test: 0.7133

====epoch 32
Train Loss 6.43538204493361
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9123 test: 0.7194 | best val epoch -- val: 0.9123 test: 0.7194

====epoch 33
Train Loss 6.878102951388256
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9123 test: 0.7127 | best val epoch -- val: 0.9123 test: 0.7194

====epoch 34
Train Loss 6.0405289998614835
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9180 test: 0.7105 | best val epoch -- val: 0.9180 test: 0.7105

====epoch 35
Train Loss 7.100209564119193
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9148 test: 0.7151 | best val epoch -- val: 0.9180 test: 0.7105

====epoch 36
Train Loss 6.382426045130376
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8991 test: 0.7079 | best val epoch -- val: 0.9180 test: 0.7105

====epoch 37
Train Loss 6.457929208537736
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8864 test: 0.6999 | best val epoch -- val: 0.9180 test: 0.7105

====epoch 38
Train Loss 6.039269905003443
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9032 test: 0.7080 | best val epoch -- val: 0.9180 test: 0.7105

====epoch 39
Train Loss 5.9881495094681165
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9011 test: 0.7151 | best val epoch -- val: 0.9180 test: 0.7105

====epoch 40
Train Loss 5.643135682652752
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8897 test: 0.7011 | best val epoch -- val: 0.9180 test: 0.7105

====epoch 41
Train Loss 6.2772356924776185
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8894 test: 0.6932 | best val epoch -- val: 0.9180 test: 0.7105

====epoch 42
Train Loss 6.432324677643252
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8890 test: 0.6948 | best val epoch -- val: 0.9180 test: 0.7105

====epoch 43
Train Loss 5.742500615113244
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8817 test: 0.6980 | best val epoch -- val: 0.9180 test: 0.7105

====epoch 44
Train Loss 5.846518575735988
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8796 test: 0.6913 | best val epoch -- val: 0.9180 test: 0.7105

====epoch 45
Train Loss 5.6539538119953905
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8606 test: 0.6874 | best val epoch -- val: 0.9180 test: 0.7105

====epoch 46
Train Loss 5.70706357111637
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8690 test: 0.6898 | best val epoch -- val: 0.9180 test: 0.7105

====epoch 47
Train Loss 5.360062920015962
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8881 test: 0.6963 | best val epoch -- val: 0.9180 test: 0.7105

====epoch 48
Train Loss 5.635927849457666
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8936 test: 0.7043 | best val epoch -- val: 0.9180 test: 0.7105

====epoch 49
Train Loss 5.8159966829230365
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8926 test: 0.7055 | best val epoch -- val: 0.9180 test: 0.7105

====epoch 50
Train Loss 5.4207099035544655
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8899 test: 0.7044 | best val epoch -- val: 0.9180 test: 0.7105

====epoch 51
Train Loss 5.309687366905645
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8891 test: 0.7038 | best val epoch -- val: 0.9180 test: 0.7105

====epoch 52
Train Loss 4.685963388925247
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8928 test: 0.7058 | best val epoch -- val: 0.9180 test: 0.7105

====epoch 53
Train Loss 5.290605286949918
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8836 test: 0.7011 | best val epoch -- val: 0.9180 test: 0.7105

====epoch 54
Train Loss 4.886278860440623
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8905 test: 0.7032 | best val epoch -- val: 0.9180 test: 0.7105

====epoch 55
Train Loss 4.773997526903405
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8892 test: 0.7024 | best val epoch -- val: 0.9180 test: 0.7105

====epoch 56
Train Loss 5.270297868781111
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8697 test: 0.7077 | best val epoch -- val: 0.9180 test: 0.7105

====epoch 57
Train Loss 4.8180230119905305
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9040 test: 0.7198 | best val epoch -- val: 0.9180 test: 0.7105

====epoch 58
Train Loss 4.567350679122671
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8980 test: 0.7162 | best val epoch -- val: 0.9180 test: 0.7105

====epoch 59
Train Loss 4.671867801998314
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8919 test: 0.7051 | best val epoch -- val: 0.9180 test: 0.7105

====epoch 60
Train Loss 4.805714202877366
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8916 test: 0.7101 | best val epoch -- val: 0.9180 test: 0.7105

====epoch 61
Train Loss 4.612570691989072
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8826 test: 0.7056 | best val epoch -- val: 0.9180 test: 0.7105

====epoch 62
Train Loss 5.173130699967731
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8860 test: 0.7003 | best val epoch -- val: 0.9180 test: 0.7105

====epoch 63
Train Loss 4.606923316035524
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8773 test: 0.6921 | best val epoch -- val: 0.9180 test: 0.7105

====epoch 64
Train Loss 4.327213718174357
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8832 test: 0.7064 | best val epoch -- val: 0.9180 test: 0.7105

====epoch 65
Train Loss 4.367650547814153
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8721 test: 0.7001 | best val epoch -- val: 0.9180 test: 0.7105

====epoch 66
Train Loss 4.782543025359786
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8877 test: 0.7092 | best val epoch -- val: 0.9180 test: 0.7105

====epoch 67
Train Loss 4.552890740161441
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8839 test: 0.7116 | best val epoch -- val: 0.9180 test: 0.7105

====epoch 68
Train Loss 4.264166819353142
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8853 test: 0.6996 | best val epoch -- val: 0.9180 test: 0.7105

====epoch 69
Train Loss 4.275296774039343
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9013 test: 0.7013 | best val epoch -- val: 0.9180 test: 0.7105

====epoch 70
Train Loss 4.425395410453214
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8969 test: 0.7024 | best val epoch -- val: 0.9180 test: 0.7105

====epoch 71
Train Loss 3.8975786443638825
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8956 test: 0.7005 | best val epoch -- val: 0.9180 test: 0.7105

====epoch 72
Train Loss 3.920617920610749
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8874 test: 0.6953 | best val epoch -- val: 0.9180 test: 0.7105

====epoch 73
Train Loss 3.9144620323354404
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8637 test: 0.6820 | best val epoch -- val: 0.9180 test: 0.7105

====epoch 74
Train Loss 4.239963763673481
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8877 test: 0.6925 | best val epoch -- val: 0.9180 test: 0.7105

====epoch 75
Train Loss 3.643418407874291
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8750 test: 0.6892 | best val epoch -- val: 0.9180 test: 0.7105

====epoch 76
Train Loss 3.5600879020889282
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8726 test: 0.6993 | best val epoch -- val: 0.9180 test: 0.7105

====epoch 77
Train Loss 4.190335273141163
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8801 test: 0.6967 | best val epoch -- val: 0.9180 test: 0.7105

====epoch 78
Train Loss 3.6276277636239507
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8720 test: 0.6975 | best val epoch -- val: 0.9180 test: 0.7105

====epoch 79
Train Loss 4.020161568264742
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8952 test: 0.7087 | best val epoch -- val: 0.9180 test: 0.7105

====epoch 80
Train Loss 3.511117957992595
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8853 test: 0.7010 | best val epoch -- val: 0.9180 test: 0.7105

====epoch 81
Train Loss 3.4915515283503895
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8937 test: 0.7010 | best val epoch -- val: 0.9180 test: 0.7105

====epoch 82
Train Loss 3.89505477357661
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8534 test: 0.6671 | best val epoch -- val: 0.9180 test: 0.7105

====epoch 83
Train Loss 3.6200535821291955
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8967 test: 0.6966 | best val epoch -- val: 0.9180 test: 0.7105

====epoch 84
Train Loss 3.3781583427442996
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8785 test: 0.6845 | best val epoch -- val: 0.9180 test: 0.7105

====epoch 85
Train Loss 3.338180823919611
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8935 test: 0.6912 | best val epoch -- val: 0.9180 test: 0.7105

====epoch 86
Train Loss 3.603630914070895
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8816 test: 0.6790 | best val epoch -- val: 0.9180 test: 0.7105

====epoch 87
Train Loss 3.5046802123950305
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8834 test: 0.6763 | best val epoch -- val: 0.9180 test: 0.7105

====epoch 88
Train Loss 3.837232950913692
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8672 test: 0.6738 | best val epoch -- val: 0.9180 test: 0.7105

====epoch 89
Train Loss 3.9531683849014985
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8866 test: 0.6875 | best val epoch -- val: 0.9180 test: 0.7105

====epoch 90
Train Loss 3.1765725473129773
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8520 test: 0.6732 | best val epoch -- val: 0.9180 test: 0.7105

====epoch 91
Train Loss 3.8732194898844514
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8744 test: 0.6761 | best val epoch -- val: 0.9180 test: 0.7105

====epoch 92
Train Loss 3.269939146394105
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8847 test: 0.6791 | best val epoch -- val: 0.9180 test: 0.7105

====epoch 93
Train Loss 3.033767515236165
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8781 test: 0.6811 | best val epoch -- val: 0.9180 test: 0.7105

====epoch 94
Train Loss 3.3130614590484213
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8747 test: 0.6839 | best val epoch -- val: 0.9180 test: 0.7105

====epoch 95
Train Loss 3.01374780617605
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8772 test: 0.6793 | best val epoch -- val: 0.9180 test: 0.7105

====epoch 96
Train Loss 2.7875802276399746
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8501 test: 0.6772 | best val epoch -- val: 0.9180 test: 0.7105

====epoch 97
Train Loss 3.229635945632021
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8669 test: 0.6731 | best val epoch -- val: 0.9180 test: 0.7105

====epoch 98
Train Loss 2.9150539700296583
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8871 test: 0.6748 | best val epoch -- val: 0.9180 test: 0.7105

====epoch 99
Train Loss 2.919403018630057
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8878 test: 0.6780 | best val epoch -- val: 0.9180 test: 0.7105

====epoch 100
Train Loss 2.816929657125709
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8873 test: 0.6700 | best val epoch -- val: 0.9180 test: 0.7105

[18:46:30] WARNING: not removing hydrogen atom without neighbors
[18:46:30] WARNING: not removing hydrogen atom without neighbors
[18:46:30] WARNING: not removing hydrogen atom without neighbors
[18:46:30] WARNING: not removing hydrogen atom without neighbors
[18:46:30] WARNING: not removing hydrogen atom without neighbors
[18:46:30] WARNING: not removing hydrogen atom without neighbors
[18:46:30] WARNING: not removing hydrogen atom without neighbors
[18:46:30] WARNING: not removing hydrogen atom without neighbors
[18:46:30] WARNING: not removing hydrogen atom without neighbors
[18:46:30] WARNING: not removing hydrogen atom without neighbors
[18:46:30] WARNING: not removing hydrogen atom without neighbors
[18:46:30] WARNING: not removing hydrogen atom without neighbors
[18:46:30] WARNING: not removing hydrogen atom without neighbors
[18:46:30] WARNING: not removing hydrogen atom without neighbors
[18:46:30] WARNING: not removing hydrogen atom without neighbors
[18:46:30] Conflicting single bond directions around double bond at index 1.
[18:46:30]   BondStereo set to STEREONONE and single bond directions set to NONE.
[18:46:30] WARNING: not removing hydrogen atom without neighbors
[18:46:30] WARNING: not removing hydrogen atom without neighbors
[18:46:30] WARNING: not removing hydrogen atom without neighbors
[18:46:30] WARNING: not removing hydrogen atom without neighbors
[18:46:30] WARNING: not removing hydrogen atom without neighbors
[18:46:30] WARNING: not removing hydrogen atom without neighbors
[18:46:30] WARNING: not removing hydrogen atom without neighbors
[18:46:30] WARNING: not removing hydrogen atom without neighbors
[18:46:30] WARNING: not removing hydrogen atom without neighbors
[18:46:30] WARNING: not removing hydrogen atom without neighbors
[18:46:30] WARNING: not removing hydrogen atom without neighbors
[18:46:30] WARNING: not removing hydrogen atom without neighbors
[18:46:31] WARNING: not removing hydrogen atom without neighbors
[18:46:31] WARNING: not removing hydrogen atom without neighbors
[18:46:31] WARNING: not removing hydrogen atom without neighbors
[18:46:31] WARNING: not removing hydrogen atom without neighbors
[18:46:31] WARNING: not removing hydrogen atom without neighbors
[18:46:31] WARNING: not removing hydrogen atom without neighbors
[18:46:31] WARNING: not removing hydrogen atom without neighbors
[18:46:31] WARNING: not removing hydrogen atom without neighbors
[18:46:31] WARNING: not removing hydrogen atom without neighbors
[18:46:31] WARNING: not removing hydrogen atom without neighbors
[18:46:31] WARNING: not removing hydrogen atom without neighbors
[18:46:31] WARNING: not removing hydrogen atom without neighbors
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.4.
[18:46:31] WARNING: not removing hydrogen atom without neighbors
2022-09-13 18:46:31.293 | INFO     | modules.masked_transformer_encoder:__init__:122 - number of parameters: 0.000000e+00
=========================================
batch_size = 32
d_model = 128
dataset = bbbp
decay = 0
device = 0
dim_feedforward = 512
eval_train = 0
filename =
gnn_JK = cat
gnn_dropout = 0.3
gnn_emb_dim = 300
gnn_num_layer = 5
gnn_residual = False
gnn_type = gin
gnn_virtual_node = False
graph_pooling = cls
input_model_file = models_graphtrans/graphtrans-sr-gcl.pth
lr = 0.0001
lr_scale = 1
max_input_len = 1000
nhead = 4
num_encoder_layers = 4
num_encoder_layers_masked = 0
num_workers = 0
pos_encoder = False
runseed = 8
seed = 12344
split = scaffold
transformer_activation = relu
transformer_dropout = 0.3
transformer_norm_input = True
transformer_prenorm = False
=========================================
bbbp
scaffold
Loaded GraphTrans from models_graphtrans/graphtrans-sr-gcl.pth
====epoch 1
Train Loss 25.285796711108578
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6932 test: 0.5018 | best val epoch -- val: 0.6932 test: 0.5018

====epoch 2
Train Loss 20.927309539331464
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9127 test: 0.5989 | best val epoch -- val: 0.9127 test: 0.5989

====epoch 3
Train Loss 18.641430393545818
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9138 test: 0.6220 | best val epoch -- val: 0.9138 test: 0.6220

====epoch 4
Train Loss 16.52671035476866
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9268 test: 0.6247 | best val epoch -- val: 0.9268 test: 0.6247

====epoch 5
Train Loss 14.694299391719193
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9334 test: 0.6597 | best val epoch -- val: 0.9334 test: 0.6597

====epoch 6
Train Loss 14.205060354752737
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9443 test: 0.6852 | best val epoch -- val: 0.9443 test: 0.6852

====epoch 7
Train Loss 13.227222090232782
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9297 test: 0.6911 | best val epoch -- val: 0.9443 test: 0.6852

====epoch 8
Train Loss 12.283155216056368
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9001 test: 0.6898 | best val epoch -- val: 0.9443 test: 0.6852

====epoch 9
Train Loss 11.717923128956174
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9170 test: 0.7130 | best val epoch -- val: 0.9443 test: 0.6852

====epoch 10
Train Loss 11.630586761268948
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9397 test: 0.7111 | best val epoch -- val: 0.9443 test: 0.6852

====epoch 11
Train Loss 11.509291700009413
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9441 test: 0.7211 | best val epoch -- val: 0.9443 test: 0.6852

====epoch 12
Train Loss 10.116712682333931
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9473 test: 0.7287 | best val epoch -- val: 0.9473 test: 0.7287

====epoch 13
Train Loss 10.7076667853288
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9466 test: 0.7380 | best val epoch -- val: 0.9473 test: 0.7287

====epoch 14
Train Loss 10.094598859112185
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9055 test: 0.7189 | best val epoch -- val: 0.9473 test: 0.7287

====epoch 15
Train Loss 9.523173062763831
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9095 test: 0.7173 | best val epoch -- val: 0.9473 test: 0.7287

====epoch 16
Train Loss 8.940378464856673
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9268 test: 0.7371 | best val epoch -- val: 0.9473 test: 0.7287

====epoch 17
Train Loss 9.28414205680412
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8958 test: 0.7378 | best val epoch -- val: 0.9473 test: 0.7287

====epoch 18
Train Loss 9.716382973067283
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9119 test: 0.7376 | best val epoch -- val: 0.9473 test: 0.7287

====epoch 19
Train Loss 9.042535784778515
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9339 test: 0.7378 | best val epoch -- val: 0.9473 test: 0.7287

====epoch 20
Train Loss 9.00918762098067
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9221 test: 0.7338 | best val epoch -- val: 0.9473 test: 0.7287

====epoch 21
Train Loss 8.820456354825401
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9340 test: 0.7423 | best val epoch -- val: 0.9473 test: 0.7287

====epoch 22
Train Loss 8.300031814813673
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9422 test: 0.7379 | best val epoch -- val: 0.9473 test: 0.7287

====epoch 23
Train Loss 8.147744109815722
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9265 test: 0.7340 | best val epoch -- val: 0.9473 test: 0.7287

====epoch 24
Train Loss 8.21529351130216
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9277 test: 0.7354 | best val epoch -- val: 0.9473 test: 0.7287

====epoch 25
Train Loss 7.638909659912227
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9314 test: 0.7399 | best val epoch -- val: 0.9473 test: 0.7287

====epoch 26
Train Loss 8.224733299594241
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9316 test: 0.7335 | best val epoch -- val: 0.9473 test: 0.7287

====epoch 27
Train Loss 7.560734471557929
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9164 test: 0.7213 | best val epoch -- val: 0.9473 test: 0.7287

====epoch 28
Train Loss 7.266336761677787
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9368 test: 0.7459 | best val epoch -- val: 0.9473 test: 0.7287

====epoch 29
Train Loss 7.263744450210397
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9080 test: 0.7386 | best val epoch -- val: 0.9473 test: 0.7287

====epoch 30
Train Loss 7.308063288356769
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9236 test: 0.7310 | best val epoch -- val: 0.9473 test: 0.7287

====epoch 31
Train Loss 7.225011521677593
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9284 test: 0.7361 | best val epoch -- val: 0.9473 test: 0.7287

====epoch 32
Train Loss 7.103796667122708
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9281 test: 0.7342 | best val epoch -- val: 0.9473 test: 0.7287

====epoch 33
Train Loss 6.7880256856356995
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9276 test: 0.7370 | best val epoch -- val: 0.9473 test: 0.7287

====epoch 34
Train Loss 6.720104166208112
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9250 test: 0.7234 | best val epoch -- val: 0.9473 test: 0.7287

====epoch 35
Train Loss 6.968864512974569
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9243 test: 0.7260 | best val epoch -- val: 0.9473 test: 0.7287

====epoch 36
Train Loss 6.383801956850272
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9088 test: 0.7270 | best val epoch -- val: 0.9473 test: 0.7287

====epoch 37
Train Loss 5.598590128699907
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9031 test: 0.7226 | best val epoch -- val: 0.9473 test: 0.7287

====epoch 38
Train Loss 6.444118751625948
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9069 test: 0.7219 | best val epoch -- val: 0.9473 test: 0.7287

====epoch 39
Train Loss 6.2583211283018265
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9200 test: 0.7229 | best val epoch -- val: 0.9473 test: 0.7287

====epoch 40
Train Loss 6.367972879188939
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9180 test: 0.7214 | best val epoch -- val: 0.9473 test: 0.7287

====epoch 41
Train Loss 6.763555505026507
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8952 test: 0.7085 | best val epoch -- val: 0.9473 test: 0.7287

====epoch 42
Train Loss 6.286719735937908
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9173 test: 0.7224 | best val epoch -- val: 0.9473 test: 0.7287

====epoch 43
Train Loss 6.649230401955158
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9172 test: 0.7251 | best val epoch -- val: 0.9473 test: 0.7287

====epoch 44
Train Loss 6.089108117898531
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9293 test: 0.7314 | best val epoch -- val: 0.9473 test: 0.7287

====epoch 45
Train Loss 4.839518554028921
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9264 test: 0.7348 | best val epoch -- val: 0.9473 test: 0.7287

====epoch 46
Train Loss 5.302041608533809
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9223 test: 0.7224 | best val epoch -- val: 0.9473 test: 0.7287

====epoch 47
Train Loss 5.50349072121707
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9257 test: 0.7305 | best val epoch -- val: 0.9473 test: 0.7287

====epoch 48
Train Loss 5.344459997821269
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9190 test: 0.7159 | best val epoch -- val: 0.9473 test: 0.7287

====epoch 49
Train Loss 5.520197802531317
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9184 test: 0.7228 | best val epoch -- val: 0.9473 test: 0.7287

====epoch 50
Train Loss 5.650349786119877
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9172 test: 0.7242 | best val epoch -- val: 0.9473 test: 0.7287

====epoch 51
Train Loss 4.771151794589111
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9142 test: 0.7273 | best val epoch -- val: 0.9473 test: 0.7287

====epoch 52
Train Loss 5.224841494303209
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9147 test: 0.7155 | best val epoch -- val: 0.9473 test: 0.7287

====epoch 53
Train Loss 5.444285669605339
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9020 test: 0.7069 | best val epoch -- val: 0.9473 test: 0.7287

====epoch 54
Train Loss 5.288351716392454
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9153 test: 0.7189 | best val epoch -- val: 0.9473 test: 0.7287

====epoch 55
Train Loss 5.140818364883772
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9121 test: 0.7320 | best val epoch -- val: 0.9473 test: 0.7287

====epoch 56
Train Loss 5.17688306804548
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9196 test: 0.7306 | best val epoch -- val: 0.9473 test: 0.7287

====epoch 57
Train Loss 4.915267651608491
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9218 test: 0.7279 | best val epoch -- val: 0.9473 test: 0.7287

====epoch 58
Train Loss 4.598224205917955
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9197 test: 0.7248 | best val epoch -- val: 0.9473 test: 0.7287

====epoch 59
Train Loss 4.094560522163662
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9068 test: 0.7218 | best val epoch -- val: 0.9473 test: 0.7287

====epoch 60
Train Loss 4.964155223198928
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9145 test: 0.7200 | best val epoch -- val: 0.9473 test: 0.7287

====epoch 61
Train Loss 5.247377952034065
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9094 test: 0.7203 | best val epoch -- val: 0.9473 test: 0.7287

====epoch 62
Train Loss 4.8979288715087925
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9078 test: 0.7209 | best val epoch -- val: 0.9473 test: 0.7287

====epoch 63
Train Loss 4.033100014197412
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9095 test: 0.7263 | best val epoch -- val: 0.9473 test: 0.7287

====epoch 64
Train Loss 4.910121644981609
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9021 test: 0.7036 | best val epoch -- val: 0.9473 test: 0.7287

====epoch 65
Train Loss 4.258044120976471
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9081 test: 0.7095 | best val epoch -- val: 0.9473 test: 0.7287

====epoch 66
Train Loss 3.8547829411381267
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9170 test: 0.7073 | best val epoch -- val: 0.9473 test: 0.7287

====epoch 67
Train Loss 4.378680739846706
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9114 test: 0.7154 | best val epoch -- val: 0.9473 test: 0.7287

====epoch 68
Train Loss 4.257232092369448
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9183 test: 0.7070 | best val epoch -- val: 0.9473 test: 0.7287

====epoch 69
Train Loss 4.382937593600172
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9144 test: 0.7008 | best val epoch -- val: 0.9473 test: 0.7287

====epoch 70
Train Loss 4.650883855604772
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9222 test: 0.7073 | best val epoch -- val: 0.9473 test: 0.7287

====epoch 71
Train Loss 4.190292038576159
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9014 test: 0.6964 | best val epoch -- val: 0.9473 test: 0.7287

====epoch 72
Train Loss 4.014885081248458
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9180 test: 0.7064 | best val epoch -- val: 0.9473 test: 0.7287

====epoch 73
Train Loss 4.640906265693812
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9092 test: 0.7026 | best val epoch -- val: 0.9473 test: 0.7287

====epoch 74
Train Loss 4.346544379944347
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9217 test: 0.7069 | best val epoch -- val: 0.9473 test: 0.7287

====epoch 75
Train Loss 4.039350846893656
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9209 test: 0.7069 | best val epoch -- val: 0.9473 test: 0.7287

====epoch 76
Train Loss 4.236780377808196
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9100 test: 0.7097 | best val epoch -- val: 0.9473 test: 0.7287

====epoch 77
Train Loss 3.788917661435363
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8989 test: 0.7005 | best val epoch -- val: 0.9473 test: 0.7287

====epoch 78
Train Loss 3.620005040390244
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9145 test: 0.7179 | best val epoch -- val: 0.9473 test: 0.7287

====epoch 79
Train Loss 4.355842470211558
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9163 test: 0.7083 | best val epoch -- val: 0.9473 test: 0.7287

====epoch 80
Train Loss 3.403784847621659
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9257 test: 0.7112 | best val epoch -- val: 0.9473 test: 0.7287

====epoch 81
Train Loss 3.88885620828539
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9258 test: 0.7208 | best val epoch -- val: 0.9473 test: 0.7287

====epoch 82
Train Loss 3.502393913230302
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9179 test: 0.7182 | best val epoch -- val: 0.9473 test: 0.7287

====epoch 83
Train Loss 3.6515890298909723
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9072 test: 0.7091 | best val epoch -- val: 0.9473 test: 0.7287

====epoch 84
Train Loss 3.4797188413992135
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9052 test: 0.7160 | best val epoch -- val: 0.9473 test: 0.7287

====epoch 85
Train Loss 3.496863369475869
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9027 test: 0.7093 | best val epoch -- val: 0.9473 test: 0.7287

====epoch 86
Train Loss 3.3778943301666478
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9170 test: 0.6962 | best val epoch -- val: 0.9473 test: 0.7287

====epoch 87
Train Loss 3.2827675766456115
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9093 test: 0.6977 | best val epoch -- val: 0.9473 test: 0.7287

====epoch 88
Train Loss 2.9689726735955677
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9181 test: 0.6963 | best val epoch -- val: 0.9473 test: 0.7287

====epoch 89
Train Loss 3.79791920134847
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9063 test: 0.6955 | best val epoch -- val: 0.9473 test: 0.7287

====epoch 90
Train Loss 3.6387554031334877
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9112 test: 0.7015 | best val epoch -- val: 0.9473 test: 0.7287

====epoch 91
Train Loss 3.6048579927061524
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9155 test: 0.6960 | best val epoch -- val: 0.9473 test: 0.7287

====epoch 92
Train Loss 3.4820437661145975
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9235 test: 0.7009 | best val epoch -- val: 0.9473 test: 0.7287

====epoch 93
Train Loss 3.6005158491113565
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9098 test: 0.6924 | best val epoch -- val: 0.9473 test: 0.7287

====epoch 94
Train Loss 3.2393984278412935
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9123 test: 0.6992 | best val epoch -- val: 0.9473 test: 0.7287

====epoch 95
Train Loss 3.324164863900057
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9089 test: 0.6997 | best val epoch -- val: 0.9473 test: 0.7287

====epoch 96
Train Loss 3.1802989037848683
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9217 test: 0.7061 | best val epoch -- val: 0.9473 test: 0.7287

====epoch 97
Train Loss 2.5877189493260095
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9084 test: 0.7004 | best val epoch -- val: 0.9473 test: 0.7287

====epoch 98
Train Loss 2.8888409979187566
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9227 test: 0.7057 | best val epoch -- val: 0.9473 test: 0.7287

====epoch 99
Train Loss 3.262438353023574
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9156 test: 0.7070 | best val epoch -- val: 0.9473 test: 0.7287

====epoch 100
Train Loss 2.785353463029537
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9155 test: 0.7005 | best val epoch -- val: 0.9473 test: 0.7287

[18:50:13] WARNING: not removing hydrogen atom without neighbors
[18:50:13] WARNING: not removing hydrogen atom without neighbors
[18:50:13] WARNING: not removing hydrogen atom without neighbors
[18:50:13] WARNING: not removing hydrogen atom without neighbors
[18:50:13] WARNING: not removing hydrogen atom without neighbors
[18:50:13] WARNING: not removing hydrogen atom without neighbors
[18:50:13] WARNING: not removing hydrogen atom without neighbors
[18:50:13] WARNING: not removing hydrogen atom without neighbors
[18:50:13] WARNING: not removing hydrogen atom without neighbors
[18:50:13] WARNING: not removing hydrogen atom without neighbors
[18:50:13] WARNING: not removing hydrogen atom without neighbors
[18:50:13] WARNING: not removing hydrogen atom without neighbors
[18:50:13] WARNING: not removing hydrogen atom without neighbors
[18:50:13] WARNING: not removing hydrogen atom without neighbors
[18:50:14] WARNING: not removing hydrogen atom without neighbors
[18:50:14] Conflicting single bond directions around double bond at index 1.
[18:50:14]   BondStereo set to STEREONONE and single bond directions set to NONE.
[18:50:14] WARNING: not removing hydrogen atom without neighbors
[18:50:14] WARNING: not removing hydrogen atom without neighbors
[18:50:14] WARNING: not removing hydrogen atom without neighbors
[18:50:14] WARNING: not removing hydrogen atom without neighbors
[18:50:14] WARNING: not removing hydrogen atom without neighbors
[18:50:14] WARNING: not removing hydrogen atom without neighbors
[18:50:14] WARNING: not removing hydrogen atom without neighbors
[18:50:14] WARNING: not removing hydrogen atom without neighbors
[18:50:14] WARNING: not removing hydrogen atom without neighbors
[18:50:14] WARNING: not removing hydrogen atom without neighbors
[18:50:14] WARNING: not removing hydrogen atom without neighbors
[18:50:14] WARNING: not removing hydrogen atom without neighbors
[18:50:14] WARNING: not removing hydrogen atom without neighbors
[18:50:14] WARNING: not removing hydrogen atom without neighbors
[18:50:14] WARNING: not removing hydrogen atom without neighbors
[18:50:14] WARNING: not removing hydrogen atom without neighbors
[18:50:14] WARNING: not removing hydrogen atom without neighbors
[18:50:14] WARNING: not removing hydrogen atom without neighbors
[18:50:14] WARNING: not removing hydrogen atom without neighbors
[18:50:14] WARNING: not removing hydrogen atom without neighbors
[18:50:14] WARNING: not removing hydrogen atom without neighbors
[18:50:14] WARNING: not removing hydrogen atom without neighbors
[18:50:14] WARNING: not removing hydrogen atom without neighbors
[18:50:14] WARNING: not removing hydrogen atom without neighbors
[18:50:14] WARNING: not removing hydrogen atom without neighbors
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.4.
2022-09-13 18:50:14.548 | INFO     | modules.masked_transformer_encoder:__init__:122 - number of parameters: 0.000000e+00
=========================================
batch_size = 32
d_model = 128
dataset = bbbp
decay = 0
device = 0
dim_feedforward = 512
eval_train = 0
filename =
gnn_JK = cat
gnn_dropout = 0.3
gnn_emb_dim = 300
gnn_num_layer = 5
gnn_residual = False
gnn_type = gin
gnn_virtual_node = False
graph_pooling = cls
input_model_file = models_graphtrans/graphtrans-sr-gcl.pth
lr = 0.0001
lr_scale = 1
max_input_len = 1000
nhead = 4
num_encoder_layers = 4
num_encoder_layers_masked = 0
num_workers = 0
pos_encoder = False
runseed = 9
seed = 12344
split = scaffold
transformer_activation = relu
transformer_dropout = 0.3
transformer_norm_input = True
transformer_prenorm = False
=========================================
bbbp
scaffold
Loaded GraphTrans from models_graphtrans/graphtrans-sr-gcl.pth
====epoch 1
Train Loss 24.421493060714607
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.5598 test: 0.5243 | best val epoch -- val: 0.5598 test: 0.5243

====epoch 2
Train Loss 20.95122568156973
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8699 test: 0.6151 | best val epoch -- val: 0.8699 test: 0.6151

====epoch 3
Train Loss 18.35577386133896
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8953 test: 0.6252 | best val epoch -- val: 0.8953 test: 0.6252

====epoch 4
Train Loss 15.112576451245712
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9051 test: 0.6532 | best val epoch -- val: 0.9051 test: 0.6532

====epoch 5
Train Loss 13.74322338386513
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9179 test: 0.6796 | best val epoch -- val: 0.9179 test: 0.6796

====epoch 6
Train Loss 13.462221932843333
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9366 test: 0.7164 | best val epoch -- val: 0.9366 test: 0.7164

====epoch 7
Train Loss 12.57042703721093
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9263 test: 0.7115 | best val epoch -- val: 0.9366 test: 0.7164

====epoch 8
Train Loss 11.917941885850485
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9143 test: 0.7060 | best val epoch -- val: 0.9366 test: 0.7164

====epoch 9
Train Loss 10.834774314923534
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9213 test: 0.7301 | best val epoch -- val: 0.9366 test: 0.7164

====epoch 10
Train Loss 10.786360454992321
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9283 test: 0.7300 | best val epoch -- val: 0.9366 test: 0.7164

====epoch 11
Train Loss 10.278161444147088
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9068 test: 0.7273 | best val epoch -- val: 0.9366 test: 0.7164

====epoch 12
Train Loss 10.260063010908858
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9216 test: 0.7290 | best val epoch -- val: 0.9366 test: 0.7164

====epoch 13
Train Loss 9.672827069515817
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9206 test: 0.7300 | best val epoch -- val: 0.9366 test: 0.7164

====epoch 14
Train Loss 9.134354702287208
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9189 test: 0.7221 | best val epoch -- val: 0.9366 test: 0.7164

====epoch 15
Train Loss 9.419937678591475
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9310 test: 0.7219 | best val epoch -- val: 0.9366 test: 0.7164

====epoch 16
Train Loss 9.04354509328699
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8977 test: 0.7146 | best val epoch -- val: 0.9366 test: 0.7164

====epoch 17
Train Loss 8.771319103513397
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9214 test: 0.7177 | best val epoch -- val: 0.9366 test: 0.7164

====epoch 18
Train Loss 8.057055591695095
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9039 test: 0.7248 | best val epoch -- val: 0.9366 test: 0.7164

====epoch 19
Train Loss 8.42987253064783
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9056 test: 0.7107 | best val epoch -- val: 0.9366 test: 0.7164

====epoch 20
Train Loss 8.846872165374846
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9027 test: 0.7114 | best val epoch -- val: 0.9366 test: 0.7164

====epoch 21
Train Loss 7.907991815953809
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8971 test: 0.7089 | best val epoch -- val: 0.9366 test: 0.7164

====epoch 22
Train Loss 7.702505858940093
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8891 test: 0.7100 | best val epoch -- val: 0.9366 test: 0.7164

====epoch 23
Train Loss 7.41612109336064
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8841 test: 0.7269 | best val epoch -- val: 0.9366 test: 0.7164

====epoch 24
Train Loss 7.825822811530662
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9109 test: 0.7200 | best val epoch -- val: 0.9366 test: 0.7164

====epoch 25
Train Loss 7.0075663179529055
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8914 test: 0.7249 | best val epoch -- val: 0.9366 test: 0.7164

====epoch 26
Train Loss 7.953439850197763
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8804 test: 0.7230 | best val epoch -- val: 0.9366 test: 0.7164

====epoch 27
Train Loss 6.680629840177806
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8619 test: 0.7139 | best val epoch -- val: 0.9366 test: 0.7164

====epoch 28
Train Loss 7.173142334911531
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8769 test: 0.7178 | best val epoch -- val: 0.9366 test: 0.7164

====epoch 29
Train Loss 7.903107373511581
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8842 test: 0.7141 | best val epoch -- val: 0.9366 test: 0.7164

====epoch 30
Train Loss 7.28179732106408
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8922 test: 0.7096 | best val epoch -- val: 0.9366 test: 0.7164

====epoch 31
Train Loss 6.433878744772937
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8913 test: 0.7212 | best val epoch -- val: 0.9366 test: 0.7164

====epoch 32
Train Loss 6.73592784640514
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8567 test: 0.6999 | best val epoch -- val: 0.9366 test: 0.7164

====epoch 33
Train Loss 6.575513543568591
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8753 test: 0.7019 | best val epoch -- val: 0.9366 test: 0.7164

====epoch 34
Train Loss 6.449426810907331
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8977 test: 0.7141 | best val epoch -- val: 0.9366 test: 0.7164

====epoch 35
Train Loss 6.548033652930675
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8658 test: 0.6941 | best val epoch -- val: 0.9366 test: 0.7164

====epoch 36
Train Loss 6.363814380795199
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9016 test: 0.7221 | best val epoch -- val: 0.9366 test: 0.7164

====epoch 37
Train Loss 5.864090030495696
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8754 test: 0.7043 | best val epoch -- val: 0.9366 test: 0.7164

====epoch 38
Train Loss 6.450977979394006
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8712 test: 0.7021 | best val epoch -- val: 0.9366 test: 0.7164

====epoch 39
Train Loss 5.990707788796829
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8952 test: 0.7075 | best val epoch -- val: 0.9366 test: 0.7164

====epoch 40
Train Loss 7.1371686563462315
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8853 test: 0.6997 | best val epoch -- val: 0.9366 test: 0.7164

====epoch 41
Train Loss 5.9871159875115785
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8831 test: 0.7110 | best val epoch -- val: 0.9366 test: 0.7164

====epoch 42
Train Loss 5.41514715824674
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8909 test: 0.7156 | best val epoch -- val: 0.9366 test: 0.7164

====epoch 43
Train Loss 6.0701865266192305
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8968 test: 0.7206 | best val epoch -- val: 0.9366 test: 0.7164

====epoch 44
Train Loss 5.651890306384492
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8984 test: 0.7144 | best val epoch -- val: 0.9366 test: 0.7164

====epoch 45
Train Loss 5.493492915746931
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8981 test: 0.7189 | best val epoch -- val: 0.9366 test: 0.7164

====epoch 46
Train Loss 5.918341548704306
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8966 test: 0.7124 | best val epoch -- val: 0.9366 test: 0.7164

====epoch 47
Train Loss 5.48166418914745
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9035 test: 0.7105 | best val epoch -- val: 0.9366 test: 0.7164

====epoch 48
Train Loss 5.064395549504046
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8949 test: 0.7119 | best val epoch -- val: 0.9366 test: 0.7164

====epoch 49
Train Loss 5.601575648905942
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8834 test: 0.7073 | best val epoch -- val: 0.9366 test: 0.7164

====epoch 50
Train Loss 5.481065580498974
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8867 test: 0.7074 | best val epoch -- val: 0.9366 test: 0.7164

====epoch 51
Train Loss 4.856380357164857
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8941 test: 0.7051 | best val epoch -- val: 0.9366 test: 0.7164

====epoch 52
Train Loss 4.566103125393979
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8934 test: 0.7050 | best val epoch -- val: 0.9366 test: 0.7164

====epoch 53
Train Loss 4.112847238720082
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8939 test: 0.7065 | best val epoch -- val: 0.9366 test: 0.7164

====epoch 54
Train Loss 4.26910723841135
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8944 test: 0.6970 | best val epoch -- val: 0.9366 test: 0.7164

====epoch 55
Train Loss 4.455943429133028
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8989 test: 0.7010 | best val epoch -- val: 0.9366 test: 0.7164

====epoch 56
Train Loss 4.209465330500133
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8850 test: 0.6957 | best val epoch -- val: 0.9366 test: 0.7164

====epoch 57
Train Loss 4.932265451496373
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8963 test: 0.6956 | best val epoch -- val: 0.9366 test: 0.7164

====epoch 58
Train Loss 4.641813759825978
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8766 test: 0.6828 | best val epoch -- val: 0.9366 test: 0.7164

====epoch 59
Train Loss 4.481452802932479
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8727 test: 0.6697 | best val epoch -- val: 0.9366 test: 0.7164

====epoch 60
Train Loss 4.308728663846408
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8778 test: 0.6793 | best val epoch -- val: 0.9366 test: 0.7164

====epoch 61
Train Loss 3.857584190660701
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8843 test: 0.6763 | best val epoch -- val: 0.9366 test: 0.7164

====epoch 62
Train Loss 4.7169967269091
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8700 test: 0.6714 | best val epoch -- val: 0.9366 test: 0.7164

====epoch 63
Train Loss 4.098960745308392
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8921 test: 0.6825 | best val epoch -- val: 0.9366 test: 0.7164

====epoch 64
Train Loss 3.72999507104437
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8814 test: 0.6769 | best val epoch -- val: 0.9366 test: 0.7164

====epoch 65
Train Loss 3.525578289212679
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8800 test: 0.6777 | best val epoch -- val: 0.9366 test: 0.7164

====epoch 66
Train Loss 4.6470897819869235
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8900 test: 0.6834 | best val epoch -- val: 0.9366 test: 0.7164

====epoch 67
Train Loss 3.678885059060899
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8761 test: 0.6818 | best val epoch -- val: 0.9366 test: 0.7164

====epoch 68
Train Loss 4.092827635946382
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8794 test: 0.6945 | best val epoch -- val: 0.9366 test: 0.7164

====epoch 69
Train Loss 3.9354262240701696
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8686 test: 0.6792 | best val epoch -- val: 0.9366 test: 0.7164

====epoch 70
Train Loss 4.068383152793889
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8722 test: 0.6804 | best val epoch -- val: 0.9366 test: 0.7164

====epoch 71
Train Loss 4.091143593788095
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9019 test: 0.6836 | best val epoch -- val: 0.9366 test: 0.7164

====epoch 72
Train Loss 4.339784286327092
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8935 test: 0.6882 | best val epoch -- val: 0.9366 test: 0.7164

====epoch 73
Train Loss 3.676829764481193
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8875 test: 0.6807 | best val epoch -- val: 0.9366 test: 0.7164

====epoch 74
Train Loss 2.893951099692649
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8706 test: 0.6696 | best val epoch -- val: 0.9366 test: 0.7164

====epoch 75
Train Loss 3.7705221349328286
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8793 test: 0.6777 | best val epoch -- val: 0.9366 test: 0.7164

====epoch 76
Train Loss 3.609144275262008
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8674 test: 0.6644 | best val epoch -- val: 0.9366 test: 0.7164

====epoch 77
Train Loss 3.310118638248889
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8585 test: 0.6453 | best val epoch -- val: 0.9366 test: 0.7164

====epoch 78
Train Loss 4.31335083966262
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8757 test: 0.6770 | best val epoch -- val: 0.9366 test: 0.7164

====epoch 79
Train Loss 2.914401219074025
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8539 test: 0.6641 | best val epoch -- val: 0.9366 test: 0.7164

====epoch 80
Train Loss 4.046793810038935
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8517 test: 0.6617 | best val epoch -- val: 0.9366 test: 0.7164

====epoch 81
Train Loss 3.6348459247440097
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8656 test: 0.6596 | best val epoch -- val: 0.9366 test: 0.7164

====epoch 82
Train Loss 2.882036116048192
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8767 test: 0.6687 | best val epoch -- val: 0.9366 test: 0.7164

====epoch 83
Train Loss 3.4378707748803454
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8654 test: 0.6702 | best val epoch -- val: 0.9366 test: 0.7164

====epoch 84
Train Loss 3.815161150229172
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8934 test: 0.6784 | best val epoch -- val: 0.9366 test: 0.7164

====epoch 85
Train Loss 3.3072273666451504
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8812 test: 0.6782 | best val epoch -- val: 0.9366 test: 0.7164

====epoch 86
Train Loss 3.030808739299395
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8632 test: 0.6713 | best val epoch -- val: 0.9366 test: 0.7164

====epoch 87
Train Loss 3.393469088241812
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8613 test: 0.6666 | best val epoch -- val: 0.9366 test: 0.7164

====epoch 88
Train Loss 3.650153062504252
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8799 test: 0.6832 | best val epoch -- val: 0.9366 test: 0.7164

====epoch 89
Train Loss 2.628640563120749
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8725 test: 0.6882 | best val epoch -- val: 0.9366 test: 0.7164

====epoch 90
Train Loss 3.4013505077521136
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8602 test: 0.6674 | best val epoch -- val: 0.9366 test: 0.7164

====epoch 91
Train Loss 3.3687123325009725
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8779 test: 0.6798 | best val epoch -- val: 0.9366 test: 0.7164

====epoch 92
Train Loss 3.1252739853421967
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8819 test: 0.6888 | best val epoch -- val: 0.9366 test: 0.7164

====epoch 93
Train Loss 3.0772357098676353
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8797 test: 0.6812 | best val epoch -- val: 0.9366 test: 0.7164

====epoch 94
Train Loss 3.1354609344082807
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8875 test: 0.6931 | best val epoch -- val: 0.9366 test: 0.7164

====epoch 95
Train Loss 3.165565047332238
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8854 test: 0.6891 | best val epoch -- val: 0.9366 test: 0.7164

====epoch 96
Train Loss 2.926259153244105
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8723 test: 0.6731 | best val epoch -- val: 0.9366 test: 0.7164

====epoch 97
Train Loss 3.2284199906724367
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8865 test: 0.6867 | best val epoch -- val: 0.9366 test: 0.7164

====epoch 98
Train Loss 2.735139073254521
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8731 test: 0.6799 | best val epoch -- val: 0.9366 test: 0.7164

====epoch 99
Train Loss 2.6083536521573296
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8693 test: 0.6646 | best val epoch -- val: 0.9366 test: 0.7164

====epoch 100
Train Loss 3.1325668195135044
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8803 test: 0.6729 | best val epoch -- val: 0.9366 test: 0.7164

WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.4.
2022-09-13 18:54:14.673 | INFO     | modules.masked_transformer_encoder:__init__:122 - number of parameters: 0.000000e+00
=========================================
batch_size = 32
d_model = 128
dataset = muv
decay = 0
device = 0
dim_feedforward = 512
eval_train = 0
filename =
gnn_JK = cat
gnn_dropout = 0.3
gnn_emb_dim = 300
gnn_num_layer = 5
gnn_residual = False
gnn_type = gin
gnn_virtual_node = False
graph_pooling = cls
input_model_file = models_graphtrans/graphtrans-sr-gcl.pth
lr = 0.0001
lr_scale = 1
max_input_len = 1000
nhead = 4
num_encoder_layers = 4
num_encoder_layers_masked = 0
num_workers = 0
pos_encoder = False
runseed = 0
seed = 12344
split = scaffold
transformer_activation = relu
transformer_dropout = 0.3
transformer_norm_input = True
transformer_prenorm = False
=========================================
muv
scaffold
Loaded GraphTrans from models_graphtrans/graphtrans-sr-gcl.pth
====epoch 1
Train Loss 107.48760544105916
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.4231 test: 0.4364 | best val epoch -- val: 0.4231 test: 0.4364

====epoch 2
Train Loss 32.759453538076016
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.5349 test: 0.4772 | best val epoch -- val: 0.5349 test: 0.4772

====epoch 3
Train Loss 32.776417301429554
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.6475 test: 0.6222 | best val epoch -- val: 0.6475 test: 0.6222

====epoch 4
Train Loss 33.01323314161373
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7285 test: 0.7391 | best val epoch -- val: 0.7285 test: 0.7391

====epoch 5
Train Loss 31.219364364689373
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7197 test: 0.7839 | best val epoch -- val: 0.7285 test: 0.7391

====epoch 6
Train Loss 31.31460905745397
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7226 test: 0.6927 | best val epoch -- val: 0.7285 test: 0.7391

====epoch 7
Train Loss 29.891380473950445
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7614 test: 0.7126 | best val epoch -- val: 0.7614 test: 0.7126

====epoch 8
Train Loss 30.03405503181513
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7485 test: 0.7496 | best val epoch -- val: 0.7614 test: 0.7126

====epoch 9
Train Loss 28.842060436815675
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7806 test: 0.7526 | best val epoch -- val: 0.7806 test: 0.7526

====epoch 10
Train Loss 28.374259487875193
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7344 test: 0.7431 | best val epoch -- val: 0.7806 test: 0.7526

====epoch 11
Train Loss 27.694853081272793
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7458 test: 0.7546 | best val epoch -- val: 0.7806 test: 0.7526

====epoch 12
Train Loss 27.76720312659254
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7635 test: 0.7513 | best val epoch -- val: 0.7806 test: 0.7526

====epoch 13
Train Loss 27.085149091823556
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7580 test: 0.7327 | best val epoch -- val: 0.7806 test: 0.7526

====epoch 14
Train Loss 27.345032345297227
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7452 test: 0.6823 | best val epoch -- val: 0.7806 test: 0.7526

====epoch 15
Train Loss 26.447889947384756
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7473 test: 0.7142 | best val epoch -- val: 0.7806 test: 0.7526

====epoch 16
Train Loss 26.106720995413085
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7456 test: 0.7280 | best val epoch -- val: 0.7806 test: 0.7526

====epoch 17
Train Loss 26.722296626333936
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7551 test: 0.7720 | best val epoch -- val: 0.7806 test: 0.7526

====epoch 18
Train Loss 25.886791505130397
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7895 test: 0.7693 | best val epoch -- val: 0.7895 test: 0.7693

====epoch 19
Train Loss 25.86387715688495
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7613 test: 0.7726 | best val epoch -- val: 0.7895 test: 0.7693

====epoch 20
Train Loss 25.511142006821643
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7789 test: 0.7602 | best val epoch -- val: 0.7895 test: 0.7693

====epoch 21
Train Loss 25.291905290834674
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7926 test: 0.8007 | best val epoch -- val: 0.7926 test: 0.8007

====epoch 22
Train Loss 25.205573251839592
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7660 test: 0.7651 | best val epoch -- val: 0.7926 test: 0.8007

====epoch 23
Train Loss 24.854324380820838
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7858 test: 0.7915 | best val epoch -- val: 0.7926 test: 0.8007

====epoch 24
Train Loss 24.750277065203484
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7707 test: 0.7703 | best val epoch -- val: 0.7926 test: 0.8007

====epoch 25
Train Loss 23.886346825124395
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7922 test: 0.7657 | best val epoch -- val: 0.7926 test: 0.8007

====epoch 26
Train Loss 24.100585083933698
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7918 test: 0.7842 | best val epoch -- val: 0.7926 test: 0.8007

====epoch 27
Train Loss 23.998764204196288
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7933 test: 0.7554 | best val epoch -- val: 0.7933 test: 0.7554

====epoch 28
Train Loss 23.8238424800301
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7876 test: 0.7559 | best val epoch -- val: 0.7933 test: 0.7554

====epoch 29
Train Loss 23.400841593960266
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7791 test: 0.7329 | best val epoch -- val: 0.7933 test: 0.7554

====epoch 30
Train Loss 23.87009576771487
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7895 test: 0.7870 | best val epoch -- val: 0.7933 test: 0.7554

====epoch 31
Train Loss 23.03336707998227
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7999 test: 0.7498 | best val epoch -- val: 0.7999 test: 0.7498

====epoch 32
Train Loss 23.21302432295918
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7682 test: 0.7542 | best val epoch -- val: 0.7999 test: 0.7498

====epoch 33
Train Loss 22.797548386625724
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7825 test: 0.7602 | best val epoch -- val: 0.7999 test: 0.7498

====epoch 34
Train Loss 22.444200027541655
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7717 test: 0.7927 | best val epoch -- val: 0.7999 test: 0.7498

====epoch 35
Train Loss 22.46376066962461
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7887 test: 0.7662 | best val epoch -- val: 0.7999 test: 0.7498

====epoch 36
Train Loss 22.03849300557019
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7507 test: 0.7173 | best val epoch -- val: 0.7999 test: 0.7498

====epoch 37
Train Loss 21.74135826603542
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7809 test: 0.7634 | best val epoch -- val: 0.7999 test: 0.7498

====epoch 38
Train Loss 21.944481103477088
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7699 test: 0.7699 | best val epoch -- val: 0.7999 test: 0.7498

====epoch 39
Train Loss 21.725052768059058
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7817 test: 0.7521 | best val epoch -- val: 0.7999 test: 0.7498

====epoch 40
Train Loss 22.065826850683248
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7890 test: 0.7550 | best val epoch -- val: 0.7999 test: 0.7498

====epoch 41
Train Loss 21.698837043437123
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.8161 test: 0.7823 | best val epoch -- val: 0.8161 test: 0.7823

====epoch 42
Train Loss 21.499631618511053
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.8195 test: 0.7814 | best val epoch -- val: 0.8195 test: 0.7814

====epoch 43
Train Loss 21.192105776123075
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7954 test: 0.7663 | best val epoch -- val: 0.8195 test: 0.7814

====epoch 44
Train Loss 21.079237059965163
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7954 test: 0.7626 | best val epoch -- val: 0.8195 test: 0.7814

====epoch 45
Train Loss 20.979965941251184
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.8065 test: 0.8235 | best val epoch -- val: 0.8195 test: 0.7814

====epoch 46
Train Loss 20.078615764778284
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7587 test: 0.7971 | best val epoch -- val: 0.8195 test: 0.7814

====epoch 47
Train Loss 20.44168948596253
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.8011 test: 0.7683 | best val epoch -- val: 0.8195 test: 0.7814

====epoch 48
Train Loss 20.447732927021192
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7621 test: 0.7228 | best val epoch -- val: 0.8195 test: 0.7814

====epoch 49
Train Loss 20.083468267203468
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.8198 test: 0.7952 | best val epoch -- val: 0.8198 test: 0.7952

====epoch 50
Train Loss 20.10760150750171
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7742 test: 0.7572 | best val epoch -- val: 0.8198 test: 0.7952

WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.4.
2022-09-13 20:13:23.848 | INFO     | modules.masked_transformer_encoder:__init__:122 - number of parameters: 0.000000e+00
=========================================
batch_size = 32
d_model = 128
dataset = muv
decay = 0
device = 0
dim_feedforward = 512
eval_train = 0
filename =
gnn_JK = cat
gnn_dropout = 0.3
gnn_emb_dim = 300
gnn_num_layer = 5
gnn_residual = False
gnn_type = gin
gnn_virtual_node = False
graph_pooling = cls
input_model_file = models_graphtrans/graphtrans-sr-gcl.pth
lr = 0.0001
lr_scale = 1
max_input_len = 1000
nhead = 4
num_encoder_layers = 4
num_encoder_layers_masked = 0
num_workers = 0
pos_encoder = False
runseed = 1
seed = 12344
split = scaffold
transformer_activation = relu
transformer_dropout = 0.3
transformer_norm_input = True
transformer_prenorm = False
=========================================
muv
scaffold
Loaded GraphTrans from models_graphtrans/graphtrans-sr-gcl.pth
====epoch 1
Train Loss 106.31454107636509
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.5274 test: 0.5114 | best val epoch -- val: 0.5274 test: 0.5114

====epoch 2
Train Loss 32.724325506745494
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.5544 test: 0.5571 | best val epoch -- val: 0.5544 test: 0.5571

====epoch 3
Train Loss 33.05267530293852
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.6248 test: 0.5829 | best val epoch -- val: 0.6248 test: 0.5829

====epoch 4
Train Loss 32.50589247783368
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7572 test: 0.7057 | best val epoch -- val: 0.7572 test: 0.7057

====epoch 5
Train Loss 31.909340602389598
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7442 test: 0.6805 | best val epoch -- val: 0.7572 test: 0.7057

====epoch 6
Train Loss 31.1147992028431
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7614 test: 0.7080 | best val epoch -- val: 0.7614 test: 0.7080

====epoch 7
Train Loss 30.436597768546818
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7434 test: 0.7073 | best val epoch -- val: 0.7614 test: 0.7080

====epoch 8
Train Loss 30.191084892907806
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7119 test: 0.7049 | best val epoch -- val: 0.7614 test: 0.7080

====epoch 9
Train Loss 30.363082705471374
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7126 test: 0.6976 | best val epoch -- val: 0.7614 test: 0.7080

====epoch 10
Train Loss 29.626318268476247
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7445 test: 0.7208 | best val epoch -- val: 0.7614 test: 0.7080

====epoch 11
Train Loss 28.89190435766321
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7427 test: 0.7119 | best val epoch -- val: 0.7614 test: 0.7080

====epoch 12
Train Loss 28.5924392059944
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7454 test: 0.7347 | best val epoch -- val: 0.7614 test: 0.7080

====epoch 13
Train Loss 28.709234498661036
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7592 test: 0.7145 | best val epoch -- val: 0.7614 test: 0.7080

====epoch 14
Train Loss 28.291886428710118
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7553 test: 0.7343 | best val epoch -- val: 0.7614 test: 0.7080

====epoch 15
Train Loss 27.64805545962012
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7374 test: 0.7449 | best val epoch -- val: 0.7614 test: 0.7080

====epoch 16
Train Loss 27.793089689503052
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7764 test: 0.7568 | best val epoch -- val: 0.7764 test: 0.7568

====epoch 17
Train Loss 27.41578439684114
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7305 test: 0.7885 | best val epoch -- val: 0.7764 test: 0.7568

====epoch 18
Train Loss 27.359600865749748
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7379 test: 0.7833 | best val epoch -- val: 0.7764 test: 0.7568

====epoch 19
Train Loss 27.19377859147608
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7724 test: 0.7806 | best val epoch -- val: 0.7764 test: 0.7568

====epoch 20
Train Loss 26.927175444964035
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7821 test: 0.7756 | best val epoch -- val: 0.7821 test: 0.7756

====epoch 21
Train Loss 26.501439854011036
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7861 test: 0.7846 | best val epoch -- val: 0.7861 test: 0.7846

====epoch 22
Train Loss 25.905482697028095
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7545 test: 0.7838 | best val epoch -- val: 0.7861 test: 0.7846

====epoch 23
Train Loss 26.201347630079805
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.8038 test: 0.7790 | best val epoch -- val: 0.8038 test: 0.7790

====epoch 24
Train Loss 25.569928183202208
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7806 test: 0.7636 | best val epoch -- val: 0.8038 test: 0.7790

====epoch 25
Train Loss 25.64953260048781
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7603 test: 0.7437 | best val epoch -- val: 0.8038 test: 0.7790

====epoch 26
Train Loss 25.085802795369887
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7757 test: 0.7940 | best val epoch -- val: 0.8038 test: 0.7790

====epoch 27
Train Loss 25.299884212907635
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7347 test: 0.7615 | best val epoch -- val: 0.8038 test: 0.7790

====epoch 28
Train Loss 25.111550077829577
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.8020 test: 0.7856 | best val epoch -- val: 0.8038 test: 0.7790

====epoch 29
Train Loss 24.818125671172012
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7850 test: 0.7601 | best val epoch -- val: 0.8038 test: 0.7790

====epoch 30
Train Loss 24.678347146730925
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7831 test: 0.7454 | best val epoch -- val: 0.8038 test: 0.7790

====epoch 31
Train Loss 24.043459905533
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7346 test: 0.7518 | best val epoch -- val: 0.8038 test: 0.7790

====epoch 32
Train Loss 24.140308398483082
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7553 test: 0.7392 | best val epoch -- val: 0.8038 test: 0.7790

====epoch 33
Train Loss 24.310745320353433
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7617 test: 0.7711 | best val epoch -- val: 0.8038 test: 0.7790

====epoch 34
Train Loss 23.900923524583504
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7830 test: 0.7706 | best val epoch -- val: 0.8038 test: 0.7790

====epoch 35
Train Loss 23.606367079004936
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7881 test: 0.7784 | best val epoch -- val: 0.8038 test: 0.7790

====epoch 36
Train Loss 23.064175861640905
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7308 test: 0.7486 | best val epoch -- val: 0.8038 test: 0.7790

====epoch 37
Train Loss 23.366453296558543
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7891 test: 0.7608 | best val epoch -- val: 0.8038 test: 0.7790

====epoch 38
Train Loss 23.155379103216255
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7774 test: 0.7369 | best val epoch -- val: 0.8038 test: 0.7790

====epoch 39
Train Loss 23.725869710008602
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7860 test: 0.7510 | best val epoch -- val: 0.8038 test: 0.7790

====epoch 40
Train Loss 23.18581467406576
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7746 test: 0.7719 | best val epoch -- val: 0.8038 test: 0.7790

====epoch 41
Train Loss 22.6937285127184
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7253 test: 0.7497 | best val epoch -- val: 0.8038 test: 0.7790

====epoch 42
Train Loss 22.278464802213122
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7767 test: 0.7697 | best val epoch -- val: 0.8038 test: 0.7790

====epoch 43
Train Loss 22.474263867264717
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7683 test: 0.7532 | best val epoch -- val: 0.8038 test: 0.7790

====epoch 44
Train Loss 21.942445687238415
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7598 test: 0.7644 | best val epoch -- val: 0.8038 test: 0.7790

====epoch 45
Train Loss 21.999396508268042
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7665 test: 0.7563 | best val epoch -- val: 0.8038 test: 0.7790

====epoch 46
Train Loss 22.070909939653088
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7743 test: 0.7497 | best val epoch -- val: 0.8038 test: 0.7790

====epoch 47
Train Loss 21.528335152075062
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7678 test: 0.7611 | best val epoch -- val: 0.8038 test: 0.7790

====epoch 48
Train Loss 21.61573817360808
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7253 test: 0.7119 | best val epoch -- val: 0.8038 test: 0.7790

====epoch 49
Train Loss 21.403165300932457
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7339 test: 0.7510 | best val epoch -- val: 0.8038 test: 0.7790

====epoch 50
Train Loss 20.60772385398315
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7941 test: 0.7675 | best val epoch -- val: 0.8038 test: 0.7790

WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.4.
2022-09-13 21:34:26.379 | INFO     | modules.masked_transformer_encoder:__init__:122 - number of parameters: 0.000000e+00
=========================================
batch_size = 32
d_model = 128
dataset = muv
decay = 0
device = 0
dim_feedforward = 512
eval_train = 0
filename =
gnn_JK = cat
gnn_dropout = 0.3
gnn_emb_dim = 300
gnn_num_layer = 5
gnn_residual = False
gnn_type = gin
gnn_virtual_node = False
graph_pooling = cls
input_model_file = models_graphtrans/graphtrans-sr-gcl.pth
lr = 0.0001
lr_scale = 1
max_input_len = 1000
nhead = 4
num_encoder_layers = 4
num_encoder_layers_masked = 0
num_workers = 0
pos_encoder = False
runseed = 2
seed = 12344
split = scaffold
transformer_activation = relu
transformer_dropout = 0.3
transformer_norm_input = True
transformer_prenorm = False
=========================================
muv
scaffold
Loaded GraphTrans from models_graphtrans/graphtrans-sr-gcl.pth
====epoch 1
Train Loss 99.68540027732685
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.4977 test: 0.5064 | best val epoch -- val: 0.4977 test: 0.5064

====epoch 2
Train Loss 32.63709133344976
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.4971 test: 0.5824 | best val epoch -- val: 0.4977 test: 0.5064

====epoch 3
Train Loss 32.52874794404839
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.6137 test: 0.6497 | best val epoch -- val: 0.6137 test: 0.6497

====epoch 4
Train Loss 32.11093190796671
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7486 test: 0.7110 | best val epoch -- val: 0.7486 test: 0.7110

====epoch 5
Train Loss 31.439485403475924
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.6769 test: 0.6928 | best val epoch -- val: 0.7486 test: 0.7110

====epoch 6
Train Loss 30.646960143887593
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.6555 test: 0.7024 | best val epoch -- val: 0.7486 test: 0.7110

====epoch 7
Train Loss 30.561923302973113
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.6765 test: 0.6469 | best val epoch -- val: 0.7486 test: 0.7110

====epoch 8
Train Loss 30.181873775252235
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7140 test: 0.7329 | best val epoch -- val: 0.7486 test: 0.7110

====epoch 9
Train Loss 29.726985361952426
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7562 test: 0.7306 | best val epoch -- val: 0.7562 test: 0.7306

====epoch 10
Train Loss 28.725272634341465
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7443 test: 0.7304 | best val epoch -- val: 0.7562 test: 0.7306

====epoch 11
Train Loss 28.67566918135245
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7709 test: 0.7370 | best val epoch -- val: 0.7709 test: 0.7370

====epoch 12
Train Loss 28.27605808856189
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7879 test: 0.7487 | best val epoch -- val: 0.7879 test: 0.7487

====epoch 13
Train Loss 28.173294384386505
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7856 test: 0.7728 | best val epoch -- val: 0.7879 test: 0.7487

====epoch 14
Train Loss 27.724835484532903
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7523 test: 0.6979 | best val epoch -- val: 0.7879 test: 0.7487

====epoch 15
Train Loss 27.344261368479838
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7800 test: 0.7489 | best val epoch -- val: 0.7879 test: 0.7487

====epoch 16
Train Loss 27.135948715017197
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.8021 test: 0.7628 | best val epoch -- val: 0.8021 test: 0.7628

====epoch 17
Train Loss 26.781649983951205
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7798 test: 0.7503 | best val epoch -- val: 0.8021 test: 0.7628

====epoch 18
Train Loss 26.656541546854086
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7809 test: 0.7384 | best val epoch -- val: 0.8021 test: 0.7628

====epoch 19
Train Loss 26.86480609043657
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7444 test: 0.7051 | best val epoch -- val: 0.8021 test: 0.7628

====epoch 20
Train Loss 25.690487572197537
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7902 test: 0.7503 | best val epoch -- val: 0.8021 test: 0.7628

====epoch 21
Train Loss 25.769808071053504
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.8180 test: 0.7534 | best val epoch -- val: 0.8180 test: 0.7534

====epoch 22
Train Loss 25.561236805046608
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.8076 test: 0.7587 | best val epoch -- val: 0.8180 test: 0.7534

====epoch 23
Train Loss 25.82389137860946
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7995 test: 0.7899 | best val epoch -- val: 0.8180 test: 0.7534

====epoch 24
Train Loss 25.325100074467105
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.8106 test: 0.7717 | best val epoch -- val: 0.8180 test: 0.7534

====epoch 25
Train Loss 24.880183064693743
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7858 test: 0.7628 | best val epoch -- val: 0.8180 test: 0.7534

====epoch 26
Train Loss 24.832057194923216
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7684 test: 0.7466 | best val epoch -- val: 0.8180 test: 0.7534

====epoch 27
Train Loss 24.709574013534965
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.8063 test: 0.7575 | best val epoch -- val: 0.8180 test: 0.7534

====epoch 28
Train Loss 24.384707333578344
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.8140 test: 0.7346 | best val epoch -- val: 0.8180 test: 0.7534

====epoch 29
Train Loss 23.830824191937523
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.8056 test: 0.7791 | best val epoch -- val: 0.8180 test: 0.7534

====epoch 30
Train Loss 24.257097326911992
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.8163 test: 0.7710 | best val epoch -- val: 0.8180 test: 0.7534

====epoch 31
Train Loss 23.79544807101391
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7724 test: 0.7501 | best val epoch -- val: 0.8180 test: 0.7534

====epoch 32
Train Loss 23.739133765485708
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7819 test: 0.7894 | best val epoch -- val: 0.8180 test: 0.7534

====epoch 33
Train Loss 23.44340163524768
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7518 test: 0.7440 | best val epoch -- val: 0.8180 test: 0.7534

====epoch 34
Train Loss 23.812093705791096
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7775 test: 0.7769 | best val epoch -- val: 0.8180 test: 0.7534

====epoch 35
Train Loss 23.531712383200837
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7899 test: 0.7470 | best val epoch -- val: 0.8180 test: 0.7534

====epoch 36
Train Loss 22.932121601944434
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.8094 test: 0.7299 | best val epoch -- val: 0.8180 test: 0.7534

====epoch 37
Train Loss 22.74263150833817
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7806 test: 0.7715 | best val epoch -- val: 0.8180 test: 0.7534

====epoch 38
Train Loss 23.175788689833816
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7715 test: 0.7463 | best val epoch -- val: 0.8180 test: 0.7534

====epoch 39
Train Loss 22.823969643815854
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.8122 test: 0.7346 | best val epoch -- val: 0.8180 test: 0.7534

====epoch 40
Train Loss 22.772278183131146
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.8247 test: 0.7698 | best val epoch -- val: 0.8247 test: 0.7698

====epoch 41
Train Loss 22.445534537085432
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.8021 test: 0.7360 | best val epoch -- val: 0.8247 test: 0.7698

====epoch 42
Train Loss 21.894010854377434
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7957 test: 0.7508 | best val epoch -- val: 0.8247 test: 0.7698

====epoch 43
Train Loss 21.957471125085412
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7743 test: 0.7747 | best val epoch -- val: 0.8247 test: 0.7698

====epoch 44
Train Loss 21.581083976073764
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7901 test: 0.7441 | best val epoch -- val: 0.8247 test: 0.7698

====epoch 45
Train Loss 21.742637265396713
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.8092 test: 0.7370 | best val epoch -- val: 0.8247 test: 0.7698

====epoch 46
Train Loss 22.080372069611435
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.8064 test: 0.7564 | best val epoch -- val: 0.8247 test: 0.7698

====epoch 47
Train Loss 20.801338486198105
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7903 test: 0.7483 | best val epoch -- val: 0.8247 test: 0.7698

====epoch 48
Train Loss 21.16289072056058
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.8068 test: 0.7823 | best val epoch -- val: 0.8247 test: 0.7698

====epoch 49
Train Loss 21.009654709406696
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7967 test: 0.7532 | best val epoch -- val: 0.8247 test: 0.7698

====epoch 50
Train Loss 20.472325292790075
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.8135 test: 0.7685 | best val epoch -- val: 0.8247 test: 0.7698

WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.4.
2022-09-13 22:53:56.922 | INFO     | modules.masked_transformer_encoder:__init__:122 - number of parameters: 0.000000e+00
=========================================
batch_size = 32
d_model = 128
dataset = muv
decay = 0
device = 0
dim_feedforward = 512
eval_train = 0
filename =
gnn_JK = cat
gnn_dropout = 0.3
gnn_emb_dim = 300
gnn_num_layer = 5
gnn_residual = False
gnn_type = gin
gnn_virtual_node = False
graph_pooling = cls
input_model_file = models_graphtrans/graphtrans-sr-gcl.pth
lr = 0.0001
lr_scale = 1
max_input_len = 1000
nhead = 4
num_encoder_layers = 4
num_encoder_layers_masked = 0
num_workers = 0
pos_encoder = False
runseed = 3
seed = 12344
split = scaffold
transformer_activation = relu
transformer_dropout = 0.3
transformer_norm_input = True
transformer_prenorm = False
=========================================
muv
scaffold
Loaded GraphTrans from models_graphtrans/graphtrans-sr-gcl.pth
====epoch 1
Train Loss 112.00241423337148
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.4880 test: 0.5226 | best val epoch -- val: 0.4880 test: 0.5226

====epoch 2
Train Loss 32.89321504128271
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.5613 test: 0.5648 | best val epoch -- val: 0.5613 test: 0.5648

====epoch 3
Train Loss 32.48882975403775
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.6526 test: 0.5971 | best val epoch -- val: 0.6526 test: 0.5971

====epoch 4
Train Loss 32.561358479902886
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.6819 test: 0.5840 | best val epoch -- val: 0.6819 test: 0.5840

====epoch 5
Train Loss 31.573730597491128
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.6864 test: 0.7074 | best val epoch -- val: 0.6864 test: 0.7074

====epoch 6
Train Loss 31.2828002135267
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7573 test: 0.6701 | best val epoch -- val: 0.7573 test: 0.6701

====epoch 7
Train Loss 30.961349862012646
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7610 test: 0.7096 | best val epoch -- val: 0.7610 test: 0.7096

====epoch 8
Train Loss 30.213457492137742
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7390 test: 0.6724 | best val epoch -- val: 0.7610 test: 0.7096

====epoch 9
Train Loss 29.352202138599637
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7553 test: 0.7509 | best val epoch -- val: 0.7610 test: 0.7096

====epoch 10
Train Loss 28.979052186806538
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7618 test: 0.7692 | best val epoch -- val: 0.7618 test: 0.7692

====epoch 11
Train Loss 28.91424580958825
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7700 test: 0.7303 | best val epoch -- val: 0.7700 test: 0.7303

====epoch 12
Train Loss 28.2785835636419
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7830 test: 0.7922 | best val epoch -- val: 0.7830 test: 0.7922

====epoch 13
Train Loss 27.996810939569382
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7932 test: 0.7615 | best val epoch -- val: 0.7932 test: 0.7615

====epoch 14
Train Loss 27.831730047591254
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7880 test: 0.7616 | best val epoch -- val: 0.7932 test: 0.7615

====epoch 15
Train Loss 27.391322637952495
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7822 test: 0.7237 | best val epoch -- val: 0.7932 test: 0.7615

====epoch 16
Train Loss 27.248295752634437
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7655 test: 0.7864 | best val epoch -- val: 0.7932 test: 0.7615

====epoch 17
Train Loss 26.727434816319125
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.8083 test: 0.7781 | best val epoch -- val: 0.8083 test: 0.7781

====epoch 18
Train Loss 26.77444568302653
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7891 test: 0.7405 | best val epoch -- val: 0.8083 test: 0.7781

====epoch 19
Train Loss 26.421975369245875
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.8005 test: 0.7317 | best val epoch -- val: 0.8083 test: 0.7781

====epoch 20
Train Loss 26.21314382464406
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.8157 test: 0.7149 | best val epoch -- val: 0.8157 test: 0.7149

====epoch 21
Train Loss 25.35090394224852
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.8241 test: 0.7206 | best val epoch -- val: 0.8241 test: 0.7206

====epoch 22
Train Loss 25.79844127176404
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.8047 test: 0.6774 | best val epoch -- val: 0.8241 test: 0.7206

====epoch 23
Train Loss 25.00249016896656
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7866 test: 0.7381 | best val epoch -- val: 0.8241 test: 0.7206

====epoch 24
Train Loss 25.352827142871206
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7543 test: 0.6936 | best val epoch -- val: 0.8241 test: 0.7206

====epoch 25
Train Loss 25.79520113327227
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7976 test: 0.7164 | best val epoch -- val: 0.8241 test: 0.7206

====epoch 26
Train Loss 24.905217113730327
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.8112 test: 0.7370 | best val epoch -- val: 0.8241 test: 0.7206

====epoch 27
Train Loss 25.595981389604844
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7908 test: 0.7495 | best val epoch -- val: 0.8241 test: 0.7206

====epoch 28
Train Loss 24.466295232030685
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7970 test: 0.7219 | best val epoch -- val: 0.8241 test: 0.7206

====epoch 29
Train Loss 24.022201138327546
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7746 test: 0.6922 | best val epoch -- val: 0.8241 test: 0.7206

====epoch 30
Train Loss 24.662460427749174
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7776 test: 0.7381 | best val epoch -- val: 0.8241 test: 0.7206

====epoch 31
Train Loss 23.62715326804303
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7932 test: 0.7407 | best val epoch -- val: 0.8241 test: 0.7206

====epoch 32
Train Loss 23.9458482672131
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7783 test: 0.7411 | best val epoch -- val: 0.8241 test: 0.7206

====epoch 33
Train Loss 23.787711365507494
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7851 test: 0.7458 | best val epoch -- val: 0.8241 test: 0.7206

====epoch 34
Train Loss 23.76688350619871
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.8002 test: 0.7374 | best val epoch -- val: 0.8241 test: 0.7206

====epoch 35
Train Loss 23.71447329823088
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.8055 test: 0.7386 | best val epoch -- val: 0.8241 test: 0.7206

====epoch 36
Train Loss 23.566220898525387
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.8051 test: 0.7628 | best val epoch -- val: 0.8241 test: 0.7206

====epoch 37
Train Loss 22.82065659286521
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.8080 test: 0.7147 | best val epoch -- val: 0.8241 test: 0.7206

====epoch 38
Train Loss 23.364726872853904
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7868 test: 0.7348 | best val epoch -- val: 0.8241 test: 0.7206

====epoch 39
Train Loss 23.08539867080406
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.8072 test: 0.7248 | best val epoch -- val: 0.8241 test: 0.7206

====epoch 40
Train Loss 22.60947533238124
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.8118 test: 0.7534 | best val epoch -- val: 0.8241 test: 0.7206

====epoch 41
Train Loss 22.069125923391095
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7951 test: 0.7369 | best val epoch -- val: 0.8241 test: 0.7206

====epoch 42
Train Loss 22.561959094069966
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7918 test: 0.7466 | best val epoch -- val: 0.8241 test: 0.7206

====epoch 43
Train Loss 22.08451609596489
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.8245 test: 0.7846 | best val epoch -- val: 0.8245 test: 0.7846

====epoch 44
Train Loss 22.265666025586807
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.8136 test: 0.7412 | best val epoch -- val: 0.8245 test: 0.7846

====epoch 45
Train Loss 21.783514314535523
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7972 test: 0.7078 | best val epoch -- val: 0.8245 test: 0.7846

====epoch 46
Train Loss 22.140874024791014
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7693 test: 0.6814 | best val epoch -- val: 0.8245 test: 0.7846

====epoch 47
Train Loss 21.719316348983913
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7984 test: 0.7073 | best val epoch -- val: 0.8245 test: 0.7846

====epoch 48
Train Loss 21.908494068667885
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7895 test: 0.7132 | best val epoch -- val: 0.8245 test: 0.7846

====epoch 49
Train Loss 21.238788958714824
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.8233 test: 0.7196 | best val epoch -- val: 0.8245 test: 0.7846

====epoch 50
Train Loss 21.424882512796017
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7935 test: 0.6959 | best val epoch -- val: 0.8245 test: 0.7846

2022-09-14 00:12:45.093 | INFO     | modules.masked_transformer_encoder:__init__:122 - number of parameters: 0.000000e+00
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.4.
=========================================
batch_size = 32
d_model = 128
dataset = muv
decay = 0
device = 0
dim_feedforward = 512
eval_train = 0
filename =
gnn_JK = cat
gnn_dropout = 0.3
gnn_emb_dim = 300
gnn_num_layer = 5
gnn_residual = False
gnn_type = gin
gnn_virtual_node = False
graph_pooling = cls
input_model_file = models_graphtrans/graphtrans-sr-gcl.pth
lr = 0.0001
lr_scale = 1
max_input_len = 1000
nhead = 4
num_encoder_layers = 4
num_encoder_layers_masked = 0
num_workers = 0
pos_encoder = False
runseed = 4
seed = 12344
split = scaffold
transformer_activation = relu
transformer_dropout = 0.3
transformer_norm_input = True
transformer_prenorm = False
=========================================
muv
scaffold
Loaded GraphTrans from models_graphtrans/graphtrans-sr-gcl.pth
====epoch 1
Train Loss 108.39009068590298
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.4939 test: 0.4752 | best val epoch -- val: 0.4939 test: 0.4752

====epoch 2
Train Loss 32.88992305654303
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.5510 test: 0.4858 | best val epoch -- val: 0.5510 test: 0.4858

====epoch 3
Train Loss 32.37233413843566
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.6295 test: 0.6028 | best val epoch -- val: 0.6295 test: 0.6028

====epoch 4
Train Loss 32.47668566546559
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7011 test: 0.7013 | best val epoch -- val: 0.7011 test: 0.7013

====epoch 5
Train Loss 31.35539279623583
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7268 test: 0.6917 | best val epoch -- val: 0.7268 test: 0.6917

====epoch 6
Train Loss 30.47706720347761
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7141 test: 0.7626 | best val epoch -- val: 0.7268 test: 0.6917

====epoch 7
Train Loss 29.975099237383652
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.6984 test: 0.7054 | best val epoch -- val: 0.7268 test: 0.6917

====epoch 8
Train Loss 29.207882121305698
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7717 test: 0.7644 | best val epoch -- val: 0.7717 test: 0.7644

====epoch 9
Train Loss 28.518275607018207
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7177 test: 0.7392 | best val epoch -- val: 0.7717 test: 0.7644

====epoch 10
Train Loss 28.07990442778601
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7189 test: 0.7530 | best val epoch -- val: 0.7717 test: 0.7644

====epoch 11
Train Loss 27.759684479617327
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7551 test: 0.7183 | best val epoch -- val: 0.7717 test: 0.7644

====epoch 12
Train Loss 27.377919669014922
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7518 test: 0.6866 | best val epoch -- val: 0.7717 test: 0.7644

====epoch 13
Train Loss 27.37986278341888
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7740 test: 0.7721 | best val epoch -- val: 0.7740 test: 0.7721

====epoch 14
Train Loss 26.670535236808217
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7452 test: 0.7183 | best val epoch -- val: 0.7740 test: 0.7721

====epoch 15
Train Loss 25.880497767062906
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7627 test: 0.7310 | best val epoch -- val: 0.7740 test: 0.7721

====epoch 16
Train Loss 25.87329631832437
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7345 test: 0.7257 | best val epoch -- val: 0.7740 test: 0.7721

====epoch 17
Train Loss 25.42306697050076
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7847 test: 0.7195 | best val epoch -- val: 0.7847 test: 0.7195

====epoch 18
Train Loss 25.212952097838397
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7732 test: 0.7059 | best val epoch -- val: 0.7847 test: 0.7195

====epoch 19
Train Loss 24.78803671174146
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7783 test: 0.7253 | best val epoch -- val: 0.7847 test: 0.7195

====epoch 20
Train Loss 24.5801210809141
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7794 test: 0.7409 | best val epoch -- val: 0.7847 test: 0.7195

====epoch 21
Train Loss 23.978461089231963
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7553 test: 0.7275 | best val epoch -- val: 0.7847 test: 0.7195

====epoch 22
Train Loss 23.781786321727587
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7908 test: 0.7264 | best val epoch -- val: 0.7908 test: 0.7264

====epoch 23
Train Loss 23.741604657228006
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7909 test: 0.6851 | best val epoch -- val: 0.7909 test: 0.6851

====epoch 24
Train Loss 23.893406057575927
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7677 test: 0.7247 | best val epoch -- val: 0.7909 test: 0.6851

====epoch 25
Train Loss 22.9892284727481
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7814 test: 0.7004 | best val epoch -- val: 0.7909 test: 0.6851

====epoch 26
Train Loss 23.356885583445383
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.8027 test: 0.7583 | best val epoch -- val: 0.8027 test: 0.7583

====epoch 27
Train Loss 22.831556990944872
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7964 test: 0.6948 | best val epoch -- val: 0.8027 test: 0.7583

====epoch 28
Train Loss 22.584904506174368
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7667 test: 0.6644 | best val epoch -- val: 0.8027 test: 0.7583

====epoch 29
Train Loss 22.943432373337718
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7834 test: 0.7000 | best val epoch -- val: 0.8027 test: 0.7583

====epoch 30
Train Loss 22.410142710467863
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7825 test: 0.7114 | best val epoch -- val: 0.8027 test: 0.7583

====epoch 31
Train Loss 22.007270556015136
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7734 test: 0.7415 | best val epoch -- val: 0.8027 test: 0.7583

====epoch 32
Train Loss 22.031130283138303
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7933 test: 0.7398 | best val epoch -- val: 0.8027 test: 0.7583

====epoch 33
Train Loss 21.65800863208761
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7790 test: 0.7582 | best val epoch -- val: 0.8027 test: 0.7583

====epoch 34
Train Loss 21.551534046436412
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7605 test: 0.7050 | best val epoch -- val: 0.8027 test: 0.7583

====epoch 35
Train Loss 21.298392894946915
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7969 test: 0.7339 | best val epoch -- val: 0.8027 test: 0.7583

====epoch 36
Train Loss 21.073622656131455
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7559 test: 0.7158 | best val epoch -- val: 0.8027 test: 0.7583

====epoch 37
Train Loss 20.715208543432748
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7921 test: 0.7244 | best val epoch -- val: 0.8027 test: 0.7583

====epoch 38
Train Loss 20.916497357682122
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7387 test: 0.6873 | best val epoch -- val: 0.8027 test: 0.7583

====epoch 39
Train Loss 20.82366355068391
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7706 test: 0.7317 | best val epoch -- val: 0.8027 test: 0.7583

====epoch 40
Train Loss 20.457617897160045
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7657 test: 0.7592 | best val epoch -- val: 0.8027 test: 0.7583

====epoch 41
Train Loss 20.519738525669997
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7857 test: 0.7442 | best val epoch -- val: 0.8027 test: 0.7583

====epoch 42
Train Loss 19.630453547622885
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7675 test: 0.6845 | best val epoch -- val: 0.8027 test: 0.7583

====epoch 43
Train Loss 19.900109868371054
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7572 test: 0.6496 | best val epoch -- val: 0.8027 test: 0.7583

====epoch 44
Train Loss 19.582960243702274
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7533 test: 0.6983 | best val epoch -- val: 0.8027 test: 0.7583

====epoch 45
Train Loss 19.092326688536666
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7981 test: 0.7411 | best val epoch -- val: 0.8027 test: 0.7583

====epoch 46
Train Loss 19.265438778382943
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7439 test: 0.7443 | best val epoch -- val: 0.8027 test: 0.7583

====epoch 47
Train Loss 19.099745250710306
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7696 test: 0.7247 | best val epoch -- val: 0.8027 test: 0.7583

====epoch 48
Train Loss 18.92160910996031
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7795 test: 0.7425 | best val epoch -- val: 0.8027 test: 0.7583

====epoch 49
Train Loss 18.359543603274567
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7699 test: 0.7114 | best val epoch -- val: 0.8027 test: 0.7583

====epoch 50
Train Loss 18.852123585462866
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7504 test: 0.6999 | best val epoch -- val: 0.8027 test: 0.7583

WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.4.
2022-09-14 01:31:42.685 | INFO     | modules.masked_transformer_encoder:__init__:122 - number of parameters: 0.000000e+00
=========================================
batch_size = 32
d_model = 128
dataset = muv
decay = 0
device = 0
dim_feedforward = 512
eval_train = 0
filename =
gnn_JK = cat
gnn_dropout = 0.3
gnn_emb_dim = 300
gnn_num_layer = 5
gnn_residual = False
gnn_type = gin
gnn_virtual_node = False
graph_pooling = cls
input_model_file = models_graphtrans/graphtrans-sr-gcl.pth
lr = 0.0001
lr_scale = 1
max_input_len = 1000
nhead = 4
num_encoder_layers = 4
num_encoder_layers_masked = 0
num_workers = 0
pos_encoder = False
runseed = 5
seed = 12344
split = scaffold
transformer_activation = relu
transformer_dropout = 0.3
transformer_norm_input = True
transformer_prenorm = False
=========================================
muv
scaffold
Loaded GraphTrans from models_graphtrans/graphtrans-sr-gcl.pth
====epoch 1
Train Loss 103.3548514218285
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.4772 test: 0.4909 | best val epoch -- val: 0.4772 test: 0.4909

====epoch 2
Train Loss 32.70566505043834
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.4973 test: 0.4818 | best val epoch -- val: 0.4973 test: 0.4818

====epoch 3
Train Loss 32.07696666760895
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.6553 test: 0.5944 | best val epoch -- val: 0.6553 test: 0.5944

====epoch 4
Train Loss 32.210713500383456
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.6655 test: 0.6299 | best val epoch -- val: 0.6655 test: 0.6299

====epoch 5
Train Loss 31.917757433974433
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7202 test: 0.6950 | best val epoch -- val: 0.7202 test: 0.6950

====epoch 6
Train Loss 31.556370461081514
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7216 test: 0.6966 | best val epoch -- val: 0.7216 test: 0.6966

====epoch 7
Train Loss 30.9282666360027
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.6881 test: 0.6611 | best val epoch -- val: 0.7216 test: 0.6966

====epoch 8
Train Loss 30.132507758855418
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7248 test: 0.7097 | best val epoch -- val: 0.7248 test: 0.7097

====epoch 9
Train Loss 29.99882704102919
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7847 test: 0.7246 | best val epoch -- val: 0.7847 test: 0.7246

====epoch 10
Train Loss 29.824498686285004
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7608 test: 0.7084 | best val epoch -- val: 0.7847 test: 0.7246

====epoch 11
Train Loss 28.882442218481092
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7734 test: 0.7432 | best val epoch -- val: 0.7847 test: 0.7246

====epoch 12
Train Loss 28.535481295897284
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7939 test: 0.7441 | best val epoch -- val: 0.7939 test: 0.7441

====epoch 13
Train Loss 28.19711764753021
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7761 test: 0.7244 | best val epoch -- val: 0.7939 test: 0.7441

====epoch 14
Train Loss 28.139547745275898
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7830 test: 0.7689 | best val epoch -- val: 0.7939 test: 0.7441

====epoch 15
Train Loss 27.693055805750227
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7871 test: 0.7763 | best val epoch -- val: 0.7939 test: 0.7441

====epoch 16
Train Loss 27.83647170481294
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7731 test: 0.7518 | best val epoch -- val: 0.7939 test: 0.7441

====epoch 17
Train Loss 26.916510934938643
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7872 test: 0.7705 | best val epoch -- val: 0.7939 test: 0.7441

====epoch 18
Train Loss 26.77816219445552
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.8027 test: 0.7751 | best val epoch -- val: 0.8027 test: 0.7751

====epoch 19
Train Loss 26.855631069704646
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.8090 test: 0.7850 | best val epoch -- val: 0.8090 test: 0.7850

====epoch 20
Train Loss 26.688982171847467
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7942 test: 0.7889 | best val epoch -- val: 0.8090 test: 0.7850

====epoch 21
Train Loss 26.538774178447778
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.8095 test: 0.7896 | best val epoch -- val: 0.8095 test: 0.7896

====epoch 22
Train Loss 26.04791101988479
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.8051 test: 0.7747 | best val epoch -- val: 0.8095 test: 0.7896

====epoch 23
Train Loss 25.688567181405123
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7914 test: 0.7788 | best val epoch -- val: 0.8095 test: 0.7896

====epoch 24
Train Loss 25.59236812840099
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7839 test: 0.7706 | best val epoch -- val: 0.8095 test: 0.7896

====epoch 25
Train Loss 25.166747710292206
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7840 test: 0.7419 | best val epoch -- val: 0.8095 test: 0.7896

====epoch 26
Train Loss 25.128923747290933
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.8129 test: 0.7905 | best val epoch -- val: 0.8129 test: 0.7905

====epoch 27
Train Loss 25.261581059709396
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7990 test: 0.7574 | best val epoch -- val: 0.8129 test: 0.7905

====epoch 28
Train Loss 25.063798349930064
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7985 test: 0.7541 | best val epoch -- val: 0.8129 test: 0.7905

====epoch 29
Train Loss 24.695697878867122
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7961 test: 0.7496 | best val epoch -- val: 0.8129 test: 0.7905

====epoch 30
Train Loss 23.97173603256331
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.8031 test: 0.7531 | best val epoch -- val: 0.8129 test: 0.7905

====epoch 31
Train Loss 24.442133486930086
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.8041 test: 0.7562 | best val epoch -- val: 0.8129 test: 0.7905

====epoch 32
Train Loss 24.464026882307657
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7835 test: 0.7479 | best val epoch -- val: 0.8129 test: 0.7905

====epoch 33
Train Loss 23.19316815651285
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.8049 test: 0.7512 | best val epoch -- val: 0.8129 test: 0.7905

====epoch 34
Train Loss 23.835860145562982
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7982 test: 0.7252 | best val epoch -- val: 0.8129 test: 0.7905

====epoch 35
Train Loss 23.177143382208172
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7930 test: 0.7488 | best val epoch -- val: 0.8129 test: 0.7905

====epoch 36
Train Loss 23.196971475273834
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7821 test: 0.7752 | best val epoch -- val: 0.8129 test: 0.7905

====epoch 37
Train Loss 23.67051625966258
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7967 test: 0.7881 | best val epoch -- val: 0.8129 test: 0.7905

====epoch 38
Train Loss 23.38534411235665
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7667 test: 0.7418 | best val epoch -- val: 0.8129 test: 0.7905

====epoch 39
Train Loss 22.894855734585402
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7881 test: 0.7641 | best val epoch -- val: 0.8129 test: 0.7905

====epoch 40
Train Loss 23.40275363389583
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.8037 test: 0.7545 | best val epoch -- val: 0.8129 test: 0.7905

====epoch 41
Train Loss 22.55307895216886
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7947 test: 0.7540 | best val epoch -- val: 0.8129 test: 0.7905

====epoch 42
Train Loss 22.490885760223783
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7970 test: 0.7509 | best val epoch -- val: 0.8129 test: 0.7905

====epoch 43
Train Loss 22.444753914641357
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7790 test: 0.7723 | best val epoch -- val: 0.8129 test: 0.7905

====epoch 44
Train Loss 22.225649353812724
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7840 test: 0.7341 | best val epoch -- val: 0.8129 test: 0.7905

====epoch 45
Train Loss 21.953089687891204
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7723 test: 0.7060 | best val epoch -- val: 0.8129 test: 0.7905

====epoch 46
Train Loss 22.033856730103334
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7910 test: 0.7556 | best val epoch -- val: 0.8129 test: 0.7905

====epoch 47
Train Loss 22.135991458818282
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7524 test: 0.7397 | best val epoch -- val: 0.8129 test: 0.7905

====epoch 48
Train Loss 22.236168570287937
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7991 test: 0.7557 | best val epoch -- val: 0.8129 test: 0.7905

====epoch 49
Train Loss 21.406475885490032
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7781 test: 0.7549 | best val epoch -- val: 0.8129 test: 0.7905

====epoch 50
Train Loss 21.95221666315446
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7757 test: 0.7379 | best val epoch -- val: 0.8129 test: 0.7905

WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.4.
2022-09-14 02:46:36.701 | INFO     | modules.masked_transformer_encoder:__init__:122 - number of parameters: 0.000000e+00
=========================================
batch_size = 32
d_model = 128
dataset = muv
decay = 0
device = 0
dim_feedforward = 512
eval_train = 0
filename =
gnn_JK = cat
gnn_dropout = 0.3
gnn_emb_dim = 300
gnn_num_layer = 5
gnn_residual = False
gnn_type = gin
gnn_virtual_node = False
graph_pooling = cls
input_model_file = models_graphtrans/graphtrans-sr-gcl.pth
lr = 0.0001
lr_scale = 1
max_input_len = 1000
nhead = 4
num_encoder_layers = 4
num_encoder_layers_masked = 0
num_workers = 0
pos_encoder = False
runseed = 6
seed = 12344
split = scaffold
transformer_activation = relu
transformer_dropout = 0.3
transformer_norm_input = True
transformer_prenorm = False
=========================================
muv
scaffold
Loaded GraphTrans from models_graphtrans/graphtrans-sr-gcl.pth
====epoch 1
Train Loss 105.01302436337586
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.4479 test: 0.4663 | best val epoch -- val: 0.4479 test: 0.4663

====epoch 2
Train Loss 32.52355684674482
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.4686 test: 0.5668 | best val epoch -- val: 0.4686 test: 0.5668

====epoch 3
Train Loss 32.27957779850769
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.5887 test: 0.5743 | best val epoch -- val: 0.5887 test: 0.5743

====epoch 4
Train Loss 32.19808582489358
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.6930 test: 0.5758 | best val epoch -- val: 0.6930 test: 0.5758

====epoch 5
Train Loss 31.325325130594074
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7218 test: 0.6989 | best val epoch -- val: 0.7218 test: 0.6989

====epoch 6
Train Loss 31.154893965924003
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7451 test: 0.6968 | best val epoch -- val: 0.7451 test: 0.6968

====epoch 7
Train Loss 30.431454823517303
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.6930 test: 0.6140 | best val epoch -- val: 0.7451 test: 0.6968

====epoch 8
Train Loss 30.557751127608594
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7346 test: 0.7437 | best val epoch -- val: 0.7451 test: 0.6968

====epoch 9
Train Loss 29.72775377978113
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7547 test: 0.7464 | best val epoch -- val: 0.7547 test: 0.7464

====epoch 10
Train Loss 29.646368730117445
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.6696 test: 0.6997 | best val epoch -- val: 0.7547 test: 0.7464

====epoch 11
Train Loss 29.16447110020789
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7161 test: 0.7136 | best val epoch -- val: 0.7547 test: 0.7464

====epoch 12
Train Loss 29.010962672698916
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7349 test: 0.7378 | best val epoch -- val: 0.7547 test: 0.7464

====epoch 13
Train Loss 28.473603444528685
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7429 test: 0.7340 | best val epoch -- val: 0.7547 test: 0.7464

====epoch 14
Train Loss 28.04872240353029
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.6896 test: 0.7801 | best val epoch -- val: 0.7547 test: 0.7464

====epoch 15
Train Loss 27.58314722995123
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7558 test: 0.7486 | best val epoch -- val: 0.7558 test: 0.7486

====epoch 16
Train Loss 27.763573802689326
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7325 test: 0.7348 | best val epoch -- val: 0.7558 test: 0.7486

====epoch 17
Train Loss 27.084066128260492
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7327 test: 0.7377 | best val epoch -- val: 0.7558 test: 0.7486

====epoch 18
Train Loss 26.503002248302316
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7579 test: 0.7365 | best val epoch -- val: 0.7579 test: 0.7365

====epoch 19
Train Loss 27.080267353864045
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7712 test: 0.7538 | best val epoch -- val: 0.7712 test: 0.7538

====epoch 20
Train Loss 26.79438169939268
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7536 test: 0.7273 | best val epoch -- val: 0.7712 test: 0.7538

====epoch 21
Train Loss 25.990350775472066
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.6773 test: 0.7075 | best val epoch -- val: 0.7712 test: 0.7538

====epoch 22
Train Loss 25.982334803393705
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7722 test: 0.7522 | best val epoch -- val: 0.7722 test: 0.7522

====epoch 23
Train Loss 26.24229461875803
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7700 test: 0.7138 | best val epoch -- val: 0.7722 test: 0.7522

====epoch 24
Train Loss 25.88253385488902
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7559 test: 0.7160 | best val epoch -- val: 0.7722 test: 0.7522

====epoch 25
Train Loss 25.95298964598351
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7898 test: 0.7383 | best val epoch -- val: 0.7898 test: 0.7383

====epoch 26
Train Loss 25.343998252764315
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7846 test: 0.7520 | best val epoch -- val: 0.7898 test: 0.7383

====epoch 27
Train Loss 25.626321735053555
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7713 test: 0.7595 | best val epoch -- val: 0.7898 test: 0.7383

====epoch 28
Train Loss 25.64464522727016
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7739 test: 0.7469 | best val epoch -- val: 0.7898 test: 0.7383

====epoch 29
Train Loss 25.283986792325468
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7749 test: 0.7050 | best val epoch -- val: 0.7898 test: 0.7383

====epoch 30
Train Loss 24.5833221996658
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.8047 test: 0.7706 | best val epoch -- val: 0.8047 test: 0.7706

====epoch 31
Train Loss 24.60013891555595
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7423 test: 0.7095 | best val epoch -- val: 0.8047 test: 0.7706

====epoch 32
Train Loss 24.84864313901767
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7608 test: 0.7592 | best val epoch -- val: 0.8047 test: 0.7706

====epoch 33
Train Loss 25.19978364518112
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.6860 test: 0.7115 | best val epoch -- val: 0.8047 test: 0.7706

====epoch 34
Train Loss 24.74097126260509
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7184 test: 0.7100 | best val epoch -- val: 0.8047 test: 0.7706

====epoch 35
Train Loss 24.03511309214799
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7306 test: 0.7401 | best val epoch -- val: 0.8047 test: 0.7706

====epoch 36
Train Loss 24.99834830768491
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7628 test: 0.7651 | best val epoch -- val: 0.8047 test: 0.7706

====epoch 37
Train Loss 24.591350377193542
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7547 test: 0.7268 | best val epoch -- val: 0.8047 test: 0.7706

====epoch 38
Train Loss 23.712232583007662
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7363 test: 0.6948 | best val epoch -- val: 0.8047 test: 0.7706

====epoch 39
Train Loss 24.69649414696502
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7797 test: 0.7105 | best val epoch -- val: 0.8047 test: 0.7706

====epoch 40
Train Loss 23.498672800376017
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.8023 test: 0.7167 | best val epoch -- val: 0.8047 test: 0.7706

====epoch 41
Train Loss 24.107141217673544
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7119 test: 0.6417 | best val epoch -- val: 0.8047 test: 0.7706

====epoch 42
Train Loss 23.26117123250543
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7773 test: 0.7338 | best val epoch -- val: 0.8047 test: 0.7706

====epoch 43
Train Loss 23.393194032878974
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7850 test: 0.7476 | best val epoch -- val: 0.8047 test: 0.7706

====epoch 44
Train Loss 23.6012398284981
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.8037 test: 0.6963 | best val epoch -- val: 0.8047 test: 0.7706

====epoch 45
Train Loss 22.893229109747725
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7840 test: 0.7424 | best val epoch -- val: 0.8047 test: 0.7706

====epoch 46
Train Loss 23.13560914650599
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7844 test: 0.7089 | best val epoch -- val: 0.8047 test: 0.7706

====epoch 47
Train Loss 23.266260454420664
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7367 test: 0.7240 | best val epoch -- val: 0.8047 test: 0.7706

====epoch 48
Train Loss 22.661051673298736
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7251 test: 0.6661 | best val epoch -- val: 0.8047 test: 0.7706

====epoch 49
Train Loss 22.474740031568498
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7593 test: 0.7496 | best val epoch -- val: 0.8047 test: 0.7706

====epoch 50
Train Loss 22.785115457357506
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7443 test: 0.7497 | best val epoch -- val: 0.8047 test: 0.7706

WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.4.
2022-09-14 04:02:30.752 | INFO     | modules.masked_transformer_encoder:__init__:122 - number of parameters: 0.000000e+00
=========================================
batch_size = 32
d_model = 128
dataset = muv
decay = 0
device = 0
dim_feedforward = 512
eval_train = 0
filename =
gnn_JK = cat
gnn_dropout = 0.3
gnn_emb_dim = 300
gnn_num_layer = 5
gnn_residual = False
gnn_type = gin
gnn_virtual_node = False
graph_pooling = cls
input_model_file = models_graphtrans/graphtrans-sr-gcl.pth
lr = 0.0001
lr_scale = 1
max_input_len = 1000
nhead = 4
num_encoder_layers = 4
num_encoder_layers_masked = 0
num_workers = 0
pos_encoder = False
runseed = 7
seed = 12344
split = scaffold
transformer_activation = relu
transformer_dropout = 0.3
transformer_norm_input = True
transformer_prenorm = False
=========================================
muv
scaffold
Loaded GraphTrans from models_graphtrans/graphtrans-sr-gcl.pth
====epoch 1
Train Loss 106.486826917673
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.5312 test: 0.4122 | best val epoch -- val: 0.5312 test: 0.4122

====epoch 2
Train Loss 32.59664409951218
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.5904 test: 0.4571 | best val epoch -- val: 0.5904 test: 0.4571

====epoch 3
Train Loss 32.638546736284134
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.6919 test: 0.6271 | best val epoch -- val: 0.6919 test: 0.6271

====epoch 4
Train Loss 32.59495805769336
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7203 test: 0.6869 | best val epoch -- val: 0.7203 test: 0.6869

====epoch 5
Train Loss 31.366036041456272
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7089 test: 0.6969 | best val epoch -- val: 0.7203 test: 0.6869

====epoch 6
Train Loss 30.74814112549267
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7634 test: 0.7491 | best val epoch -- val: 0.7634 test: 0.7491

====epoch 7
Train Loss 30.16662901769803
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7211 test: 0.7312 | best val epoch -- val: 0.7634 test: 0.7491

====epoch 8
Train Loss 30.125911420338543
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7605 test: 0.7614 | best val epoch -- val: 0.7634 test: 0.7491

====epoch 9
Train Loss 30.251453484182885
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7798 test: 0.7743 | best val epoch -- val: 0.7798 test: 0.7743

====epoch 10
Train Loss 29.355931091861137
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7494 test: 0.7643 | best val epoch -- val: 0.7798 test: 0.7743

====epoch 11
Train Loss 28.775533512332103
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7840 test: 0.7600 | best val epoch -- val: 0.7840 test: 0.7600

====epoch 12
Train Loss 28.257008542333285
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7599 test: 0.7143 | best val epoch -- val: 0.7840 test: 0.7600

====epoch 13
Train Loss 28.066352123395212
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7676 test: 0.7390 | best val epoch -- val: 0.7840 test: 0.7600

====epoch 14
Train Loss 28.096838884263825
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7602 test: 0.7322 | best val epoch -- val: 0.7840 test: 0.7600

====epoch 15
Train Loss 27.359695752496986
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7640 test: 0.7320 | best val epoch -- val: 0.7840 test: 0.7600

====epoch 16
Train Loss 27.49642283198329
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7662 test: 0.7582 | best val epoch -- val: 0.7840 test: 0.7600

====epoch 17
Train Loss 27.05497913234236
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7811 test: 0.7626 | best val epoch -- val: 0.7840 test: 0.7600

====epoch 18
Train Loss 27.047539675680763
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7429 test: 0.7524 | best val epoch -- val: 0.7840 test: 0.7600

====epoch 19
Train Loss 26.85068508807155
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7589 test: 0.7607 | best val epoch -- val: 0.7840 test: 0.7600

====epoch 20
Train Loss 26.55111043440442
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7546 test: 0.7703 | best val epoch -- val: 0.7840 test: 0.7600

====epoch 21
Train Loss 26.193569930816853
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7582 test: 0.7931 | best val epoch -- val: 0.7840 test: 0.7600

====epoch 22
Train Loss 26.219270182556542
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7601 test: 0.7790 | best val epoch -- val: 0.7840 test: 0.7600

====epoch 23
Train Loss 25.77931644110951
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7719 test: 0.7553 | best val epoch -- val: 0.7840 test: 0.7600

====epoch 24
Train Loss 25.40661184517453
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7752 test: 0.7658 | best val epoch -- val: 0.7840 test: 0.7600

====epoch 25
Train Loss 26.226948693349843
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7788 test: 0.7271 | best val epoch -- val: 0.7840 test: 0.7600

====epoch 26
Train Loss 25.582880324802893
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7675 test: 0.7676 | best val epoch -- val: 0.7840 test: 0.7600

====epoch 27
Train Loss 24.729867030517827
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7378 test: 0.7280 | best val epoch -- val: 0.7840 test: 0.7600

====epoch 28
Train Loss 25.094785116090687
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7767 test: 0.7630 | best val epoch -- val: 0.7840 test: 0.7600

====epoch 29
Train Loss 24.702612589446947
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7787 test: 0.7594 | best val epoch -- val: 0.7840 test: 0.7600

====epoch 30
Train Loss 24.37764388102035
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7525 test: 0.7397 | best val epoch -- val: 0.7840 test: 0.7600

====epoch 31
Train Loss 24.856520354960885
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7595 test: 0.7487 | best val epoch -- val: 0.7840 test: 0.7600

====epoch 32
Train Loss 24.333456784583515
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7558 test: 0.7739 | best val epoch -- val: 0.7840 test: 0.7600

====epoch 33
Train Loss 24.690213736088243
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7678 test: 0.7699 | best val epoch -- val: 0.7840 test: 0.7600

====epoch 34
Train Loss 23.864591355172532
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7715 test: 0.7651 | best val epoch -- val: 0.7840 test: 0.7600

====epoch 35
Train Loss 23.75753256616288
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7396 test: 0.7837 | best val epoch -- val: 0.7840 test: 0.7600

====epoch 36
Train Loss 23.564370464694413
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7720 test: 0.8017 | best val epoch -- val: 0.7840 test: 0.7600

====epoch 37
Train Loss 23.59360562050855
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7781 test: 0.7537 | best val epoch -- val: 0.7840 test: 0.7600

====epoch 38
Train Loss 23.213257407585004
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7543 test: 0.7907 | best val epoch -- val: 0.7840 test: 0.7600

====epoch 39
Train Loss 23.433143652667592
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7249 test: 0.7894 | best val epoch -- val: 0.7840 test: 0.7600

====epoch 40
Train Loss 22.926774188078113
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7588 test: 0.7777 | best val epoch -- val: 0.7840 test: 0.7600

====epoch 41
Train Loss 22.52313418735949
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7348 test: 0.7616 | best val epoch -- val: 0.7840 test: 0.7600

====epoch 42
Train Loss 22.573433692315607
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7736 test: 0.7851 | best val epoch -- val: 0.7840 test: 0.7600

====epoch 43
Train Loss 22.84188580457238
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7721 test: 0.7331 | best val epoch -- val: 0.7840 test: 0.7600

====epoch 44
Train Loss 22.146811399157226
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7187 test: 0.7443 | best val epoch -- val: 0.7840 test: 0.7600

====epoch 45
Train Loss 22.156449221886792
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7722 test: 0.7235 | best val epoch -- val: 0.7840 test: 0.7600

====epoch 46
Train Loss 22.118056336225195
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7778 test: 0.7799 | best val epoch -- val: 0.7840 test: 0.7600

====epoch 47
Train Loss 22.295153956789854
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7198 test: 0.7399 | best val epoch -- val: 0.7840 test: 0.7600

====epoch 48
Train Loss 22.43876313364989
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7258 test: 0.7697 | best val epoch -- val: 0.7840 test: 0.7600

====epoch 49
Train Loss 21.817251293394758
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7205 test: 0.7469 | best val epoch -- val: 0.7840 test: 0.7600

====epoch 50
Train Loss 21.111871670915257
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7413 test: 0.7232 | best val epoch -- val: 0.7840 test: 0.7600

WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.4.
2022-09-14 05:18:31.346 | INFO     | modules.masked_transformer_encoder:__init__:122 - number of parameters: 0.000000e+00
=========================================
batch_size = 32
d_model = 128
dataset = muv
decay = 0
device = 0
dim_feedforward = 512
eval_train = 0
filename =
gnn_JK = cat
gnn_dropout = 0.3
gnn_emb_dim = 300
gnn_num_layer = 5
gnn_residual = False
gnn_type = gin
gnn_virtual_node = False
graph_pooling = cls
input_model_file = models_graphtrans/graphtrans-sr-gcl.pth
lr = 0.0001
lr_scale = 1
max_input_len = 1000
nhead = 4
num_encoder_layers = 4
num_encoder_layers_masked = 0
num_workers = 0
pos_encoder = False
runseed = 8
seed = 12344
split = scaffold
transformer_activation = relu
transformer_dropout = 0.3
transformer_norm_input = True
transformer_prenorm = False
=========================================
muv
scaffold
Loaded GraphTrans from models_graphtrans/graphtrans-sr-gcl.pth
====epoch 1
Train Loss 100.618551375446
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.4455 test: 0.5093 | best val epoch -- val: 0.4455 test: 0.5093

====epoch 2
Train Loss 32.85710901529394
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.5406 test: 0.5537 | best val epoch -- val: 0.5406 test: 0.5537

====epoch 3
Train Loss 32.64953811524109
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.5949 test: 0.5937 | best val epoch -- val: 0.5949 test: 0.5937

====epoch 4
Train Loss 32.13792871919548
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.6773 test: 0.6302 | best val epoch -- val: 0.6773 test: 0.6302

====epoch 5
Train Loss 31.52915161502224
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7669 test: 0.7425 | best val epoch -- val: 0.7669 test: 0.7425

====epoch 6
Train Loss 31.002334033616528
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7798 test: 0.7798 | best val epoch -- val: 0.7798 test: 0.7798

====epoch 7
Train Loss 30.056810737038003
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7308 test: 0.7867 | best val epoch -- val: 0.7798 test: 0.7798

====epoch 8
Train Loss 29.05188899128578
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7631 test: 0.6986 | best val epoch -- val: 0.7798 test: 0.7798

====epoch 9
Train Loss 28.710873000560518
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.8116 test: 0.7817 | best val epoch -- val: 0.8116 test: 0.7817

====epoch 10
Train Loss 27.81306243403108
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7998 test: 0.7676 | best val epoch -- val: 0.8116 test: 0.7817

====epoch 11
Train Loss 27.328349314172588
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7887 test: 0.7528 | best val epoch -- val: 0.8116 test: 0.7817

====epoch 12
Train Loss 27.60433666309521
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.8083 test: 0.7850 | best val epoch -- val: 0.8116 test: 0.7817

====epoch 13
Train Loss 26.897659583697784
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7976 test: 0.7614 | best val epoch -- val: 0.8116 test: 0.7817

====epoch 14
Train Loss 25.954387076364274
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7490 test: 0.6938 | best val epoch -- val: 0.8116 test: 0.7817

====epoch 15
Train Loss 26.0810476027697
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.8001 test: 0.7410 | best val epoch -- val: 0.8116 test: 0.7817

====epoch 16
Train Loss 26.017066914565163
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7841 test: 0.7437 | best val epoch -- val: 0.8116 test: 0.7817

====epoch 17
Train Loss 26.143610881625406
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.8195 test: 0.7852 | best val epoch -- val: 0.8195 test: 0.7852

====epoch 18
Train Loss 25.15046461356368
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7939 test: 0.7499 | best val epoch -- val: 0.8195 test: 0.7852

====epoch 19
Train Loss 24.93883136518232
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.8138 test: 0.7822 | best val epoch -- val: 0.8195 test: 0.7852

====epoch 20
Train Loss 25.263369535305976
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7935 test: 0.7818 | best val epoch -- val: 0.8195 test: 0.7852

====epoch 21
Train Loss 24.70153622142717
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7929 test: 0.7786 | best val epoch -- val: 0.8195 test: 0.7852

====epoch 22
Train Loss 24.201854565852702
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.8067 test: 0.7923 | best val epoch -- val: 0.8195 test: 0.7852

====epoch 23
Train Loss 23.43878878433851
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7853 test: 0.7627 | best val epoch -- val: 0.8195 test: 0.7852

====epoch 24
Train Loss 23.656994680363304
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7894 test: 0.7821 | best val epoch -- val: 0.8195 test: 0.7852

====epoch 25
Train Loss 23.439107498570102
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7997 test: 0.7658 | best val epoch -- val: 0.8195 test: 0.7852

====epoch 26
Train Loss 23.146609918702456
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7929 test: 0.7699 | best val epoch -- val: 0.8195 test: 0.7852

====epoch 27
Train Loss 22.613458560235358
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7887 test: 0.7878 | best val epoch -- val: 0.8195 test: 0.7852

====epoch 28
Train Loss 22.919557232217855
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7779 test: 0.7556 | best val epoch -- val: 0.8195 test: 0.7852

====epoch 29
Train Loss 23.07152475800014
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7754 test: 0.7697 | best val epoch -- val: 0.8195 test: 0.7852

====epoch 30
Train Loss 22.362576150370288
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7904 test: 0.7827 | best val epoch -- val: 0.8195 test: 0.7852

====epoch 31
Train Loss 22.234012471290267
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7966 test: 0.7604 | best val epoch -- val: 0.8195 test: 0.7852

====epoch 32
Train Loss 22.01633076346424
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7961 test: 0.7664 | best val epoch -- val: 0.8195 test: 0.7852

====epoch 33
Train Loss 22.340487799489672
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.8157 test: 0.7810 | best val epoch -- val: 0.8195 test: 0.7852

====epoch 34
Train Loss 21.843243083870288
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7798 test: 0.7718 | best val epoch -- val: 0.8195 test: 0.7852

====epoch 35
Train Loss 21.869022488155945
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.8120 test: 0.7820 | best val epoch -- val: 0.8195 test: 0.7852

====epoch 36
Train Loss 21.545057622943485
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7820 test: 0.7501 | best val epoch -- val: 0.8195 test: 0.7852

====epoch 37
Train Loss 21.246328213425482
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7924 test: 0.7678 | best val epoch -- val: 0.8195 test: 0.7852

====epoch 38
Train Loss 21.403966995699342
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7981 test: 0.7959 | best val epoch -- val: 0.8195 test: 0.7852

====epoch 39
Train Loss 20.73694056076268
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7743 test: 0.7928 | best val epoch -- val: 0.8195 test: 0.7852

====epoch 40
Train Loss 21.357200793425037
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7880 test: 0.7834 | best val epoch -- val: 0.8195 test: 0.7852

====epoch 41
Train Loss 20.305728847662696
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7962 test: 0.7682 | best val epoch -- val: 0.8195 test: 0.7852

====epoch 42
Train Loss 20.93243205223153
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.8062 test: 0.7748 | best val epoch -- val: 0.8195 test: 0.7852

====epoch 43
Train Loss 20.523591860757268
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7603 test: 0.7597 | best val epoch -- val: 0.8195 test: 0.7852

====epoch 44
Train Loss 20.22942718822588
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7765 test: 0.7636 | best val epoch -- val: 0.8195 test: 0.7852

====epoch 45
Train Loss 20.06528958033648
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7375 test: 0.7345 | best val epoch -- val: 0.8195 test: 0.7852

====epoch 46
Train Loss 19.972511452290075
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7598 test: 0.7709 | best val epoch -- val: 0.8195 test: 0.7852

====epoch 47
Train Loss 19.187651667872167
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7697 test: 0.7185 | best val epoch -- val: 0.8195 test: 0.7852

====epoch 48
Train Loss 19.337594141993016
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7919 test: 0.7022 | best val epoch -- val: 0.8195 test: 0.7852

====epoch 49
Train Loss 19.668418199558314
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7702 test: 0.7582 | best val epoch -- val: 0.8195 test: 0.7852

====epoch 50
Train Loss 18.94583045472036
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7917 test: 0.7442 | best val epoch -- val: 0.8195 test: 0.7852

WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.4.
2022-09-14 06:38:08.936 | INFO     | modules.masked_transformer_encoder:__init__:122 - number of parameters: 0.000000e+00
=========================================
batch_size = 32
d_model = 128
dataset = muv
decay = 0
device = 0
dim_feedforward = 512
eval_train = 0
filename =
gnn_JK = cat
gnn_dropout = 0.3
gnn_emb_dim = 300
gnn_num_layer = 5
gnn_residual = False
gnn_type = gin
gnn_virtual_node = False
graph_pooling = cls
input_model_file = models_graphtrans/graphtrans-sr-gcl.pth
lr = 0.0001
lr_scale = 1
max_input_len = 1000
nhead = 4
num_encoder_layers = 4
num_encoder_layers_masked = 0
num_workers = 0
pos_encoder = False
runseed = 9
seed = 12344
split = scaffold
transformer_activation = relu
transformer_dropout = 0.3
transformer_norm_input = True
transformer_prenorm = False
=========================================
muv
scaffold
Loaded GraphTrans from models_graphtrans/graphtrans-sr-gcl.pth
====epoch 1
Train Loss 111.61111305011326
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.5218 test: 0.4517 | best val epoch -- val: 0.5218 test: 0.4517

====epoch 2
Train Loss 32.98451694880055
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.5674 test: 0.5842 | best val epoch -- val: 0.5674 test: 0.5842

====epoch 3
Train Loss 32.84707348532357
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.5737 test: 0.5940 | best val epoch -- val: 0.5737 test: 0.5940

====epoch 4
Train Loss 32.19769829330583
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.6959 test: 0.7286 | best val epoch -- val: 0.6959 test: 0.7286

====epoch 5
Train Loss 31.7073333263806
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7701 test: 0.6385 | best val epoch -- val: 0.7701 test: 0.6385

====epoch 6
Train Loss 30.941689937635246
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7321 test: 0.6972 | best val epoch -- val: 0.7701 test: 0.6385

====epoch 7
Train Loss 30.173901958112236
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7554 test: 0.7090 | best val epoch -- val: 0.7701 test: 0.6385

====epoch 8
Train Loss 30.43534479912709
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7221 test: 0.7139 | best val epoch -- val: 0.7701 test: 0.6385

====epoch 9
Train Loss 29.860162524987917
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7344 test: 0.6629 | best val epoch -- val: 0.7701 test: 0.6385

====epoch 10
Train Loss 29.944823519992333
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7238 test: 0.7029 | best val epoch -- val: 0.7701 test: 0.6385

====epoch 11
Train Loss 29.77269127096714
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7668 test: 0.6964 | best val epoch -- val: 0.7701 test: 0.6385

====epoch 12
Train Loss 29.070081336289977
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7829 test: 0.6802 | best val epoch -- val: 0.7829 test: 0.6802

====epoch 13
Train Loss 29.35143442996225
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7344 test: 0.6926 | best val epoch -- val: 0.7829 test: 0.6802

====epoch 14
Train Loss 28.484173231347363
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7534 test: 0.6740 | best val epoch -- val: 0.7829 test: 0.6802

====epoch 15
Train Loss 28.509421045781227
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7399 test: 0.6803 | best val epoch -- val: 0.7829 test: 0.6802

====epoch 16
Train Loss 28.249949630833466
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7881 test: 0.7672 | best val epoch -- val: 0.7881 test: 0.7672

====epoch 17
Train Loss 28.295189449420615
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7675 test: 0.7621 | best val epoch -- val: 0.7881 test: 0.7672

====epoch 18
Train Loss 27.322419571276097
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7896 test: 0.7292 | best val epoch -- val: 0.7896 test: 0.7292

====epoch 19
Train Loss 27.099302607908946
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7835 test: 0.7279 | best val epoch -- val: 0.7896 test: 0.7292

====epoch 20
Train Loss 27.188974766653114
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7825 test: 0.7189 | best val epoch -- val: 0.7896 test: 0.7292

====epoch 21
Train Loss 27.2687820807461
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7742 test: 0.7114 | best val epoch -- val: 0.7896 test: 0.7292

====epoch 22
Train Loss 26.833461749800225
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7723 test: 0.6975 | best val epoch -- val: 0.7896 test: 0.7292

====epoch 23
Train Loss 26.930452945319125
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7854 test: 0.7532 | best val epoch -- val: 0.7896 test: 0.7292

====epoch 24
Train Loss 26.237421014379926
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.8003 test: 0.6873 | best val epoch -- val: 0.8003 test: 0.6873

====epoch 25
Train Loss 26.723646033956292
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7761 test: 0.7025 | best val epoch -- val: 0.8003 test: 0.6873

====epoch 26
Train Loss 26.56611527003286
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.8024 test: 0.7095 | best val epoch -- val: 0.8024 test: 0.7095

====epoch 27
Train Loss 25.774019629610372
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7904 test: 0.7225 | best val epoch -- val: 0.8024 test: 0.7095

====epoch 28
Train Loss 26.340219850279194
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7692 test: 0.7284 | best val epoch -- val: 0.8024 test: 0.7095

====epoch 29
Train Loss 26.301428850285838
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7536 test: 0.7659 | best val epoch -- val: 0.8024 test: 0.7095

====epoch 30
Train Loss 25.69759722471732
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7811 test: 0.7268 | best val epoch -- val: 0.8024 test: 0.7095

====epoch 31
Train Loss 25.91179836009229
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7759 test: 0.6934 | best val epoch -- val: 0.8024 test: 0.7095

====epoch 32
Train Loss 25.363380243053896
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7783 test: 0.7123 | best val epoch -- val: 0.8024 test: 0.7095

====epoch 33
Train Loss 25.38427763642389
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7931 test: 0.7051 | best val epoch -- val: 0.8024 test: 0.7095

====epoch 34
Train Loss 25.153800491715526
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7986 test: 0.6872 | best val epoch -- val: 0.8024 test: 0.7095

====epoch 35
Train Loss 25.054782717923548
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7583 test: 0.6861 | best val epoch -- val: 0.8024 test: 0.7095

====epoch 36
Train Loss 24.9016064144178
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7756 test: 0.6354 | best val epoch -- val: 0.8024 test: 0.7095

====epoch 37
Train Loss 25.358490563731916
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.8039 test: 0.7117 | best val epoch -- val: 0.8039 test: 0.7117

====epoch 38
Train Loss 24.743195018154452
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7758 test: 0.7005 | best val epoch -- val: 0.8039 test: 0.7117

====epoch 39
Train Loss 25.24474622886446
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7940 test: 0.7280 | best val epoch -- val: 0.8039 test: 0.7117

====epoch 40
Train Loss 24.26259479471651
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7879 test: 0.7081 | best val epoch -- val: 0.8039 test: 0.7117

====epoch 41
Train Loss 24.67468401769276
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.8103 test: 0.7068 | best val epoch -- val: 0.8103 test: 0.7068

====epoch 42
Train Loss 23.97707636999565
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.8142 test: 0.7823 | best val epoch -- val: 0.8142 test: 0.7823

====epoch 43
Train Loss 24.064452918886253
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7901 test: 0.7199 | best val epoch -- val: 0.8142 test: 0.7823

====epoch 44
Train Loss 23.813313442984622
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.8017 test: 0.6997 | best val epoch -- val: 0.8142 test: 0.7823

====epoch 45
Train Loss 23.64839409263164
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7909 test: 0.7069 | best val epoch -- val: 0.8142 test: 0.7823

====epoch 46
Train Loss 24.80974087699791
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7650 test: 0.7063 | best val epoch -- val: 0.8142 test: 0.7823

====epoch 47
Train Loss 23.762215899919052
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7727 test: 0.6728 | best val epoch -- val: 0.8142 test: 0.7823

====epoch 48
Train Loss 23.494485746124692
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7807 test: 0.7091 | best val epoch -- val: 0.8142 test: 0.7823

====epoch 49
Train Loss 23.859412936393017
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7772 test: 0.6704 | best val epoch -- val: 0.8142 test: 0.7823

====epoch 50
Train Loss 23.653181932720916
====Evaluation
omit the training accuracy computation
Some target is missing!
Missing ratio: 0.058824
Some target is missing!
Missing ratio: 0.117647
train: 0.0000 val: 0.7766 test: 0.6635 | best val epoch -- val: 0.8142 test: 0.7823

2022-09-14 01:58:26.175 | INFO     | modules.masked_transformer_encoder:__init__:122 - number of parameters: 0.000000e+00
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.4.
=========================================
batch_size = 32
d_model = 128
dataset = clintox
decay = 0
device = 3
dim_feedforward = 512
eval_train = 0
filename =
gnn_JK = cat
gnn_dropout = 0.3
gnn_emb_dim = 300
gnn_num_layer = 5
gnn_residual = False
gnn_type = gin
gnn_virtual_node = False
graph_pooling = cls
input_model_file = models_graphtrans/graphtrans-sr-gcl.pth
lr = 5e-05
lr_scale = 1
max_input_len = 1000
nhead = 4
num_encoder_layers = 4
num_encoder_layers_masked = 0
num_workers = 0
pos_encoder = False
runseed = 0
seed = 12344
split = scaffold
transformer_activation = relu
transformer_dropout = 0.3
transformer_norm_input = True
transformer_prenorm = False
=========================================
clintox
scaffold
Loaded GraphTrans from models_graphtrans/graphtrans-sr-gcl.pth
====epoch 1
Train Loss 18.79304996418792
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.3141 test: 0.5387 | best val epoch -- val: 0.3141 test: 0.5387

====epoch 2
Train Loss 12.189356974131803
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.3070 test: 0.5505 | best val epoch -- val: 0.3141 test: 0.5387

====epoch 3
Train Loss 10.674526859046335
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.3777 test: 0.5401 | best val epoch -- val: 0.3777 test: 0.5401

====epoch 4
Train Loss 10.042921539976625
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.3674 test: 0.5635 | best val epoch -- val: 0.3777 test: 0.5401

====epoch 5
Train Loss 9.708894207292143
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.3718 test: 0.5808 | best val epoch -- val: 0.3777 test: 0.5401

====epoch 6
Train Loss 9.58441169409553
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.3952 test: 0.6258 | best val epoch -- val: 0.3952 test: 0.6258

====epoch 7
Train Loss 9.708259234904926
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.3981 test: 0.6352 | best val epoch -- val: 0.3981 test: 0.6352

====epoch 8
Train Loss 9.579478316769606
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.4008 test: 0.6460 | best val epoch -- val: 0.4008 test: 0.6460

====epoch 9
Train Loss 9.67455869932215
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.4313 test: 0.6421 | best val epoch -- val: 0.4313 test: 0.6421

====epoch 10
Train Loss 9.906633993654783
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.5027 test: 0.6459 | best val epoch -- val: 0.5027 test: 0.6459

====epoch 11
Train Loss 9.592809212138087
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.4286 test: 0.6472 | best val epoch -- val: 0.5027 test: 0.6459

====epoch 12
Train Loss 9.296876122283624
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.4562 test: 0.6503 | best val epoch -- val: 0.5027 test: 0.6459

====epoch 13
Train Loss 9.161691330014332
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.4997 test: 0.6486 | best val epoch -- val: 0.5027 test: 0.6459

====epoch 14
Train Loss 9.413654865023425
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.5023 test: 0.6531 | best val epoch -- val: 0.5027 test: 0.6459

====epoch 15
Train Loss 9.392398616509242
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.5768 test: 0.6585 | best val epoch -- val: 0.5768 test: 0.6585

====epoch 16
Train Loss 9.06771750220405
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6283 test: 0.6659 | best val epoch -- val: 0.6283 test: 0.6659

====epoch 17
Train Loss 8.87451592586155
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6392 test: 0.6790 | best val epoch -- val: 0.6392 test: 0.6790

====epoch 18
Train Loss 8.964817122280357
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6794 test: 0.6790 | best val epoch -- val: 0.6794 test: 0.6790

====epoch 19
Train Loss 8.867721558164238
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7567 test: 0.6631 | best val epoch -- val: 0.7567 test: 0.6631

====epoch 20
Train Loss 8.599705565800294
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7906 test: 0.6676 | best val epoch -- val: 0.7906 test: 0.6676

====epoch 21
Train Loss 8.694357196012238
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7851 test: 0.6714 | best val epoch -- val: 0.7906 test: 0.6676

====epoch 22
Train Loss 8.407159781795716
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7796 test: 0.6798 | best val epoch -- val: 0.7906 test: 0.6676

====epoch 23
Train Loss 8.5575414352347
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8184 test: 0.6710 | best val epoch -- val: 0.8184 test: 0.6710

====epoch 24
Train Loss 7.990672262426289
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8265 test: 0.6809 | best val epoch -- val: 0.8265 test: 0.6809

====epoch 25
Train Loss 7.916144723629692
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8341 test: 0.6904 | best val epoch -- val: 0.8341 test: 0.6904

====epoch 26
Train Loss 7.901065870297008
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8396 test: 0.6911 | best val epoch -- val: 0.8396 test: 0.6911

====epoch 27
Train Loss 7.77254519985842
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8437 test: 0.6832 | best val epoch -- val: 0.8437 test: 0.6832

====epoch 28
Train Loss 7.43197012759722
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8540 test: 0.6772 | best val epoch -- val: 0.8540 test: 0.6772

====epoch 29
Train Loss 7.222022062486681
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8567 test: 0.6969 | best val epoch -- val: 0.8567 test: 0.6969

====epoch 30
Train Loss 7.175804402967396
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8621 test: 0.6769 | best val epoch -- val: 0.8621 test: 0.6769

====epoch 31
Train Loss 7.654802512844661
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8502 test: 0.6992 | best val epoch -- val: 0.8621 test: 0.6769

====epoch 32
Train Loss 7.420305185135344
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8508 test: 0.6970 | best val epoch -- val: 0.8621 test: 0.6769

====epoch 33
Train Loss 6.915034072120633
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8533 test: 0.6832 | best val epoch -- val: 0.8621 test: 0.6769

====epoch 34
Train Loss 7.140752330927735
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8508 test: 0.6745 | best val epoch -- val: 0.8621 test: 0.6769

====epoch 35
Train Loss 6.796353005359836
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8473 test: 0.6956 | best val epoch -- val: 0.8621 test: 0.6769

====epoch 36
Train Loss 7.019435402196543
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8546 test: 0.6846 | best val epoch -- val: 0.8621 test: 0.6769

====epoch 37
Train Loss 6.767807863114886
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8533 test: 0.7180 | best val epoch -- val: 0.8621 test: 0.6769

====epoch 38
Train Loss 6.64390108885741
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8727 test: 0.7168 | best val epoch -- val: 0.8727 test: 0.7168

====epoch 39
Train Loss 6.429255887643054
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8663 test: 0.7244 | best val epoch -- val: 0.8727 test: 0.7168

====epoch 40
Train Loss 6.391644779430017
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8569 test: 0.7187 | best val epoch -- val: 0.8727 test: 0.7168

====epoch 41
Train Loss 6.5258196216568685
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8524 test: 0.7146 | best val epoch -- val: 0.8727 test: 0.7168

====epoch 42
Train Loss 6.446376557004048
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8577 test: 0.7129 | best val epoch -- val: 0.8727 test: 0.7168

====epoch 43
Train Loss 6.160501376500324
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8793 test: 0.6998 | best val epoch -- val: 0.8793 test: 0.6998

====epoch 44
Train Loss 6.7188938704087295
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8595 test: 0.7224 | best val epoch -- val: 0.8793 test: 0.6998

====epoch 45
Train Loss 6.154734118996376
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8669 test: 0.7266 | best val epoch -- val: 0.8793 test: 0.6998

====epoch 46
Train Loss 6.050538914848997
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8622 test: 0.7526 | best val epoch -- val: 0.8793 test: 0.6998

====epoch 47
Train Loss 6.028719582785963
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8593 test: 0.7551 | best val epoch -- val: 0.8793 test: 0.6998

====epoch 48
Train Loss 6.302614170785308
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8680 test: 0.7482 | best val epoch -- val: 0.8793 test: 0.6998

====epoch 49
Train Loss 5.8305114409762355
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8484 test: 0.7616 | best val epoch -- val: 0.8793 test: 0.6998

====epoch 50
Train Loss 6.0793211241129255
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8569 test: 0.7441 | best val epoch -- val: 0.8793 test: 0.6998

====epoch 51
Train Loss 5.769647803584494
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8666 test: 0.7743 | best val epoch -- val: 0.8793 test: 0.6998

====epoch 52
Train Loss 5.687211690633313
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8793 test: 0.7604 | best val epoch -- val: 0.8793 test: 0.7604

====epoch 53
Train Loss 5.34575260515106
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8882 test: 0.7429 | best val epoch -- val: 0.8882 test: 0.7429

====epoch 54
Train Loss 5.677120027574133
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8733 test: 0.7805 | best val epoch -- val: 0.8882 test: 0.7429

====epoch 55
Train Loss 5.96856570345124
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8712 test: 0.7761 | best val epoch -- val: 0.8882 test: 0.7429

====epoch 56
Train Loss 5.757344022818533
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8884 test: 0.7804 | best val epoch -- val: 0.8884 test: 0.7804

====epoch 57
Train Loss 5.9960463661325205
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8907 test: 0.7808 | best val epoch -- val: 0.8907 test: 0.7808

====epoch 58
Train Loss 5.8065645062764535
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8759 test: 0.7887 | best val epoch -- val: 0.8907 test: 0.7808

====epoch 59
Train Loss 5.6773112516004565
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8811 test: 0.7937 | best val epoch -- val: 0.8907 test: 0.7808

====epoch 60
Train Loss 5.648421555833189
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8889 test: 0.7902 | best val epoch -- val: 0.8907 test: 0.7808

====epoch 61
Train Loss 5.643005711136725
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8706 test: 0.7838 | best val epoch -- val: 0.8907 test: 0.7808

====epoch 62
Train Loss 5.786460651005074
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8682 test: 0.7962 | best val epoch -- val: 0.8907 test: 0.7808

====epoch 63
Train Loss 5.115088692040254
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8719 test: 0.8043 | best val epoch -- val: 0.8907 test: 0.7808

====epoch 64
Train Loss 5.676990185153594
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8681 test: 0.7969 | best val epoch -- val: 0.8907 test: 0.7808

====epoch 65
Train Loss 5.090773720393957
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8825 test: 0.7905 | best val epoch -- val: 0.8907 test: 0.7808

====epoch 66
Train Loss 5.525640926751781
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8876 test: 0.7664 | best val epoch -- val: 0.8907 test: 0.7808

====epoch 67
Train Loss 5.34020015783591
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8694 test: 0.7925 | best val epoch -- val: 0.8907 test: 0.7808

====epoch 68
Train Loss 5.323885886443361
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8691 test: 0.7751 | best val epoch -- val: 0.8907 test: 0.7808

====epoch 69
Train Loss 5.2350197529759885
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8779 test: 0.7613 | best val epoch -- val: 0.8907 test: 0.7808

====epoch 70
Train Loss 5.107225158439502
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8791 test: 0.7492 | best val epoch -- val: 0.8907 test: 0.7808

====epoch 71
Train Loss 5.186806618476218
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8780 test: 0.7691 | best val epoch -- val: 0.8907 test: 0.7808

====epoch 72
Train Loss 5.029911964384712
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8743 test: 0.7840 | best val epoch -- val: 0.8907 test: 0.7808

====epoch 73
Train Loss 5.494058216369039
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8752 test: 0.8016 | best val epoch -- val: 0.8907 test: 0.7808

====epoch 74
Train Loss 5.500058817004387
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8809 test: 0.7929 | best val epoch -- val: 0.8907 test: 0.7808

====epoch 75
Train Loss 5.056298617658447
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8744 test: 0.8080 | best val epoch -- val: 0.8907 test: 0.7808

====epoch 76
Train Loss 5.435662685888096
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8682 test: 0.8142 | best val epoch -- val: 0.8907 test: 0.7808

====epoch 77
Train Loss 5.2586680293834815
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8717 test: 0.8027 | best val epoch -- val: 0.8907 test: 0.7808

====epoch 78
Train Loss 4.699104146906915
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8704 test: 0.7917 | best val epoch -- val: 0.8907 test: 0.7808

====epoch 79
Train Loss 4.9341710096013545
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8797 test: 0.7919 | best val epoch -- val: 0.8907 test: 0.7808

====epoch 80
Train Loss 4.880946674179683
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8722 test: 0.8021 | best val epoch -- val: 0.8907 test: 0.7808

====epoch 81
Train Loss 5.088821958509464
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8638 test: 0.8078 | best val epoch -- val: 0.8907 test: 0.7808

====epoch 82
Train Loss 4.755284682800809
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8897 test: 0.7978 | best val epoch -- val: 0.8907 test: 0.7808

====epoch 83
Train Loss 4.861615902937999
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8676 test: 0.8013 | best val epoch -- val: 0.8907 test: 0.7808

====epoch 84
Train Loss 4.96213371396426
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8496 test: 0.7997 | best val epoch -- val: 0.8907 test: 0.7808

====epoch 85
Train Loss 5.021723769764663
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8729 test: 0.7935 | best val epoch -- val: 0.8907 test: 0.7808

====epoch 86
Train Loss 4.883563466415724
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8638 test: 0.7930 | best val epoch -- val: 0.8907 test: 0.7808

====epoch 87
Train Loss 4.737910156386338
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8667 test: 0.8033 | best val epoch -- val: 0.8907 test: 0.7808

====epoch 88
Train Loss 4.5335819391821515
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8681 test: 0.7916 | best val epoch -- val: 0.8907 test: 0.7808

====epoch 89
Train Loss 4.784101975084212
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8754 test: 0.7905 | best val epoch -- val: 0.8907 test: 0.7808

====epoch 90
Train Loss 4.726947073226472
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8879 test: 0.7959 | best val epoch -- val: 0.8907 test: 0.7808

====epoch 91
Train Loss 5.053882169613512
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8828 test: 0.7845 | best val epoch -- val: 0.8907 test: 0.7808

====epoch 92
Train Loss 4.970073769875248
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8656 test: 0.8096 | best val epoch -- val: 0.8907 test: 0.7808

====epoch 93
Train Loss 5.153168038416967
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8822 test: 0.8149 | best val epoch -- val: 0.8907 test: 0.7808

====epoch 94
Train Loss 4.388462167948103
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8812 test: 0.7850 | best val epoch -- val: 0.8907 test: 0.7808

====epoch 95
Train Loss 4.713283463576442
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8701 test: 0.8058 | best val epoch -- val: 0.8907 test: 0.7808

====epoch 96
Train Loss 4.519900348914046
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8794 test: 0.8051 | best val epoch -- val: 0.8907 test: 0.7808

====epoch 97
Train Loss 4.907582877071648
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8785 test: 0.8169 | best val epoch -- val: 0.8907 test: 0.7808

====epoch 98
Train Loss 4.683376943060349
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8690 test: 0.8098 | best val epoch -- val: 0.8907 test: 0.7808

====epoch 99
Train Loss 4.842240494488854
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8642 test: 0.8034 | best val epoch -- val: 0.8907 test: 0.7808

====epoch 100
Train Loss 4.341194539271835
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8666 test: 0.7947 | best val epoch -- val: 0.8907 test: 0.7808

====epoch 101
Train Loss 5.382809703390218
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8580 test: 0.8027 | best val epoch -- val: 0.8907 test: 0.7808

====epoch 102
Train Loss 4.599978595849643
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8693 test: 0.7792 | best val epoch -- val: 0.8907 test: 0.7808

====epoch 103
Train Loss 4.864823662954271
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8685 test: 0.7807 | best val epoch -- val: 0.8907 test: 0.7808

====epoch 104
Train Loss 4.5317384237550735
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8599 test: 0.8053 | best val epoch -- val: 0.8907 test: 0.7808

====epoch 105
Train Loss 4.542724393056059
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8598 test: 0.8031 | best val epoch -- val: 0.8907 test: 0.7808

====epoch 106
Train Loss 4.726387101074883
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8612 test: 0.8015 | best val epoch -- val: 0.8907 test: 0.7808

====epoch 107
Train Loss 4.600504709377767
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8580 test: 0.8052 | best val epoch -- val: 0.8907 test: 0.7808

====epoch 108
Train Loss 4.664303753565491
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8678 test: 0.8111 | best val epoch -- val: 0.8907 test: 0.7808

====epoch 109
Train Loss 4.737899912034282
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8592 test: 0.8128 | best val epoch -- val: 0.8907 test: 0.7808

====epoch 110
Train Loss 4.655783274357361
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8585 test: 0.8101 | best val epoch -- val: 0.8907 test: 0.7808

====epoch 111
Train Loss 4.53134551617015
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8592 test: 0.8083 | best val epoch -- val: 0.8907 test: 0.7808

====epoch 112
Train Loss 4.382487952757739
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8710 test: 0.8190 | best val epoch -- val: 0.8907 test: 0.7808

====epoch 113
Train Loss 4.515885440141461
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8694 test: 0.8141 | best val epoch -- val: 0.8907 test: 0.7808

====epoch 114
Train Loss 4.4679907127430365
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8620 test: 0.8152 | best val epoch -- val: 0.8907 test: 0.7808

====epoch 115
Train Loss 4.631629642027313
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8563 test: 0.8149 | best val epoch -- val: 0.8907 test: 0.7808

====epoch 116
Train Loss 4.61145731512288
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8494 test: 0.8071 | best val epoch -- val: 0.8907 test: 0.7808

====epoch 117
Train Loss 4.239147578932256
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8614 test: 0.8105 | best val epoch -- val: 0.8907 test: 0.7808

====epoch 118
Train Loss 4.275028416236195
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8742 test: 0.8105 | best val epoch -- val: 0.8907 test: 0.7808

====epoch 119
Train Loss 4.5516820596923875
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8846 test: 0.8190 | best val epoch -- val: 0.8907 test: 0.7808

====epoch 120
Train Loss 4.631783167567398
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8886 test: 0.8047 | best val epoch -- val: 0.8907 test: 0.7808

====epoch 121
Train Loss 4.114609992386749
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8935 test: 0.7987 | best val epoch -- val: 0.8935 test: 0.7987

====epoch 122
Train Loss 4.715672745368564
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8721 test: 0.8090 | best val epoch -- val: 0.8935 test: 0.7987

====epoch 123
Train Loss 4.341569969491599
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8688 test: 0.8015 | best val epoch -- val: 0.8935 test: 0.7987

====epoch 124
Train Loss 4.20987404850407
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8665 test: 0.7844 | best val epoch -- val: 0.8935 test: 0.7987

====epoch 125
Train Loss 4.546833418660144
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8775 test: 0.7931 | best val epoch -- val: 0.8935 test: 0.7987

====epoch 126
Train Loss 4.216166260601028
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8765 test: 0.7883 | best val epoch -- val: 0.8935 test: 0.7987

====epoch 127
Train Loss 4.574289203131457
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8776 test: 0.7942 | best val epoch -- val: 0.8935 test: 0.7987

====epoch 128
Train Loss 4.499453133765912
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8600 test: 0.7925 | best val epoch -- val: 0.8935 test: 0.7987

====epoch 129
Train Loss 4.506612782158515
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8705 test: 0.7794 | best val epoch -- val: 0.8935 test: 0.7987

====epoch 130
Train Loss 4.178020983800116
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8801 test: 0.7830 | best val epoch -- val: 0.8935 test: 0.7987

====epoch 131
Train Loss 4.525512962522949
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8835 test: 0.7841 | best val epoch -- val: 0.8935 test: 0.7987

====epoch 132
Train Loss 4.3664034113802055
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8807 test: 0.7834 | best val epoch -- val: 0.8935 test: 0.7987

====epoch 133
Train Loss 4.675566107325276
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8835 test: 0.7972 | best val epoch -- val: 0.8935 test: 0.7987

====epoch 134
Train Loss 4.475429214476095
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8698 test: 0.7934 | best val epoch -- val: 0.8935 test: 0.7987

====epoch 135
Train Loss 4.218069166043168
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8681 test: 0.7807 | best val epoch -- val: 0.8935 test: 0.7987

====epoch 136
Train Loss 4.431984899327984
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8642 test: 0.7954 | best val epoch -- val: 0.8935 test: 0.7987

====epoch 137
Train Loss 4.180255705904471
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8753 test: 0.8002 | best val epoch -- val: 0.8935 test: 0.7987

====epoch 138
Train Loss 4.083801177023732
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8737 test: 0.7770 | best val epoch -- val: 0.8935 test: 0.7987

====epoch 139
Train Loss 4.479730353634674
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8890 test: 0.7707 | best val epoch -- val: 0.8935 test: 0.7987

====epoch 140
Train Loss 3.954202297652731
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8869 test: 0.7889 | best val epoch -- val: 0.8935 test: 0.7987

====epoch 141
Train Loss 4.064432742084137
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8833 test: 0.7942 | best val epoch -- val: 0.8935 test: 0.7987

====epoch 142
Train Loss 4.875335513710487
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8810 test: 0.7897 | best val epoch -- val: 0.8935 test: 0.7987

====epoch 143
Train Loss 4.422920897516234
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8983 test: 0.8013 | best val epoch -- val: 0.8983 test: 0.8013

====epoch 144
Train Loss 4.15764081446661
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8907 test: 0.8045 | best val epoch -- val: 0.8983 test: 0.8013

====epoch 145
Train Loss 4.1647260767026575
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8853 test: 0.8016 | best val epoch -- val: 0.8983 test: 0.8013

====epoch 146
Train Loss 4.306387932862599
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8764 test: 0.7910 | best val epoch -- val: 0.8983 test: 0.8013

====epoch 147
Train Loss 3.9351090476001125
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8770 test: 0.7902 | best val epoch -- val: 0.8983 test: 0.8013

====epoch 148
Train Loss 4.098334182974767
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8413 test: 0.7849 | best val epoch -- val: 0.8983 test: 0.8013

====epoch 149
Train Loss 4.054088177460225
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8615 test: 0.7885 | best val epoch -- val: 0.8983 test: 0.8013

====epoch 150
Train Loss 4.395432357088729
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8565 test: 0.7810 | best val epoch -- val: 0.8983 test: 0.8013

====epoch 151
Train Loss 4.4013024251567625
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8716 test: 0.7719 | best val epoch -- val: 0.8983 test: 0.8013

====epoch 152
Train Loss 4.337566726357575
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8222 test: 0.8012 | best val epoch -- val: 0.8983 test: 0.8013

====epoch 153
Train Loss 4.183607570473339
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8267 test: 0.7875 | best val epoch -- val: 0.8983 test: 0.8013

====epoch 154
Train Loss 4.055848252541293
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8245 test: 0.7795 | best val epoch -- val: 0.8983 test: 0.8013

====epoch 155
Train Loss 4.155257007544075
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8372 test: 0.7494 | best val epoch -- val: 0.8983 test: 0.8013

====epoch 156
Train Loss 4.280656155331875
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8299 test: 0.7754 | best val epoch -- val: 0.8983 test: 0.8013

====epoch 157
Train Loss 4.262343907022606
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8378 test: 0.7565 | best val epoch -- val: 0.8983 test: 0.8013

====epoch 158
Train Loss 4.130197049574013
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8330 test: 0.7466 | best val epoch -- val: 0.8983 test: 0.8013

====epoch 159
Train Loss 4.1170381087496315
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8260 test: 0.7724 | best val epoch -- val: 0.8983 test: 0.8013

====epoch 160
Train Loss 4.009883924409427
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8366 test: 0.7732 | best val epoch -- val: 0.8983 test: 0.8013

====epoch 161
Train Loss 4.1253368857247645
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8712 test: 0.7656 | best val epoch -- val: 0.8983 test: 0.8013

====epoch 162
Train Loss 3.9890171601302593
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8294 test: 0.7649 | best val epoch -- val: 0.8983 test: 0.8013

====epoch 163
Train Loss 4.083703230063962
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8308 test: 0.7645 | best val epoch -- val: 0.8983 test: 0.8013

====epoch 164
Train Loss 4.463369367032085
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8394 test: 0.7534 | best val epoch -- val: 0.8983 test: 0.8013

====epoch 165
Train Loss 4.071560704032349
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8872 test: 0.7504 | best val epoch -- val: 0.8983 test: 0.8013

====epoch 166
Train Loss 3.94308332362825
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8384 test: 0.7473 | best val epoch -- val: 0.8983 test: 0.8013

====epoch 167
Train Loss 4.199711932059538
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8773 test: 0.7606 | best val epoch -- val: 0.8983 test: 0.8013

====epoch 168
Train Loss 3.9424183340613
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8405 test: 0.7524 | best val epoch -- val: 0.8983 test: 0.8013

====epoch 169
Train Loss 4.077181746231468
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8537 test: 0.7474 | best val epoch -- val: 0.8983 test: 0.8013

====epoch 170
Train Loss 3.9678304392368697
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8331 test: 0.7527 | best val epoch -- val: 0.8983 test: 0.8013

====epoch 171
Train Loss 3.9439661607567507
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8320 test: 0.7550 | best val epoch -- val: 0.8983 test: 0.8013

====epoch 172
Train Loss 4.04938192097918
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8272 test: 0.7599 | best val epoch -- val: 0.8983 test: 0.8013

====epoch 173
Train Loss 4.145779912032971
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8287 test: 0.7826 | best val epoch -- val: 0.8983 test: 0.8013

====epoch 174
Train Loss 4.160729339409606
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8329 test: 0.7809 | best val epoch -- val: 0.8983 test: 0.8013

====epoch 175
Train Loss 3.951821890985076
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8349 test: 0.7946 | best val epoch -- val: 0.8983 test: 0.8013

====epoch 176
Train Loss 4.223200023601813
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8432 test: 0.7894 | best val epoch -- val: 0.8983 test: 0.8013

====epoch 177
Train Loss 3.9044317340542656
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8408 test: 0.7553 | best val epoch -- val: 0.8983 test: 0.8013

====epoch 178
Train Loss 4.172025678720014
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8241 test: 0.7535 | best val epoch -- val: 0.8983 test: 0.8013

====epoch 179
Train Loss 4.143693929471758
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8117 test: 0.7836 | best val epoch -- val: 0.8983 test: 0.8013

====epoch 180
Train Loss 4.0142012180606805
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8254 test: 0.7602 | best val epoch -- val: 0.8983 test: 0.8013

====epoch 181
Train Loss 3.9927029784589165
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8314 test: 0.7507 | best val epoch -- val: 0.8983 test: 0.8013

====epoch 182
Train Loss 3.9362143981418205
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8437 test: 0.7778 | best val epoch -- val: 0.8983 test: 0.8013

====epoch 183
Train Loss 4.214004725624756
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8231 test: 0.7867 | best val epoch -- val: 0.8983 test: 0.8013

====epoch 184
Train Loss 3.9850970618393484
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8186 test: 0.7923 | best val epoch -- val: 0.8983 test: 0.8013

====epoch 185
Train Loss 4.45086875180277
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8234 test: 0.7885 | best val epoch -- val: 0.8983 test: 0.8013

====epoch 186
Train Loss 3.6067293744389715
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8398 test: 0.7860 | best val epoch -- val: 0.8983 test: 0.8013

====epoch 187
Train Loss 3.752770874361374
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8526 test: 0.7974 | best val epoch -- val: 0.8983 test: 0.8013

====epoch 188
Train Loss 4.094332897764236
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8701 test: 0.8077 | best val epoch -- val: 0.8983 test: 0.8013

====epoch 189
Train Loss 3.678652570056777
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8516 test: 0.8102 | best val epoch -- val: 0.8983 test: 0.8013

====epoch 190
Train Loss 4.163039918905605
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8424 test: 0.7894 | best val epoch -- val: 0.8983 test: 0.8013

====epoch 191
Train Loss 4.0024994426884755
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8513 test: 0.7985 | best val epoch -- val: 0.8983 test: 0.8013

====epoch 192
Train Loss 3.87399715225801
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8557 test: 0.8010 | best val epoch -- val: 0.8983 test: 0.8013

====epoch 193
Train Loss 3.9112242704923075
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8508 test: 0.8030 | best val epoch -- val: 0.8983 test: 0.8013

====epoch 194
Train Loss 3.9087728968133026
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8484 test: 0.8017 | best val epoch -- val: 0.8983 test: 0.8013

====epoch 195
Train Loss 4.073864899267375
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8823 test: 0.7989 | best val epoch -- val: 0.8983 test: 0.8013

====epoch 196
Train Loss 3.917516830906856
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8476 test: 0.8015 | best val epoch -- val: 0.8983 test: 0.8013

====epoch 197
Train Loss 3.760894776657177
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8474 test: 0.8051 | best val epoch -- val: 0.8983 test: 0.8013

====epoch 198
Train Loss 3.875626247073379
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8856 test: 0.7999 | best val epoch -- val: 0.8983 test: 0.8013

====epoch 199
Train Loss 3.8071781820237436
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8461 test: 0.8052 | best val epoch -- val: 0.8983 test: 0.8013

====epoch 200
Train Loss 3.9050886768830644
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8548 test: 0.8111 | best val epoch -- val: 0.8983 test: 0.8013

2022-09-14 02:05:15.637 | INFO     | modules.masked_transformer_encoder:__init__:122 - number of parameters: 0.000000e+00
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.4.
=========================================
batch_size = 32
d_model = 128
dataset = clintox
decay = 0
device = 3
dim_feedforward = 512
eval_train = 0
filename =
gnn_JK = cat
gnn_dropout = 0.3
gnn_emb_dim = 300
gnn_num_layer = 5
gnn_residual = False
gnn_type = gin
gnn_virtual_node = False
graph_pooling = cls
input_model_file = models_graphtrans/graphtrans-sr-gcl.pth
lr = 5e-05
lr_scale = 1
max_input_len = 1000
nhead = 4
num_encoder_layers = 4
num_encoder_layers_masked = 0
num_workers = 0
pos_encoder = False
runseed = 1
seed = 12344
split = scaffold
transformer_activation = relu
transformer_dropout = 0.3
transformer_norm_input = True
transformer_prenorm = False
=========================================
clintox
scaffold
Loaded GraphTrans from models_graphtrans/graphtrans-sr-gcl.pth
====epoch 1
Train Loss 19.17675926328135
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.4595 test: 0.5718 | best val epoch -- val: 0.4595 test: 0.5718

====epoch 2
Train Loss 11.794570024240356
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.3913 test: 0.5904 | best val epoch -- val: 0.4595 test: 0.5718

====epoch 3
Train Loss 10.288267365141264
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.4258 test: 0.6103 | best val epoch -- val: 0.4595 test: 0.5718

====epoch 4
Train Loss 10.116529525271046
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.4293 test: 0.6222 | best val epoch -- val: 0.4595 test: 0.5718

====epoch 5
Train Loss 9.986843205294003
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.4650 test: 0.5952 | best val epoch -- val: 0.4650 test: 0.5952

====epoch 6
Train Loss 9.767538733517519
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.4760 test: 0.5958 | best val epoch -- val: 0.4760 test: 0.5958

====epoch 7
Train Loss 9.719776574500838
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.4847 test: 0.6020 | best val epoch -- val: 0.4847 test: 0.6020

====epoch 8
Train Loss 9.715831116184534
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.5318 test: 0.6149 | best val epoch -- val: 0.5318 test: 0.6149

====epoch 9
Train Loss 9.789925830440648
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.5701 test: 0.6351 | best val epoch -- val: 0.5701 test: 0.6351

====epoch 10
Train Loss 9.442938235859899
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.5620 test: 0.6278 | best val epoch -- val: 0.5701 test: 0.6351

====epoch 11
Train Loss 9.534995733109547
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.5567 test: 0.6421 | best val epoch -- val: 0.5701 test: 0.6351

====epoch 12
Train Loss 9.524273830682652
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.5898 test: 0.6488 | best val epoch -- val: 0.5898 test: 0.6488

====epoch 13
Train Loss 9.375928309412588
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6396 test: 0.6699 | best val epoch -- val: 0.6396 test: 0.6699

====epoch 14
Train Loss 9.212422223155318
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6639 test: 0.6829 | best val epoch -- val: 0.6639 test: 0.6829

====epoch 15
Train Loss 9.072797007631527
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6715 test: 0.6691 | best val epoch -- val: 0.6715 test: 0.6691

====epoch 16
Train Loss 9.026507400495491
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6771 test: 0.6838 | best val epoch -- val: 0.6771 test: 0.6838

====epoch 17
Train Loss 8.797872851748599
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7088 test: 0.6973 | best val epoch -- val: 0.7088 test: 0.6973

====epoch 18
Train Loss 9.087476131193961
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7773 test: 0.6842 | best val epoch -- val: 0.7773 test: 0.6842

====epoch 19
Train Loss 8.749815882089061
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8010 test: 0.6953 | best val epoch -- val: 0.8010 test: 0.6953

====epoch 20
Train Loss 8.589185304989947
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8340 test: 0.7023 | best val epoch -- val: 0.8340 test: 0.7023

====epoch 21
Train Loss 8.63131443762081
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8531 test: 0.7077 | best val epoch -- val: 0.8531 test: 0.7077

====epoch 22
Train Loss 8.00692984631317
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8600 test: 0.7102 | best val epoch -- val: 0.8600 test: 0.7102

====epoch 23
Train Loss 7.775010951708661
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8504 test: 0.6976 | best val epoch -- val: 0.8600 test: 0.7102

====epoch 24
Train Loss 7.882862570075075
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8641 test: 0.7109 | best val epoch -- val: 0.8641 test: 0.7109

====epoch 25
Train Loss 7.712153362347753
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8676 test: 0.7293 | best val epoch -- val: 0.8676 test: 0.7293

====epoch 26
Train Loss 7.42062106112288
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8631 test: 0.7264 | best val epoch -- val: 0.8676 test: 0.7293

====epoch 27
Train Loss 7.650125781110141
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8684 test: 0.7288 | best val epoch -- val: 0.8684 test: 0.7288

====epoch 28
Train Loss 7.087057584852534
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8763 test: 0.7172 | best val epoch -- val: 0.8763 test: 0.7172

====epoch 29
Train Loss 7.1841381173921395
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8580 test: 0.7372 | best val epoch -- val: 0.8763 test: 0.7172

====epoch 30
Train Loss 7.270539530157024
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8596 test: 0.7301 | best val epoch -- val: 0.8763 test: 0.7172

====epoch 31
Train Loss 6.606142579379732
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8395 test: 0.7491 | best val epoch -- val: 0.8763 test: 0.7172

====epoch 32
Train Loss 6.679289227707755
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8599 test: 0.7453 | best val epoch -- val: 0.8763 test: 0.7172

====epoch 33
Train Loss 6.791238172479037
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8581 test: 0.7439 | best val epoch -- val: 0.8763 test: 0.7172

====epoch 34
Train Loss 6.788320469165043
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8676 test: 0.7460 | best val epoch -- val: 0.8763 test: 0.7172

====epoch 35
Train Loss 6.551039446120705
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8710 test: 0.7505 | best val epoch -- val: 0.8763 test: 0.7172

====epoch 36
Train Loss 6.190818094260734
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8642 test: 0.7473 | best val epoch -- val: 0.8763 test: 0.7172

====epoch 37
Train Loss 6.374103774700269
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8571 test: 0.7529 | best val epoch -- val: 0.8763 test: 0.7172

====epoch 38
Train Loss 6.125085829584868
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8496 test: 0.7614 | best val epoch -- val: 0.8763 test: 0.7172

====epoch 39
Train Loss 6.612252817369367
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8544 test: 0.7542 | best val epoch -- val: 0.8763 test: 0.7172

====epoch 40
Train Loss 6.362280144499384
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8443 test: 0.7580 | best val epoch -- val: 0.8763 test: 0.7172

====epoch 41
Train Loss 5.89488049783986
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8317 test: 0.7607 | best val epoch -- val: 0.8763 test: 0.7172

====epoch 42
Train Loss 6.306526893677916
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8156 test: 0.7559 | best val epoch -- val: 0.8763 test: 0.7172

====epoch 43
Train Loss 6.124675045875325
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8336 test: 0.7511 | best val epoch -- val: 0.8763 test: 0.7172

====epoch 44
Train Loss 5.515173501288708
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8517 test: 0.7526 | best val epoch -- val: 0.8763 test: 0.7172

====epoch 45
Train Loss 5.682818565986451
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8494 test: 0.7599 | best val epoch -- val: 0.8763 test: 0.7172

====epoch 46
Train Loss 6.138188723306433
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8606 test: 0.7776 | best val epoch -- val: 0.8763 test: 0.7172

====epoch 47
Train Loss 6.007351720871669
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8390 test: 0.7777 | best val epoch -- val: 0.8763 test: 0.7172

====epoch 48
Train Loss 5.963195416355293
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8530 test: 0.7700 | best val epoch -- val: 0.8763 test: 0.7172

====epoch 49
Train Loss 5.9138296126739505
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8524 test: 0.7766 | best val epoch -- val: 0.8763 test: 0.7172

====epoch 50
Train Loss 5.568136355247732
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8442 test: 0.7882 | best val epoch -- val: 0.8763 test: 0.7172

====epoch 51
Train Loss 5.9911698590068685
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8535 test: 0.7763 | best val epoch -- val: 0.8763 test: 0.7172

====epoch 52
Train Loss 6.295105567119019
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8527 test: 0.7931 | best val epoch -- val: 0.8763 test: 0.7172

====epoch 53
Train Loss 5.395077239548021
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8645 test: 0.7988 | best val epoch -- val: 0.8763 test: 0.7172

====epoch 54
Train Loss 5.853708591412196
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8671 test: 0.7947 | best val epoch -- val: 0.8763 test: 0.7172

====epoch 55
Train Loss 5.721158749996125
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8611 test: 0.7921 | best val epoch -- val: 0.8763 test: 0.7172

====epoch 56
Train Loss 5.418962708814842
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8733 test: 0.7953 | best val epoch -- val: 0.8763 test: 0.7172

====epoch 57
Train Loss 5.5318959740935725
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8726 test: 0.8006 | best val epoch -- val: 0.8763 test: 0.7172

====epoch 58
Train Loss 5.402564126681712
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8473 test: 0.8105 | best val epoch -- val: 0.8763 test: 0.7172

====epoch 59
Train Loss 5.833370554886772
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8579 test: 0.8045 | best val epoch -- val: 0.8763 test: 0.7172

====epoch 60
Train Loss 5.656500372652499
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8808 test: 0.7928 | best val epoch -- val: 0.8808 test: 0.7928

====epoch 61
Train Loss 6.123249663625318
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8766 test: 0.7996 | best val epoch -- val: 0.8808 test: 0.7928

====epoch 62
Train Loss 5.76301918759443
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8813 test: 0.7904 | best val epoch -- val: 0.8813 test: 0.7904

====epoch 63
Train Loss 5.721951908860809
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8715 test: 0.8017 | best val epoch -- val: 0.8813 test: 0.7904

====epoch 64
Train Loss 5.317864558122599
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8676 test: 0.8099 | best val epoch -- val: 0.8813 test: 0.7904

====epoch 65
Train Loss 4.935362046035642
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8690 test: 0.8028 | best val epoch -- val: 0.8813 test: 0.7904

====epoch 66
Train Loss 5.089153314861878
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8957 test: 0.7867 | best val epoch -- val: 0.8957 test: 0.7867

====epoch 67
Train Loss 4.922150414046818
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8866 test: 0.7889 | best val epoch -- val: 0.8957 test: 0.7867

====epoch 68
Train Loss 5.752217681927043
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8805 test: 0.8069 | best val epoch -- val: 0.8957 test: 0.7867

====epoch 69
Train Loss 5.323432489096224
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8886 test: 0.8048 | best val epoch -- val: 0.8957 test: 0.7867

====epoch 70
Train Loss 5.513827955075033
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9020 test: 0.8130 | best val epoch -- val: 0.9020 test: 0.8130

====epoch 71
Train Loss 5.3880866271008845
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9092 test: 0.8070 | best val epoch -- val: 0.9092 test: 0.8070

====epoch 72
Train Loss 5.108812968184534
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8911 test: 0.8059 | best val epoch -- val: 0.9092 test: 0.8070

====epoch 73
Train Loss 5.575680261192073
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8882 test: 0.8065 | best val epoch -- val: 0.9092 test: 0.8070

====epoch 74
Train Loss 5.534812821882155
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8838 test: 0.8125 | best val epoch -- val: 0.9092 test: 0.8070

====epoch 75
Train Loss 5.337933064242783
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8798 test: 0.8207 | best val epoch -- val: 0.9092 test: 0.8070

====epoch 76
Train Loss 5.187838679325801
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8934 test: 0.8213 | best val epoch -- val: 0.9092 test: 0.8070

====epoch 77
Train Loss 5.472346227469445
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8869 test: 0.8217 | best val epoch -- val: 0.9092 test: 0.8070

====epoch 78
Train Loss 5.170734815416621
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8809 test: 0.8244 | best val epoch -- val: 0.9092 test: 0.8070

====epoch 79
Train Loss 5.1058123803282
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8629 test: 0.8228 | best val epoch -- val: 0.9092 test: 0.8070

====epoch 80
Train Loss 4.808620976151282
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8772 test: 0.8157 | best val epoch -- val: 0.9092 test: 0.8070

====epoch 81
Train Loss 5.333323621902648
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8737 test: 0.8415 | best val epoch -- val: 0.9092 test: 0.8070

====epoch 82
Train Loss 5.089181309576825
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8610 test: 0.8371 | best val epoch -- val: 0.9092 test: 0.8070

====epoch 83
Train Loss 5.016250900983674
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8784 test: 0.8289 | best val epoch -- val: 0.9092 test: 0.8070

====epoch 84
Train Loss 5.098370618921058
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8811 test: 0.8304 | best val epoch -- val: 0.9092 test: 0.8070

====epoch 85
Train Loss 5.287292446391032
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8803 test: 0.8171 | best val epoch -- val: 0.9092 test: 0.8070

====epoch 86
Train Loss 5.204723035901355
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8822 test: 0.8266 | best val epoch -- val: 0.9092 test: 0.8070

====epoch 87
Train Loss 4.782371585616823
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8789 test: 0.8315 | best val epoch -- val: 0.9092 test: 0.8070

====epoch 88
Train Loss 4.8230527874472795
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8730 test: 0.8266 | best val epoch -- val: 0.9092 test: 0.8070

====epoch 89
Train Loss 4.527465144935228
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8633 test: 0.8297 | best val epoch -- val: 0.9092 test: 0.8070

====epoch 90
Train Loss 4.945864603107963
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8619 test: 0.8353 | best val epoch -- val: 0.9092 test: 0.8070

====epoch 91
Train Loss 4.633318041989385
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8740 test: 0.8372 | best val epoch -- val: 0.9092 test: 0.8070

====epoch 92
Train Loss 4.778105552779847
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8758 test: 0.8432 | best val epoch -- val: 0.9092 test: 0.8070

====epoch 93
Train Loss 5.2328440081734096
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8778 test: 0.8379 | best val epoch -- val: 0.9092 test: 0.8070

====epoch 94
Train Loss 5.1505735847208705
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8891 test: 0.8424 | best val epoch -- val: 0.9092 test: 0.8070

====epoch 95
Train Loss 4.539217745547759
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8930 test: 0.8394 | best val epoch -- val: 0.9092 test: 0.8070

====epoch 96
Train Loss 4.9222113018419185
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8879 test: 0.8254 | best val epoch -- val: 0.9092 test: 0.8070

====epoch 97
Train Loss 4.724904926719804
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8856 test: 0.8316 | best val epoch -- val: 0.9092 test: 0.8070

====epoch 98
Train Loss 4.868419644151858
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8797 test: 0.8303 | best val epoch -- val: 0.9092 test: 0.8070

====epoch 99
Train Loss 5.035769846253593
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8798 test: 0.8238 | best val epoch -- val: 0.9092 test: 0.8070

====epoch 100
Train Loss 4.792012488730149
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8846 test: 0.8175 | best val epoch -- val: 0.9092 test: 0.8070

====epoch 101
Train Loss 4.863738736857513
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8937 test: 0.8353 | best val epoch -- val: 0.9092 test: 0.8070

====epoch 102
Train Loss 4.699698642557262
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8874 test: 0.8344 | best val epoch -- val: 0.9092 test: 0.8070

====epoch 103
Train Loss 4.85489741618462
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8868 test: 0.8348 | best val epoch -- val: 0.9092 test: 0.8070

====epoch 104
Train Loss 4.278027299830685
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8914 test: 0.8333 | best val epoch -- val: 0.9092 test: 0.8070

====epoch 105
Train Loss 5.302634351484018
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8951 test: 0.8421 | best val epoch -- val: 0.9092 test: 0.8070

====epoch 106
Train Loss 4.52678780024834
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9017 test: 0.8271 | best val epoch -- val: 0.9092 test: 0.8070

====epoch 107
Train Loss 4.564546929017598
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8948 test: 0.8368 | best val epoch -- val: 0.9092 test: 0.8070

====epoch 108
Train Loss 4.874131931643049
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8900 test: 0.8281 | best val epoch -- val: 0.9092 test: 0.8070

====epoch 109
Train Loss 4.445902592998957
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8884 test: 0.8360 | best val epoch -- val: 0.9092 test: 0.8070

====epoch 110
Train Loss 4.779002205198286
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8867 test: 0.8317 | best val epoch -- val: 0.9092 test: 0.8070

====epoch 111
Train Loss 4.705177550319026
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8793 test: 0.8326 | best val epoch -- val: 0.9092 test: 0.8070

====epoch 112
Train Loss 4.678284717122366
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8873 test: 0.8344 | best val epoch -- val: 0.9092 test: 0.8070

====epoch 113
Train Loss 4.631688818798859
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8815 test: 0.8416 | best val epoch -- val: 0.9092 test: 0.8070

====epoch 114
Train Loss 4.451000668457565
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8840 test: 0.8231 | best val epoch -- val: 0.9092 test: 0.8070

====epoch 115
Train Loss 4.660291635934407
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8891 test: 0.8152 | best val epoch -- val: 0.9092 test: 0.8070

====epoch 116
Train Loss 5.106384183192791
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8967 test: 0.8102 | best val epoch -- val: 0.9092 test: 0.8070

====epoch 117
Train Loss 4.755616850092501
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8923 test: 0.8218 | best val epoch -- val: 0.9092 test: 0.8070

====epoch 118
Train Loss 4.500846094629787
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9061 test: 0.8312 | best val epoch -- val: 0.9092 test: 0.8070

====epoch 119
Train Loss 4.463963129780198
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8798 test: 0.8336 | best val epoch -- val: 0.9092 test: 0.8070

====epoch 120
Train Loss 4.504449808474952
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8916 test: 0.8273 | best val epoch -- val: 0.9092 test: 0.8070

====epoch 121
Train Loss 4.894185585326381
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8895 test: 0.8355 | best val epoch -- val: 0.9092 test: 0.8070

====epoch 122
Train Loss 4.589700567008218
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8896 test: 0.8277 | best val epoch -- val: 0.9092 test: 0.8070

====epoch 123
Train Loss 4.280487526122179
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8849 test: 0.8267 | best val epoch -- val: 0.9092 test: 0.8070

====epoch 124
Train Loss 4.831132714583009
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8874 test: 0.8335 | best val epoch -- val: 0.9092 test: 0.8070

====epoch 125
Train Loss 4.444686700367242
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8766 test: 0.8234 | best val epoch -- val: 0.9092 test: 0.8070

====epoch 126
Train Loss 4.363893246188655
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8702 test: 0.8410 | best val epoch -- val: 0.9092 test: 0.8070

====epoch 127
Train Loss 4.114051591786071
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8817 test: 0.8311 | best val epoch -- val: 0.9092 test: 0.8070

====epoch 128
Train Loss 4.5168514855082
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8798 test: 0.8433 | best val epoch -- val: 0.9092 test: 0.8070

====epoch 129
Train Loss 4.234061433043044
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8786 test: 0.8470 | best val epoch -- val: 0.9092 test: 0.8070

====epoch 130
Train Loss 4.777872571725287
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8717 test: 0.8492 | best val epoch -- val: 0.9092 test: 0.8070

====epoch 131
Train Loss 4.727748821050365
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8710 test: 0.8429 | best val epoch -- val: 0.9092 test: 0.8070

====epoch 132
Train Loss 4.155780439238534
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8921 test: 0.8351 | best val epoch -- val: 0.9092 test: 0.8070

====epoch 133
Train Loss 4.626233369149799
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8816 test: 0.8380 | best val epoch -- val: 0.9092 test: 0.8070

====epoch 134
Train Loss 4.2678093045479
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8955 test: 0.8387 | best val epoch -- val: 0.9092 test: 0.8070

====epoch 135
Train Loss 4.351808244272686
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8859 test: 0.8440 | best val epoch -- val: 0.9092 test: 0.8070

====epoch 136
Train Loss 4.41489426591325
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8754 test: 0.8532 | best val epoch -- val: 0.9092 test: 0.8070

====epoch 137
Train Loss 4.386722521653932
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8908 test: 0.8412 | best val epoch -- val: 0.9092 test: 0.8070

====epoch 138
Train Loss 4.283107260005225
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8889 test: 0.8409 | best val epoch -- val: 0.9092 test: 0.8070

====epoch 139
Train Loss 4.489824498462272
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8757 test: 0.8407 | best val epoch -- val: 0.9092 test: 0.8070

====epoch 140
Train Loss 4.27378994163184
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8738 test: 0.8333 | best val epoch -- val: 0.9092 test: 0.8070

====epoch 141
Train Loss 4.28214147431007
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8763 test: 0.8386 | best val epoch -- val: 0.9092 test: 0.8070

====epoch 142
Train Loss 4.362791758161606
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8801 test: 0.8409 | best val epoch -- val: 0.9092 test: 0.8070

====epoch 143
Train Loss 4.807350184869934
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8716 test: 0.8342 | best val epoch -- val: 0.9092 test: 0.8070

====epoch 144
Train Loss 4.28977749035385
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8710 test: 0.8374 | best val epoch -- val: 0.9092 test: 0.8070

====epoch 145
Train Loss 4.476396716827649
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8703 test: 0.8358 | best val epoch -- val: 0.9092 test: 0.8070

====epoch 146
Train Loss 4.454856603751247
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8891 test: 0.8320 | best val epoch -- val: 0.9092 test: 0.8070

====epoch 147
Train Loss 4.562723732469229
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8846 test: 0.8406 | best val epoch -- val: 0.9092 test: 0.8070

====epoch 148
Train Loss 4.306954611030398
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8839 test: 0.8322 | best val epoch -- val: 0.9092 test: 0.8070

====epoch 149
Train Loss 4.482382155584173
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8800 test: 0.8291 | best val epoch -- val: 0.9092 test: 0.8070

====epoch 150
Train Loss 4.386902902572908
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8660 test: 0.8353 | best val epoch -- val: 0.9092 test: 0.8070

====epoch 151
Train Loss 4.792834977490505
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8721 test: 0.8404 | best val epoch -- val: 0.9092 test: 0.8070

====epoch 152
Train Loss 4.423504588629454
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8775 test: 0.8430 | best val epoch -- val: 0.9092 test: 0.8070

====epoch 153
Train Loss 4.198444422209213
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8765 test: 0.8442 | best val epoch -- val: 0.9092 test: 0.8070

====epoch 154
Train Loss 4.165241383070221
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8716 test: 0.8278 | best val epoch -- val: 0.9092 test: 0.8070

====epoch 155
Train Loss 4.260759283384668
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8716 test: 0.8422 | best val epoch -- val: 0.9092 test: 0.8070

====epoch 156
Train Loss 4.195741540530037
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8640 test: 0.8278 | best val epoch -- val: 0.9092 test: 0.8070

====epoch 157
Train Loss 4.104367320266115
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8742 test: 0.8241 | best val epoch -- val: 0.9092 test: 0.8070

====epoch 158
Train Loss 4.39489942822505
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8718 test: 0.8139 | best val epoch -- val: 0.9092 test: 0.8070

====epoch 159
Train Loss 4.095454183367229
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8808 test: 0.8334 | best val epoch -- val: 0.9092 test: 0.8070

====epoch 160
Train Loss 4.347283203215162
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8752 test: 0.8386 | best val epoch -- val: 0.9092 test: 0.8070

====epoch 161
Train Loss 4.416490782426466
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8680 test: 0.8413 | best val epoch -- val: 0.9092 test: 0.8070

====epoch 162
Train Loss 4.16207623369117
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8698 test: 0.8437 | best val epoch -- val: 0.9092 test: 0.8070

====epoch 163
Train Loss 4.208086550041956
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8752 test: 0.8548 | best val epoch -- val: 0.9092 test: 0.8070

====epoch 164
Train Loss 4.485345662048453
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8661 test: 0.8482 | best val epoch -- val: 0.9092 test: 0.8070

====epoch 165
Train Loss 4.265429073500836
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8689 test: 0.8416 | best val epoch -- val: 0.9092 test: 0.8070

====epoch 166
Train Loss 4.195596903706181
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8696 test: 0.8466 | best val epoch -- val: 0.9092 test: 0.8070

====epoch 167
Train Loss 4.449992285964272
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8480 test: 0.8419 | best val epoch -- val: 0.9092 test: 0.8070

====epoch 168
Train Loss 4.110015288122433
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8722 test: 0.8233 | best val epoch -- val: 0.9092 test: 0.8070

====epoch 169
Train Loss 4.356641056879057
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8730 test: 0.8370 | best val epoch -- val: 0.9092 test: 0.8070

====epoch 170
Train Loss 4.169473837874603
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8628 test: 0.8430 | best val epoch -- val: 0.9092 test: 0.8070

====epoch 171
Train Loss 4.2496009671002195
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8649 test: 0.8385 | best val epoch -- val: 0.9092 test: 0.8070

====epoch 172
Train Loss 4.18705056080462
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8600 test: 0.8537 | best val epoch -- val: 0.9092 test: 0.8070

====epoch 173
Train Loss 3.9281125249271347
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8571 test: 0.8587 | best val epoch -- val: 0.9092 test: 0.8070

====epoch 174
Train Loss 4.073616663165094
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8503 test: 0.8480 | best val epoch -- val: 0.9092 test: 0.8070

====epoch 175
Train Loss 4.161691227088109
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8477 test: 0.8512 | best val epoch -- val: 0.9092 test: 0.8070

====epoch 176
Train Loss 4.118206060070828
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8709 test: 0.8579 | best val epoch -- val: 0.9092 test: 0.8070

====epoch 177
Train Loss 4.076368210904133
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8623 test: 0.8438 | best val epoch -- val: 0.9092 test: 0.8070

====epoch 178
Train Loss 3.8148581526853786
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8598 test: 0.8465 | best val epoch -- val: 0.9092 test: 0.8070

====epoch 179
Train Loss 4.046504652434587
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8639 test: 0.8389 | best val epoch -- val: 0.9092 test: 0.8070

====epoch 180
Train Loss 4.076916596356286
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8600 test: 0.8346 | best val epoch -- val: 0.9092 test: 0.8070

====epoch 181
Train Loss 4.3249160826894055
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8675 test: 0.8365 | best val epoch -- val: 0.9092 test: 0.8070

====epoch 182
Train Loss 4.111720298318502
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8776 test: 0.8303 | best val epoch -- val: 0.9092 test: 0.8070

====epoch 183
Train Loss 4.089742985844734
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8721 test: 0.8302 | best val epoch -- val: 0.9092 test: 0.8070

====epoch 184
Train Loss 3.800552305573495
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8552 test: 0.8205 | best val epoch -- val: 0.9092 test: 0.8070

====epoch 185
Train Loss 4.102193033749187
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8776 test: 0.8158 | best val epoch -- val: 0.9092 test: 0.8070

====epoch 186
Train Loss 4.3097240176684375
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8772 test: 0.8372 | best val epoch -- val: 0.9092 test: 0.8070

====epoch 187
Train Loss 4.113493813891972
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8793 test: 0.8457 | best val epoch -- val: 0.9092 test: 0.8070

====epoch 188
Train Loss 4.13132550302974
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8839 test: 0.8502 | best val epoch -- val: 0.9092 test: 0.8070

====epoch 189
Train Loss 3.96588782935098
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8778 test: 0.8109 | best val epoch -- val: 0.9092 test: 0.8070

====epoch 190
Train Loss 3.94901154688338
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8876 test: 0.8163 | best val epoch -- val: 0.9092 test: 0.8070

====epoch 191
Train Loss 3.934776891716842
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8868 test: 0.8474 | best val epoch -- val: 0.9092 test: 0.8070

====epoch 192
Train Loss 3.933712187068004
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8894 test: 0.8371 | best val epoch -- val: 0.9092 test: 0.8070

====epoch 193
Train Loss 4.131402745916311
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8905 test: 0.8231 | best val epoch -- val: 0.9092 test: 0.8070

====epoch 194
Train Loss 3.8949610492891216
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8935 test: 0.8090 | best val epoch -- val: 0.9092 test: 0.8070

====epoch 195
Train Loss 3.7714825428987484
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8903 test: 0.7738 | best val epoch -- val: 0.9092 test: 0.8070

====epoch 196
Train Loss 3.7743149514014687
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8870 test: 0.8181 | best val epoch -- val: 0.9092 test: 0.8070

====epoch 197
Train Loss 4.150531749034847
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8994 test: 0.8295 | best val epoch -- val: 0.9092 test: 0.8070

====epoch 198
Train Loss 3.9291311201646004
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8714 test: 0.8318 | best val epoch -- val: 0.9092 test: 0.8070

====epoch 199
Train Loss 3.8785718644450964
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8773 test: 0.8344 | best val epoch -- val: 0.9092 test: 0.8070

====epoch 200
Train Loss 3.9968598976899434
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8758 test: 0.8519 | best val epoch -- val: 0.9092 test: 0.8070

2022-09-14 02:12:10.084 | INFO     | modules.masked_transformer_encoder:__init__:122 - number of parameters: 0.000000e+00
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.4.
=========================================
batch_size = 32
d_model = 128
dataset = clintox
decay = 0
device = 3
dim_feedforward = 512
eval_train = 0
filename =
gnn_JK = cat
gnn_dropout = 0.3
gnn_emb_dim = 300
gnn_num_layer = 5
gnn_residual = False
gnn_type = gin
gnn_virtual_node = False
graph_pooling = cls
input_model_file = models_graphtrans/graphtrans-sr-gcl.pth
lr = 5e-05
lr_scale = 1
max_input_len = 1000
nhead = 4
num_encoder_layers = 4
num_encoder_layers_masked = 0
num_workers = 0
pos_encoder = False
runseed = 2
seed = 12344
split = scaffold
transformer_activation = relu
transformer_dropout = 0.3
transformer_norm_input = True
transformer_prenorm = False
=========================================
clintox
scaffold
Loaded GraphTrans from models_graphtrans/graphtrans-sr-gcl.pth
====epoch 1
Train Loss 18.135347483567838
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.4456 test: 0.5392 | best val epoch -- val: 0.4456 test: 0.5392

====epoch 2
Train Loss 12.064053841757554
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.3592 test: 0.5644 | best val epoch -- val: 0.4456 test: 0.5392

====epoch 3
Train Loss 10.397369466976244
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.3661 test: 0.5726 | best val epoch -- val: 0.4456 test: 0.5392

====epoch 4
Train Loss 10.21534776535443
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.3736 test: 0.5957 | best val epoch -- val: 0.4456 test: 0.5392

====epoch 5
Train Loss 9.811679491393052
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.3771 test: 0.6068 | best val epoch -- val: 0.4456 test: 0.5392

====epoch 6
Train Loss 9.91372634916889
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.4472 test: 0.6110 | best val epoch -- val: 0.4472 test: 0.6110

====epoch 7
Train Loss 9.908660451385678
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.4819 test: 0.6192 | best val epoch -- val: 0.4819 test: 0.6192

====epoch 8
Train Loss 9.85974783925122
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.4772 test: 0.6278 | best val epoch -- val: 0.4819 test: 0.6192

====epoch 9
Train Loss 9.743189751046712
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.5298 test: 0.6199 | best val epoch -- val: 0.5298 test: 0.6199

====epoch 10
Train Loss 9.666132534301425
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.4810 test: 0.6339 | best val epoch -- val: 0.5298 test: 0.6199

====epoch 11
Train Loss 9.59590106814523
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.5278 test: 0.6473 | best val epoch -- val: 0.5298 test: 0.6199

====epoch 12
Train Loss 9.545206697076148
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.5765 test: 0.6612 | best val epoch -- val: 0.5765 test: 0.6612

====epoch 13
Train Loss 9.571164093906113
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6293 test: 0.6788 | best val epoch -- val: 0.6293 test: 0.6788

====epoch 14
Train Loss 9.195026824482765
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6389 test: 0.6870 | best val epoch -- val: 0.6389 test: 0.6870

====epoch 15
Train Loss 9.22771491462424
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6741 test: 0.6879 | best val epoch -- val: 0.6741 test: 0.6879

====epoch 16
Train Loss 9.304794084954327
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6852 test: 0.6719 | best val epoch -- val: 0.6852 test: 0.6719

====epoch 17
Train Loss 9.010031648880117
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7174 test: 0.6570 | best val epoch -- val: 0.7174 test: 0.6570

====epoch 18
Train Loss 9.228988108195725
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7209 test: 0.6792 | best val epoch -- val: 0.7209 test: 0.6792

====epoch 19
Train Loss 8.915183532942446
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7376 test: 0.6894 | best val epoch -- val: 0.7376 test: 0.6894

====epoch 20
Train Loss 8.813710844465685
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7582 test: 0.6906 | best val epoch -- val: 0.7582 test: 0.6906

====epoch 21
Train Loss 8.80421163944486
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7824 test: 0.6986 | best val epoch -- val: 0.7824 test: 0.6986

====epoch 22
Train Loss 8.668572509698604
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7725 test: 0.7079 | best val epoch -- val: 0.7824 test: 0.6986

====epoch 23
Train Loss 8.45592917720783
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8063 test: 0.6993 | best val epoch -- val: 0.8063 test: 0.6993

====epoch 24
Train Loss 8.235245085829224
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8105 test: 0.7144 | best val epoch -- val: 0.8105 test: 0.7144

====epoch 25
Train Loss 8.150450171124545
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8038 test: 0.7407 | best val epoch -- val: 0.8105 test: 0.7144

====epoch 26
Train Loss 8.093191783331001
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8119 test: 0.7253 | best val epoch -- val: 0.8119 test: 0.7253

====epoch 27
Train Loss 7.960323802064648
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8150 test: 0.7327 | best val epoch -- val: 0.8150 test: 0.7327

====epoch 28
Train Loss 7.427738713852223
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8047 test: 0.7414 | best val epoch -- val: 0.8150 test: 0.7327

====epoch 29
Train Loss 7.507454143178585
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8102 test: 0.7387 | best val epoch -- val: 0.8150 test: 0.7327

====epoch 30
Train Loss 7.390219465195408
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8200 test: 0.7397 | best val epoch -- val: 0.8200 test: 0.7397

====epoch 31
Train Loss 7.161036147902582
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8108 test: 0.7329 | best val epoch -- val: 0.8200 test: 0.7397

====epoch 32
Train Loss 7.0501155085874965
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8189 test: 0.7498 | best val epoch -- val: 0.8200 test: 0.7397

====epoch 33
Train Loss 7.109211320093581
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8195 test: 0.7639 | best val epoch -- val: 0.8200 test: 0.7397

====epoch 34
Train Loss 6.884503308518789
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8324 test: 0.7751 | best val epoch -- val: 0.8324 test: 0.7751

====epoch 35
Train Loss 7.3286336360288935
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8418 test: 0.7601 | best val epoch -- val: 0.8418 test: 0.7601

====epoch 36
Train Loss 6.611645870548801
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8068 test: 0.7664 | best val epoch -- val: 0.8418 test: 0.7601

====epoch 37
Train Loss 6.285097431024999
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8076 test: 0.7812 | best val epoch -- val: 0.8418 test: 0.7601

====epoch 38
Train Loss 6.572869197164077
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8233 test: 0.7899 | best val epoch -- val: 0.8418 test: 0.7601

====epoch 39
Train Loss 6.336077997900879
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8111 test: 0.7828 | best val epoch -- val: 0.8418 test: 0.7601

====epoch 40
Train Loss 6.414751952537289
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7870 test: 0.7898 | best val epoch -- val: 0.8418 test: 0.7601

====epoch 41
Train Loss 6.373603353998657
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8194 test: 0.7992 | best val epoch -- val: 0.8418 test: 0.7601

====epoch 42
Train Loss 6.527761514536205
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8229 test: 0.7944 | best val epoch -- val: 0.8418 test: 0.7601

====epoch 43
Train Loss 6.189583708361372
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8386 test: 0.7938 | best val epoch -- val: 0.8418 test: 0.7601

====epoch 44
Train Loss 6.14080563999827
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8376 test: 0.7833 | best val epoch -- val: 0.8418 test: 0.7601

====epoch 45
Train Loss 6.232322514514196
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8499 test: 0.7911 | best val epoch -- val: 0.8499 test: 0.7911

====epoch 46
Train Loss 6.024800081033545
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8553 test: 0.7991 | best val epoch -- val: 0.8553 test: 0.7991

====epoch 47
Train Loss 5.981270302497906
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8501 test: 0.7910 | best val epoch -- val: 0.8553 test: 0.7991

====epoch 48
Train Loss 5.703020406622939
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8467 test: 0.7978 | best val epoch -- val: 0.8553 test: 0.7991

====epoch 49
Train Loss 5.687045211996426
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8443 test: 0.7979 | best val epoch -- val: 0.8553 test: 0.7991

====epoch 50
Train Loss 5.736278901839388
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8395 test: 0.8138 | best val epoch -- val: 0.8553 test: 0.7991

====epoch 51
Train Loss 5.701676759779455
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8341 test: 0.8105 | best val epoch -- val: 0.8553 test: 0.7991

====epoch 52
Train Loss 5.886740392474753
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8262 test: 0.8106 | best val epoch -- val: 0.8553 test: 0.7991

====epoch 53
Train Loss 6.223981492001223
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8408 test: 0.8112 | best val epoch -- val: 0.8553 test: 0.7991

====epoch 54
Train Loss 5.667330514905932
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8538 test: 0.8113 | best val epoch -- val: 0.8553 test: 0.7991

====epoch 55
Train Loss 5.797238829391726
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8373 test: 0.8098 | best val epoch -- val: 0.8553 test: 0.7991

====epoch 56
Train Loss 5.67033659279732
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8309 test: 0.8152 | best val epoch -- val: 0.8553 test: 0.7991

====epoch 57
Train Loss 5.786993824896019
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8316 test: 0.8278 | best val epoch -- val: 0.8553 test: 0.7991

====epoch 58
Train Loss 5.677751912608678
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8360 test: 0.8309 | best val epoch -- val: 0.8553 test: 0.7991

====epoch 59
Train Loss 5.351666452800065
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8312 test: 0.8280 | best val epoch -- val: 0.8553 test: 0.7991

====epoch 60
Train Loss 5.556359307467141
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8264 test: 0.8103 | best val epoch -- val: 0.8553 test: 0.7991

====epoch 61
Train Loss 5.395458306382723
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8364 test: 0.8264 | best val epoch -- val: 0.8553 test: 0.7991

====epoch 62
Train Loss 5.831427167291308
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8309 test: 0.8277 | best val epoch -- val: 0.8553 test: 0.7991

====epoch 63
Train Loss 5.247375036149132
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8304 test: 0.8364 | best val epoch -- val: 0.8553 test: 0.7991

====epoch 64
Train Loss 5.354638428435732
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8264 test: 0.8291 | best val epoch -- val: 0.8553 test: 0.7991

====epoch 65
Train Loss 5.430591247818514
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8476 test: 0.8266 | best val epoch -- val: 0.8553 test: 0.7991

====epoch 66
Train Loss 5.328667818469206
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8443 test: 0.8230 | best val epoch -- val: 0.8553 test: 0.7991

====epoch 67
Train Loss 5.2773459707864125
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8456 test: 0.8165 | best val epoch -- val: 0.8553 test: 0.7991

====epoch 68
Train Loss 5.6556121329882485
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8358 test: 0.8110 | best val epoch -- val: 0.8553 test: 0.7991

====epoch 69
Train Loss 5.437007339027906
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8456 test: 0.8246 | best val epoch -- val: 0.8553 test: 0.7991

====epoch 70
Train Loss 5.6527712682627635
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8540 test: 0.8190 | best val epoch -- val: 0.8553 test: 0.7991

====epoch 71
Train Loss 5.260297643809664
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8544 test: 0.8217 | best val epoch -- val: 0.8553 test: 0.7991

====epoch 72
Train Loss 5.176880824041936
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8453 test: 0.8338 | best val epoch -- val: 0.8553 test: 0.7991

====epoch 73
Train Loss 5.334615193910093
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8349 test: 0.8185 | best val epoch -- val: 0.8553 test: 0.7991

====epoch 74
Train Loss 5.244800835797454
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8399 test: 0.8209 | best val epoch -- val: 0.8553 test: 0.7991

====epoch 75
Train Loss 5.552686489832402
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8383 test: 0.8220 | best val epoch -- val: 0.8553 test: 0.7991

====epoch 76
Train Loss 4.742587717144198
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8432 test: 0.8054 | best val epoch -- val: 0.8553 test: 0.7991

====epoch 77
Train Loss 5.072154893066329
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8414 test: 0.8235 | best val epoch -- val: 0.8553 test: 0.7991

====epoch 78
Train Loss 5.10785365433599
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8339 test: 0.8375 | best val epoch -- val: 0.8553 test: 0.7991

====epoch 79
Train Loss 4.800806457802887
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8401 test: 0.8361 | best val epoch -- val: 0.8553 test: 0.7991

====epoch 80
Train Loss 4.910874532388789
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8250 test: 0.8328 | best val epoch -- val: 0.8553 test: 0.7991

====epoch 81
Train Loss 5.1194209391548515
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8409 test: 0.8488 | best val epoch -- val: 0.8553 test: 0.7991

====epoch 82
Train Loss 5.364352599741742
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8348 test: 0.8430 | best val epoch -- val: 0.8553 test: 0.7991

====epoch 83
Train Loss 5.136473504666475
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8388 test: 0.8290 | best val epoch -- val: 0.8553 test: 0.7991

====epoch 84
Train Loss 4.8492281135580155
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8458 test: 0.8175 | best val epoch -- val: 0.8553 test: 0.7991

====epoch 85
Train Loss 5.084874997321773
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8405 test: 0.8392 | best val epoch -- val: 0.8553 test: 0.7991

====epoch 86
Train Loss 5.258007189739066
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8440 test: 0.8264 | best val epoch -- val: 0.8553 test: 0.7991

====epoch 87
Train Loss 5.099089315286685
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8519 test: 0.8354 | best val epoch -- val: 0.8553 test: 0.7991

====epoch 88
Train Loss 4.990481480232374
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8488 test: 0.8466 | best val epoch -- val: 0.8553 test: 0.7991

====epoch 89
Train Loss 5.113773625544881
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8382 test: 0.8474 | best val epoch -- val: 0.8553 test: 0.7991

====epoch 90
Train Loss 4.8502585286296345
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8386 test: 0.8468 | best val epoch -- val: 0.8553 test: 0.7991

====epoch 91
Train Loss 5.5320723691603755
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8372 test: 0.8438 | best val epoch -- val: 0.8553 test: 0.7991

====epoch 92
Train Loss 5.092138088855176
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8497 test: 0.8564 | best val epoch -- val: 0.8553 test: 0.7991

====epoch 93
Train Loss 4.955407590427016
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8425 test: 0.8577 | best val epoch -- val: 0.8553 test: 0.7991

====epoch 94
Train Loss 4.955975236390133
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8392 test: 0.8566 | best val epoch -- val: 0.8553 test: 0.7991

====epoch 95
Train Loss 4.873495284256407
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8541 test: 0.8508 | best val epoch -- val: 0.8553 test: 0.7991

====epoch 96
Train Loss 4.980047663798516
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8572 test: 0.8420 | best val epoch -- val: 0.8572 test: 0.8420

====epoch 97
Train Loss 4.884865676744703
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8522 test: 0.8426 | best val epoch -- val: 0.8572 test: 0.8420

====epoch 98
Train Loss 4.71269826207066
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8624 test: 0.8372 | best val epoch -- val: 0.8624 test: 0.8372

====epoch 99
Train Loss 4.925825419941794
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8691 test: 0.8535 | best val epoch -- val: 0.8691 test: 0.8535

====epoch 100
Train Loss 4.7950743586012905
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8654 test: 0.8571 | best val epoch -- val: 0.8691 test: 0.8535

====epoch 101
Train Loss 4.993017371874218
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8757 test: 0.8544 | best val epoch -- val: 0.8757 test: 0.8544

====epoch 102
Train Loss 4.75887466937183
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8610 test: 0.8480 | best val epoch -- val: 0.8757 test: 0.8544

====epoch 103
Train Loss 4.874190715915881
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8728 test: 0.8444 | best val epoch -- val: 0.8757 test: 0.8544

====epoch 104
Train Loss 4.692437736955661
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8779 test: 0.8160 | best val epoch -- val: 0.8779 test: 0.8160

====epoch 105
Train Loss 4.719890809999721
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8643 test: 0.8001 | best val epoch -- val: 0.8779 test: 0.8160

====epoch 106
Train Loss 4.934669471442852
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8581 test: 0.8246 | best val epoch -- val: 0.8779 test: 0.8160

====epoch 107
Train Loss 4.647771099439534
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8698 test: 0.8126 | best val epoch -- val: 0.8779 test: 0.8160

====epoch 108
Train Loss 4.710350492771851
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8757 test: 0.8019 | best val epoch -- val: 0.8779 test: 0.8160

====epoch 109
Train Loss 4.485439252318689
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8572 test: 0.8042 | best val epoch -- val: 0.8779 test: 0.8160

====epoch 110
Train Loss 4.868432215864018
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8735 test: 0.8250 | best val epoch -- val: 0.8779 test: 0.8160

====epoch 111
Train Loss 4.571377092147557
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8833 test: 0.8253 | best val epoch -- val: 0.8833 test: 0.8253

====epoch 112
Train Loss 5.015640076297441
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8946 test: 0.8479 | best val epoch -- val: 0.8946 test: 0.8479

====epoch 113
Train Loss 4.608449443177889
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8958 test: 0.8473 | best val epoch -- val: 0.8958 test: 0.8473

====epoch 114
Train Loss 4.370199785782283
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8928 test: 0.8466 | best val epoch -- val: 0.8958 test: 0.8473

====epoch 115
Train Loss 4.875073132276506
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8882 test: 0.8431 | best val epoch -- val: 0.8958 test: 0.8473

====epoch 116
Train Loss 4.4407006785547
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8903 test: 0.8388 | best val epoch -- val: 0.8958 test: 0.8473

====epoch 117
Train Loss 4.655993482339001
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8893 test: 0.8543 | best val epoch -- val: 0.8958 test: 0.8473

====epoch 118
Train Loss 4.654716404129956
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8764 test: 0.8401 | best val epoch -- val: 0.8958 test: 0.8473

====epoch 119
Train Loss 4.646079758641566
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8830 test: 0.8455 | best val epoch -- val: 0.8958 test: 0.8473

====epoch 120
Train Loss 4.911249939763096
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8827 test: 0.8383 | best val epoch -- val: 0.8958 test: 0.8473

====epoch 121
Train Loss 4.67671628347604
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8874 test: 0.8425 | best val epoch -- val: 0.8958 test: 0.8473

====epoch 122
Train Loss 4.589762471526265
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8756 test: 0.8375 | best val epoch -- val: 0.8958 test: 0.8473

====epoch 123
Train Loss 4.584242473443679
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8869 test: 0.8296 | best val epoch -- val: 0.8958 test: 0.8473

====epoch 124
Train Loss 4.600611567934199
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8879 test: 0.8431 | best val epoch -- val: 0.8958 test: 0.8473

====epoch 125
Train Loss 4.643393279291973
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8772 test: 0.8341 | best val epoch -- val: 0.8958 test: 0.8473

====epoch 126
Train Loss 4.476492268083021
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8808 test: 0.8364 | best val epoch -- val: 0.8958 test: 0.8473

====epoch 127
Train Loss 4.650678425233774
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8925 test: 0.8407 | best val epoch -- val: 0.8958 test: 0.8473

====epoch 128
Train Loss 4.659533789299217
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8924 test: 0.8479 | best val epoch -- val: 0.8958 test: 0.8473

====epoch 129
Train Loss 4.345174971826654
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8955 test: 0.8307 | best val epoch -- val: 0.8958 test: 0.8473

====epoch 130
Train Loss 4.318361566730205
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8882 test: 0.8294 | best val epoch -- val: 0.8958 test: 0.8473

====epoch 131
Train Loss 4.740509802509956
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8853 test: 0.8383 | best val epoch -- val: 0.8958 test: 0.8473

====epoch 132
Train Loss 4.317955725580768
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8997 test: 0.8362 | best val epoch -- val: 0.8997 test: 0.8362

====epoch 133
Train Loss 4.582665699707699
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8980 test: 0.8405 | best val epoch -- val: 0.8997 test: 0.8362

====epoch 134
Train Loss 4.582061133628178
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9009 test: 0.8427 | best val epoch -- val: 0.9009 test: 0.8427

====epoch 135
Train Loss 4.4765241112054674
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8960 test: 0.8430 | best val epoch -- val: 0.9009 test: 0.8427

====epoch 136
Train Loss 4.444036489447009
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9128 test: 0.8532 | best val epoch -- val: 0.9128 test: 0.8532

====epoch 137
Train Loss 4.296859826069482
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9053 test: 0.8463 | best val epoch -- val: 0.9128 test: 0.8532

====epoch 138
Train Loss 4.550099922728653
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9080 test: 0.8434 | best val epoch -- val: 0.9128 test: 0.8532

====epoch 139
Train Loss 4.904845384415345
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9123 test: 0.8223 | best val epoch -- val: 0.9128 test: 0.8532

====epoch 140
Train Loss 4.384572116101587
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9076 test: 0.8162 | best val epoch -- val: 0.9128 test: 0.8532

====epoch 141
Train Loss 4.105103872009325
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9158 test: 0.8203 | best val epoch -- val: 0.9158 test: 0.8203

====epoch 142
Train Loss 4.8076496553802315
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9163 test: 0.8210 | best val epoch -- val: 0.9163 test: 0.8210

====epoch 143
Train Loss 4.921345182686443
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9153 test: 0.8317 | best val epoch -- val: 0.9163 test: 0.8210

====epoch 144
Train Loss 4.148156865085033
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9219 test: 0.8309 | best val epoch -- val: 0.9219 test: 0.8309

====epoch 145
Train Loss 4.2109042730304385
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9219 test: 0.8277 | best val epoch -- val: 0.9219 test: 0.8309

====epoch 146
Train Loss 4.144784005215024
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9143 test: 0.8332 | best val epoch -- val: 0.9219 test: 0.8309

====epoch 147
Train Loss 4.441160513329176
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9067 test: 0.8225 | best val epoch -- val: 0.9219 test: 0.8309

====epoch 148
Train Loss 4.180406096147227
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9085 test: 0.8256 | best val epoch -- val: 0.9219 test: 0.8309

====epoch 149
Train Loss 4.543243424022663
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9132 test: 0.8273 | best val epoch -- val: 0.9219 test: 0.8309

====epoch 150
Train Loss 4.1417683738828455
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9141 test: 0.8145 | best val epoch -- val: 0.9219 test: 0.8309

====epoch 151
Train Loss 4.183452160835379
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9149 test: 0.8198 | best val epoch -- val: 0.9219 test: 0.8309

====epoch 152
Train Loss 4.10963537884023
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9135 test: 0.8330 | best val epoch -- val: 0.9219 test: 0.8309

====epoch 153
Train Loss 4.312376552055754
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9028 test: 0.8108 | best val epoch -- val: 0.9219 test: 0.8309

====epoch 154
Train Loss 4.178605926798269
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9057 test: 0.8049 | best val epoch -- val: 0.9219 test: 0.8309

====epoch 155
Train Loss 4.220728954717346
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9159 test: 0.8333 | best val epoch -- val: 0.9219 test: 0.8309

====epoch 156
Train Loss 4.151982316476892
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9205 test: 0.8358 | best val epoch -- val: 0.9219 test: 0.8309

====epoch 157
Train Loss 4.212467169450583
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9191 test: 0.8287 | best val epoch -- val: 0.9219 test: 0.8309

====epoch 158
Train Loss 4.351192895121724
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9143 test: 0.8209 | best val epoch -- val: 0.9219 test: 0.8309

====epoch 159
Train Loss 4.002570284082363
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9143 test: 0.8181 | best val epoch -- val: 0.9219 test: 0.8309

====epoch 160
Train Loss 4.234384661636458
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9053 test: 0.8259 | best val epoch -- val: 0.9219 test: 0.8309

====epoch 161
Train Loss 4.16804470382416
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9052 test: 0.8172 | best val epoch -- val: 0.9219 test: 0.8309

====epoch 162
Train Loss 4.132060947569081
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9006 test: 0.8156 | best val epoch -- val: 0.9219 test: 0.8309

====epoch 163
Train Loss 3.753044735391978
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8998 test: 0.8161 | best val epoch -- val: 0.9219 test: 0.8309

====epoch 164
Train Loss 4.140271047947828
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9102 test: 0.8267 | best val epoch -- val: 0.9219 test: 0.8309

====epoch 165
Train Loss 4.287273853245084
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9019 test: 0.8340 | best val epoch -- val: 0.9219 test: 0.8309

====epoch 166
Train Loss 3.8088768415516387
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9064 test: 0.8313 | best val epoch -- val: 0.9219 test: 0.8309

====epoch 167
Train Loss 4.133201397776416
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9044 test: 0.8354 | best val epoch -- val: 0.9219 test: 0.8309

====epoch 168
Train Loss 4.229363009421142
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9032 test: 0.8264 | best val epoch -- val: 0.9219 test: 0.8309

====epoch 169
Train Loss 3.967807455157227
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9007 test: 0.8121 | best val epoch -- val: 0.9219 test: 0.8309

====epoch 170
Train Loss 4.040073346950588
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9042 test: 0.8045 | best val epoch -- val: 0.9219 test: 0.8309

====epoch 171
Train Loss 3.895458279764015
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9083 test: 0.8113 | best val epoch -- val: 0.9219 test: 0.8309

====epoch 172
Train Loss 4.086631534718846
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9182 test: 0.8301 | best val epoch -- val: 0.9219 test: 0.8309

====epoch 173
Train Loss 4.174766232483861
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9070 test: 0.8208 | best val epoch -- val: 0.9219 test: 0.8309

====epoch 174
Train Loss 4.229249066648054
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9078 test: 0.8221 | best val epoch -- val: 0.9219 test: 0.8309

====epoch 175
Train Loss 4.032022600559949
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9084 test: 0.8241 | best val epoch -- val: 0.9219 test: 0.8309

====epoch 176
Train Loss 4.073001739553532
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9035 test: 0.8161 | best val epoch -- val: 0.9219 test: 0.8309

====epoch 177
Train Loss 4.373034328275756
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8962 test: 0.8201 | best val epoch -- val: 0.9219 test: 0.8309

====epoch 178
Train Loss 3.9547411727536126
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9031 test: 0.8256 | best val epoch -- val: 0.9219 test: 0.8309

====epoch 179
Train Loss 4.049234314363956
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8952 test: 0.8090 | best val epoch -- val: 0.9219 test: 0.8309

====epoch 180
Train Loss 4.012151550645379
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8970 test: 0.8089 | best val epoch -- val: 0.9219 test: 0.8309

====epoch 181
Train Loss 4.087322834918551
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8976 test: 0.8026 | best val epoch -- val: 0.9219 test: 0.8309

====epoch 182
Train Loss 4.355552239293887
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8953 test: 0.7993 | best val epoch -- val: 0.9219 test: 0.8309

====epoch 183
Train Loss 3.8510411855400477
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9033 test: 0.8101 | best val epoch -- val: 0.9219 test: 0.8309

====epoch 184
Train Loss 3.874045148320874
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9061 test: 0.8053 | best val epoch -- val: 0.9219 test: 0.8309

====epoch 185
Train Loss 4.038833754726286
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9033 test: 0.7928 | best val epoch -- val: 0.9219 test: 0.8309

====epoch 186
Train Loss 3.92868390630378
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9118 test: 0.8102 | best val epoch -- val: 0.9219 test: 0.8309

====epoch 187
Train Loss 3.938342307009971
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9121 test: 0.8098 | best val epoch -- val: 0.9219 test: 0.8309

====epoch 188
Train Loss 4.196906164823371
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9130 test: 0.8153 | best val epoch -- val: 0.9219 test: 0.8309

====epoch 189
Train Loss 4.025715692430217
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8964 test: 0.8202 | best val epoch -- val: 0.9219 test: 0.8309

====epoch 190
Train Loss 3.8733147916137423
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9060 test: 0.8158 | best val epoch -- val: 0.9219 test: 0.8309

====epoch 191
Train Loss 3.8134252282210825
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9073 test: 0.8121 | best val epoch -- val: 0.9219 test: 0.8309

====epoch 192
Train Loss 4.059766221218812
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9069 test: 0.8250 | best val epoch -- val: 0.9219 test: 0.8309

====epoch 193
Train Loss 3.897232574450519
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8990 test: 0.8098 | best val epoch -- val: 0.9219 test: 0.8309

====epoch 194
Train Loss 4.018113290940606
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9007 test: 0.8127 | best val epoch -- val: 0.9219 test: 0.8309

====epoch 195
Train Loss 4.0321519518786735
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9026 test: 0.8271 | best val epoch -- val: 0.9219 test: 0.8309

====epoch 196
Train Loss 3.953819151789298
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9105 test: 0.8279 | best val epoch -- val: 0.9219 test: 0.8309

====epoch 197
Train Loss 3.7452466233853317
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9109 test: 0.8419 | best val epoch -- val: 0.9219 test: 0.8309

====epoch 198
Train Loss 3.8069870361118645
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9121 test: 0.8399 | best val epoch -- val: 0.9219 test: 0.8309

====epoch 199
Train Loss 3.6442242774028437
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9089 test: 0.8386 | best val epoch -- val: 0.9219 test: 0.8309

====epoch 200
Train Loss 4.0119499890132015
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9145 test: 0.8416 | best val epoch -- val: 0.9219 test: 0.8309

2022-09-14 02:18:56.049 | INFO     | modules.masked_transformer_encoder:__init__:122 - number of parameters: 0.000000e+00
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.4.
=========================================
batch_size = 32
d_model = 128
dataset = clintox
decay = 0
device = 3
dim_feedforward = 512
eval_train = 0
filename =
gnn_JK = cat
gnn_dropout = 0.3
gnn_emb_dim = 300
gnn_num_layer = 5
gnn_residual = False
gnn_type = gin
gnn_virtual_node = False
graph_pooling = cls
input_model_file = models_graphtrans/graphtrans-sr-gcl.pth
lr = 5e-05
lr_scale = 1
max_input_len = 1000
nhead = 4
num_encoder_layers = 4
num_encoder_layers_masked = 0
num_workers = 0
pos_encoder = False
runseed = 3
seed = 12344
split = scaffold
transformer_activation = relu
transformer_dropout = 0.3
transformer_norm_input = True
transformer_prenorm = False
=========================================
clintox
scaffold
Loaded GraphTrans from models_graphtrans/graphtrans-sr-gcl.pth
====epoch 1
Train Loss 18.74520663852465
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.3964 test: 0.4953 | best val epoch -- val: 0.3964 test: 0.4953

====epoch 2
Train Loss 12.010787956942341
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.3483 test: 0.5197 | best val epoch -- val: 0.3964 test: 0.4953

====epoch 3
Train Loss 10.369695723572969
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.2906 test: 0.5970 | best val epoch -- val: 0.3964 test: 0.4953

====epoch 4
Train Loss 9.927831355703141
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.3555 test: 0.5542 | best val epoch -- val: 0.3964 test: 0.4953

====epoch 5
Train Loss 9.715721108153184
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.3151 test: 0.5975 | best val epoch -- val: 0.3964 test: 0.4953

====epoch 6
Train Loss 9.879610578576619
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.3362 test: 0.5951 | best val epoch -- val: 0.3964 test: 0.4953

====epoch 7
Train Loss 9.750430029365427
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.3623 test: 0.6596 | best val epoch -- val: 0.3964 test: 0.4953

====epoch 8
Train Loss 9.70158615708058
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.3949 test: 0.6690 | best val epoch -- val: 0.3964 test: 0.4953

====epoch 9
Train Loss 9.780709758016801
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.4355 test: 0.6634 | best val epoch -- val: 0.4355 test: 0.6634

====epoch 10
Train Loss 9.899142769091684
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.4623 test: 0.7089 | best val epoch -- val: 0.4623 test: 0.7089

====epoch 11
Train Loss 9.474852317049345
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.4953 test: 0.7315 | best val epoch -- val: 0.4953 test: 0.7315

====epoch 12
Train Loss 9.542552167852579
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.5691 test: 0.7166 | best val epoch -- val: 0.5691 test: 0.7166

====epoch 13
Train Loss 9.357977645044375
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6779 test: 0.6907 | best val epoch -- val: 0.6779 test: 0.6907

====epoch 14
Train Loss 9.319052680458656
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7403 test: 0.6995 | best val epoch -- val: 0.7403 test: 0.6995

====epoch 15
Train Loss 9.188224202251382
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7477 test: 0.7088 | best val epoch -- val: 0.7477 test: 0.7088

====epoch 16
Train Loss 9.227007298425162
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7391 test: 0.7507 | best val epoch -- val: 0.7477 test: 0.7088

====epoch 17
Train Loss 8.987970377049617
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7680 test: 0.7220 | best val epoch -- val: 0.7680 test: 0.7220

====epoch 18
Train Loss 8.93516379750309
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7900 test: 0.7295 | best val epoch -- val: 0.7900 test: 0.7295

====epoch 19
Train Loss 8.779750929049346
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8082 test: 0.7104 | best val epoch -- val: 0.8082 test: 0.7104

====epoch 20
Train Loss 8.508054435892664
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8178 test: 0.7125 | best val epoch -- val: 0.8178 test: 0.7125

====epoch 21
Train Loss 8.57211768137476
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8317 test: 0.7302 | best val epoch -- val: 0.8317 test: 0.7302

====epoch 22
Train Loss 8.139982994294916
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8349 test: 0.7162 | best val epoch -- val: 0.8349 test: 0.7162

====epoch 23
Train Loss 7.956381506471346
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8304 test: 0.7355 | best val epoch -- val: 0.8349 test: 0.7162

====epoch 24
Train Loss 7.579884874578916
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8184 test: 0.7409 | best val epoch -- val: 0.8349 test: 0.7162

====epoch 25
Train Loss 7.643819045352156
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8229 test: 0.7333 | best val epoch -- val: 0.8349 test: 0.7162

====epoch 26
Train Loss 7.614136954209543
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8020 test: 0.7090 | best val epoch -- val: 0.8349 test: 0.7162

====epoch 27
Train Loss 7.660519668100731
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8044 test: 0.7134 | best val epoch -- val: 0.8349 test: 0.7162

====epoch 28
Train Loss 7.333649226650946
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8133 test: 0.7113 | best val epoch -- val: 0.8349 test: 0.7162

====epoch 29
Train Loss 7.0674694264335844
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8137 test: 0.7165 | best val epoch -- val: 0.8349 test: 0.7162

====epoch 30
Train Loss 6.81373100461877
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8071 test: 0.7094 | best val epoch -- val: 0.8349 test: 0.7162

====epoch 31
Train Loss 6.864940836076395
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8208 test: 0.7125 | best val epoch -- val: 0.8349 test: 0.7162

====epoch 32
Train Loss 6.64277711003194
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7746 test: 0.7188 | best val epoch -- val: 0.8349 test: 0.7162

====epoch 33
Train Loss 6.795286439896602
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8133 test: 0.7386 | best val epoch -- val: 0.8349 test: 0.7162

====epoch 34
Train Loss 6.376408748226263
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8613 test: 0.7452 | best val epoch -- val: 0.8613 test: 0.7452

====epoch 35
Train Loss 6.928239981471402
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8494 test: 0.7376 | best val epoch -- val: 0.8613 test: 0.7452

====epoch 36
Train Loss 6.793949605239367
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8517 test: 0.7286 | best val epoch -- val: 0.8613 test: 0.7452

====epoch 37
Train Loss 6.771201682703035
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8247 test: 0.7335 | best val epoch -- val: 0.8613 test: 0.7452

====epoch 38
Train Loss 6.680975229343831
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8278 test: 0.7317 | best val epoch -- val: 0.8613 test: 0.7452

====epoch 39
Train Loss 6.649770444770527
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8177 test: 0.7436 | best val epoch -- val: 0.8613 test: 0.7452

====epoch 40
Train Loss 6.130298162761293
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8234 test: 0.7445 | best val epoch -- val: 0.8613 test: 0.7452

====epoch 41
Train Loss 6.1115897961618515
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8174 test: 0.7505 | best val epoch -- val: 0.8613 test: 0.7452

====epoch 42
Train Loss 6.190454939269129
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8432 test: 0.7586 | best val epoch -- val: 0.8613 test: 0.7452

====epoch 43
Train Loss 5.959849030068126
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8352 test: 0.7624 | best val epoch -- val: 0.8613 test: 0.7452

====epoch 44
Train Loss 6.215907682156277
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8233 test: 0.7800 | best val epoch -- val: 0.8613 test: 0.7452

====epoch 45
Train Loss 6.1160324005379
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8341 test: 0.7669 | best val epoch -- val: 0.8613 test: 0.7452

====epoch 46
Train Loss 5.441339634961412
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8248 test: 0.7714 | best val epoch -- val: 0.8613 test: 0.7452

====epoch 47
Train Loss 6.4212430134929
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8318 test: 0.7790 | best val epoch -- val: 0.8613 test: 0.7452

====epoch 48
Train Loss 6.120200821394953
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8227 test: 0.7901 | best val epoch -- val: 0.8613 test: 0.7452

====epoch 49
Train Loss 5.762928779035687
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8239 test: 0.7814 | best val epoch -- val: 0.8613 test: 0.7452

====epoch 50
Train Loss 5.751611577003148
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8206 test: 0.7786 | best val epoch -- val: 0.8613 test: 0.7452

====epoch 51
Train Loss 5.712107614175499
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8197 test: 0.7747 | best val epoch -- val: 0.8613 test: 0.7452

====epoch 52
Train Loss 5.940629665866985
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8151 test: 0.7791 | best val epoch -- val: 0.8613 test: 0.7452

====epoch 53
Train Loss 5.868005905221328
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8080 test: 0.7848 | best val epoch -- val: 0.8613 test: 0.7452

====epoch 54
Train Loss 5.782924561978182
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8207 test: 0.7838 | best val epoch -- val: 0.8613 test: 0.7452

====epoch 55
Train Loss 6.005816611892271
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8215 test: 0.7897 | best val epoch -- val: 0.8613 test: 0.7452

====epoch 56
Train Loss 6.042185170798697
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8237 test: 0.7969 | best val epoch -- val: 0.8613 test: 0.7452

====epoch 57
Train Loss 5.9738163463439715
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8174 test: 0.7959 | best val epoch -- val: 0.8613 test: 0.7452

====epoch 58
Train Loss 5.571185723879468
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8052 test: 0.8013 | best val epoch -- val: 0.8613 test: 0.7452

====epoch 59
Train Loss 5.595902784487604
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7925 test: 0.7700 | best val epoch -- val: 0.8613 test: 0.7452

====epoch 60
Train Loss 5.679821447056429
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8048 test: 0.7791 | best val epoch -- val: 0.8613 test: 0.7452

====epoch 61
Train Loss 5.402623003983147
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8160 test: 0.8006 | best val epoch -- val: 0.8613 test: 0.7452

====epoch 62
Train Loss 5.406159127933714
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8269 test: 0.7996 | best val epoch -- val: 0.8613 test: 0.7452

====epoch 63
Train Loss 5.23854417759569
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8152 test: 0.8010 | best val epoch -- val: 0.8613 test: 0.7452

====epoch 64
Train Loss 5.115940997387483
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8158 test: 0.8161 | best val epoch -- val: 0.8613 test: 0.7452

====epoch 65
Train Loss 5.708991625534922
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8264 test: 0.8310 | best val epoch -- val: 0.8613 test: 0.7452

====epoch 66
Train Loss 4.91546317551323
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8147 test: 0.8193 | best val epoch -- val: 0.8613 test: 0.7452

====epoch 67
Train Loss 5.4917485881611565
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8191 test: 0.8115 | best val epoch -- val: 0.8613 test: 0.7452

====epoch 68
Train Loss 5.415819279432914
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8261 test: 0.8255 | best val epoch -- val: 0.8613 test: 0.7452

====epoch 69
Train Loss 5.449492858887945
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8125 test: 0.8035 | best val epoch -- val: 0.8613 test: 0.7452

====epoch 70
Train Loss 5.172228768630523
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8324 test: 0.7904 | best val epoch -- val: 0.8613 test: 0.7452

====epoch 71
Train Loss 5.0621496250586695
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8417 test: 0.7829 | best val epoch -- val: 0.8613 test: 0.7452

====epoch 72
Train Loss 5.271098638895023
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8312 test: 0.7725 | best val epoch -- val: 0.8613 test: 0.7452

====epoch 73
Train Loss 5.233771683605333
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8386 test: 0.7728 | best val epoch -- val: 0.8613 test: 0.7452

====epoch 74
Train Loss 5.24179473518701
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8457 test: 0.8009 | best val epoch -- val: 0.8613 test: 0.7452

====epoch 75
Train Loss 5.098472273637541
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8409 test: 0.8127 | best val epoch -- val: 0.8613 test: 0.7452

====epoch 76
Train Loss 4.787374916136409
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8544 test: 0.8050 | best val epoch -- val: 0.8613 test: 0.7452

====epoch 77
Train Loss 4.9225521607625335
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8537 test: 0.8123 | best val epoch -- val: 0.8613 test: 0.7452

====epoch 78
Train Loss 4.581938059627273
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8420 test: 0.8227 | best val epoch -- val: 0.8613 test: 0.7452

====epoch 79
Train Loss 4.892709250449986
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8460 test: 0.8153 | best val epoch -- val: 0.8613 test: 0.7452

====epoch 80
Train Loss 4.813488688415175
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8433 test: 0.8058 | best val epoch -- val: 0.8613 test: 0.7452

====epoch 81
Train Loss 4.813818301550739
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8470 test: 0.7998 | best val epoch -- val: 0.8613 test: 0.7452

====epoch 82
Train Loss 4.706558858955382
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8467 test: 0.8031 | best val epoch -- val: 0.8613 test: 0.7452

====epoch 83
Train Loss 4.52456614507612
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8405 test: 0.7923 | best val epoch -- val: 0.8613 test: 0.7452

====epoch 84
Train Loss 5.103506861970389
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8420 test: 0.8069 | best val epoch -- val: 0.8613 test: 0.7452

====epoch 85
Train Loss 5.193577193006299
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8373 test: 0.7911 | best val epoch -- val: 0.8613 test: 0.7452

====epoch 86
Train Loss 4.971578290148998
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8394 test: 0.7975 | best val epoch -- val: 0.8613 test: 0.7452

====epoch 87
Train Loss 5.00154511010564
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8449 test: 0.7814 | best val epoch -- val: 0.8613 test: 0.7452

====epoch 88
Train Loss 4.829006130496975
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8482 test: 0.7999 | best val epoch -- val: 0.8613 test: 0.7452

====epoch 89
Train Loss 4.993753851324458
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8369 test: 0.7947 | best val epoch -- val: 0.8613 test: 0.7452

====epoch 90
Train Loss 5.03753673430316
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8311 test: 0.7897 | best val epoch -- val: 0.8613 test: 0.7452

====epoch 91
Train Loss 4.97360292851609
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8456 test: 0.8035 | best val epoch -- val: 0.8613 test: 0.7452

====epoch 92
Train Loss 4.848399050308313
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8385 test: 0.7900 | best val epoch -- val: 0.8613 test: 0.7452

====epoch 93
Train Loss 5.150892336901426
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8572 test: 0.7782 | best val epoch -- val: 0.8613 test: 0.7452

====epoch 94
Train Loss 4.686587396650928
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8565 test: 0.7878 | best val epoch -- val: 0.8613 test: 0.7452

====epoch 95
Train Loss 4.688170849817866
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8422 test: 0.7766 | best val epoch -- val: 0.8613 test: 0.7452

====epoch 96
Train Loss 4.926464784026163
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8428 test: 0.7815 | best val epoch -- val: 0.8613 test: 0.7452

====epoch 97
Train Loss 5.071832018745534
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8309 test: 0.7663 | best val epoch -- val: 0.8613 test: 0.7452

====epoch 98
Train Loss 4.688403465295508
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8313 test: 0.7754 | best val epoch -- val: 0.8613 test: 0.7452

====epoch 99
Train Loss 4.714264345010634
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8515 test: 0.7471 | best val epoch -- val: 0.8613 test: 0.7452

====epoch 100
Train Loss 4.713895267040771
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8496 test: 0.7524 | best val epoch -- val: 0.8613 test: 0.7452

====epoch 101
Train Loss 4.66790512235237
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8550 test: 0.7599 | best val epoch -- val: 0.8613 test: 0.7452

====epoch 102
Train Loss 4.633178181606526
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8408 test: 0.7713 | best val epoch -- val: 0.8613 test: 0.7452

====epoch 103
Train Loss 4.493528422126393
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8456 test: 0.7509 | best val epoch -- val: 0.8613 test: 0.7452

====epoch 104
Train Loss 4.556233425001902
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8475 test: 0.7507 | best val epoch -- val: 0.8613 test: 0.7452

====epoch 105
Train Loss 4.397534631426428
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8349 test: 0.7404 | best val epoch -- val: 0.8613 test: 0.7452

====epoch 106
Train Loss 4.732767231381873
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8219 test: 0.7501 | best val epoch -- val: 0.8613 test: 0.7452

====epoch 107
Train Loss 4.6766728860158535
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8426 test: 0.7412 | best val epoch -- val: 0.8613 test: 0.7452

====epoch 108
Train Loss 4.381702526013824
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8381 test: 0.7383 | best val epoch -- val: 0.8613 test: 0.7452

====epoch 109
Train Loss 4.567882921512457
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8400 test: 0.7259 | best val epoch -- val: 0.8613 test: 0.7452

====epoch 110
Train Loss 4.77032378415568
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8275 test: 0.7151 | best val epoch -- val: 0.8613 test: 0.7452

====epoch 111
Train Loss 4.665790079947586
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8164 test: 0.7196 | best val epoch -- val: 0.8613 test: 0.7452

====epoch 112
Train Loss 4.501243438310644
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8287 test: 0.7303 | best val epoch -- val: 0.8613 test: 0.7452

====epoch 113
Train Loss 4.646731951503948
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8328 test: 0.7312 | best val epoch -- val: 0.8613 test: 0.7452

====epoch 114
Train Loss 4.747418297989279
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8335 test: 0.7395 | best val epoch -- val: 0.8613 test: 0.7452

====epoch 115
Train Loss 4.291530856320706
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8332 test: 0.7380 | best val epoch -- val: 0.8613 test: 0.7452

====epoch 116
Train Loss 4.463245444522231
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8220 test: 0.7270 | best val epoch -- val: 0.8613 test: 0.7452

====epoch 117
Train Loss 4.46918109032594
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8415 test: 0.7347 | best val epoch -- val: 0.8613 test: 0.7452

====epoch 118
Train Loss 4.513945690144999
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8485 test: 0.7281 | best val epoch -- val: 0.8613 test: 0.7452

====epoch 119
Train Loss 4.475798036975449
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8462 test: 0.7360 | best val epoch -- val: 0.8613 test: 0.7452

====epoch 120
Train Loss 4.688817701373068
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8369 test: 0.7332 | best val epoch -- val: 0.8613 test: 0.7452

====epoch 121
Train Loss 4.401820911796347
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8311 test: 0.7437 | best val epoch -- val: 0.8613 test: 0.7452

====epoch 122
Train Loss 4.4656304845352395
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8283 test: 0.7624 | best val epoch -- val: 0.8613 test: 0.7452

====epoch 123
Train Loss 4.5132538624030225
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8559 test: 0.7701 | best val epoch -- val: 0.8613 test: 0.7452

====epoch 124
Train Loss 4.673472966499074
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8527 test: 0.7708 | best val epoch -- val: 0.8613 test: 0.7452

====epoch 125
Train Loss 4.606997041651031
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8410 test: 0.7782 | best val epoch -- val: 0.8613 test: 0.7452

====epoch 126
Train Loss 4.522833863535624
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8319 test: 0.7696 | best val epoch -- val: 0.8613 test: 0.7452

====epoch 127
Train Loss 4.410223888957966
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8289 test: 0.7827 | best val epoch -- val: 0.8613 test: 0.7452

====epoch 128
Train Loss 4.55739761384049
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8369 test: 0.7891 | best val epoch -- val: 0.8613 test: 0.7452

====epoch 129
Train Loss 4.618553966139477
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8157 test: 0.7670 | best val epoch -- val: 0.8613 test: 0.7452

====epoch 130
Train Loss 4.605134720317212
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8175 test: 0.7691 | best val epoch -- val: 0.8613 test: 0.7452

====epoch 131
Train Loss 4.21555439046835
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8204 test: 0.7627 | best val epoch -- val: 0.8613 test: 0.7452

====epoch 132
Train Loss 4.403115232674109
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8293 test: 0.7523 | best val epoch -- val: 0.8613 test: 0.7452

====epoch 133
Train Loss 4.439644183727271
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8302 test: 0.7614 | best val epoch -- val: 0.8613 test: 0.7452

====epoch 134
Train Loss 4.460522688719933
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8130 test: 0.7428 | best val epoch -- val: 0.8613 test: 0.7452

====epoch 135
Train Loss 4.454330044360752
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8363 test: 0.7866 | best val epoch -- val: 0.8613 test: 0.7452

====epoch 136
Train Loss 4.420902462066166
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8294 test: 0.7839 | best val epoch -- val: 0.8613 test: 0.7452

====epoch 137
Train Loss 4.708308251779276
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8283 test: 0.7848 | best val epoch -- val: 0.8613 test: 0.7452

====epoch 138
Train Loss 4.222057215903667
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8310 test: 0.7589 | best val epoch -- val: 0.8613 test: 0.7452

====epoch 139
Train Loss 4.462127560891814
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8232 test: 0.7812 | best val epoch -- val: 0.8613 test: 0.7452

====epoch 140
Train Loss 3.9692298539295847
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8327 test: 0.7859 | best val epoch -- val: 0.8613 test: 0.7452

====epoch 141
Train Loss 3.99601013079055
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8183 test: 0.7690 | best val epoch -- val: 0.8613 test: 0.7452

====epoch 142
Train Loss 4.17547118692576
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8271 test: 0.7772 | best val epoch -- val: 0.8613 test: 0.7452

====epoch 143
Train Loss 4.239940542356503
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8257 test: 0.7849 | best val epoch -- val: 0.8613 test: 0.7452

====epoch 144
Train Loss 4.260874351276676
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8196 test: 0.7901 | best val epoch -- val: 0.8613 test: 0.7452

====epoch 145
Train Loss 4.397606755525331
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8295 test: 0.7994 | best val epoch -- val: 0.8613 test: 0.7452

====epoch 146
Train Loss 4.154675296167718
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8293 test: 0.7922 | best val epoch -- val: 0.8613 test: 0.7452

====epoch 147
Train Loss 4.2536888926315
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8272 test: 0.7824 | best val epoch -- val: 0.8613 test: 0.7452

====epoch 148
Train Loss 4.223378667386476
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8190 test: 0.7783 | best val epoch -- val: 0.8613 test: 0.7452

====epoch 149
Train Loss 3.60234872570163
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8286 test: 0.7687 | best val epoch -- val: 0.8613 test: 0.7452

====epoch 150
Train Loss 4.157186170052595
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8011 test: 0.7633 | best val epoch -- val: 0.8613 test: 0.7452

====epoch 151
Train Loss 3.9724156420602235
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8052 test: 0.7721 | best val epoch -- val: 0.8613 test: 0.7452

====epoch 152
Train Loss 4.1437423543207865
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8310 test: 0.7794 | best val epoch -- val: 0.8613 test: 0.7452

====epoch 153
Train Loss 3.982394862107205
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8024 test: 0.7796 | best val epoch -- val: 0.8613 test: 0.7452

====epoch 154
Train Loss 4.037685991191764
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8346 test: 0.7730 | best val epoch -- val: 0.8613 test: 0.7452

====epoch 155
Train Loss 3.9742111522490817
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8518 test: 0.7688 | best val epoch -- val: 0.8613 test: 0.7452

====epoch 156
Train Loss 4.168732356756975
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8246 test: 0.7866 | best val epoch -- val: 0.8613 test: 0.7452

====epoch 157
Train Loss 4.260287475969554
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8478 test: 0.7827 | best val epoch -- val: 0.8613 test: 0.7452

====epoch 158
Train Loss 3.8673299023303653
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8245 test: 0.7801 | best val epoch -- val: 0.8613 test: 0.7452

====epoch 159
Train Loss 4.160025096522918
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8163 test: 0.7665 | best val epoch -- val: 0.8613 test: 0.7452

====epoch 160
Train Loss 3.8798162473789337
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8322 test: 0.7822 | best val epoch -- val: 0.8613 test: 0.7452

====epoch 161
Train Loss 3.789115242230512
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8447 test: 0.7982 | best val epoch -- val: 0.8613 test: 0.7452

====epoch 162
Train Loss 3.98037184304802
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8123 test: 0.7801 | best val epoch -- val: 0.8613 test: 0.7452

====epoch 163
Train Loss 3.7821083357863694
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8116 test: 0.7728 | best val epoch -- val: 0.8613 test: 0.7452

====epoch 164
Train Loss 4.131383300810583
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8321 test: 0.7779 | best val epoch -- val: 0.8613 test: 0.7452

====epoch 165
Train Loss 4.465522175921066
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8279 test: 0.7904 | best val epoch -- val: 0.8613 test: 0.7452

====epoch 166
Train Loss 4.034529586406635
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8356 test: 0.7876 | best val epoch -- val: 0.8613 test: 0.7452

====epoch 167
Train Loss 4.058311445909057
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8080 test: 0.7865 | best val epoch -- val: 0.8613 test: 0.7452

====epoch 168
Train Loss 4.3847742579956295
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8447 test: 0.7819 | best val epoch -- val: 0.8613 test: 0.7452

====epoch 169
Train Loss 3.974270941630874
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8441 test: 0.7798 | best val epoch -- val: 0.8613 test: 0.7452

====epoch 170
Train Loss 4.027536595657343
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8472 test: 0.7831 | best val epoch -- val: 0.8613 test: 0.7452

====epoch 171
Train Loss 3.8210016694369533
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8376 test: 0.7774 | best val epoch -- val: 0.8613 test: 0.7452

====epoch 172
Train Loss 4.004677718802569
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8404 test: 0.7840 | best val epoch -- val: 0.8613 test: 0.7452

====epoch 173
Train Loss 3.917178643703498
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8550 test: 0.7693 | best val epoch -- val: 0.8613 test: 0.7452

====epoch 174
Train Loss 3.8910405485024278
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8307 test: 0.8026 | best val epoch -- val: 0.8613 test: 0.7452

====epoch 175
Train Loss 3.9693206528144276
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8653 test: 0.8419 | best val epoch -- val: 0.8653 test: 0.8419

====epoch 176
Train Loss 4.182806945936054
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8212 test: 0.7890 | best val epoch -- val: 0.8653 test: 0.8419

====epoch 177
Train Loss 3.867088972389417
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8528 test: 0.7860 | best val epoch -- val: 0.8653 test: 0.8419

====epoch 178
Train Loss 3.9322692629078464
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8514 test: 0.7839 | best val epoch -- val: 0.8653 test: 0.8419

====epoch 179
Train Loss 3.77523438296397
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8440 test: 0.7738 | best val epoch -- val: 0.8653 test: 0.8419

====epoch 180
Train Loss 3.7490875297918005
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8129 test: 0.7722 | best val epoch -- val: 0.8653 test: 0.8419

====epoch 181
Train Loss 4.061123847683801
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8500 test: 0.7643 | best val epoch -- val: 0.8653 test: 0.8419

====epoch 182
Train Loss 3.7268523496821357
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8178 test: 0.7813 | best val epoch -- val: 0.8653 test: 0.8419

====epoch 183
Train Loss 3.4810284300213237
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8208 test: 0.7807 | best val epoch -- val: 0.8653 test: 0.8419

====epoch 184
Train Loss 3.736664615994857
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8176 test: 0.7786 | best val epoch -- val: 0.8653 test: 0.8419

====epoch 185
Train Loss 3.8285485599223117
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8255 test: 0.7878 | best val epoch -- val: 0.8653 test: 0.8419

====epoch 186
Train Loss 4.017496862523134
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8278 test: 0.7880 | best val epoch -- val: 0.8653 test: 0.8419

====epoch 187
Train Loss 4.107918281985615
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8265 test: 0.7795 | best val epoch -- val: 0.8653 test: 0.8419

====epoch 188
Train Loss 3.9029994919767255
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8099 test: 0.7874 | best val epoch -- val: 0.8653 test: 0.8419

====epoch 189
Train Loss 3.8835386290711247
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8155 test: 0.7832 | best val epoch -- val: 0.8653 test: 0.8419

====epoch 190
Train Loss 3.947718991531204
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8185 test: 0.8006 | best val epoch -- val: 0.8653 test: 0.8419

====epoch 191
Train Loss 3.9327075349155534
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8339 test: 0.7858 | best val epoch -- val: 0.8653 test: 0.8419

====epoch 192
Train Loss 3.885406818097426
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8484 test: 0.7852 | best val epoch -- val: 0.8653 test: 0.8419

====epoch 193
Train Loss 3.7288501867786676
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8396 test: 0.7952 | best val epoch -- val: 0.8653 test: 0.8419

====epoch 194
Train Loss 4.049602721601832
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8387 test: 0.8011 | best val epoch -- val: 0.8653 test: 0.8419

====epoch 195
Train Loss 3.8446090044720145
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8395 test: 0.7989 | best val epoch -- val: 0.8653 test: 0.8419

====epoch 196
Train Loss 3.7102472743945643
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8215 test: 0.7945 | best val epoch -- val: 0.8653 test: 0.8419

====epoch 197
Train Loss 3.6573197600363034
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8238 test: 0.7935 | best val epoch -- val: 0.8653 test: 0.8419

====epoch 198
Train Loss 3.6503347601725173
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8072 test: 0.7826 | best val epoch -- val: 0.8653 test: 0.8419

====epoch 199
Train Loss 3.4709098604479935
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8035 test: 0.7883 | best val epoch -- val: 0.8653 test: 0.8419

====epoch 200
Train Loss 3.788766231879509
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8108 test: 0.7915 | best val epoch -- val: 0.8653 test: 0.8419

2022-09-14 02:26:10.784 | INFO     | modules.masked_transformer_encoder:__init__:122 - number of parameters: 0.000000e+00
=========================================
batch_size = 32
d_model = 128
dataset = clintox
decay = 0
device = 3
dim_feedforward = 512
eval_train = 0
filename =
gnn_JK = cat
gnn_dropout = 0.3
gnn_emb_dim = 300
gnn_num_layer = 5
gnn_residual = False
gnn_type = gin
gnn_virtual_node = False
graph_pooling = cls
input_model_file = models_graphtrans/graphtrans-sr-gcl.pth
lr = 5e-05
lr_scale = 1
max_input_len = 1000
nhead = 4
num_encoder_layers = 4
num_encoder_layers_masked = 0
num_workers = 0
pos_encoder = False
runseed = 4
seed = 12344
split = scaffold
transformer_activation = relu
transformer_dropout = 0.3
transformer_norm_input = True
transformer_prenorm = False
=========================================
clintox
scaffold
Loaded GraphTrans from models_graphtrans/graphtrans-sr-gcl.pth
====epoch 1
Train Loss 18.38173069124438
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.3902 test: 0.5535 | best val epoch -- val: 0.3902 test: 0.5535

====epoch 2
Train Loss 11.507969803631946
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.4880 test: 0.5740 | best val epoch -- val: 0.4880 test: 0.5740

====epoch 3
Train Loss 10.270390621188728
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.5160 test: 0.5917 | best val epoch -- val: 0.5160 test: 0.5917

====epoch 4
Train Loss 9.813195559689367
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6619 test: 0.6411 | best val epoch -- val: 0.6619 test: 0.6411

====epoch 5
Train Loss 9.778541526044643
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6917 test: 0.6551 | best val epoch -- val: 0.6917 test: 0.6551

====epoch 6
Train Loss 9.678353319759674
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7035 test: 0.6483 | best val epoch -- val: 0.7035 test: 0.6483

====epoch 7
Train Loss 9.850826049857302
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7048 test: 0.6683 | best val epoch -- val: 0.7048 test: 0.6683

====epoch 8
Train Loss 9.744444734146125
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6938 test: 0.6754 | best val epoch -- val: 0.7048 test: 0.6683

====epoch 9
Train Loss 9.732097952318135
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6577 test: 0.6923 | best val epoch -- val: 0.7048 test: 0.6683

====epoch 10
Train Loss 9.501813985399108
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6542 test: 0.6788 | best val epoch -- val: 0.7048 test: 0.6683

====epoch 11
Train Loss 9.45302917439449
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6282 test: 0.6846 | best val epoch -- val: 0.7048 test: 0.6683

====epoch 12
Train Loss 9.286689094490207
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.5857 test: 0.6830 | best val epoch -- val: 0.7048 test: 0.6683

====epoch 13
Train Loss 9.216086035281627
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6385 test: 0.6965 | best val epoch -- val: 0.7048 test: 0.6683

====epoch 14
Train Loss 9.174261823570518
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6641 test: 0.7086 | best val epoch -- val: 0.7048 test: 0.6683

====epoch 15
Train Loss 9.153402930410657
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6914 test: 0.7114 | best val epoch -- val: 0.7048 test: 0.6683

====epoch 16
Train Loss 8.981035870589988
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6984 test: 0.7182 | best val epoch -- val: 0.7048 test: 0.6683

====epoch 17
Train Loss 9.004541770294683
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7581 test: 0.7121 | best val epoch -- val: 0.7581 test: 0.7121

====epoch 18
Train Loss 8.840763279187833
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8140 test: 0.7046 | best val epoch -- val: 0.8140 test: 0.7046

====epoch 19
Train Loss 8.53329192492677
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8296 test: 0.7006 | best val epoch -- val: 0.8296 test: 0.7006

====epoch 20
Train Loss 8.698032324508413
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8364 test: 0.6951 | best val epoch -- val: 0.8364 test: 0.6951

====epoch 21
Train Loss 8.472995017317183
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8004 test: 0.7032 | best val epoch -- val: 0.8364 test: 0.6951

====epoch 22
Train Loss 8.354716076530515
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7947 test: 0.7063 | best val epoch -- val: 0.8364 test: 0.6951

====epoch 23
Train Loss 7.9073997938159435
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8393 test: 0.7014 | best val epoch -- val: 0.8393 test: 0.7014

====epoch 24
Train Loss 8.026864718088163
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8068 test: 0.7140 | best val epoch -- val: 0.8393 test: 0.7014

====epoch 25
Train Loss 7.802960599182887
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8105 test: 0.7197 | best val epoch -- val: 0.8393 test: 0.7014

====epoch 26
Train Loss 7.539019830664501
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8258 test: 0.7136 | best val epoch -- val: 0.8393 test: 0.7014

====epoch 27
Train Loss 7.716755524533698
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8138 test: 0.7188 | best val epoch -- val: 0.8393 test: 0.7014

====epoch 28
Train Loss 7.502515098627934
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8191 test: 0.7236 | best val epoch -- val: 0.8393 test: 0.7014

====epoch 29
Train Loss 7.824324878846579
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8041 test: 0.7358 | best val epoch -- val: 0.8393 test: 0.7014

====epoch 30
Train Loss 7.397595693455824
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8233 test: 0.7332 | best val epoch -- val: 0.8393 test: 0.7014

====epoch 31
Train Loss 7.153463374161277
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8232 test: 0.7304 | best val epoch -- val: 0.8393 test: 0.7014

====epoch 32
Train Loss 7.009445086256383
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8115 test: 0.7422 | best val epoch -- val: 0.8393 test: 0.7014

====epoch 33
Train Loss 6.995199211115769
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8443 test: 0.7351 | best val epoch -- val: 0.8443 test: 0.7351

====epoch 34
Train Loss 7.045947591681521
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8370 test: 0.7333 | best val epoch -- val: 0.8443 test: 0.7351

====epoch 35
Train Loss 6.99673975095107
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8447 test: 0.7380 | best val epoch -- val: 0.8447 test: 0.7380

====epoch 36
Train Loss 7.041357462239956
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8330 test: 0.7301 | best val epoch -- val: 0.8447 test: 0.7380

====epoch 37
Train Loss 6.5419473618994015
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8324 test: 0.7167 | best val epoch -- val: 0.8447 test: 0.7380

====epoch 38
Train Loss 6.561542076152517
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8229 test: 0.7288 | best val epoch -- val: 0.8447 test: 0.7380

====epoch 39
Train Loss 6.166489292009262
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8025 test: 0.7321 | best val epoch -- val: 0.8447 test: 0.7380

====epoch 40
Train Loss 6.695239244242652
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8184 test: 0.7295 | best val epoch -- val: 0.8447 test: 0.7380

====epoch 41
Train Loss 6.378555015836755
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8097 test: 0.7250 | best val epoch -- val: 0.8447 test: 0.7380

====epoch 42
Train Loss 6.136449555639201
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8320 test: 0.7400 | best val epoch -- val: 0.8447 test: 0.7380

====epoch 43
Train Loss 6.351055361955286
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8449 test: 0.7431 | best val epoch -- val: 0.8449 test: 0.7431

====epoch 44
Train Loss 6.692220775914825
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8437 test: 0.7524 | best val epoch -- val: 0.8449 test: 0.7431

====epoch 45
Train Loss 6.359575311750215
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8383 test: 0.7600 | best val epoch -- val: 0.8449 test: 0.7431

====epoch 46
Train Loss 6.454398259947032
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8398 test: 0.7660 | best val epoch -- val: 0.8449 test: 0.7431

====epoch 47
Train Loss 6.023724384009545
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8271 test: 0.7686 | best val epoch -- val: 0.8449 test: 0.7431

====epoch 48
Train Loss 6.1837456758546585
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8247 test: 0.7741 | best val epoch -- val: 0.8449 test: 0.7431

====epoch 49
Train Loss 6.316637492321066
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8253 test: 0.7770 | best val epoch -- val: 0.8449 test: 0.7431

====epoch 50
Train Loss 5.969655214936347
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8459 test: 0.7673 | best val epoch -- val: 0.8459 test: 0.7673

====epoch 51
Train Loss 5.616757014880193
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8619 test: 0.7709 | best val epoch -- val: 0.8619 test: 0.7709

====epoch 52
Train Loss 6.342644079303014
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8420 test: 0.7714 | best val epoch -- val: 0.8619 test: 0.7709

====epoch 53
Train Loss 6.211972363253511
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8237 test: 0.7754 | best val epoch -- val: 0.8619 test: 0.7709

====epoch 54
Train Loss 6.069130552737977
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8483 test: 0.7766 | best val epoch -- val: 0.8619 test: 0.7709

====epoch 55
Train Loss 5.726489904880265
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8519 test: 0.7859 | best val epoch -- val: 0.8619 test: 0.7709

====epoch 56
Train Loss 5.506614852455071
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8629 test: 0.7881 | best val epoch -- val: 0.8629 test: 0.7881

====epoch 57
Train Loss 5.578037949535124
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8455 test: 0.8006 | best val epoch -- val: 0.8629 test: 0.7881

====epoch 58
Train Loss 5.668748118566842
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8412 test: 0.7977 | best val epoch -- val: 0.8629 test: 0.7881

====epoch 59
Train Loss 5.7950430049793775
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8634 test: 0.8011 | best val epoch -- val: 0.8634 test: 0.8011

====epoch 60
Train Loss 5.531682833455218
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8551 test: 0.7945 | best val epoch -- val: 0.8634 test: 0.8011

====epoch 61
Train Loss 5.931165329524983
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8485 test: 0.8228 | best val epoch -- val: 0.8634 test: 0.8011

====epoch 62
Train Loss 5.849626215913915
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8560 test: 0.8080 | best val epoch -- val: 0.8634 test: 0.8011

====epoch 63
Train Loss 5.448768808992644
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8411 test: 0.8100 | best val epoch -- val: 0.8634 test: 0.8011

====epoch 64
Train Loss 5.353379078363551
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8455 test: 0.8172 | best val epoch -- val: 0.8634 test: 0.8011

====epoch 65
Train Loss 5.712402809025265
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8497 test: 0.8093 | best val epoch -- val: 0.8634 test: 0.8011

====epoch 66
Train Loss 5.586629916206563
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8539 test: 0.8135 | best val epoch -- val: 0.8634 test: 0.8011

====epoch 67
Train Loss 5.510219992093156
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8633 test: 0.8196 | best val epoch -- val: 0.8634 test: 0.8011

====epoch 68
Train Loss 5.575533459533839
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8404 test: 0.8224 | best val epoch -- val: 0.8634 test: 0.8011

====epoch 69
Train Loss 5.238588588015659
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8490 test: 0.8156 | best val epoch -- val: 0.8634 test: 0.8011

====epoch 70
Train Loss 5.678945779828049
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8260 test: 0.8225 | best val epoch -- val: 0.8634 test: 0.8011

====epoch 71
Train Loss 5.7043550767719715
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8352 test: 0.8170 | best val epoch -- val: 0.8634 test: 0.8011

====epoch 72
Train Loss 5.513597978933255
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8456 test: 0.8132 | best val epoch -- val: 0.8634 test: 0.8011

====epoch 73
Train Loss 5.3700918965203135
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8506 test: 0.8164 | best val epoch -- val: 0.8634 test: 0.8011

====epoch 74
Train Loss 5.486040611781092
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8405 test: 0.8072 | best val epoch -- val: 0.8634 test: 0.8011

====epoch 75
Train Loss 5.235671814471281
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8502 test: 0.8094 | best val epoch -- val: 0.8634 test: 0.8011

====epoch 76
Train Loss 5.469633126813363
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8671 test: 0.8198 | best val epoch -- val: 0.8671 test: 0.8198

====epoch 77
Train Loss 5.257231280240502
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8454 test: 0.8194 | best val epoch -- val: 0.8671 test: 0.8198

====epoch 78
Train Loss 5.091621531003798
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8474 test: 0.8225 | best val epoch -- val: 0.8671 test: 0.8198

====epoch 79
Train Loss 5.004108813670977
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8467 test: 0.8189 | best val epoch -- val: 0.8671 test: 0.8198

====epoch 80
Train Loss 5.518900823256964
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8554 test: 0.8256 | best val epoch -- val: 0.8671 test: 0.8198

====epoch 81
Train Loss 5.245232813032483
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8652 test: 0.8118 | best val epoch -- val: 0.8671 test: 0.8198

====epoch 82
Train Loss 4.965301728935515
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8572 test: 0.8017 | best val epoch -- val: 0.8671 test: 0.8198

====epoch 83
Train Loss 5.210946819764528
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8527 test: 0.8138 | best val epoch -- val: 0.8671 test: 0.8198

====epoch 84
Train Loss 5.183181297340693
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8400 test: 0.7804 | best val epoch -- val: 0.8671 test: 0.8198

====epoch 85
Train Loss 5.125966718385155
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8420 test: 0.7991 | best val epoch -- val: 0.8671 test: 0.8198

====epoch 86
Train Loss 5.138648837356424
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8477 test: 0.8140 | best val epoch -- val: 0.8671 test: 0.8198

====epoch 87
Train Loss 5.249418552043928
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8460 test: 0.8042 | best val epoch -- val: 0.8671 test: 0.8198

====epoch 88
Train Loss 4.742608289903178
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8421 test: 0.8058 | best val epoch -- val: 0.8671 test: 0.8198

====epoch 89
Train Loss 5.097716954733838
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8450 test: 0.7987 | best val epoch -- val: 0.8671 test: 0.8198

====epoch 90
Train Loss 4.92725200924248
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8527 test: 0.8204 | best val epoch -- val: 0.8671 test: 0.8198

====epoch 91
Train Loss 5.0044049417578105
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8565 test: 0.8071 | best val epoch -- val: 0.8671 test: 0.8198

====epoch 92
Train Loss 4.721957572714455
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8705 test: 0.8033 | best val epoch -- val: 0.8705 test: 0.8033

====epoch 93
Train Loss 5.075382012809827
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8530 test: 0.8037 | best val epoch -- val: 0.8705 test: 0.8033WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.4.


====epoch 94
Train Loss 4.7906385211406155
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8670 test: 0.8062 | best val epoch -- val: 0.8705 test: 0.8033

====epoch 95
Train Loss 4.861464063596765
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8539 test: 0.7951 | best val epoch -- val: 0.8705 test: 0.8033

====epoch 96
Train Loss 5.363573081060972
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8633 test: 0.8063 | best val epoch -- val: 0.8705 test: 0.8033

====epoch 97
Train Loss 4.860027806733352
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8529 test: 0.8101 | best val epoch -- val: 0.8705 test: 0.8033

====epoch 98
Train Loss 4.874383548739117
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8671 test: 0.8007 | best val epoch -- val: 0.8705 test: 0.8033

====epoch 99
Train Loss 4.809829397821746
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8577 test: 0.7842 | best val epoch -- val: 0.8705 test: 0.8033

====epoch 100
Train Loss 4.904321197486204
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8768 test: 0.8003 | best val epoch -- val: 0.8768 test: 0.8003

====epoch 101
Train Loss 4.77779956057349
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8522 test: 0.8079 | best val epoch -- val: 0.8768 test: 0.8003

====epoch 102
Train Loss 4.624356757498789
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8554 test: 0.7945 | best val epoch -- val: 0.8768 test: 0.8003

====epoch 103
Train Loss 4.71556168404148
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8611 test: 0.8296 | best val epoch -- val: 0.8768 test: 0.8003

====epoch 104
Train Loss 4.60049587000073
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8527 test: 0.8175 | best val epoch -- val: 0.8768 test: 0.8003

====epoch 105
Train Loss 4.465622677183807
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8605 test: 0.8227 | best val epoch -- val: 0.8768 test: 0.8003

====epoch 106
Train Loss 4.974719089417191
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8407 test: 0.8158 | best val epoch -- val: 0.8768 test: 0.8003

====epoch 107
Train Loss 4.505440404297909
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8454 test: 0.8027 | best val epoch -- val: 0.8768 test: 0.8003

====epoch 108
Train Loss 5.064069840316781
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8610 test: 0.8177 | best val epoch -- val: 0.8768 test: 0.8003

====epoch 109
Train Loss 4.595452087189706
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8574 test: 0.8083 | best val epoch -- val: 0.8768 test: 0.8003

====epoch 110
Train Loss 4.9322940570511795
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8612 test: 0.8085 | best val epoch -- val: 0.8768 test: 0.8003

====epoch 111
Train Loss 4.529241900911144
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8617 test: 0.8166 | best val epoch -- val: 0.8768 test: 0.8003

====epoch 112
Train Loss 4.754805398280619
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8664 test: 0.8188 | best val epoch -- val: 0.8768 test: 0.8003

====epoch 113
Train Loss 4.393159957307293
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8639 test: 0.8154 | best val epoch -- val: 0.8768 test: 0.8003

====epoch 114
Train Loss 4.883526049065241
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8659 test: 0.8098 | best val epoch -- val: 0.8768 test: 0.8003

====epoch 115
Train Loss 4.777144017387582
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8631 test: 0.8086 | best val epoch -- val: 0.8768 test: 0.8003

====epoch 116
Train Loss 4.689545621434965
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8674 test: 0.7988 | best val epoch -- val: 0.8768 test: 0.8003

====epoch 117
Train Loss 4.229919395629566
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8650 test: 0.8003 | best val epoch -- val: 0.8768 test: 0.8003

====epoch 118
Train Loss 4.611342704040178
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8595 test: 0.8093 | best val epoch -- val: 0.8768 test: 0.8003

====epoch 119
Train Loss 4.536961240576232
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8747 test: 0.8235 | best val epoch -- val: 0.8768 test: 0.8003

====epoch 120
Train Loss 4.576884338875977
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8621 test: 0.8190 | best val epoch -- val: 0.8768 test: 0.8003

====epoch 121
Train Loss 4.778780355062667
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8571 test: 0.8004 | best val epoch -- val: 0.8768 test: 0.8003

====epoch 122
Train Loss 4.410682742706886
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8639 test: 0.8069 | best val epoch -- val: 0.8768 test: 0.8003

====epoch 123
Train Loss 4.3371771381184585
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8524 test: 0.8183 | best val epoch -- val: 0.8768 test: 0.8003

====epoch 124
Train Loss 4.584377591907602
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8627 test: 0.8160 | best val epoch -- val: 0.8768 test: 0.8003

====epoch 125
Train Loss 4.364449172774624
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8508 test: 0.8182 | best val epoch -- val: 0.8768 test: 0.8003

====epoch 126
Train Loss 4.332185180330766
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8606 test: 0.8083 | best val epoch -- val: 0.8768 test: 0.8003

====epoch 127
Train Loss 4.458459488302513
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8522 test: 0.7864 | best val epoch -- val: 0.8768 test: 0.8003

====epoch 128
Train Loss 4.232149599824976
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8631 test: 0.7883 | best val epoch -- val: 0.8768 test: 0.8003

====epoch 129
Train Loss 4.234175245038031
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8657 test: 0.7865 | best val epoch -- val: 0.8768 test: 0.8003

====epoch 130
Train Loss 4.43444855084415
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8719 test: 0.8128 | best val epoch -- val: 0.8768 test: 0.8003

====epoch 131
Train Loss 4.165130456634159
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8640 test: 0.7975 | best val epoch -- val: 0.8768 test: 0.8003

====epoch 132
Train Loss 4.269479083364552
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8705 test: 0.7983 | best val epoch -- val: 0.8768 test: 0.8003

====epoch 133
Train Loss 3.8814514035019894
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8644 test: 0.7802 | best val epoch -- val: 0.8768 test: 0.8003

====epoch 134
Train Loss 4.216345797213256
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8695 test: 0.7863 | best val epoch -- val: 0.8768 test: 0.8003

====epoch 135
Train Loss 4.122537463991312
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8697 test: 0.7858 | best val epoch -- val: 0.8768 test: 0.8003

====epoch 136
Train Loss 4.26047344878862
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8558 test: 0.7957 | best val epoch -- val: 0.8768 test: 0.8003

====epoch 137
Train Loss 4.382687472736182
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8620 test: 0.7953 | best val epoch -- val: 0.8768 test: 0.8003

====epoch 138
Train Loss 4.336444156056433
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8653 test: 0.7988 | best val epoch -- val: 0.8768 test: 0.8003

====epoch 139
Train Loss 4.4749674465153655
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8640 test: 0.8032 | best val epoch -- val: 0.8768 test: 0.8003

====epoch 140
Train Loss 4.083487864370975
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8633 test: 0.8111 | best val epoch -- val: 0.8768 test: 0.8003

====epoch 141
Train Loss 3.939689984359237
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8621 test: 0.8160 | best val epoch -- val: 0.8768 test: 0.8003

====epoch 142
Train Loss 4.403098894122454
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8594 test: 0.8137 | best val epoch -- val: 0.8768 test: 0.8003

====epoch 143
Train Loss 4.251458754204872
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8683 test: 0.8197 | best val epoch -- val: 0.8768 test: 0.8003

====epoch 144
Train Loss 4.188010495648429
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8671 test: 0.8097 | best val epoch -- val: 0.8768 test: 0.8003

====epoch 145
Train Loss 4.290080920662906
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8733 test: 0.8267 | best val epoch -- val: 0.8768 test: 0.8003

====epoch 146
Train Loss 4.1313640649108345
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8528 test: 0.8179 | best val epoch -- val: 0.8768 test: 0.8003

====epoch 147
Train Loss 4.12246034414742
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8656 test: 0.8279 | best val epoch -- val: 0.8768 test: 0.8003

====epoch 148
Train Loss 4.034618157070781
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8612 test: 0.8142 | best val epoch -- val: 0.8768 test: 0.8003

====epoch 149
Train Loss 3.9010252145090103
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8548 test: 0.8248 | best val epoch -- val: 0.8768 test: 0.8003

====epoch 150
Train Loss 4.008536808417155
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8598 test: 0.8277 | best val epoch -- val: 0.8768 test: 0.8003

====epoch 151
Train Loss 4.029760680104812
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8481 test: 0.8240 | best val epoch -- val: 0.8768 test: 0.8003

====epoch 152
Train Loss 4.120334441421525
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8505 test: 0.8271 | best val epoch -- val: 0.8768 test: 0.8003

====epoch 153
Train Loss 4.030919519501577
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8474 test: 0.8301 | best val epoch -- val: 0.8768 test: 0.8003

====epoch 154
Train Loss 4.269702726038118
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8716 test: 0.8230 | best val epoch -- val: 0.8768 test: 0.8003

====epoch 155
Train Loss 4.14724514906633
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8688 test: 0.8192 | best val epoch -- val: 0.8768 test: 0.8003

====epoch 156
Train Loss 4.072188474479935
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8724 test: 0.8036 | best val epoch -- val: 0.8768 test: 0.8003

====epoch 157
Train Loss 4.277173804345979
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8732 test: 0.8207 | best val epoch -- val: 0.8768 test: 0.8003

====epoch 158
Train Loss 3.9353526856786565
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8726 test: 0.8115 | best val epoch -- val: 0.8768 test: 0.8003

====epoch 159
Train Loss 3.7586002677193124
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8795 test: 0.8162 | best val epoch -- val: 0.8795 test: 0.8162

====epoch 160
Train Loss 3.9780724557819687
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8666 test: 0.8116 | best val epoch -- val: 0.8795 test: 0.8162

====epoch 161
Train Loss 4.171539814293935
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8608 test: 0.7825 | best val epoch -- val: 0.8795 test: 0.8162

====epoch 162
Train Loss 3.9246885232758313
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8644 test: 0.7966 | best val epoch -- val: 0.8795 test: 0.8162

====epoch 163
Train Loss 3.9230617067379847
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8703 test: 0.7820 | best val epoch -- val: 0.8795 test: 0.8162

====epoch 164
Train Loss 4.039573553006183
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8754 test: 0.7750 | best val epoch -- val: 0.8795 test: 0.8162

====epoch 165
Train Loss 3.952739170136775
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8627 test: 0.7809 | best val epoch -- val: 0.8795 test: 0.8162

====epoch 166
Train Loss 4.05782343332904
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8660 test: 0.8041 | best val epoch -- val: 0.8795 test: 0.8162

====epoch 167
Train Loss 4.12782090239448
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8650 test: 0.8030 | best val epoch -- val: 0.8795 test: 0.8162

====epoch 168
Train Loss 3.9571540148367763
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8655 test: 0.8023 | best val epoch -- val: 0.8795 test: 0.8162

====epoch 169
Train Loss 3.9757356522918608
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8684 test: 0.7845 | best val epoch -- val: 0.8795 test: 0.8162

====epoch 170
Train Loss 3.8062012148284694
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8617 test: 0.7983 | best val epoch -- val: 0.8795 test: 0.8162

====epoch 171
Train Loss 4.139518296749056
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8569 test: 0.8037 | best val epoch -- val: 0.8795 test: 0.8162

====epoch 172
Train Loss 3.991617956972096
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8660 test: 0.7973 | best val epoch -- val: 0.8795 test: 0.8162

====epoch 173
Train Loss 4.115204676180259
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8213 test: 0.8021 | best val epoch -- val: 0.8795 test: 0.8162

====epoch 174
Train Loss 4.151274147202516
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8550 test: 0.7919 | best val epoch -- val: 0.8795 test: 0.8162

====epoch 175
Train Loss 4.051427326531699
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8652 test: 0.7863 | best val epoch -- val: 0.8795 test: 0.8162

====epoch 176
Train Loss 3.8611495500917457
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8602 test: 0.8078 | best val epoch -- val: 0.8795 test: 0.8162

====epoch 177
Train Loss 3.758186572143509
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8645 test: 0.8012 | best val epoch -- val: 0.8795 test: 0.8162

====epoch 178
Train Loss 3.9820622789164566
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8609 test: 0.7892 | best val epoch -- val: 0.8795 test: 0.8162

====epoch 179
Train Loss 3.9360176810048473
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8547 test: 0.7834 | best val epoch -- val: 0.8795 test: 0.8162

====epoch 180
Train Loss 3.962045124457066
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8654 test: 0.7788 | best val epoch -- val: 0.8795 test: 0.8162

====epoch 181
Train Loss 3.512912030136901
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8542 test: 0.7892 | best val epoch -- val: 0.8795 test: 0.8162

====epoch 182
Train Loss 3.769337935258222
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8590 test: 0.7950 | best val epoch -- val: 0.8795 test: 0.8162

====epoch 183
Train Loss 3.899805645769336
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8589 test: 0.7981 | best val epoch -- val: 0.8795 test: 0.8162

====epoch 184
Train Loss 3.9399508277819923
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8650 test: 0.7880 | best val epoch -- val: 0.8795 test: 0.8162

====epoch 185
Train Loss 3.7766790754738304
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8502 test: 0.8170 | best val epoch -- val: 0.8795 test: 0.8162

====epoch 186
Train Loss 3.67580392632782
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8203 test: 0.7929 | best val epoch -- val: 0.8795 test: 0.8162

====epoch 187
Train Loss 3.9183843982507116
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8661 test: 0.7906 | best val epoch -- val: 0.8795 test: 0.8162

====epoch 188
Train Loss 4.058402262872054
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8628 test: 0.7837 | best val epoch -- val: 0.8795 test: 0.8162

====epoch 189
Train Loss 4.005490425812554
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8830 test: 0.7975 | best val epoch -- val: 0.8830 test: 0.7975

====epoch 190
Train Loss 3.6503285435977166
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8838 test: 0.8027 | best val epoch -- val: 0.8838 test: 0.8027

====epoch 191
Train Loss 3.523838262421699
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8820 test: 0.8001 | best val epoch -- val: 0.8838 test: 0.8027

====epoch 192
Train Loss 4.017980224960225
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8617 test: 0.7847 | best val epoch -- val: 0.8838 test: 0.8027

====epoch 193
Train Loss 3.95559343236912
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8638 test: 0.7821 | best val epoch -- val: 0.8838 test: 0.8027

====epoch 194
Train Loss 3.7653508165947494
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8608 test: 0.7737 | best val epoch -- val: 0.8838 test: 0.8027

====epoch 195
Train Loss 3.7504112522040716
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8753 test: 0.7880 | best val epoch -- val: 0.8838 test: 0.8027

====epoch 196
Train Loss 3.6820004735835066
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8760 test: 0.7877 | best val epoch -- val: 0.8838 test: 0.8027

====epoch 197
Train Loss 3.678236917783477
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8714 test: 0.7914 | best val epoch -- val: 0.8838 test: 0.8027

====epoch 198
Train Loss 3.627833121160018
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8717 test: 0.7817 | best val epoch -- val: 0.8838 test: 0.8027

====epoch 199
Train Loss 3.6350844388655448
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8724 test: 0.7921 | best val epoch -- val: 0.8838 test: 0.8027

====epoch 200
Train Loss 3.775603290829487
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8630 test: 0.7920 | best val epoch -- val: 0.8838 test: 0.8027

2022-09-14 02:32:54.254 | INFO     | modules.masked_transformer_encoder:__init__:122 - number of parameters: 0.000000e+00
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.4.
=========================================
batch_size = 32
d_model = 128
dataset = clintox
decay = 0
device = 3
dim_feedforward = 512
eval_train = 0
filename =
gnn_JK = cat
gnn_dropout = 0.3
gnn_emb_dim = 300
gnn_num_layer = 5
gnn_residual = False
gnn_type = gin
gnn_virtual_node = False
graph_pooling = cls
input_model_file = models_graphtrans/graphtrans-sr-gcl.pth
lr = 5e-05
lr_scale = 1
max_input_len = 1000
nhead = 4
num_encoder_layers = 4
num_encoder_layers_masked = 0
num_workers = 0
pos_encoder = False
runseed = 5
seed = 12344
split = scaffold
transformer_activation = relu
transformer_dropout = 0.3
transformer_norm_input = True
transformer_prenorm = False
=========================================
clintox
scaffold
Loaded GraphTrans from models_graphtrans/graphtrans-sr-gcl.pth
====epoch 1
Train Loss 19.074277821474197
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.5038 test: 0.5360 | best val epoch -- val: 0.5038 test: 0.5360

====epoch 2
Train Loss 11.950957625516468
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.4972 test: 0.5649 | best val epoch -- val: 0.5038 test: 0.5360

====epoch 3
Train Loss 10.430875071155343
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.4705 test: 0.5793 | best val epoch -- val: 0.5038 test: 0.5360

====epoch 4
Train Loss 10.087746773496821
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.4934 test: 0.5898 | best val epoch -- val: 0.5038 test: 0.5360

====epoch 5
Train Loss 9.918291910023028
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.5021 test: 0.6126 | best val epoch -- val: 0.5038 test: 0.5360

====epoch 6
Train Loss 9.856749539812899
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.5488 test: 0.6235 | best val epoch -- val: 0.5488 test: 0.6235

====epoch 7
Train Loss 9.822698460952772
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6078 test: 0.6484 | best val epoch -- val: 0.6078 test: 0.6484

====epoch 8
Train Loss 9.645711423100632
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6312 test: 0.6515 | best val epoch -- val: 0.6312 test: 0.6515

====epoch 9
Train Loss 9.606380068109404
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6508 test: 0.6792 | best val epoch -- val: 0.6508 test: 0.6792

====epoch 10
Train Loss 9.489970516014179
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6807 test: 0.7000 | best val epoch -- val: 0.6807 test: 0.7000

====epoch 11
Train Loss 9.402853211997371
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6661 test: 0.6593 | best val epoch -- val: 0.6807 test: 0.7000

====epoch 12
Train Loss 9.424573663807553
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6801 test: 0.6642 | best val epoch -- val: 0.6807 test: 0.7000

====epoch 13
Train Loss 9.223719147793158
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6932 test: 0.6876 | best val epoch -- val: 0.6932 test: 0.6876

====epoch 14
Train Loss 9.245231174927977
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7246 test: 0.6886 | best val epoch -- val: 0.7246 test: 0.6886

====epoch 15
Train Loss 9.18828651548243
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7554 test: 0.7087 | best val epoch -- val: 0.7554 test: 0.7087

====epoch 16
Train Loss 9.132033190052624
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7853 test: 0.7121 | best val epoch -- val: 0.7853 test: 0.7121

====epoch 17
Train Loss 8.793846614551878
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8168 test: 0.7170 | best val epoch -- val: 0.8168 test: 0.7170

====epoch 18
Train Loss 8.764564159703832
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8267 test: 0.7022 | best val epoch -- val: 0.8267 test: 0.7022

====epoch 19
Train Loss 8.66331184568952
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8172 test: 0.6932 | best val epoch -- val: 0.8267 test: 0.7022

====epoch 20
Train Loss 8.231453270063424
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8054 test: 0.6954 | best val epoch -- val: 0.8267 test: 0.7022

====epoch 21
Train Loss 8.399115729916497
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8124 test: 0.7002 | best val epoch -- val: 0.8267 test: 0.7022

====epoch 22
Train Loss 8.00640746649415
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8339 test: 0.7132 | best val epoch -- val: 0.8339 test: 0.7132

====epoch 23
Train Loss 7.683269820154393
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8199 test: 0.7069 | best val epoch -- val: 0.8339 test: 0.7132

====epoch 24
Train Loss 8.043432868295927
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8601 test: 0.7093 | best val epoch -- val: 0.8601 test: 0.7093

====epoch 25
Train Loss 7.676917743917017
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8536 test: 0.7239 | best val epoch -- val: 0.8601 test: 0.7093

====epoch 26
Train Loss 7.5909648484278085
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8392 test: 0.7153 | best val epoch -- val: 0.8601 test: 0.7093

====epoch 27
Train Loss 7.721097765422678
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8248 test: 0.7320 | best val epoch -- val: 0.8601 test: 0.7093

====epoch 28
Train Loss 6.857606386276053
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8194 test: 0.7393 | best val epoch -- val: 0.8601 test: 0.7093

====epoch 29
Train Loss 7.307739794120145
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8281 test: 0.7529 | best val epoch -- val: 0.8601 test: 0.7093

====epoch 30
Train Loss 7.101370598170857
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8319 test: 0.7375 | best val epoch -- val: 0.8601 test: 0.7093

====epoch 31
Train Loss 7.044506060527488
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8304 test: 0.7307 | best val epoch -- val: 0.8601 test: 0.7093

====epoch 32
Train Loss 6.898812334768477
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8436 test: 0.7380 | best val epoch -- val: 0.8601 test: 0.7093

====epoch 33
Train Loss 6.783986039031071
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8586 test: 0.7480 | best val epoch -- val: 0.8601 test: 0.7093

====epoch 34
Train Loss 6.813296795048024
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8358 test: 0.7482 | best val epoch -- val: 0.8601 test: 0.7093

====epoch 35
Train Loss 6.714788630980861
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8198 test: 0.7333 | best val epoch -- val: 0.8601 test: 0.7093

====epoch 36
Train Loss 6.569212769930374
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8642 test: 0.7523 | best val epoch -- val: 0.8642 test: 0.7523

====epoch 37
Train Loss 6.742965810773853
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8534 test: 0.7471 | best val epoch -- val: 0.8642 test: 0.7523

====epoch 38
Train Loss 6.342109019401688
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8572 test: 0.7589 | best val epoch -- val: 0.8642 test: 0.7523

====epoch 39
Train Loss 6.4185842777872
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8688 test: 0.7677 | best val epoch -- val: 0.8688 test: 0.7677

====epoch 40
Train Loss 6.102937327838667
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8648 test: 0.7668 | best val epoch -- val: 0.8688 test: 0.7677

====epoch 41
Train Loss 6.396105496820465
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8700 test: 0.7732 | best val epoch -- val: 0.8700 test: 0.7732

====epoch 42
Train Loss 6.32638172469913
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8608 test: 0.7782 | best val epoch -- val: 0.8700 test: 0.7732

====epoch 43
Train Loss 6.134446452928735
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8630 test: 0.7848 | best val epoch -- val: 0.8700 test: 0.7732

====epoch 44
Train Loss 6.353886182596278
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8723 test: 0.7872 | best val epoch -- val: 0.8723 test: 0.7872

====epoch 45
Train Loss 6.165091654094781
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8683 test: 0.7774 | best val epoch -- val: 0.8723 test: 0.7872

====epoch 46
Train Loss 6.077378091659602
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8562 test: 0.7773 | best val epoch -- val: 0.8723 test: 0.7872

====epoch 47
Train Loss 5.888452063752966
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8726 test: 0.7906 | best val epoch -- val: 0.8726 test: 0.7906

====epoch 48
Train Loss 5.836862844701922
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8696 test: 0.7949 | best val epoch -- val: 0.8726 test: 0.7906

====epoch 49
Train Loss 5.627194945729521
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8746 test: 0.8033 | best val epoch -- val: 0.8746 test: 0.8033

====epoch 50
Train Loss 5.656841037382025
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8799 test: 0.7973 | best val epoch -- val: 0.8799 test: 0.7973

====epoch 51
Train Loss 5.647236346393191
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8618 test: 0.7900 | best val epoch -- val: 0.8799 test: 0.7973

====epoch 52
Train Loss 5.961451270564377
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8778 test: 0.7942 | best val epoch -- val: 0.8799 test: 0.7973

====epoch 53
Train Loss 5.825748419457623
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8794 test: 0.7919 | best val epoch -- val: 0.8799 test: 0.7973

====epoch 54
Train Loss 5.5138966218982866
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8875 test: 0.8087 | best val epoch -- val: 0.8875 test: 0.8087

====epoch 55
Train Loss 5.6252211291129
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8831 test: 0.8041 | best val epoch -- val: 0.8875 test: 0.8087

====epoch 56
Train Loss 5.342736202739043
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8949 test: 0.8019 | best val epoch -- val: 0.8949 test: 0.8019

====epoch 57
Train Loss 5.282480195275409
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8893 test: 0.8037 | best val epoch -- val: 0.8949 test: 0.8019

====epoch 58
Train Loss 5.400049403170237
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8874 test: 0.8023 | best val epoch -- val: 0.8949 test: 0.8019

====epoch 59
Train Loss 5.693485014362823
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8852 test: 0.8100 | best val epoch -- val: 0.8949 test: 0.8019

====epoch 60
Train Loss 5.9157733208146395
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8930 test: 0.8107 | best val epoch -- val: 0.8949 test: 0.8019

====epoch 61
Train Loss 5.466511416022295
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8997 test: 0.8059 | best val epoch -- val: 0.8997 test: 0.8059

====epoch 62
Train Loss 5.324912724957939
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8976 test: 0.8089 | best val epoch -- val: 0.8997 test: 0.8059

====epoch 63
Train Loss 5.118981635346638
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8891 test: 0.8074 | best val epoch -- val: 0.8997 test: 0.8059

====epoch 64
Train Loss 5.469175020888352
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8917 test: 0.8156 | best val epoch -- val: 0.8997 test: 0.8059

====epoch 65
Train Loss 5.589320358181081
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8928 test: 0.8189 | best val epoch -- val: 0.8997 test: 0.8059

====epoch 66
Train Loss 5.454138307723303
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8911 test: 0.8288 | best val epoch -- val: 0.8997 test: 0.8059

====epoch 67
Train Loss 5.27034003812935
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8905 test: 0.8268 | best val epoch -- val: 0.8997 test: 0.8059

====epoch 68
Train Loss 5.507690738182401
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9003 test: 0.8238 | best val epoch -- val: 0.9003 test: 0.8238

====epoch 69
Train Loss 5.585043971342752
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8930 test: 0.8235 | best val epoch -- val: 0.9003 test: 0.8238

====epoch 70
Train Loss 4.947841191967786
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8924 test: 0.8246 | best val epoch -- val: 0.9003 test: 0.8238

====epoch 71
Train Loss 5.2481711332895316
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8900 test: 0.8178 | best val epoch -- val: 0.9003 test: 0.8238

====epoch 72
Train Loss 5.140216154537427
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9014 test: 0.8192 | best val epoch -- val: 0.9014 test: 0.8192

====epoch 73
Train Loss 4.882075284711682
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8924 test: 0.8129 | best val epoch -- val: 0.9014 test: 0.8192

====epoch 74
Train Loss 5.323414554997149
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8786 test: 0.8121 | best val epoch -- val: 0.9014 test: 0.8192

====epoch 75
Train Loss 5.2566817723961705
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8839 test: 0.8146 | best val epoch -- val: 0.9014 test: 0.8192

====epoch 76
Train Loss 5.202364717686851
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8931 test: 0.8145 | best val epoch -- val: 0.9014 test: 0.8192

====epoch 77
Train Loss 5.239938289179015
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8851 test: 0.8190 | best val epoch -- val: 0.9014 test: 0.8192

====epoch 78
Train Loss 5.172319314345793
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8736 test: 0.8112 | best val epoch -- val: 0.9014 test: 0.8192

====epoch 79
Train Loss 5.201594228334478
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8835 test: 0.8200 | best val epoch -- val: 0.9014 test: 0.8192

====epoch 80
Train Loss 5.191429038679964
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8894 test: 0.8278 | best val epoch -- val: 0.9014 test: 0.8192

====epoch 81
Train Loss 4.59832745365145
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8938 test: 0.8240 | best val epoch -- val: 0.9014 test: 0.8192

====epoch 82
Train Loss 4.868102393774212
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8971 test: 0.8262 | best val epoch -- val: 0.9014 test: 0.8192

====epoch 83
Train Loss 4.606894010412254
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8848 test: 0.8111 | best val epoch -- val: 0.9014 test: 0.8192

====epoch 84
Train Loss 4.919653627648077
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8920 test: 0.8186 | best val epoch -- val: 0.9014 test: 0.8192

====epoch 85
Train Loss 4.9594859251795596
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8848 test: 0.8083 | best val epoch -- val: 0.9014 test: 0.8192

====epoch 86
Train Loss 5.048976732979018
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8937 test: 0.8113 | best val epoch -- val: 0.9014 test: 0.8192

====epoch 87
Train Loss 4.791394024600654
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8941 test: 0.8270 | best val epoch -- val: 0.9014 test: 0.8192

====epoch 88
Train Loss 5.130227218022382
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8916 test: 0.8319 | best val epoch -- val: 0.9014 test: 0.8192

====epoch 89
Train Loss 4.856884784718728
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8897 test: 0.8201 | best val epoch -- val: 0.9014 test: 0.8192

====epoch 90
Train Loss 4.593154170249803
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8959 test: 0.8267 | best val epoch -- val: 0.9014 test: 0.8192

====epoch 91
Train Loss 5.164693139538322
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8911 test: 0.8235 | best val epoch -- val: 0.9014 test: 0.8192

====epoch 92
Train Loss 4.842876021312012
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8916 test: 0.8257 | best val epoch -- val: 0.9014 test: 0.8192

====epoch 93
Train Loss 4.870243423847315
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8932 test: 0.8184 | best val epoch -- val: 0.9014 test: 0.8192

====epoch 94
Train Loss 4.537507933490774
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8955 test: 0.8115 | best val epoch -- val: 0.9014 test: 0.8192

====epoch 95
Train Loss 4.98919167102379
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8949 test: 0.8096 | best val epoch -- val: 0.9014 test: 0.8192

====epoch 96
Train Loss 4.460431503249917
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8996 test: 0.8048 | best val epoch -- val: 0.9014 test: 0.8192

====epoch 97
Train Loss 4.539856606275554
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8966 test: 0.7998 | best val epoch -- val: 0.9014 test: 0.8192

====epoch 98
Train Loss 4.628679369613533
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8853 test: 0.8149 | best val epoch -- val: 0.9014 test: 0.8192

====epoch 99
Train Loss 4.893475955948204
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8874 test: 0.8143 | best val epoch -- val: 0.9014 test: 0.8192

====epoch 100
Train Loss 4.390771147473254
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8937 test: 0.7847 | best val epoch -- val: 0.9014 test: 0.8192

====epoch 101
Train Loss 4.485784715084745
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8929 test: 0.8128 | best val epoch -- val: 0.9014 test: 0.8192

====epoch 102
Train Loss 4.745259601565474
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8868 test: 0.8098 | best val epoch -- val: 0.9014 test: 0.8192

====epoch 103
Train Loss 4.80062100880894
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8853 test: 0.7990 | best val epoch -- val: 0.9014 test: 0.8192

====epoch 104
Train Loss 4.904682434114312
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8797 test: 0.8010 | best val epoch -- val: 0.9014 test: 0.8192

====epoch 105
Train Loss 4.486051098169666
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8866 test: 0.7734 | best val epoch -- val: 0.9014 test: 0.8192

====epoch 106
Train Loss 4.410306321328102
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8815 test: 0.7704 | best val epoch -- val: 0.9014 test: 0.8192

====epoch 107
Train Loss 4.442679686701528
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8919 test: 0.8092 | best val epoch -- val: 0.9014 test: 0.8192

====epoch 108
Train Loss 4.60209581437696
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8937 test: 0.7919 | best val epoch -- val: 0.9014 test: 0.8192

====epoch 109
Train Loss 4.9370357357820245
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8953 test: 0.8180 | best val epoch -- val: 0.9014 test: 0.8192

====epoch 110
Train Loss 4.349224790755743
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9011 test: 0.8196 | best val epoch -- val: 0.9014 test: 0.8192

====epoch 111
Train Loss 4.664051850525484
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8888 test: 0.8121 | best val epoch -- val: 0.9014 test: 0.8192

====epoch 112
Train Loss 4.6924645330227
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9026 test: 0.7659 | best val epoch -- val: 0.9026 test: 0.7659

====epoch 113
Train Loss 4.436706328178615
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8967 test: 0.8062 | best val epoch -- val: 0.9026 test: 0.7659

====epoch 114
Train Loss 4.346676498418474
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8907 test: 0.8039 | best val epoch -- val: 0.9026 test: 0.7659

====epoch 115
Train Loss 4.207428408442703
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8909 test: 0.7807 | best val epoch -- val: 0.9026 test: 0.7659

====epoch 116
Train Loss 4.494074940213287
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8711 test: 0.7946 | best val epoch -- val: 0.9026 test: 0.7659

====epoch 117
Train Loss 4.199424755507396
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8513 test: 0.8146 | best val epoch -- val: 0.9026 test: 0.7659

====epoch 118
Train Loss 4.579394066162799
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8423 test: 0.8093 | best val epoch -- val: 0.9026 test: 0.7659

====epoch 119
Train Loss 4.500649542018305
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8868 test: 0.7990 | best val epoch -- val: 0.9026 test: 0.7659

====epoch 120
Train Loss 4.40568750425581
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8915 test: 0.8003 | best val epoch -- val: 0.9026 test: 0.7659

====epoch 121
Train Loss 4.356760307025958
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8984 test: 0.8140 | best val epoch -- val: 0.9026 test: 0.7659

====epoch 122
Train Loss 4.014300427703985
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9042 test: 0.7766 | best val epoch -- val: 0.9042 test: 0.7766

====epoch 123
Train Loss 4.23806586148621
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8938 test: 0.7696 | best val epoch -- val: 0.9042 test: 0.7766

====epoch 124
Train Loss 4.6403873889411384
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8992 test: 0.7946 | best val epoch -- val: 0.9042 test: 0.7766

====epoch 125
Train Loss 4.355476501634382
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8887 test: 0.7976 | best val epoch -- val: 0.9042 test: 0.7766

====epoch 126
Train Loss 4.570836473015627
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8435 test: 0.8062 | best val epoch -- val: 0.9042 test: 0.7766

====epoch 127
Train Loss 3.9452234431687594
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8786 test: 0.7698 | best val epoch -- val: 0.9042 test: 0.7766

====epoch 128
Train Loss 4.579109086055045
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8888 test: 0.7885 | best val epoch -- val: 0.9042 test: 0.7766

====epoch 129
Train Loss 4.168207520621639
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9017 test: 0.7751 | best val epoch -- val: 0.9042 test: 0.7766

====epoch 130
Train Loss 4.188707386558289
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8999 test: 0.7642 | best val epoch -- val: 0.9042 test: 0.7766

====epoch 131
Train Loss 4.259497353830576
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8947 test: 0.7460 | best val epoch -- val: 0.9042 test: 0.7766

====epoch 132
Train Loss 4.131128584083665
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8917 test: 0.8234 | best val epoch -- val: 0.9042 test: 0.7766

====epoch 133
Train Loss 4.392978983614491
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8912 test: 0.8192 | best val epoch -- val: 0.9042 test: 0.7766

====epoch 134
Train Loss 4.290835442348473
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8989 test: 0.8265 | best val epoch -- val: 0.9042 test: 0.7766

====epoch 135
Train Loss 4.1025343917263
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8391 test: 0.8187 | best val epoch -- val: 0.9042 test: 0.7766

====epoch 136
Train Loss 4.3253432084200005
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8449 test: 0.7707 | best val epoch -- val: 0.9042 test: 0.7766

====epoch 137
Train Loss 4.2128875973924975
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8965 test: 0.7471 | best val epoch -- val: 0.9042 test: 0.7766

====epoch 138
Train Loss 4.177706627247247
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8976 test: 0.7715 | best val epoch -- val: 0.9042 test: 0.7766

====epoch 139
Train Loss 4.105189138399935
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8944 test: 0.7820 | best val epoch -- val: 0.9042 test: 0.7766

====epoch 140
Train Loss 4.541480100058167
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8973 test: 0.7796 | best val epoch -- val: 0.9042 test: 0.7766

====epoch 141
Train Loss 4.435561903849387
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8955 test: 0.7885 | best val epoch -- val: 0.9042 test: 0.7766

====epoch 142
Train Loss 4.334048596667998
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9014 test: 0.8236 | best val epoch -- val: 0.9042 test: 0.7766

====epoch 143
Train Loss 4.178671684965688
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8879 test: 0.8205 | best val epoch -- val: 0.9042 test: 0.7766

====epoch 144
Train Loss 4.0990711814357015
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8984 test: 0.7992 | best val epoch -- val: 0.9042 test: 0.7766

====epoch 145
Train Loss 3.9927493692396645
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9011 test: 0.8308 | best val epoch -- val: 0.9042 test: 0.7766

====epoch 146
Train Loss 4.215763642100997
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8994 test: 0.8278 | best val epoch -- val: 0.9042 test: 0.7766

====epoch 147
Train Loss 4.152406709644215
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8889 test: 0.8449 | best val epoch -- val: 0.9042 test: 0.7766

====epoch 148
Train Loss 4.3198863725339525
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8408 test: 0.8370 | best val epoch -- val: 0.9042 test: 0.7766

====epoch 149
Train Loss 4.155976557391069
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8935 test: 0.8303 | best val epoch -- val: 0.9042 test: 0.7766

====epoch 150
Train Loss 4.070101761308149
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8597 test: 0.8185 | best val epoch -- val: 0.9042 test: 0.7766

====epoch 151
Train Loss 3.9946439996135217
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9013 test: 0.8337 | best val epoch -- val: 0.9042 test: 0.7766

====epoch 152
Train Loss 4.209819984516183
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8404 test: 0.8355 | best val epoch -- val: 0.9042 test: 0.7766

====epoch 153
Train Loss 4.172569851432892
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8510 test: 0.8029 | best val epoch -- val: 0.9042 test: 0.7766

====epoch 154
Train Loss 4.208897057418921
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8505 test: 0.7920 | best val epoch -- val: 0.9042 test: 0.7766

====epoch 155
Train Loss 3.857776821860802
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8477 test: 0.7976 | best val epoch -- val: 0.9042 test: 0.7766

====epoch 156
Train Loss 4.261061318249699
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8476 test: 0.8406 | best val epoch -- val: 0.9042 test: 0.7766

====epoch 157
Train Loss 4.145206866489515
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9025 test: 0.8454 | best val epoch -- val: 0.9042 test: 0.7766

====epoch 158
Train Loss 4.233498593536786
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8970 test: 0.8275 | best val epoch -- val: 0.9042 test: 0.7766

====epoch 159
Train Loss 4.151421399400592
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9021 test: 0.8380 | best val epoch -- val: 0.9042 test: 0.7766

====epoch 160
Train Loss 4.309175180187717
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8917 test: 0.8382 | best val epoch -- val: 0.9042 test: 0.7766

====epoch 161
Train Loss 4.270600985833283
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9090 test: 0.8367 | best val epoch -- val: 0.9090 test: 0.8367

====epoch 162
Train Loss 3.9722962460062483
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9109 test: 0.8329 | best val epoch -- val: 0.9109 test: 0.8329

====epoch 163
Train Loss 3.927479412916772
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9104 test: 0.8205 | best val epoch -- val: 0.9109 test: 0.8329

====epoch 164
Train Loss 4.331060057649141
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8829 test: 0.8023 | best val epoch -- val: 0.9109 test: 0.8329

====epoch 165
Train Loss 4.003418158178878
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9042 test: 0.8368 | best val epoch -- val: 0.9109 test: 0.8329

====epoch 166
Train Loss 3.855958306407337
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9046 test: 0.8272 | best val epoch -- val: 0.9109 test: 0.8329

====epoch 167
Train Loss 3.9976351190680104
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8951 test: 0.8300 | best val epoch -- val: 0.9109 test: 0.8329

====epoch 168
Train Loss 3.9230300835739986
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9101 test: 0.8428 | best val epoch -- val: 0.9109 test: 0.8329

====epoch 169
Train Loss 3.9629827477150186
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9007 test: 0.8305 | best val epoch -- val: 0.9109 test: 0.8329

====epoch 170
Train Loss 4.079990106283649
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9039 test: 0.8309 | best val epoch -- val: 0.9109 test: 0.8329

====epoch 171
Train Loss 3.836147236312199
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9084 test: 0.8399 | best val epoch -- val: 0.9109 test: 0.8329

====epoch 172
Train Loss 3.544880110867546
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9120 test: 0.8362 | best val epoch -- val: 0.9120 test: 0.8362

====epoch 173
Train Loss 4.089920658308703
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9029 test: 0.8351 | best val epoch -- val: 0.9120 test: 0.8362

====epoch 174
Train Loss 4.3873646579564465
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8914 test: 0.8340 | best val epoch -- val: 0.9120 test: 0.8362

====epoch 175
Train Loss 4.1346864092248525
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8834 test: 0.8339 | best val epoch -- val: 0.9120 test: 0.8362

====epoch 176
Train Loss 4.085704896451796
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8526 test: 0.8339 | best val epoch -- val: 0.9120 test: 0.8362

====epoch 177
Train Loss 3.844090921877213
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8534 test: 0.8267 | best val epoch -- val: 0.9120 test: 0.8362

====epoch 178
Train Loss 3.997876175838799
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8874 test: 0.8229 | best val epoch -- val: 0.9120 test: 0.8362

====epoch 179
Train Loss 4.025980064904624
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8870 test: 0.8194 | best val epoch -- val: 0.9120 test: 0.8362

====epoch 180
Train Loss 3.832251276963133
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8415 test: 0.8250 | best val epoch -- val: 0.9120 test: 0.8362

====epoch 181
Train Loss 3.9225512337128206
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8356 test: 0.8348 | best val epoch -- val: 0.9120 test: 0.8362

====epoch 182
Train Loss 3.8729690023292713
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8367 test: 0.8273 | best val epoch -- val: 0.9120 test: 0.8362

====epoch 183
Train Loss 3.763843054229419
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9008 test: 0.8144 | best val epoch -- val: 0.9120 test: 0.8362

====epoch 184
Train Loss 3.9487243106092755
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8959 test: 0.8191 | best val epoch -- val: 0.9120 test: 0.8362

====epoch 185
Train Loss 3.973820625954958
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8562 test: 0.8265 | best val epoch -- val: 0.9120 test: 0.8362

====epoch 186
Train Loss 3.574636935907889
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8923 test: 0.8244 | best val epoch -- val: 0.9120 test: 0.8362

====epoch 187
Train Loss 4.1280546990813995
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9031 test: 0.8303 | best val epoch -- val: 0.9120 test: 0.8362

====epoch 188
Train Loss 3.814004018088755
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8877 test: 0.8020 | best val epoch -- val: 0.9120 test: 0.8362

====epoch 189
Train Loss 4.141385927632705
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8957 test: 0.8316 | best val epoch -- val: 0.9120 test: 0.8362

====epoch 190
Train Loss 3.810884587177149
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8912 test: 0.8020 | best val epoch -- val: 0.9120 test: 0.8362

====epoch 191
Train Loss 3.9422396532701027
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8847 test: 0.8263 | best val epoch -- val: 0.9120 test: 0.8362

====epoch 192
Train Loss 3.9269778295516744
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8687 test: 0.8274 | best val epoch -- val: 0.9120 test: 0.8362

====epoch 193
Train Loss 3.9291718797108297
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8223 test: 0.8317 | best val epoch -- val: 0.9120 test: 0.8362

====epoch 194
Train Loss 3.944626980770862
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8190 test: 0.8324 | best val epoch -- val: 0.9120 test: 0.8362

====epoch 195
Train Loss 3.7646215507155096
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8302 test: 0.8297 | best val epoch -- val: 0.9120 test: 0.8362

====epoch 196
Train Loss 3.713140955025627
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8296 test: 0.8275 | best val epoch -- val: 0.9120 test: 0.8362

====epoch 197
Train Loss 3.773614212273234
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8429 test: 0.8239 | best val epoch -- val: 0.9120 test: 0.8362

====epoch 198
Train Loss 3.886440978143499
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8385 test: 0.8291 | best val epoch -- val: 0.9120 test: 0.8362

====epoch 199
Train Loss 4.138045545939234
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8246 test: 0.8347 | best val epoch -- val: 0.9120 test: 0.8362

====epoch 200
Train Loss 3.630790185933758
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8293 test: 0.8341 | best val epoch -- val: 0.9120 test: 0.8362

2022-09-14 02:39:55.591 | INFO     | modules.masked_transformer_encoder:__init__:122 - number of parameters: 0.000000e+00
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.4.
=========================================
batch_size = 32
d_model = 128
dataset = clintox
decay = 0
device = 3
dim_feedforward = 512
eval_train = 0
filename =
gnn_JK = cat
gnn_dropout = 0.3
gnn_emb_dim = 300
gnn_num_layer = 5
gnn_residual = False
gnn_type = gin
gnn_virtual_node = False
graph_pooling = cls
input_model_file = models_graphtrans/graphtrans-sr-gcl.pth
lr = 5e-05
lr_scale = 1
max_input_len = 1000
nhead = 4
num_encoder_layers = 4
num_encoder_layers_masked = 0
num_workers = 0
pos_encoder = False
runseed = 6
seed = 12344
split = scaffold
transformer_activation = relu
transformer_dropout = 0.3
transformer_norm_input = True
transformer_prenorm = False
=========================================
clintox
scaffold
Loaded GraphTrans from models_graphtrans/graphtrans-sr-gcl.pth
====epoch 1
Train Loss 19.276063901763415
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.4839 test: 0.5381 | best val epoch -- val: 0.4839 test: 0.5381

====epoch 2
Train Loss 11.97168991637629
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.4723 test: 0.5870 | best val epoch -- val: 0.4839 test: 0.5381

====epoch 3
Train Loss 10.156112672882562
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.5182 test: 0.6322 | best val epoch -- val: 0.5182 test: 0.6322

====epoch 4
Train Loss 9.778240088775654
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.5566 test: 0.6477 | best val epoch -- val: 0.5566 test: 0.6477

====epoch 5
Train Loss 9.639739845810585
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6528 test: 0.6048 | best val epoch -- val: 0.6528 test: 0.6048

====epoch 6
Train Loss 9.79052490068147
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6594 test: 0.6174 | best val epoch -- val: 0.6594 test: 0.6174

====epoch 7
Train Loss 9.70272258835134
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6979 test: 0.6086 | best val epoch -- val: 0.6979 test: 0.6086

====epoch 8
Train Loss 9.627151196020737
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6166 test: 0.6741 | best val epoch -- val: 0.6979 test: 0.6086

====epoch 9
Train Loss 9.447452655193771
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7096 test: 0.6166 | best val epoch -- val: 0.7096 test: 0.6166

====epoch 10
Train Loss 9.509205403591585
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7621 test: 0.6292 | best val epoch -- val: 0.7621 test: 0.6292

====epoch 11
Train Loss 9.737852442688318
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7739 test: 0.6370 | best val epoch -- val: 0.7739 test: 0.6370

====epoch 12
Train Loss 9.307316546318331
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7883 test: 0.6677 | best val epoch -- val: 0.7883 test: 0.6677

====epoch 13
Train Loss 9.199665898863733
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7946 test: 0.6725 | best val epoch -- val: 0.7946 test: 0.6725

====epoch 14
Train Loss 9.387879250176237
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8084 test: 0.6748 | best val epoch -- val: 0.8084 test: 0.6748

====epoch 15
Train Loss 9.316070973367221
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8098 test: 0.6757 | best val epoch -- val: 0.8098 test: 0.6757

====epoch 16
Train Loss 9.273112249329186
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8089 test: 0.6685 | best val epoch -- val: 0.8098 test: 0.6757

====epoch 17
Train Loss 9.050154888660117
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8173 test: 0.6821 | best val epoch -- val: 0.8173 test: 0.6821

====epoch 18
Train Loss 9.068014419106031
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8275 test: 0.6850 | best val epoch -- val: 0.8275 test: 0.6850

====epoch 19
Train Loss 8.905780772734701
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8406 test: 0.6945 | best val epoch -- val: 0.8406 test: 0.6945

====epoch 20
Train Loss 8.79008724805981
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8705 test: 0.6849 | best val epoch -- val: 0.8705 test: 0.6849

====epoch 21
Train Loss 8.644252966799497
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8628 test: 0.7038 | best val epoch -- val: 0.8705 test: 0.6849

====epoch 22
Train Loss 8.57972895601966
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8935 test: 0.7042 | best val epoch -- val: 0.8935 test: 0.7042

====epoch 23
Train Loss 8.50221373452783
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8874 test: 0.6971 | best val epoch -- val: 0.8935 test: 0.7042

====epoch 24
Train Loss 8.054440907574955
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8961 test: 0.7062 | best val epoch -- val: 0.8961 test: 0.7062

====epoch 25
Train Loss 8.303057379162775
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8877 test: 0.6941 | best val epoch -- val: 0.8961 test: 0.7062

====epoch 26
Train Loss 7.827327747659889
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8962 test: 0.7068 | best val epoch -- val: 0.8962 test: 0.7068

====epoch 27
Train Loss 7.701693945109129
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8949 test: 0.7197 | best val epoch -- val: 0.8962 test: 0.7068

====epoch 28
Train Loss 7.639474824351388
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8651 test: 0.7425 | best val epoch -- val: 0.8962 test: 0.7068

====epoch 29
Train Loss 7.805469757065874
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8752 test: 0.7371 | best val epoch -- val: 0.8962 test: 0.7068

====epoch 30
Train Loss 7.381588675269684
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8398 test: 0.7382 | best val epoch -- val: 0.8962 test: 0.7068

====epoch 31
Train Loss 7.292855944851245
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8636 test: 0.7387 | best val epoch -- val: 0.8962 test: 0.7068

====epoch 32
Train Loss 7.1050553881913014
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8600 test: 0.7315 | best val epoch -- val: 0.8962 test: 0.7068

====epoch 33
Train Loss 6.964745174370005
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8286 test: 0.7358 | best val epoch -- val: 0.8962 test: 0.7068

====epoch 34
Train Loss 7.229726085005273
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8579 test: 0.7277 | best val epoch -- val: 0.8962 test: 0.7068

====epoch 35
Train Loss 7.191002023176033
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8586 test: 0.7365 | best val epoch -- val: 0.8962 test: 0.7068

====epoch 36
Train Loss 7.059180185823784
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8592 test: 0.7400 | best val epoch -- val: 0.8962 test: 0.7068

====epoch 37
Train Loss 6.745088986346505
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8726 test: 0.7393 | best val epoch -- val: 0.8962 test: 0.7068

====epoch 38
Train Loss 6.535321422191354
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8746 test: 0.7508 | best val epoch -- val: 0.8962 test: 0.7068

====epoch 39
Train Loss 6.671746353103421
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8747 test: 0.7533 | best val epoch -- val: 0.8962 test: 0.7068

====epoch 40
Train Loss 6.623094858796967
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8679 test: 0.7499 | best val epoch -- val: 0.8962 test: 0.7068

====epoch 41
Train Loss 6.340431517600801
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8720 test: 0.7602 | best val epoch -- val: 0.8962 test: 0.7068

====epoch 42
Train Loss 6.5015571554638845
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8623 test: 0.7571 | best val epoch -- val: 0.8962 test: 0.7068

====epoch 43
Train Loss 6.221240398880801
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8555 test: 0.7647 | best val epoch -- val: 0.8962 test: 0.7068

====epoch 44
Train Loss 6.266004771289071
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8640 test: 0.7708 | best val epoch -- val: 0.8962 test: 0.7068

====epoch 45
Train Loss 6.003036372112902
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8682 test: 0.7745 | best val epoch -- val: 0.8962 test: 0.7068

====epoch 46
Train Loss 5.977170926156038
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8626 test: 0.7782 | best val epoch -- val: 0.8962 test: 0.7068

====epoch 47
Train Loss 6.114067879927455
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8627 test: 0.7895 | best val epoch -- val: 0.8962 test: 0.7068

====epoch 48
Train Loss 6.077670863990347
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8505 test: 0.7799 | best val epoch -- val: 0.8962 test: 0.7068

====epoch 49
Train Loss 6.280935505258612
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8536 test: 0.7883 | best val epoch -- val: 0.8962 test: 0.7068

====epoch 50
Train Loss 6.164718590666608
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8435 test: 0.7856 | best val epoch -- val: 0.8962 test: 0.7068

====epoch 51
Train Loss 6.267483386173834
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8603 test: 0.7926 | best val epoch -- val: 0.8962 test: 0.7068

====epoch 52
Train Loss 5.920844028906718
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8738 test: 0.7936 | best val epoch -- val: 0.8962 test: 0.7068

====epoch 53
Train Loss 5.996064391206766
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8841 test: 0.7941 | best val epoch -- val: 0.8962 test: 0.7068

====epoch 54
Train Loss 5.773377206253219
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8950 test: 0.7895 | best val epoch -- val: 0.8962 test: 0.7068

====epoch 55
Train Loss 5.917328481347115
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8937 test: 0.7917 | best val epoch -- val: 0.8962 test: 0.7068

====epoch 56
Train Loss 6.177145834587809
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8777 test: 0.7850 | best val epoch -- val: 0.8962 test: 0.7068

====epoch 57
Train Loss 5.806322599639184
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8757 test: 0.7825 | best val epoch -- val: 0.8962 test: 0.7068

====epoch 58
Train Loss 5.704138780186018
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8819 test: 0.7780 | best val epoch -- val: 0.8962 test: 0.7068

====epoch 59
Train Loss 5.784355119476084
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9001 test: 0.7916 | best val epoch -- val: 0.9001 test: 0.7916

====epoch 60
Train Loss 5.629566245444525
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8973 test: 0.7992 | best val epoch -- val: 0.9001 test: 0.7916

====epoch 61
Train Loss 5.462840295580646
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9096 test: 0.7995 | best val epoch -- val: 0.9096 test: 0.7995

====epoch 62
Train Loss 5.4061966059241335
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9084 test: 0.8012 | best val epoch -- val: 0.9096 test: 0.7995

====epoch 63
Train Loss 5.87665370736028
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8981 test: 0.7863 | best val epoch -- val: 0.9096 test: 0.7995

====epoch 64
Train Loss 5.63472389782721
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8868 test: 0.7825 | best val epoch -- val: 0.9096 test: 0.7995

====epoch 65
Train Loss 5.552726538591455
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8949 test: 0.7940 | best val epoch -- val: 0.9096 test: 0.7995

====epoch 66
Train Loss 5.947972508301743
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9098 test: 0.8023 | best val epoch -- val: 0.9098 test: 0.8023

====epoch 67
Train Loss 5.1749476938508225
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9041 test: 0.8046 | best val epoch -- val: 0.9098 test: 0.8023

====epoch 68
Train Loss 5.302889064089375
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8897 test: 0.7986 | best val epoch -- val: 0.9098 test: 0.8023

====epoch 69
Train Loss 5.290626891396032
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8999 test: 0.8004 | best val epoch -- val: 0.9098 test: 0.8023

====epoch 70
Train Loss 5.564507513500595
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8995 test: 0.8052 | best val epoch -- val: 0.9098 test: 0.8023

====epoch 71
Train Loss 5.5534145237190495
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8943 test: 0.8028 | best val epoch -- val: 0.9098 test: 0.8023

====epoch 72
Train Loss 5.369005174155039
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8897 test: 0.7916 | best val epoch -- val: 0.9098 test: 0.8023

====epoch 73
Train Loss 5.351103430025835
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8935 test: 0.7851 | best val epoch -- val: 0.9098 test: 0.8023

====epoch 74
Train Loss 5.382989334721591
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9049 test: 0.7838 | best val epoch -- val: 0.9098 test: 0.8023

====epoch 75
Train Loss 5.126980762828571
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8865 test: 0.7935 | best val epoch -- val: 0.9098 test: 0.8023

====epoch 76
Train Loss 4.972497917421366
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8890 test: 0.7910 | best val epoch -- val: 0.9098 test: 0.8023

====epoch 77
Train Loss 5.031208455698146
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8729 test: 0.7950 | best val epoch -- val: 0.9098 test: 0.8023

====epoch 78
Train Loss 4.766268139201865
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8883 test: 0.7941 | best val epoch -- val: 0.9098 test: 0.8023

====epoch 79
Train Loss 5.099261825293264
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8769 test: 0.7919 | best val epoch -- val: 0.9098 test: 0.8023

====epoch 80
Train Loss 5.213811959338136
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8804 test: 0.8025 | best val epoch -- val: 0.9098 test: 0.8023

====epoch 81
Train Loss 5.078275927955628
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9061 test: 0.7959 | best val epoch -- val: 0.9098 test: 0.8023

====epoch 82
Train Loss 4.676003359077889
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8945 test: 0.7918 | best val epoch -- val: 0.9098 test: 0.8023

====epoch 83
Train Loss 5.207087739828028
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8919 test: 0.7922 | best val epoch -- val: 0.9098 test: 0.8023

====epoch 84
Train Loss 4.799872699459492
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8882 test: 0.7927 | best val epoch -- val: 0.9098 test: 0.8023

====epoch 85
Train Loss 5.210563263772529
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8942 test: 0.7906 | best val epoch -- val: 0.9098 test: 0.8023

====epoch 86
Train Loss 5.028982447341178
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8811 test: 0.7888 | best val epoch -- val: 0.9098 test: 0.8023

====epoch 87
Train Loss 4.993638805998152
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8623 test: 0.7918 | best val epoch -- val: 0.9098 test: 0.8023

====epoch 88
Train Loss 5.558693469921643
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8734 test: 0.7974 | best val epoch -- val: 0.9098 test: 0.8023

====epoch 89
Train Loss 4.9713635970317105
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8518 test: 0.7885 | best val epoch -- val: 0.9098 test: 0.8023

====epoch 90
Train Loss 4.967976808238005
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8690 test: 0.7955 | best val epoch -- val: 0.9098 test: 0.8023

====epoch 91
Train Loss 5.25403395041711
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8848 test: 0.7829 | best val epoch -- val: 0.9098 test: 0.8023

====epoch 92
Train Loss 4.676265391641086
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8967 test: 0.7831 | best val epoch -- val: 0.9098 test: 0.8023

====epoch 93
Train Loss 5.088660750832017
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8977 test: 0.7883 | best val epoch -- val: 0.9098 test: 0.8023

====epoch 94
Train Loss 4.685224975729523
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8909 test: 0.7881 | best val epoch -- val: 0.9098 test: 0.8023

====epoch 95
Train Loss 5.169402520658627
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8733 test: 0.7725 | best val epoch -- val: 0.9098 test: 0.8023

====epoch 96
Train Loss 4.770449610358592
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8724 test: 0.7823 | best val epoch -- val: 0.9098 test: 0.8023

====epoch 97
Train Loss 5.374626118708056
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8901 test: 0.7931 | best val epoch -- val: 0.9098 test: 0.8023

====epoch 98
Train Loss 4.933997714886919
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8873 test: 0.7810 | best val epoch -- val: 0.9098 test: 0.8023

====epoch 99
Train Loss 5.167616911402391
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8854 test: 0.7835 | best val epoch -- val: 0.9098 test: 0.8023

====epoch 100
Train Loss 4.705312432949435
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8778 test: 0.7788 | best val epoch -- val: 0.9098 test: 0.8023

====epoch 101
Train Loss 4.667787147570544
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8796 test: 0.7751 | best val epoch -- val: 0.9098 test: 0.8023

====epoch 102
Train Loss 5.028383446332384
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8607 test: 0.7812 | best val epoch -- val: 0.9098 test: 0.8023

====epoch 103
Train Loss 4.62621532351635
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8818 test: 0.7793 | best val epoch -- val: 0.9098 test: 0.8023

====epoch 104
Train Loss 4.693107194320623
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8932 test: 0.7810 | best val epoch -- val: 0.9098 test: 0.8023

====epoch 105
Train Loss 4.662157851038267
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9016 test: 0.7828 | best val epoch -- val: 0.9098 test: 0.8023

====epoch 106
Train Loss 5.313294586424629
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8941 test: 0.7759 | best val epoch -- val: 0.9098 test: 0.8023

====epoch 107
Train Loss 4.609061134505999
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9014 test: 0.7791 | best val epoch -- val: 0.9098 test: 0.8023

====epoch 108
Train Loss 4.968563490921811
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9007 test: 0.7788 | best val epoch -- val: 0.9098 test: 0.8023

====epoch 109
Train Loss 4.444956609973094
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8905 test: 0.7989 | best val epoch -- val: 0.9098 test: 0.8023

====epoch 110
Train Loss 4.851437350371729
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8696 test: 0.7946 | best val epoch -- val: 0.9098 test: 0.8023

====epoch 111
Train Loss 4.424172535929562
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8749 test: 0.7991 | best val epoch -- val: 0.9098 test: 0.8023

====epoch 112
Train Loss 4.884018698668713
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8822 test: 0.7934 | best val epoch -- val: 0.9098 test: 0.8023

====epoch 113
Train Loss 5.0488312024684925
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8887 test: 0.7994 | best val epoch -- val: 0.9098 test: 0.8023

====epoch 114
Train Loss 4.778810711020128
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8733 test: 0.7981 | best val epoch -- val: 0.9098 test: 0.8023

====epoch 115
Train Loss 4.961785319236584
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8872 test: 0.7944 | best val epoch -- val: 0.9098 test: 0.8023

====epoch 116
Train Loss 4.939758396927251
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9039 test: 0.7932 | best val epoch -- val: 0.9098 test: 0.8023

====epoch 117
Train Loss 4.445482653590924
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8936 test: 0.7853 | best val epoch -- val: 0.9098 test: 0.8023

====epoch 118
Train Loss 4.5491219966166305
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8891 test: 0.7912 | best val epoch -- val: 0.9098 test: 0.8023

====epoch 119
Train Loss 4.4440327209966295
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8719 test: 0.7851 | best val epoch -- val: 0.9098 test: 0.8023

====epoch 120
Train Loss 4.736519696665824
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8953 test: 0.7756 | best val epoch -- val: 0.9098 test: 0.8023

====epoch 121
Train Loss 4.627961864935723
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9062 test: 0.7795 | best val epoch -- val: 0.9098 test: 0.8023

====epoch 122
Train Loss 4.126031105241653
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8928 test: 0.7851 | best val epoch -- val: 0.9098 test: 0.8023

====epoch 123
Train Loss 4.514955183935186
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8853 test: 0.7784 | best val epoch -- val: 0.9098 test: 0.8023

====epoch 124
Train Loss 4.50832079362252
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8774 test: 0.7791 | best val epoch -- val: 0.9098 test: 0.8023

====epoch 125
Train Loss 4.452487450251718
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8924 test: 0.7846 | best val epoch -- val: 0.9098 test: 0.8023

====epoch 126
Train Loss 4.767351482602861
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8909 test: 0.7703 | best val epoch -- val: 0.9098 test: 0.8023

====epoch 127
Train Loss 4.537926300032964
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8774 test: 0.7725 | best val epoch -- val: 0.9098 test: 0.8023

====epoch 128
Train Loss 4.480168430270688
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8775 test: 0.7654 | best val epoch -- val: 0.9098 test: 0.8023

====epoch 129
Train Loss 4.334650022809452
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8778 test: 0.7465 | best val epoch -- val: 0.9098 test: 0.8023

====epoch 130
Train Loss 4.38998403539491
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8823 test: 0.7607 | best val epoch -- val: 0.9098 test: 0.8023

====epoch 131
Train Loss 4.439784309450883
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8891 test: 0.7572 | best val epoch -- val: 0.9098 test: 0.8023

====epoch 132
Train Loss 4.333134102646777
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8895 test: 0.7631 | best val epoch -- val: 0.9098 test: 0.8023

====epoch 133
Train Loss 4.635771679456652
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8893 test: 0.7627 | best val epoch -- val: 0.9098 test: 0.8023

====epoch 134
Train Loss 4.311700083941576
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8711 test: 0.7677 | best val epoch -- val: 0.9098 test: 0.8023

====epoch 135
Train Loss 4.602141717983299
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8713 test: 0.7752 | best val epoch -- val: 0.9098 test: 0.8023

====epoch 136
Train Loss 4.2438826426273
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8742 test: 0.7750 | best val epoch -- val: 0.9098 test: 0.8023

====epoch 137
Train Loss 4.627899452574959
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8607 test: 0.7804 | best val epoch -- val: 0.9098 test: 0.8023

====epoch 138
Train Loss 4.28991079658284
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8490 test: 0.7791 | best val epoch -- val: 0.9098 test: 0.8023

====epoch 139
Train Loss 4.165477255884844
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8706 test: 0.7756 | best val epoch -- val: 0.9098 test: 0.8023

====epoch 140
Train Loss 4.117515651265295
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8865 test: 0.7720 | best val epoch -- val: 0.9098 test: 0.8023

====epoch 141
Train Loss 4.242247191596427
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8829 test: 0.7697 | best val epoch -- val: 0.9098 test: 0.8023

====epoch 142
Train Loss 4.130606960127919
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8658 test: 0.7550 | best val epoch -- val: 0.9098 test: 0.8023

====epoch 143
Train Loss 4.321119412056198
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8608 test: 0.7754 | best val epoch -- val: 0.9098 test: 0.8023

====epoch 144
Train Loss 4.400555211341597
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8787 test: 0.7820 | best val epoch -- val: 0.9098 test: 0.8023

====epoch 145
Train Loss 4.087121263327554
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8857 test: 0.7784 | best val epoch -- val: 0.9098 test: 0.8023

====epoch 146
Train Loss 4.269146750728247
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8791 test: 0.7739 | best val epoch -- val: 0.9098 test: 0.8023

====epoch 147
Train Loss 4.230667180453134
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8863 test: 0.7674 | best val epoch -- val: 0.9098 test: 0.8023

====epoch 148
Train Loss 4.137749407208903
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8876 test: 0.7677 | best val epoch -- val: 0.9098 test: 0.8023

====epoch 149
Train Loss 4.412556578169689
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9026 test: 0.7737 | best val epoch -- val: 0.9098 test: 0.8023

====epoch 150
Train Loss 4.5496893202677
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8789 test: 0.7664 | best val epoch -- val: 0.9098 test: 0.8023

====epoch 151
Train Loss 4.1560565301757135
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8468 test: 0.7624 | best val epoch -- val: 0.9098 test: 0.8023

====epoch 152
Train Loss 4.252685010060259
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8953 test: 0.7713 | best val epoch -- val: 0.9098 test: 0.8023

====epoch 153
Train Loss 4.28569341977238
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8749 test: 0.7643 | best val epoch -- val: 0.9098 test: 0.8023

====epoch 154
Train Loss 3.978924673125753
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9076 test: 0.7693 | best val epoch -- val: 0.9098 test: 0.8023

====epoch 155
Train Loss 4.293529605713045
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9046 test: 0.7787 | best val epoch -- val: 0.9098 test: 0.8023

====epoch 156
Train Loss 4.298712087921272
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9177 test: 0.7811 | best val epoch -- val: 0.9177 test: 0.7811

====epoch 157
Train Loss 4.030722379664855
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9115 test: 0.7794 | best val epoch -- val: 0.9177 test: 0.7811

====epoch 158
Train Loss 4.3800411259747865
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9067 test: 0.7893 | best val epoch -- val: 0.9177 test: 0.7811

====epoch 159
Train Loss 4.232943599391848
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9124 test: 0.7869 | best val epoch -- val: 0.9177 test: 0.7811

====epoch 160
Train Loss 4.152437512173818
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9189 test: 0.7797 | best val epoch -- val: 0.9189 test: 0.7797

====epoch 161
Train Loss 3.891849222996733
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9095 test: 0.7735 | best val epoch -- val: 0.9189 test: 0.7797

====epoch 162
Train Loss 4.043501703695894
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9189 test: 0.7734 | best val epoch -- val: 0.9189 test: 0.7797

====epoch 163
Train Loss 4.462650090938412
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9101 test: 0.7721 | best val epoch -- val: 0.9189 test: 0.7797

====epoch 164
Train Loss 4.040542518065101
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9125 test: 0.7830 | best val epoch -- val: 0.9189 test: 0.7797

====epoch 165
Train Loss 3.837069163265275
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8730 test: 0.7829 | best val epoch -- val: 0.9189 test: 0.7797

====epoch 166
Train Loss 4.258692324761061
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8970 test: 0.7785 | best val epoch -- val: 0.9189 test: 0.7797

====epoch 167
Train Loss 3.9661579164307015
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8782 test: 0.7693 | best val epoch -- val: 0.9189 test: 0.7797

====epoch 168
Train Loss 4.188409764616796
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8969 test: 0.7811 | best val epoch -- val: 0.9189 test: 0.7797

====epoch 169
Train Loss 4.254634076527472
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8665 test: 0.7821 | best val epoch -- val: 0.9189 test: 0.7797

====epoch 170
Train Loss 3.9137499368218083
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8863 test: 0.7813 | best val epoch -- val: 0.9189 test: 0.7797

====epoch 171
Train Loss 4.15515927057755
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8710 test: 0.7716 | best val epoch -- val: 0.9189 test: 0.7797

====epoch 172
Train Loss 4.053001851234909
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8682 test: 0.7857 | best val epoch -- val: 0.9189 test: 0.7797

====epoch 173
Train Loss 3.915070774853688
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8017 test: 0.7783 | best val epoch -- val: 0.9189 test: 0.7797

====epoch 174
Train Loss 3.7387734116357048
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8727 test: 0.7863 | best val epoch -- val: 0.9189 test: 0.7797

====epoch 175
Train Loss 3.967928848780211
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8830 test: 0.7893 | best val epoch -- val: 0.9189 test: 0.7797

====epoch 176
Train Loss 4.218731482674076
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9116 test: 0.8015 | best val epoch -- val: 0.9189 test: 0.7797

====epoch 177
Train Loss 3.8690746112049093
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9119 test: 0.8076 | best val epoch -- val: 0.9189 test: 0.7797

====epoch 178
Train Loss 4.14319446297372
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9329 test: 0.8087 | best val epoch -- val: 0.9329 test: 0.8087

====epoch 179
Train Loss 3.792968473352454
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9170 test: 0.8079 | best val epoch -- val: 0.9329 test: 0.8087

====epoch 180
Train Loss 3.914473953123491
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9282 test: 0.8110 | best val epoch -- val: 0.9329 test: 0.8087

====epoch 181
Train Loss 3.928019646737159
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9271 test: 0.7958 | best val epoch -- val: 0.9329 test: 0.8087

====epoch 182
Train Loss 4.010254432717394
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9356 test: 0.8268 | best val epoch -- val: 0.9356 test: 0.8268

====epoch 183
Train Loss 4.236623267430354
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9289 test: 0.7946 | best val epoch -- val: 0.9356 test: 0.8268

====epoch 184
Train Loss 3.987557572797765
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9217 test: 0.7832 | best val epoch -- val: 0.9356 test: 0.8268

====epoch 185
Train Loss 3.914407278499201
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8646 test: 0.7805 | best val epoch -- val: 0.9356 test: 0.8268

====epoch 186
Train Loss 3.854847985987851
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8646 test: 0.7828 | best val epoch -- val: 0.9356 test: 0.8268

====epoch 187
Train Loss 4.199701827353312
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9123 test: 0.7816 | best val epoch -- val: 0.9356 test: 0.8268

====epoch 188
Train Loss 3.8074548117369864
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8645 test: 0.7889 | best val epoch -- val: 0.9356 test: 0.8268

====epoch 189
Train Loss 4.021905067877583
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8991 test: 0.7987 | best val epoch -- val: 0.9356 test: 0.8268

====epoch 190
Train Loss 3.734921836270457
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9027 test: 0.7949 | best val epoch -- val: 0.9356 test: 0.8268

====epoch 191
Train Loss 3.842835920176778
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8730 test: 0.7906 | best val epoch -- val: 0.9356 test: 0.8268

====epoch 192
Train Loss 4.210567824459023
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9257 test: 0.7881 | best val epoch -- val: 0.9356 test: 0.8268

====epoch 193
Train Loss 3.7921586370864255
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9219 test: 0.7941 | best val epoch -- val: 0.9356 test: 0.8268

====epoch 194
Train Loss 4.052478883463
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9199 test: 0.7894 | best val epoch -- val: 0.9356 test: 0.8268

====epoch 195
Train Loss 3.777132958631022
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8638 test: 0.7888 | best val epoch -- val: 0.9356 test: 0.8268

====epoch 196
Train Loss 3.877276352767608
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8713 test: 0.7840 | best val epoch -- val: 0.9356 test: 0.8268

====epoch 197
Train Loss 4.121076607149322
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9217 test: 0.7819 | best val epoch -- val: 0.9356 test: 0.8268

====epoch 198
Train Loss 3.643037402860388
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8799 test: 0.7790 | best val epoch -- val: 0.9356 test: 0.8268

====epoch 199
Train Loss 3.995596686460611
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9198 test: 0.7716 | best val epoch -- val: 0.9356 test: 0.8268

====epoch 200
Train Loss 3.928156804308431
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9316 test: 0.7808 | best val epoch -- val: 0.9356 test: 0.8268

2022-09-14 02:46:59.675 | INFO     | modules.masked_transformer_encoder:__init__:122 - number of parameters: 0.000000e+00
=========================================
batch_size = 32
d_model = 128
dataset = clintox
decay = 0
device = 3
dim_feedforward = 512
eval_train = 0
filename =
gnn_JK = cat
gnn_dropout = 0.3
gnn_emb_dim = 300
gnn_num_layer = 5
gnn_residual = False
gnn_type = gin
gnn_virtual_node = False
graph_pooling = cls
input_model_file = models_graphtrans/graphtrans-sr-gcl.pth
lr = 5e-05
lr_scale = 1
max_input_len = 1000
nhead = 4
num_encoder_layers = 4
num_encoder_layers_masked = 0
num_workers = 0
pos_encoder = False
runseed = 7
seed = 12344
split = scaffold
transformer_activation = relu
transformer_dropout = 0.3
transformer_norm_input = True
transformer_prenorm = False
=========================================
clintox
scaffold
Loaded GraphTrans from models_graphtrans/graphtrans-sr-gcl.pth
====epoch 1
Train Loss 18.96318748915114
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.3319 test: 0.5402 | best val epoch -- val: 0.3319 test: 0.5402

====epoch 2
Train Loss 11.850578590893745
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.3433 test: 0.5355 | best val epoch -- val: 0.3433 test: 0.5355

====epoch 3
Train Loss 10.645633137717143
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.3074 test: 0.5408 | best val epoch -- val: 0.3433 test: 0.5355

====epoch 4
Train Loss 10.015824926558233
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.2977 test: 0.5410 | best val epoch -- val: 0.3433 test: 0.5355

====epoch 5
Train Loss 10.011811871220337
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.3033 test: 0.5791 | best val epoch -- val: 0.3433 test: 0.5355

====epoch 6
Train Loss 9.821550506095706
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.3315 test: 0.5697 | best val epoch -- val: 0.3433 test: 0.5355

====epoch 7
Train Loss 10.037481738328333
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.3424 test: 0.5920 | best val epoch -- val: 0.3433 test: 0.5355

====epoch 8
Train Loss 9.858935781191796
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.3874 test: 0.6185 | best val epoch -- val: 0.3874 test: 0.6185

====epoch 9
Train Loss 9.857202533178148
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.4472 test: 0.6149 | best val epoch -- val: 0.4472 test: 0.6149

====epoch 10
Train Loss 9.670109959750816
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.5623 test: 0.6259 | best val epoch -- val: 0.5623 test: 0.6259

====epoch 11
Train Loss 9.605553932003893
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.5405 test: 0.6062 | best val epoch -- val: 0.5623 test: 0.6259

====epoch 12
Train Loss 9.575841657862384
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.4917 test: 0.6118 | best val epoch -- val: 0.5623 test: 0.6259

====epoch 13
Train Loss 9.532380313214158
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.5307 test: 0.6245 | best val epoch -- val: 0.5623 test: 0.6259

====epoch 14
Train Loss 9.608953228799757
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.5866 test: 0.6344 | best val epoch -- val: 0.5866 test: 0.6344

====epoch 15
Train Loss 9.441441592875998
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6368 test: 0.6383 | best val epoch -- val: 0.6368 test: 0.6383

====epoch 16
Train Loss 9.338897417894577
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6607 test: 0.6527 | best val epoch -- val: 0.6607 test: 0.6527

====epoch 17
Train Loss 9.201208473161088
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6689 test: 0.6716 | best val epoch -- val: 0.6689 test: 0.6716

====epoch 18
Train Loss 9.133074491086507
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7758 test: 0.6871 | best val epoch -- val: 0.7758 test: 0.6871

====epoch 19
Train Loss 8.945268658780412
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8095 test: 0.7117 | best val epoch -- val: 0.8095 test: 0.7117

====epoch 20
Train Loss 8.939826782354073
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8529 test: 0.7131 | best val epoch -- val: 0.8529 test: 0.7131

====epoch 21
Train Loss 8.399573570852768
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8554 test: 0.7173 | best val epoch -- val: 0.8554 test: 0.7173

====epoch 22
Train Loss 8.383320682547705
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8865 test: 0.7232 | best val epoch -- val: 0.8865 test: 0.7232

====epoch 23
Train Loss 8.104138112954928
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8871 test: 0.7438 | best val epoch -- val: 0.8871 test: 0.7438

====epoch 24
Train Loss 7.811094354270576
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8898 test: 0.7404 | best val epoch -- val: 0.8898 test: 0.7404

====epoch 25
Train Loss 7.815757274316983
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8838 test: 0.7399 | best val epoch -- val: 0.8898 test: 0.7404

====epoch 26
Train Loss 7.703126803770053
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8944 test: 0.7386 | best val epoch -- val: 0.8944 test: 0.7386

====epoch 27
Train Loss 7.416216747688129
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8893 test: 0.7333 | best val epoch -- val: 0.8944 test: 0.7386

====epoch 28
Train Loss 7.867621755688739
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8699 test: 0.7438 | best val epoch -- val: 0.8944 test: 0.7386

====epoch 29
Train Loss 7.443329812563143
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8673 test: 0.7408 | best val epoch -- val: 0.8944 test: 0.7386

====epoch 30
Train Loss 7.249744423258657
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8772 test: 0.7459 | best val epoch -- val: 0.8944 test: 0.7386

====epoch 31
Train Loss 6.887694687231557
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8377 test: 0.7489 | best val epoch -- val: 0.8944 test: 0.7386

====epoch 32
Train Loss 7.253769587842779
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8416 test: 0.7537 | best val epoch -- val: 0.8944 test: 0.7386

====epoch 33
Train Loss 7.277682956395547
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8529 test: 0.7577 | best val epoch -- val: 0.8944 test: 0.7386

====epoch 34
Train Loss 6.950841552818629
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8658 test: 0.7593 | best val epoch -- val: 0.8944 test: 0.7386

====epoch 35
Train Loss 7.051708808242158
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8601 test: 0.7568 | best val epoch -- val: 0.8944 test: 0.7386

====epoch 36
Train Loss 6.703307018160486
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8742 test: 0.7504 | best val epoch -- val: 0.8944 test: 0.7386

====epoch 37
Train Loss 6.795944042433775
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8592 test: 0.7486 | best val epoch -- val: 0.8944 test: 0.7386

====epoch 38
Train Loss 6.754753742493623
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8582 test: 0.7386 | best val epoch -- val: 0.8944 test: 0.7386

====epoch 39
Train Loss 6.4990857281536885
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8467 test: 0.7378 | best val epoch -- val: 0.8944 test: 0.7386

====epoch 40
Train Loss 6.66305765772955
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8568 test: 0.7394 | best val epoch -- val: 0.8944 test: 0.7386

====epoch 41
Train Loss 6.249744343501248
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8453 test: 0.7406 | best val epoch -- val: 0.8944 test: 0.7386

====epoch 42
Train Loss 6.7414486211097095
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8689 test: 0.7519 | best val epoch -- val: 0.8944 test: 0.7386

====epoch 43
Train Loss 6.091500924018868
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8672 test: 0.7542 | best val epoch -- val: 0.8944 test: 0.7386

====epoch 44
Train Loss 6.523005591146718
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8533 test: 0.7566 | best val epoch -- val: 0.8944 test: 0.7386

====epoch 45
Train Loss 6.1018813627946615
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8607 test: 0.7565 | best val epoch -- val: 0.8944 test: 0.7386

====epoch 46
Train Loss 6.519583925251584
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8652 test: 0.7504 | best val epoch -- val: 0.8944 test: 0.7386

====epoch 47
Train Loss 6.350172405686101
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8510 test: 0.7378 | best val epoch -- val: 0.8944 test: 0.7386

====epoch 48
Train Loss 5.929677029526186
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8409 test: 0.7382 | best val epoch -- val: 0.8944 test: 0.7386

====epoch 49
Train Loss 6.031363322806619
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8635 test: 0.7557 | best val epoch -- val: 0.8944 test: 0.7386

====epoch 50
Train Loss 6.18762686323099
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8513 test: 0.7527 | best val epoch -- val: 0.8944 test: 0.7386

====epoch 51
Train Loss 6.096230076132519
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8428 test: 0.7591 | best val epoch -- val: 0.8944 test: 0.7386

====epoch 52
Train Loss 5.889301543363648
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8672 test: 0.7593 | best val epoch -- val: 0.8944 test: 0.7386

====epoch 53
Train Loss 5.889547137546834
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8586 test: 0.7483 | best val epoch -- val: 0.8944 test: 0.7386

====epoch 54
Train Loss 5.910949685988148
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8567 test: 0.7704 | best val epoch -- val: 0.8944 test: 0.7386

====epoch 55
Train Loss 6.176276992647734
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8595 test: 0.7739 | best val epoch -- val: 0.8944 test: 0.7386

====epoch 56
Train Loss 6.124270693559526
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8676 test: 0.7747 | best val epoch -- val: 0.8944 test: 0.7386

====epoch 57
Train Loss 5.576988988486157
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8574 test: 0.7745 | best val epoch -- val: 0.8944 test: 0.7386

====epoch 58
Train Loss 5.50105274443508
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8733 test: 0.7826 | best val epoch -- val: 0.8944 test: 0.7386

====epoch 59
Train Loss 5.60334868464162
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8779 test: 0.7815 | best val epoch -- val: 0.8944 test: 0.7386

====epoch 60
Train Loss 5.545934283218841
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8727 test: 0.7858 | best val epoch -- val: 0.8944 test: 0.7386

====epoch 61
Train Loss 5.5245952703417025
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8840 test: 0.7872 | best val epoch -- val: 0.8944 test: 0.7386

====epoch 62
Train Loss 5.678571179417168
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8727 test: 0.7749 | best val epoch -- val: 0.8944 test: 0.7386

====epoch 63
Train Loss 5.627714501643188
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8726 test: 0.7729 | best val epoch -- val: 0.8944 test: 0.7386

====epoch 64
Train Loss 5.348614519938003
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8600 test: 0.7872 | best val epoch -- val: 0.8944 test: 0.7386

====epoch 65
Train Loss 5.4568598340221826
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8733 test: 0.7953 | best val epoch -- val: 0.8944 test: 0.7386

====epoch 66
Train Loss 5.959703909558459
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8638 test: 0.7939 | best val epoch -- val: 0.8944 test: 0.7386

====epoch 67
Train Loss 5.4153027818151696
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8717 test: 0.7981 | best val epoch -- val: 0.8944 test: 0.7386

====epoch 68
Train Loss 5.169499967168466
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8839 test: 0.7805 | best val epoch -- val: 0.8944 test: 0.7386

====epoch 69
Train Loss 5.082108213097887
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8740 test: 0.7879 | best val epoch -- val: 0.8944 test: 0.7386

====epoch 70
Train Loss 5.479222314894547
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8749 test: 0.7915 | best val epoch -- val: 0.8944 test: 0.7386

====epoch 71
Train Loss 5.325515483261719
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8681 test: 0.8006 | best val epoch -- val: 0.8944 test: 0.7386

====epoch 72
Train Loss 5.007610536421622
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8631 test: 0.7895 | best val epoch -- val: 0.8944 test: 0.7386

====epoch 73
Train Loss 5.116809097848032
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8642 test: 0.7875 | best val epoch -- val: 0.8944 test: 0.7386

====epoch 74
Train Loss 5.544100188411485
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8618 test: 0.8045 | best val epoch -- val: 0.8944 test: 0.7386

====epoch 75
Train Loss 5.214423810925628
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8750 test: 0.8056 | best val epoch -- val: 0.8944 test: 0.7386

====epoch 76
Train Loss 5.287520909715641
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8544 test: 0.7853 | best val epoch -- val: 0.8944 test: 0.7386

====epoch 77
Train Loss 5.173471654289872
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8722 test: 0.7939 | best val epoch -- val: 0.8944 test: 0.7386

====epoch 78
Train Loss 4.766037292309814
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8721 test: 0.7820 | best val epoch -- val: 0.8944 test: 0.7386

====epoch 79
Train Loss 5.007656178774717
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8743 test: 0.7872 | best val epoch -- val: 0.8944 test: 0.7386

====epoch 80
Train Loss 4.919579652221861
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8682 test: 0.7876 | best val epoch -- val: 0.8944 test: 0.7386

====epoch 81
Train Loss 5.0993700610353585
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8710 test: 0.7943 | best val epoch -- val: 0.8944 test: 0.7386

====epoch 82
Train Loss 5.231239390534026
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8805 test: 0.7782 | best val epoch -- val: 0.8944 test: 0.7386

====epoch 83
Train Loss 4.757522386438906
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8800 test: 0.7891 | best val epoch -- val: 0.8944 test: 0.7386

====epoch 84
Train Loss 5.146888625280025
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8849 test: 0.7964 | best val epoch -- val: 0.8944 test: 0.7386

====epoch 85
Train Loss 4.98312451657241
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8921 test: 0.8036 | best val epoch -- val: 0.8944 test: 0.7386

====epoch 86
Train Loss 5.061771787356461
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8986 test: 0.7935 | best val epoch -- val: 0.8986 test: 0.7935

====epoch 87
Train Loss 4.44413080926427
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8952 test: 0.7986 | best val epoch -- val: 0.8986 test: 0.7935

====epoch 88
Train Loss 4.925045666086584
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8739 test: 0.7851 | best val epoch -- val: 0.8986 test: 0.7935

====epoch 89
Train Loss 5.0364715448250905
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8861 test: 0.7786 | best val epoch -- val: 0.8986 test: 0.7935

====epoch 90
Train Loss 5.284287490515686
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8883 test: 0.7957 | best val epoch -- val: 0.8986 test: 0.7935

====epoch 91
Train Loss 4.928637775692587
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8787 test: 0.7907 | best val epoch -- val: 0.8986 test: 0.7935

====epoch 92
Train Loss 4.803531294966602
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8852 test: 0.7954 | best val epoch -- val: 0.8986 test: 0.7935

====epoch 93
Train Loss 5.001753290934697
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8827 test: 0.7969 | best val epoch -- val: 0.8986 test: 0.7935

====epoch 94WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.4.

Train Loss 4.8235999724471625
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8855 test: 0.7924 | best val epoch -- val: 0.8986 test: 0.7935

====epoch 95
Train Loss 4.908616020297064
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9023 test: 0.8071 | best val epoch -- val: 0.9023 test: 0.8071

====epoch 96
Train Loss 4.867525962504278
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8966 test: 0.7899 | best val epoch -- val: 0.9023 test: 0.8071

====epoch 97
Train Loss 4.631331545465493
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8900 test: 0.7883 | best val epoch -- val: 0.9023 test: 0.8071

====epoch 98
Train Loss 4.991223830513655
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8758 test: 0.7932 | best val epoch -- val: 0.9023 test: 0.8071

====epoch 99
Train Loss 4.684242094008418
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8773 test: 0.8008 | best val epoch -- val: 0.9023 test: 0.8071

====epoch 100
Train Loss 5.117334345753896
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8868 test: 0.8070 | best val epoch -- val: 0.9023 test: 0.8071

====epoch 101
Train Loss 4.884858399067688
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8812 test: 0.8121 | best val epoch -- val: 0.9023 test: 0.8071

====epoch 102
Train Loss 4.590116054675941
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8835 test: 0.8082 | best val epoch -- val: 0.9023 test: 0.8071

====epoch 103
Train Loss 4.871751297258772
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8833 test: 0.8120 | best val epoch -- val: 0.9023 test: 0.8071

====epoch 104
Train Loss 4.742908774408371
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8859 test: 0.8097 | best val epoch -- val: 0.9023 test: 0.8071

====epoch 105
Train Loss 4.833844667104132
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8819 test: 0.8024 | best val epoch -- val: 0.9023 test: 0.8071

====epoch 106
Train Loss 4.809401326031912
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8942 test: 0.7905 | best val epoch -- val: 0.9023 test: 0.8071

====epoch 107
Train Loss 5.144760566780299
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8823 test: 0.7950 | best val epoch -- val: 0.9023 test: 0.8071

====epoch 108
Train Loss 4.616553178283427
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8981 test: 0.7824 | best val epoch -- val: 0.9023 test: 0.8071

====epoch 109
Train Loss 4.462540389296564
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8960 test: 0.8023 | best val epoch -- val: 0.9023 test: 0.8071

====epoch 110
Train Loss 4.571186976984758
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8914 test: 0.7949 | best val epoch -- val: 0.9023 test: 0.8071

====epoch 111
Train Loss 4.781013390188375
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8992 test: 0.7796 | best val epoch -- val: 0.9023 test: 0.8071

====epoch 112
Train Loss 4.524430875564052
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9000 test: 0.7870 | best val epoch -- val: 0.9023 test: 0.8071

====epoch 113
Train Loss 4.7488022139426675
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8888 test: 0.7787 | best val epoch -- val: 0.9023 test: 0.8071

====epoch 114
Train Loss 4.395289641055682
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8977 test: 0.7654 | best val epoch -- val: 0.9023 test: 0.8071

====epoch 115
Train Loss 4.575850374536587
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8944 test: 0.7797 | best val epoch -- val: 0.9023 test: 0.8071

====epoch 116
Train Loss 4.598269809675815
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9046 test: 0.7767 | best val epoch -- val: 0.9046 test: 0.7767

====epoch 117
Train Loss 4.571875942257442
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9125 test: 0.7745 | best val epoch -- val: 0.9125 test: 0.7745

====epoch 118
Train Loss 4.725576224059115
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9012 test: 0.7788 | best val epoch -- val: 0.9125 test: 0.7745

====epoch 119
Train Loss 4.407895408294228
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9001 test: 0.7741 | best val epoch -- val: 0.9125 test: 0.7745

====epoch 120
Train Loss 4.544157789535076
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8987 test: 0.7794 | best val epoch -- val: 0.9125 test: 0.7745

====epoch 121
Train Loss 4.460932344604489
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8912 test: 0.7864 | best val epoch -- val: 0.9125 test: 0.7745

====epoch 122
Train Loss 4.00603584061753
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8886 test: 0.7885 | best val epoch -- val: 0.9125 test: 0.7745

====epoch 123
Train Loss 4.255240214287642
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8818 test: 0.7804 | best val epoch -- val: 0.9125 test: 0.7745

====epoch 124
Train Loss 4.445205711745275
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8940 test: 0.7785 | best val epoch -- val: 0.9125 test: 0.7745

====epoch 125
Train Loss 4.379497206171704
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9115 test: 0.7923 | best val epoch -- val: 0.9125 test: 0.7745

====epoch 126
Train Loss 4.48241464237701
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9111 test: 0.7959 | best val epoch -- val: 0.9125 test: 0.7745

====epoch 127
Train Loss 4.241823722209975
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9028 test: 0.7905 | best val epoch -- val: 0.9125 test: 0.7745

====epoch 128
Train Loss 4.303500181560819
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8985 test: 0.7898 | best val epoch -- val: 0.9125 test: 0.7745

====epoch 129
Train Loss 4.403849220096802
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9023 test: 0.7999 | best val epoch -- val: 0.9125 test: 0.7745

====epoch 130
Train Loss 4.439577506172168
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9073 test: 0.7857 | best val epoch -- val: 0.9125 test: 0.7745

====epoch 131
Train Loss 4.3540642295756395
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9035 test: 0.7972 | best val epoch -- val: 0.9125 test: 0.7745

====epoch 132
Train Loss 4.1580081680739145
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8972 test: 0.7913 | best val epoch -- val: 0.9125 test: 0.7745

====epoch 133
Train Loss 4.4695465864824415
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8933 test: 0.7954 | best val epoch -- val: 0.9125 test: 0.7745

====epoch 134
Train Loss 4.335431582630686
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9085 test: 0.8104 | best val epoch -- val: 0.9125 test: 0.7745

====epoch 135
Train Loss 4.3494685956922945
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9097 test: 0.8102 | best val epoch -- val: 0.9125 test: 0.7745

====epoch 136
Train Loss 4.15864898345821
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9142 test: 0.8137 | best val epoch -- val: 0.9142 test: 0.8137

====epoch 137
Train Loss 4.342957475044744
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8960 test: 0.7935 | best val epoch -- val: 0.9142 test: 0.8137

====epoch 138
Train Loss 3.8746861548093716
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9090 test: 0.7970 | best val epoch -- val: 0.9142 test: 0.8137

====epoch 139
Train Loss 4.273512142434958
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9040 test: 0.8091 | best val epoch -- val: 0.9142 test: 0.8137

====epoch 140
Train Loss 4.277514749564519
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9001 test: 0.7848 | best val epoch -- val: 0.9142 test: 0.8137

====epoch 141
Train Loss 4.256278818378419
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9093 test: 0.8112 | best val epoch -- val: 0.9142 test: 0.8137

====epoch 142
Train Loss 4.094813206684274
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9124 test: 0.7959 | best val epoch -- val: 0.9142 test: 0.8137

====epoch 143
Train Loss 4.2433496369105805
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9077 test: 0.7908 | best val epoch -- val: 0.9142 test: 0.8137

====epoch 144
Train Loss 4.588820718172004
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9175 test: 0.7907 | best val epoch -- val: 0.9175 test: 0.7907

====epoch 145
Train Loss 4.348501383382943
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9133 test: 0.8046 | best val epoch -- val: 0.9175 test: 0.7907

====epoch 146
Train Loss 3.9901619596223945
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9019 test: 0.7864 | best val epoch -- val: 0.9175 test: 0.7907

====epoch 147
Train Loss 4.34482259498159
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9120 test: 0.7854 | best val epoch -- val: 0.9175 test: 0.7907

====epoch 148
Train Loss 4.115261754365343
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8962 test: 0.7965 | best val epoch -- val: 0.9175 test: 0.7907

====epoch 149
Train Loss 4.0551788422897
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8998 test: 0.7960 | best val epoch -- val: 0.9175 test: 0.7907

====epoch 150
Train Loss 4.045806610186616
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8903 test: 0.7941 | best val epoch -- val: 0.9175 test: 0.7907

====epoch 151
Train Loss 3.9824994663128215
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9004 test: 0.7847 | best val epoch -- val: 0.9175 test: 0.7907

====epoch 152
Train Loss 3.6259434640651866
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9098 test: 0.7866 | best val epoch -- val: 0.9175 test: 0.7907

====epoch 153
Train Loss 3.660722305006476
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8922 test: 0.7827 | best val epoch -- val: 0.9175 test: 0.7907

====epoch 154
Train Loss 4.567450163858891
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9035 test: 0.7845 | best val epoch -- val: 0.9175 test: 0.7907

====epoch 155
Train Loss 4.006161493844318
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9136 test: 0.7666 | best val epoch -- val: 0.9175 test: 0.7907

====epoch 156
Train Loss 4.3305307496135255
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9135 test: 0.7705 | best val epoch -- val: 0.9175 test: 0.7907

====epoch 157
Train Loss 4.1016340746265945
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9152 test: 0.7765 | best val epoch -- val: 0.9175 test: 0.7907

====epoch 158
Train Loss 3.8903780271803305
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9149 test: 0.7895 | best val epoch -- val: 0.9175 test: 0.7907

====epoch 159
Train Loss 4.075122145018687
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9172 test: 0.7777 | best val epoch -- val: 0.9175 test: 0.7907

====epoch 160
Train Loss 4.369001109762953
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9098 test: 0.7763 | best val epoch -- val: 0.9175 test: 0.7907

====epoch 161
Train Loss 3.9576678188789907
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9217 test: 0.7726 | best val epoch -- val: 0.9217 test: 0.7726

====epoch 162
Train Loss 3.904799576776538
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9061 test: 0.7778 | best val epoch -- val: 0.9217 test: 0.7726

====epoch 163
Train Loss 3.9694908190213716
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9129 test: 0.7891 | best val epoch -- val: 0.9217 test: 0.7726

====epoch 164
Train Loss 3.6534020275540544
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9084 test: 0.7887 | best val epoch -- val: 0.9217 test: 0.7726

====epoch 165
Train Loss 3.7266632222904406
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9128 test: 0.7908 | best val epoch -- val: 0.9217 test: 0.7726

====epoch 166
Train Loss 4.152006857027221
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8977 test: 0.7971 | best val epoch -- val: 0.9217 test: 0.7726

====epoch 167
Train Loss 4.139762726900242
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9020 test: 0.7930 | best val epoch -- val: 0.9217 test: 0.7726

====epoch 168
Train Loss 3.6885228841045428
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9164 test: 0.7888 | best val epoch -- val: 0.9217 test: 0.7726

====epoch 169
Train Loss 3.697227173778102
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9215 test: 0.7696 | best val epoch -- val: 0.9217 test: 0.7726

====epoch 170
Train Loss 3.9957641551785237
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9217 test: 0.7791 | best val epoch -- val: 0.9217 test: 0.7726

====epoch 171
Train Loss 3.824725419627928
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9164 test: 0.7814 | best val epoch -- val: 0.9217 test: 0.7726

====epoch 172
Train Loss 4.029901057751547
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9153 test: 0.7833 | best val epoch -- val: 0.9217 test: 0.7726

====epoch 173
Train Loss 3.892813179439656
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9124 test: 0.7893 | best val epoch -- val: 0.9217 test: 0.7726

====epoch 174
Train Loss 3.8570973957717776
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9177 test: 0.7944 | best val epoch -- val: 0.9217 test: 0.7726

====epoch 175
Train Loss 4.0228570677655675
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9252 test: 0.8012 | best val epoch -- val: 0.9252 test: 0.8012

====epoch 176
Train Loss 3.898745110877919
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9242 test: 0.7925 | best val epoch -- val: 0.9252 test: 0.8012

====epoch 177
Train Loss 3.7943971825488867
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9300 test: 0.8036 | best val epoch -- val: 0.9300 test: 0.8036

====epoch 178
Train Loss 3.861141788159419
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9212 test: 0.7880 | best val epoch -- val: 0.9300 test: 0.8036

====epoch 179
Train Loss 3.7160526165082732
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9273 test: 0.7642 | best val epoch -- val: 0.9300 test: 0.8036

====epoch 180
Train Loss 4.173433376592334
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9286 test: 0.7733 | best val epoch -- val: 0.9300 test: 0.8036

====epoch 181
Train Loss 3.7456749686231325
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9232 test: 0.7836 | best val epoch -- val: 0.9300 test: 0.8036

====epoch 182
Train Loss 4.272801244668486
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9148 test: 0.7795 | best val epoch -- val: 0.9300 test: 0.8036

====epoch 183
Train Loss 3.9575309890903596
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9196 test: 0.7722 | best val epoch -- val: 0.9300 test: 0.8036

====epoch 184
Train Loss 3.767966590031906
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9208 test: 0.7701 | best val epoch -- val: 0.9300 test: 0.8036

====epoch 185
Train Loss 3.8182147911799498
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9096 test: 0.7773 | best val epoch -- val: 0.9300 test: 0.8036

====epoch 186
Train Loss 4.036696331094452
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9151 test: 0.7783 | best val epoch -- val: 0.9300 test: 0.8036

====epoch 187
Train Loss 3.7955532624805683
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9185 test: 0.7781 | best val epoch -- val: 0.9300 test: 0.8036

====epoch 188
Train Loss 3.809988115315325
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9109 test: 0.7648 | best val epoch -- val: 0.9300 test: 0.8036

====epoch 189
Train Loss 3.607611334413175
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8724 test: 0.7574 | best val epoch -- val: 0.9300 test: 0.8036

====epoch 190
Train Loss 3.405921377638158
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8596 test: 0.7671 | best val epoch -- val: 0.9300 test: 0.8036

====epoch 191
Train Loss 3.544349402702039
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8605 test: 0.7547 | best val epoch -- val: 0.9300 test: 0.8036

====epoch 192
Train Loss 3.46873673740325
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9105 test: 0.7546 | best val epoch -- val: 0.9300 test: 0.8036

====epoch 193
Train Loss 3.684147147853156
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9165 test: 0.7711 | best val epoch -- val: 0.9300 test: 0.8036

====epoch 194
Train Loss 3.7606894746450625
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9187 test: 0.7593 | best val epoch -- val: 0.9300 test: 0.8036

====epoch 195
Train Loss 3.5728683173704905
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9102 test: 0.7529 | best val epoch -- val: 0.9300 test: 0.8036

====epoch 196
Train Loss 3.6726148601920006
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9010 test: 0.7688 | best val epoch -- val: 0.9300 test: 0.8036

====epoch 197
Train Loss 3.5959589727639645
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.9132 test: 0.7719 | best val epoch -- val: 0.9300 test: 0.8036

====epoch 198
Train Loss 3.5975904145736943
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8974 test: 0.7691 | best val epoch -- val: 0.9300 test: 0.8036

====epoch 199
Train Loss 3.5971671499343145
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8463 test: 0.7706 | best val epoch -- val: 0.9300 test: 0.8036

====epoch 200
Train Loss 3.303703997996515
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8649 test: 0.7667 | best val epoch -- val: 0.9300 test: 0.8036

2022-09-14 02:54:00.077 | INFO     | modules.masked_transformer_encoder:__init__:122 - number of parameters: 0.000000e+00
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.4.
=========================================
batch_size = 32
d_model = 128
dataset = clintox
decay = 0
device = 3
dim_feedforward = 512
eval_train = 0
filename =
gnn_JK = cat
gnn_dropout = 0.3
gnn_emb_dim = 300
gnn_num_layer = 5
gnn_residual = False
gnn_type = gin
gnn_virtual_node = False
graph_pooling = cls
input_model_file = models_graphtrans/graphtrans-sr-gcl.pth
lr = 5e-05
lr_scale = 1
max_input_len = 1000
nhead = 4
num_encoder_layers = 4
num_encoder_layers_masked = 0
num_workers = 0
pos_encoder = False
runseed = 8
seed = 12344
split = scaffold
transformer_activation = relu
transformer_dropout = 0.3
transformer_norm_input = True
transformer_prenorm = False
=========================================
clintox
scaffold
Loaded GraphTrans from models_graphtrans/graphtrans-sr-gcl.pth
====epoch 1
Train Loss 20.59364244227843
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.4762 test: 0.4401 | best val epoch -- val: 0.4762 test: 0.4401

====epoch 2
Train Loss 12.790761373607609
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.4735 test: 0.4799 | best val epoch -- val: 0.4762 test: 0.4401

====epoch 3
Train Loss 10.524693571770575
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.4408 test: 0.5110 | best val epoch -- val: 0.4762 test: 0.4401

====epoch 4
Train Loss 10.052279369456041
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.4839 test: 0.5174 | best val epoch -- val: 0.4839 test: 0.5174

====epoch 5
Train Loss 9.950504201083637
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.4803 test: 0.5117 | best val epoch -- val: 0.4839 test: 0.5174

====epoch 6
Train Loss 9.867240995830665
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.4891 test: 0.5293 | best val epoch -- val: 0.4891 test: 0.5293

====epoch 7
Train Loss 9.791711949302949
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.4954 test: 0.5385 | best val epoch -- val: 0.4954 test: 0.5385

====epoch 8
Train Loss 9.724406168504009
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.5132 test: 0.5456 | best val epoch -- val: 0.5132 test: 0.5456

====epoch 9
Train Loss 9.617812589308873
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.5458 test: 0.5517 | best val epoch -- val: 0.5458 test: 0.5517

====epoch 10
Train Loss 9.715501150651288
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.5382 test: 0.5956 | best val epoch -- val: 0.5458 test: 0.5517

====epoch 11
Train Loss 9.594097723836219
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.5823 test: 0.5924 | best val epoch -- val: 0.5823 test: 0.5924

====epoch 12
Train Loss 9.468254768630757
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6079 test: 0.6007 | best val epoch -- val: 0.6079 test: 0.6007

====epoch 13
Train Loss 9.595816550923447
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6481 test: 0.6100 | best val epoch -- val: 0.6481 test: 0.6100

====epoch 14
Train Loss 9.354763667488905
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6831 test: 0.6218 | best val epoch -- val: 0.6831 test: 0.6218

====epoch 15
Train Loss 9.433175761342
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7161 test: 0.6375 | best val epoch -- val: 0.7161 test: 0.6375

====epoch 16
Train Loss 9.377415023037099
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7501 test: 0.6464 | best val epoch -- val: 0.7501 test: 0.6464

====epoch 17
Train Loss 9.335460594797683
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7657 test: 0.6389 | best val epoch -- val: 0.7657 test: 0.6389

====epoch 18
Train Loss 9.05176983302841
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7803 test: 0.6543 | best val epoch -- val: 0.7803 test: 0.6543

====epoch 19
Train Loss 8.910826678932846
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7921 test: 0.6475 | best val epoch -- val: 0.7921 test: 0.6475

====epoch 20
Train Loss 8.722756336872434
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8164 test: 0.6540 | best val epoch -- val: 0.8164 test: 0.6540

====epoch 21
Train Loss 8.348840795483602
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8299 test: 0.6759 | best val epoch -- val: 0.8299 test: 0.6759

====epoch 22
Train Loss 8.272160224099983
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8648 test: 0.7107 | best val epoch -- val: 0.8648 test: 0.7107

====epoch 23
Train Loss 8.038390918395686
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8650 test: 0.6800 | best val epoch -- val: 0.8650 test: 0.6800

====epoch 24
Train Loss 7.977408858077681
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8694 test: 0.7072 | best val epoch -- val: 0.8694 test: 0.7072

====epoch 25
Train Loss 7.855094389138583
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8644 test: 0.7145 | best val epoch -- val: 0.8694 test: 0.7072

====epoch 26
Train Loss 8.07375433462308
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8587 test: 0.7160 | best val epoch -- val: 0.8694 test: 0.7072

====epoch 27
Train Loss 7.826248029516822
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8614 test: 0.7274 | best val epoch -- val: 0.8694 test: 0.7072

====epoch 28
Train Loss 7.3461275641582695
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8501 test: 0.7078 | best val epoch -- val: 0.8694 test: 0.7072

====epoch 29
Train Loss 7.611541152062327
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8466 test: 0.7098 | best val epoch -- val: 0.8694 test: 0.7072

====epoch 30
Train Loss 7.241976019254414
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8506 test: 0.7337 | best val epoch -- val: 0.8694 test: 0.7072

====epoch 31
Train Loss 7.332328680620793
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8566 test: 0.7264 | best val epoch -- val: 0.8694 test: 0.7072

====epoch 32
Train Loss 7.265584119453795
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8437 test: 0.7343 | best val epoch -- val: 0.8694 test: 0.7072

====epoch 33
Train Loss 7.296961112237592
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8560 test: 0.7325 | best val epoch -- val: 0.8694 test: 0.7072

====epoch 34
Train Loss 6.794972892660235
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8529 test: 0.7471 | best val epoch -- val: 0.8694 test: 0.7072

====epoch 35
Train Loss 6.9331784630329185
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8412 test: 0.7407 | best val epoch -- val: 0.8694 test: 0.7072

====epoch 36
Train Loss 6.686446989897977
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8348 test: 0.7057 | best val epoch -- val: 0.8694 test: 0.7072

====epoch 37
Train Loss 6.7650390630226465
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8593 test: 0.7284 | best val epoch -- val: 0.8694 test: 0.7072

====epoch 38
Train Loss 6.99317770550903
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8498 test: 0.7353 | best val epoch -- val: 0.8694 test: 0.7072

====epoch 39
Train Loss 6.534811996967077
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8513 test: 0.7454 | best val epoch -- val: 0.8694 test: 0.7072

====epoch 40
Train Loss 6.754849773355038
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8696 test: 0.7401 | best val epoch -- val: 0.8696 test: 0.7401

====epoch 41
Train Loss 6.70632023625433
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8529 test: 0.7532 | best val epoch -- val: 0.8696 test: 0.7401

====epoch 42
Train Loss 6.705197659233532
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8383 test: 0.7407 | best val epoch -- val: 0.8696 test: 0.7401

====epoch 43
Train Loss 6.180183202093839
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8465 test: 0.7431 | best val epoch -- val: 0.8696 test: 0.7401

====epoch 44
Train Loss 6.595190272207844
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8385 test: 0.7493 | best val epoch -- val: 0.8696 test: 0.7401

====epoch 45
Train Loss 6.294328037346438
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8431 test: 0.7466 | best val epoch -- val: 0.8696 test: 0.7401

====epoch 46
Train Loss 6.350083407165316
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8375 test: 0.7307 | best val epoch -- val: 0.8696 test: 0.7401

====epoch 47
Train Loss 6.1735862432227675
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8477 test: 0.7454 | best val epoch -- val: 0.8696 test: 0.7401

====epoch 48
Train Loss 6.407724995860875
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8604 test: 0.7555 | best val epoch -- val: 0.8696 test: 0.7401

====epoch 49
Train Loss 6.00079474762816
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8462 test: 0.7658 | best val epoch -- val: 0.8696 test: 0.7401

====epoch 50
Train Loss 5.901411323650666
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8597 test: 0.7639 | best val epoch -- val: 0.8696 test: 0.7401

====epoch 51
Train Loss 5.902348447426141
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8587 test: 0.7642 | best val epoch -- val: 0.8696 test: 0.7401

====epoch 52
Train Loss 5.7612284317649705
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8715 test: 0.7589 | best val epoch -- val: 0.8715 test: 0.7589

====epoch 53
Train Loss 5.858729678368569
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8644 test: 0.7622 | best val epoch -- val: 0.8715 test: 0.7589

====epoch 54
Train Loss 5.88036735697451
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8484 test: 0.7563 | best val epoch -- val: 0.8715 test: 0.7589

====epoch 55
Train Loss 5.9167695424006315
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8584 test: 0.7642 | best val epoch -- val: 0.8715 test: 0.7589

====epoch 56
Train Loss 5.603706826994737
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8698 test: 0.7588 | best val epoch -- val: 0.8715 test: 0.7589

====epoch 57
Train Loss 5.721875467460884
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8832 test: 0.7686 | best val epoch -- val: 0.8832 test: 0.7686

====epoch 58
Train Loss 5.525023003218333
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8787 test: 0.7724 | best val epoch -- val: 0.8832 test: 0.7686

====epoch 59
Train Loss 5.405866724182923
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8764 test: 0.7799 | best val epoch -- val: 0.8832 test: 0.7686

====epoch 60
Train Loss 5.308802648309539
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8739 test: 0.7797 | best val epoch -- val: 0.8832 test: 0.7686

====epoch 61
Train Loss 5.530108100157107
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8705 test: 0.7839 | best val epoch -- val: 0.8832 test: 0.7686

====epoch 62
Train Loss 5.495545251961227
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8678 test: 0.7831 | best val epoch -- val: 0.8832 test: 0.7686

====epoch 63
Train Loss 5.305493896472994
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8814 test: 0.7717 | best val epoch -- val: 0.8832 test: 0.7686

====epoch 64
Train Loss 5.76794984077713
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8761 test: 0.7875 | best val epoch -- val: 0.8832 test: 0.7686

====epoch 65
Train Loss 5.376007555846634
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8798 test: 0.7659 | best val epoch -- val: 0.8832 test: 0.7686

====epoch 66
Train Loss 5.618820381898151
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8637 test: 0.7730 | best val epoch -- val: 0.8832 test: 0.7686

====epoch 67
Train Loss 5.575001612775005
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8827 test: 0.7725 | best val epoch -- val: 0.8832 test: 0.7686

====epoch 68
Train Loss 5.772402044652992
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8739 test: 0.7900 | best val epoch -- val: 0.8832 test: 0.7686

====epoch 69
Train Loss 5.433651994224638
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8687 test: 0.7674 | best val epoch -- val: 0.8832 test: 0.7686

====epoch 70
Train Loss 5.495208611242818
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8658 test: 0.7742 | best val epoch -- val: 0.8832 test: 0.7686

====epoch 71
Train Loss 5.138277030106783
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8600 test: 0.7782 | best val epoch -- val: 0.8832 test: 0.7686

====epoch 72
Train Loss 5.431727590911303
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8742 test: 0.7972 | best val epoch -- val: 0.8832 test: 0.7686

====epoch 73
Train Loss 5.599074234935696
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8787 test: 0.7866 | best val epoch -- val: 0.8832 test: 0.7686

====epoch 74
Train Loss 5.170199952366157
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8745 test: 0.7818 | best val epoch -- val: 0.8832 test: 0.7686

====epoch 75
Train Loss 5.686763438597477
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8821 test: 0.7868 | best val epoch -- val: 0.8832 test: 0.7686

====epoch 76
Train Loss 4.9141803045038905
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8825 test: 0.7836 | best val epoch -- val: 0.8832 test: 0.7686

====epoch 77
Train Loss 5.052976644700965
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8840 test: 0.7910 | best val epoch -- val: 0.8840 test: 0.7910

====epoch 78
Train Loss 5.31057302696358
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8807 test: 0.7750 | best val epoch -- val: 0.8840 test: 0.7910

====epoch 79
Train Loss 5.275891269497226
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8884 test: 0.7691 | best val epoch -- val: 0.8884 test: 0.7691

====epoch 80
Train Loss 4.991336855596968
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8808 test: 0.7840 | best val epoch -- val: 0.8884 test: 0.7691

====epoch 81
Train Loss 5.045574630976394
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8807 test: 0.7772 | best val epoch -- val: 0.8884 test: 0.7691

====epoch 82
Train Loss 5.303126769596292
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8616 test: 0.7835 | best val epoch -- val: 0.8884 test: 0.7691

====epoch 83
Train Loss 5.241843018116428
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8666 test: 0.7900 | best val epoch -- val: 0.8884 test: 0.7691

====epoch 84
Train Loss 4.837136538560942
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8823 test: 0.7758 | best val epoch -- val: 0.8884 test: 0.7691

====epoch 85
Train Loss 5.1674810511896005
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8807 test: 0.7713 | best val epoch -- val: 0.8884 test: 0.7691

====epoch 86
Train Loss 4.812468351345926
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8740 test: 0.7925 | best val epoch -- val: 0.8884 test: 0.7691

====epoch 87
Train Loss 5.313637137271709
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8801 test: 0.7917 | best val epoch -- val: 0.8884 test: 0.7691

====epoch 88
Train Loss 5.0227649546964965
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8867 test: 0.8022 | best val epoch -- val: 0.8884 test: 0.7691

====epoch 89
Train Loss 5.3566965970225855
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8755 test: 0.7766 | best val epoch -- val: 0.8884 test: 0.7691

====epoch 90
Train Loss 5.291342676852252
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8732 test: 0.7777 | best val epoch -- val: 0.8884 test: 0.7691

====epoch 91
Train Loss 5.2230906736380955
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8699 test: 0.8053 | best val epoch -- val: 0.8884 test: 0.7691

====epoch 92
Train Loss 5.11217837779367
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8760 test: 0.7999 | best val epoch -- val: 0.8884 test: 0.7691

====epoch 93
Train Loss 4.969748281952297
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8812 test: 0.7946 | best val epoch -- val: 0.8884 test: 0.7691

====epoch 94
Train Loss 4.994693868880922
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8733 test: 0.8090 | best val epoch -- val: 0.8884 test: 0.7691

====epoch 95
Train Loss 4.806079435308445
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8589 test: 0.8055 | best val epoch -- val: 0.8884 test: 0.7691

====epoch 96
Train Loss 4.9595735939441195
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8492 test: 0.8106 | best val epoch -- val: 0.8884 test: 0.7691

====epoch 97
Train Loss 4.9025432577195565
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8522 test: 0.7912 | best val epoch -- val: 0.8884 test: 0.7691

====epoch 98
Train Loss 5.135653040771867
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8593 test: 0.7983 | best val epoch -- val: 0.8884 test: 0.7691

====epoch 99
Train Loss 4.806057855585727
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8605 test: 0.7926 | best val epoch -- val: 0.8884 test: 0.7691

====epoch 100
Train Loss 4.8234310542244145
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8584 test: 0.7689 | best val epoch -- val: 0.8884 test: 0.7691

====epoch 101
Train Loss 5.282237591745134
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8686 test: 0.7557 | best val epoch -- val: 0.8884 test: 0.7691

====epoch 102
Train Loss 5.051934591150697
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8606 test: 0.7954 | best val epoch -- val: 0.8884 test: 0.7691

====epoch 103
Train Loss 4.952614222421923
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8828 test: 0.7872 | best val epoch -- val: 0.8884 test: 0.7691

====epoch 104
Train Loss 4.5449829209750305
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8814 test: 0.7701 | best val epoch -- val: 0.8884 test: 0.7691

====epoch 105
Train Loss 4.515572379253491
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8780 test: 0.7569 | best val epoch -- val: 0.8884 test: 0.7691

====epoch 106
Train Loss 4.645332166099664
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8658 test: 0.7660 | best val epoch -- val: 0.8884 test: 0.7691

====epoch 107
Train Loss 4.641848288084943
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8609 test: 0.7656 | best val epoch -- val: 0.8884 test: 0.7691

====epoch 108
Train Loss 4.687311382816919
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8881 test: 0.7575 | best val epoch -- val: 0.8884 test: 0.7691

====epoch 109
Train Loss 4.678866465296343
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8893 test: 0.7995 | best val epoch -- val: 0.8893 test: 0.7995

====epoch 110
Train Loss 5.087787229440658
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8733 test: 0.7569 | best val epoch -- val: 0.8893 test: 0.7995

====epoch 111
Train Loss 4.75420531251373
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8663 test: 0.7555 | best val epoch -- val: 0.8893 test: 0.7995

====epoch 112
Train Loss 4.645848209131806
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8671 test: 0.7552 | best val epoch -- val: 0.8893 test: 0.7995

====epoch 113
Train Loss 4.42302350329174
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8632 test: 0.7758 | best val epoch -- val: 0.8893 test: 0.7995

====epoch 114
Train Loss 4.425937141918346
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8615 test: 0.7747 | best val epoch -- val: 0.8893 test: 0.7995

====epoch 115
Train Loss 4.553064779058094
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8473 test: 0.7849 | best val epoch -- val: 0.8893 test: 0.7995

====epoch 116
Train Loss 4.713610644169075
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8438 test: 0.7638 | best val epoch -- val: 0.8893 test: 0.7995

====epoch 117
Train Loss 4.885835371170938
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8330 test: 0.7572 | best val epoch -- val: 0.8893 test: 0.7995

====epoch 118
Train Loss 4.412438725631487
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8460 test: 0.7348 | best val epoch -- val: 0.8893 test: 0.7995

====epoch 119
Train Loss 4.632295286708104
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8561 test: 0.7706 | best val epoch -- val: 0.8893 test: 0.7995

====epoch 120
Train Loss 4.781354902014893
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8498 test: 0.7727 | best val epoch -- val: 0.8893 test: 0.7995

====epoch 121
Train Loss 4.54399898012371
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8364 test: 0.7612 | best val epoch -- val: 0.8893 test: 0.7995

====epoch 122
Train Loss 4.418007473453956
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8339 test: 0.7148 | best val epoch -- val: 0.8893 test: 0.7995

====epoch 123
Train Loss 4.682243706394101
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8242 test: 0.7579 | best val epoch -- val: 0.8893 test: 0.7995

====epoch 124
Train Loss 4.417111565198605
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8285 test: 0.7555 | best val epoch -- val: 0.8893 test: 0.7995

====epoch 125
Train Loss 4.471277997592706
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8325 test: 0.7317 | best val epoch -- val: 0.8893 test: 0.7995

====epoch 126
Train Loss 4.412117351131601
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8285 test: 0.7291 | best val epoch -- val: 0.8893 test: 0.7995

====epoch 127
Train Loss 4.404169371307865
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8388 test: 0.7324 | best val epoch -- val: 0.8893 test: 0.7995

====epoch 128
Train Loss 4.275257130065032
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8540 test: 0.7214 | best val epoch -- val: 0.8893 test: 0.7995

====epoch 129
Train Loss 4.5240845296203895
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8494 test: 0.7001 | best val epoch -- val: 0.8893 test: 0.7995

====epoch 130
Train Loss 4.515605217141461
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8731 test: 0.7552 | best val epoch -- val: 0.8893 test: 0.7995

====epoch 131
Train Loss 4.146388771265555
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8642 test: 0.7874 | best val epoch -- val: 0.8893 test: 0.7995

====epoch 132
Train Loss 4.460019444348598
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8416 test: 0.7463 | best val epoch -- val: 0.8893 test: 0.7995

====epoch 133
Train Loss 4.2883111671318925
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8564 test: 0.7491 | best val epoch -- val: 0.8893 test: 0.7995

====epoch 134
Train Loss 4.354470892437921
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8374 test: 0.7246 | best val epoch -- val: 0.8893 test: 0.7995

====epoch 135
Train Loss 4.358878422056235
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8527 test: 0.7322 | best val epoch -- val: 0.8893 test: 0.7995

====epoch 136
Train Loss 4.374698908364281
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8425 test: 0.7188 | best val epoch -- val: 0.8893 test: 0.7995

====epoch 137
Train Loss 4.698249228415091
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8622 test: 0.7036 | best val epoch -- val: 0.8893 test: 0.7995

====epoch 138
Train Loss 4.552494583774136
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8493 test: 0.7071 | best val epoch -- val: 0.8893 test: 0.7995

====epoch 139
Train Loss 4.499436998692267
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8676 test: 0.7528 | best val epoch -- val: 0.8893 test: 0.7995

====epoch 140
Train Loss 4.081840614528996
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8717 test: 0.7459 | best val epoch -- val: 0.8893 test: 0.7995

====epoch 141
Train Loss 4.366828168721787
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8737 test: 0.7317 | best val epoch -- val: 0.8893 test: 0.7995

====epoch 142
Train Loss 4.331777270127893
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8659 test: 0.7566 | best val epoch -- val: 0.8893 test: 0.7995

====epoch 143
Train Loss 4.29406723937812
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8633 test: 0.7330 | best val epoch -- val: 0.8893 test: 0.7995

====epoch 144
Train Loss 4.428013480046825
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8632 test: 0.7179 | best val epoch -- val: 0.8893 test: 0.7995

====epoch 145
Train Loss 4.348834358651978
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8502 test: 0.7575 | best val epoch -- val: 0.8893 test: 0.7995

====epoch 146
Train Loss 4.2037427888915895
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8541 test: 0.7611 | best val epoch -- val: 0.8893 test: 0.7995

====epoch 147
Train Loss 4.2127236319826
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8596 test: 0.7688 | best val epoch -- val: 0.8893 test: 0.7995

====epoch 148
Train Loss 4.020417123008069
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8428 test: 0.7400 | best val epoch -- val: 0.8893 test: 0.7995

====epoch 149
Train Loss 4.191378724646379
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8558 test: 0.7378 | best val epoch -- val: 0.8893 test: 0.7995

====epoch 150
Train Loss 4.398801172473894
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8614 test: 0.7653 | best val epoch -- val: 0.8893 test: 0.7995

====epoch 151
Train Loss 4.176507983326909
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8412 test: 0.7519 | best val epoch -- val: 0.8893 test: 0.7995

====epoch 152
Train Loss 4.355255291594148
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8489 test: 0.7671 | best val epoch -- val: 0.8893 test: 0.7995

====epoch 153
Train Loss 4.097341860599933
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8519 test: 0.7666 | best val epoch -- val: 0.8893 test: 0.7995

====epoch 154
Train Loss 4.346523713748794
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8565 test: 0.7712 | best val epoch -- val: 0.8893 test: 0.7995

====epoch 155
Train Loss 4.056262624483735
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8619 test: 0.7449 | best val epoch -- val: 0.8893 test: 0.7995

====epoch 156
Train Loss 4.28760111369003
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8668 test: 0.7796 | best val epoch -- val: 0.8893 test: 0.7995

====epoch 157
Train Loss 4.442585423184937
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8493 test: 0.7677 | best val epoch -- val: 0.8893 test: 0.7995

====epoch 158
Train Loss 4.199251529839627
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8422 test: 0.7634 | best val epoch -- val: 0.8893 test: 0.7995

====epoch 159
Train Loss 4.211698247153072
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8524 test: 0.7930 | best val epoch -- val: 0.8893 test: 0.7995

====epoch 160
Train Loss 4.146183527164655
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8516 test: 0.7348 | best val epoch -- val: 0.8893 test: 0.7995

====epoch 161
Train Loss 4.10641602204997
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8607 test: 0.7631 | best val epoch -- val: 0.8893 test: 0.7995

====epoch 162
Train Loss 4.420284529614424
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8405 test: 0.7311 | best val epoch -- val: 0.8893 test: 0.7995

====epoch 163
Train Loss 4.036708203093638
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8530 test: 0.7447 | best val epoch -- val: 0.8893 test: 0.7995

====epoch 164
Train Loss 4.069373161862837
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8593 test: 0.7431 | best val epoch -- val: 0.8893 test: 0.7995

====epoch 165
Train Loss 4.133876840271978
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8621 test: 0.7536 | best val epoch -- val: 0.8893 test: 0.7995

====epoch 166
Train Loss 4.071102092906456
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8424 test: 0.7230 | best val epoch -- val: 0.8893 test: 0.7995

====epoch 167
Train Loss 4.120013694777454
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8567 test: 0.7615 | best val epoch -- val: 0.8893 test: 0.7995

====epoch 168
Train Loss 4.164512290647673
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8551 test: 0.7637 | best val epoch -- val: 0.8893 test: 0.7995

====epoch 169
Train Loss 4.3570539528791565
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8543 test: 0.7707 | best val epoch -- val: 0.8893 test: 0.7995

====epoch 170
Train Loss 4.324692139788221
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8642 test: 0.7653 | best val epoch -- val: 0.8893 test: 0.7995

====epoch 171
Train Loss 4.239734617865082
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8540 test: 0.7577 | best val epoch -- val: 0.8893 test: 0.7995

====epoch 172
Train Loss 4.19539497425653
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8712 test: 0.7251 | best val epoch -- val: 0.8893 test: 0.7995

====epoch 173
Train Loss 3.932231011578154
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8756 test: 0.7474 | best val epoch -- val: 0.8893 test: 0.7995

====epoch 174
Train Loss 4.090836285537232
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8586 test: 0.7561 | best val epoch -- val: 0.8893 test: 0.7995

====epoch 175
Train Loss 4.0009608004013435
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8731 test: 0.7457 | best val epoch -- val: 0.8893 test: 0.7995

====epoch 176
Train Loss 3.5137145737582602
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8809 test: 0.7617 | best val epoch -- val: 0.8893 test: 0.7995

====epoch 177
Train Loss 4.090572913918542
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8804 test: 0.7609 | best val epoch -- val: 0.8893 test: 0.7995

====epoch 178
Train Loss 3.669876616148603
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8660 test: 0.7730 | best val epoch -- val: 0.8893 test: 0.7995

====epoch 179
Train Loss 3.9810603002675475
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8617 test: 0.7574 | best val epoch -- val: 0.8893 test: 0.7995

====epoch 180
Train Loss 3.7155256579055242
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8606 test: 0.7530 | best val epoch -- val: 0.8893 test: 0.7995

====epoch 181
Train Loss 4.015819681105757
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8504 test: 0.7631 | best val epoch -- val: 0.8893 test: 0.7995

====epoch 182
Train Loss 4.260634850716267
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8445 test: 0.7709 | best val epoch -- val: 0.8893 test: 0.7995

====epoch 183
Train Loss 4.037868751473314
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8434 test: 0.7689 | best val epoch -- val: 0.8893 test: 0.7995

====epoch 184
Train Loss 3.7287286294777573
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8494 test: 0.7685 | best val epoch -- val: 0.8893 test: 0.7995

====epoch 185
Train Loss 3.9942998285660885
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8400 test: 0.7541 | best val epoch -- val: 0.8893 test: 0.7995

====epoch 186
Train Loss 3.861626768373431
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8321 test: 0.7581 | best val epoch -- val: 0.8893 test: 0.7995

====epoch 187
Train Loss 3.9135833881899957
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8556 test: 0.7729 | best val epoch -- val: 0.8893 test: 0.7995

====epoch 188
Train Loss 3.6805223792723294
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8494 test: 0.7623 | best val epoch -- val: 0.8893 test: 0.7995

====epoch 189
Train Loss 3.538946837115928
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8310 test: 0.7420 | best val epoch -- val: 0.8893 test: 0.7995

====epoch 190
Train Loss 3.843344536767095
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8207 test: 0.7466 | best val epoch -- val: 0.8893 test: 0.7995

====epoch 191
Train Loss 3.848427963348024
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8296 test: 0.7554 | best val epoch -- val: 0.8893 test: 0.7995

====epoch 192
Train Loss 4.0460074597575915
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8523 test: 0.7624 | best val epoch -- val: 0.8893 test: 0.7995

====epoch 193
Train Loss 3.709401776277072
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8659 test: 0.7618 | best val epoch -- val: 0.8893 test: 0.7995

====epoch 194
Train Loss 3.640016967521079
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8548 test: 0.7658 | best val epoch -- val: 0.8893 test: 0.7995

====epoch 195
Train Loss 3.7938233000627664
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8586 test: 0.7580 | best val epoch -- val: 0.8893 test: 0.7995

====epoch 196
Train Loss 3.94798859594007
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8725 test: 0.7808 | best val epoch -- val: 0.8893 test: 0.7995

====epoch 197
Train Loss 3.695653525514849
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8683 test: 0.7663 | best val epoch -- val: 0.8893 test: 0.7995

====epoch 198
Train Loss 3.7203018165413706
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8768 test: 0.7575 | best val epoch -- val: 0.8893 test: 0.7995

====epoch 199
Train Loss 3.7720979787436715
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8483 test: 0.7474 | best val epoch -- val: 0.8893 test: 0.7995

====epoch 200
Train Loss 3.521832288854703
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8508 test: 0.7411 | best val epoch -- val: 0.8893 test: 0.7995

2022-09-14 03:00:47.350 | INFO     | modules.masked_transformer_encoder:__init__:122 - number of parameters: 0.000000e+00
WARNING:root:The OGB package is out of date. Your version is 1.3.3, while the latest version is 1.3.4.
=========================================
batch_size = 32
d_model = 128
dataset = clintox
decay = 0
device = 3
dim_feedforward = 512
eval_train = 0
filename =
gnn_JK = cat
gnn_dropout = 0.3
gnn_emb_dim = 300
gnn_num_layer = 5
gnn_residual = False
gnn_type = gin
gnn_virtual_node = False
graph_pooling = cls
input_model_file = models_graphtrans/graphtrans-sr-gcl.pth
lr = 5e-05
lr_scale = 1
max_input_len = 1000
nhead = 4
num_encoder_layers = 4
num_encoder_layers_masked = 0
num_workers = 0
pos_encoder = False
runseed = 9
seed = 12344
split = scaffold
transformer_activation = relu
transformer_dropout = 0.3
transformer_norm_input = True
transformer_prenorm = False
=========================================
clintox
scaffold
Loaded GraphTrans from models_graphtrans/graphtrans-sr-gcl.pth
====epoch 1
Train Loss 21.998645965126
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.4744 test: 0.5542 | best val epoch -- val: 0.4744 test: 0.5542

====epoch 2
Train Loss 13.013714132270783
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.4817 test: 0.5761 | best val epoch -- val: 0.4817 test: 0.5761

====epoch 3
Train Loss 10.655318333503562
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.5096 test: 0.5867 | best val epoch -- val: 0.5096 test: 0.5867

====epoch 4
Train Loss 9.955590697724906
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.5288 test: 0.5821 | best val epoch -- val: 0.5288 test: 0.5821

====epoch 5
Train Loss 9.750956861116588
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.5114 test: 0.5959 | best val epoch -- val: 0.5288 test: 0.5821

====epoch 6
Train Loss 9.907927613537975
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.5521 test: 0.6009 | best val epoch -- val: 0.5521 test: 0.6009

====epoch 7
Train Loss 9.842910920075175
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.5129 test: 0.6142 | best val epoch -- val: 0.5521 test: 0.6009

====epoch 8
Train Loss 9.70157972027109
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.3579 test: 0.6487 | best val epoch -- val: 0.5521 test: 0.6009

====epoch 9
Train Loss 9.670467220783602
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.5635 test: 0.6282 | best val epoch -- val: 0.5635 test: 0.6282

====epoch 10
Train Loss 9.632626221375848
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6053 test: 0.6393 | best val epoch -- val: 0.6053 test: 0.6393

====epoch 11
Train Loss 9.373201653904813
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6055 test: 0.6420 | best val epoch -- val: 0.6055 test: 0.6420

====epoch 12
Train Loss 9.355539718412837
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6627 test: 0.6671 | best val epoch -- val: 0.6627 test: 0.6671

====epoch 13
Train Loss 9.36542989107667
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6987 test: 0.6715 | best val epoch -- val: 0.6987 test: 0.6715

====epoch 14
Train Loss 9.460800958666592
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6863 test: 0.6763 | best val epoch -- val: 0.6987 test: 0.6715

====epoch 15
Train Loss 9.343629817947452
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6780 test: 0.6610 | best val epoch -- val: 0.6987 test: 0.6715

====epoch 16
Train Loss 9.09841468523392
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.6908 test: 0.6623 | best val epoch -- val: 0.6987 test: 0.6715

====epoch 17
Train Loss 8.985404813748517
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7487 test: 0.6815 | best val epoch -- val: 0.7487 test: 0.6815

====epoch 18
Train Loss 8.963648277273961
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7648 test: 0.6899 | best val epoch -- val: 0.7648 test: 0.6899

====epoch 19
Train Loss 8.868076579464871
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7800 test: 0.6975 | best val epoch -- val: 0.7800 test: 0.6975

====epoch 20
Train Loss 8.705670902870123
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8153 test: 0.6967 | best val epoch -- val: 0.8153 test: 0.6967

====epoch 21
Train Loss 8.91206176324257
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8359 test: 0.7258 | best val epoch -- val: 0.8359 test: 0.7258

====epoch 22
Train Loss 8.563224357634382
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8590 test: 0.7273 | best val epoch -- val: 0.8590 test: 0.7273

====epoch 23
Train Loss 8.551417382669845
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8512 test: 0.7233 | best val epoch -- val: 0.8590 test: 0.7273

====epoch 24
Train Loss 8.239032868799798
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8395 test: 0.7452 | best val epoch -- val: 0.8590 test: 0.7273

====epoch 25
Train Loss 7.89527166186359
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8692 test: 0.7140 | best val epoch -- val: 0.8692 test: 0.7140

====epoch 26
Train Loss 8.224945524050176
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8780 test: 0.7139 | best val epoch -- val: 0.8780 test: 0.7139

====epoch 27
Train Loss 7.739123004692829
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8842 test: 0.7222 | best val epoch -- val: 0.8842 test: 0.7222

====epoch 28
Train Loss 7.731335828959746
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8662 test: 0.7266 | best val epoch -- val: 0.8842 test: 0.7222

====epoch 29
Train Loss 7.374603809838845
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8586 test: 0.7211 | best val epoch -- val: 0.8842 test: 0.7222

====epoch 30
Train Loss 7.314812131472735
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8439 test: 0.7309 | best val epoch -- val: 0.8842 test: 0.7222

====epoch 31
Train Loss 7.647829990693662
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8344 test: 0.7234 | best val epoch -- val: 0.8842 test: 0.7222

====epoch 32
Train Loss 6.9352674697908725
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8444 test: 0.7049 | best val epoch -- val: 0.8842 test: 0.7222

====epoch 33
Train Loss 7.089406889739505
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8313 test: 0.7074 | best val epoch -- val: 0.8842 test: 0.7222

====epoch 34
Train Loss 6.5765938685528305
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8358 test: 0.7050 | best val epoch -- val: 0.8842 test: 0.7222

====epoch 35
Train Loss 6.935672920625837
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8396 test: 0.7473 | best val epoch -- val: 0.8842 test: 0.7222

====epoch 36
Train Loss 6.7346829471512795
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8415 test: 0.7567 | best val epoch -- val: 0.8842 test: 0.7222

====epoch 37
Train Loss 7.025331867003243
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8427 test: 0.7685 | best val epoch -- val: 0.8842 test: 0.7222

====epoch 38
Train Loss 6.656857727740413
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8337 test: 0.7532 | best val epoch -- val: 0.8842 test: 0.7222

====epoch 39
Train Loss 6.75978685074213
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8496 test: 0.7332 | best val epoch -- val: 0.8842 test: 0.7222

====epoch 40
Train Loss 6.671130473447088
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8549 test: 0.7558 | best val epoch -- val: 0.8842 test: 0.7222

====epoch 41
Train Loss 7.056960881245043
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8514 test: 0.7276 | best val epoch -- val: 0.8842 test: 0.7222

====epoch 42
Train Loss 6.317476680460824
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8610 test: 0.7316 | best val epoch -- val: 0.8842 test: 0.7222

====epoch 43
Train Loss 6.223243927137235
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8519 test: 0.7306 | best val epoch -- val: 0.8842 test: 0.7222

====epoch 44
Train Loss 6.516278687473083
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8160 test: 0.7212 | best val epoch -- val: 0.8842 test: 0.7222

====epoch 45
Train Loss 6.2742312271972835
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8500 test: 0.7290 | best val epoch -- val: 0.8842 test: 0.7222

====epoch 46
Train Loss 6.22447224831889
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8294 test: 0.7318 | best val epoch -- val: 0.8842 test: 0.7222

====epoch 47
Train Loss 6.397817566706288
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8305 test: 0.7527 | best val epoch -- val: 0.8842 test: 0.7222

====epoch 48
Train Loss 5.905510813588089
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8039 test: 0.7353 | best val epoch -- val: 0.8842 test: 0.7222

====epoch 49
Train Loss 5.69357278967798
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8237 test: 0.7312 | best val epoch -- val: 0.8842 test: 0.7222

====epoch 50
Train Loss 5.940716482621967
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8269 test: 0.7625 | best val epoch -- val: 0.8842 test: 0.7222

====epoch 51
Train Loss 5.997042812827471
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8109 test: 0.7338 | best val epoch -- val: 0.8842 test: 0.7222

====epoch 52
Train Loss 6.0017387783478275
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8004 test: 0.7624 | best val epoch -- val: 0.8842 test: 0.7222

====epoch 53
Train Loss 6.068242602426876
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8279 test: 0.7500 | best val epoch -- val: 0.8842 test: 0.7222

====epoch 54
Train Loss 5.761607861782777
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8279 test: 0.7656 | best val epoch -- val: 0.8842 test: 0.7222

====epoch 55
Train Loss 5.976463444107509
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8359 test: 0.7504 | best val epoch -- val: 0.8842 test: 0.7222

====epoch 56
Train Loss 5.851061558356717
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8383 test: 0.7457 | best val epoch -- val: 0.8842 test: 0.7222

====epoch 57
Train Loss 5.809690481613428
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8189 test: 0.7435 | best val epoch -- val: 0.8842 test: 0.7222

====epoch 58
Train Loss 5.4085820715478725
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8362 test: 0.7466 | best val epoch -- val: 0.8842 test: 0.7222

====epoch 59
Train Loss 5.592810379856212
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8190 test: 0.7433 | best val epoch -- val: 0.8842 test: 0.7222

====epoch 60
Train Loss 5.617445485811885
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8140 test: 0.7341 | best val epoch -- val: 0.8842 test: 0.7222

====epoch 61
Train Loss 5.729484587318106
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8102 test: 0.7370 | best val epoch -- val: 0.8842 test: 0.7222

====epoch 62
Train Loss 5.869862155582422
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.7957 test: 0.7532 | best val epoch -- val: 0.8842 test: 0.7222

====epoch 63
Train Loss 5.761749322191843
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8067 test: 0.7547 | best val epoch -- val: 0.8842 test: 0.7222

====epoch 64
Train Loss 5.4450533131246965
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8244 test: 0.7608 | best val epoch -- val: 0.8842 test: 0.7222

====epoch 65
Train Loss 5.562599988414796
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8281 test: 0.7728 | best val epoch -- val: 0.8842 test: 0.7222

====epoch 66
Train Loss 5.715834919299415
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8251 test: 0.7724 | best val epoch -- val: 0.8842 test: 0.7222

====epoch 67
Train Loss 5.76070270652059
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8203 test: 0.7819 | best val epoch -- val: 0.8842 test: 0.7222

====epoch 68
Train Loss 5.863328611060889
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8299 test: 0.7734 | best val epoch -- val: 0.8842 test: 0.7222

====epoch 69
Train Loss 5.453072760513865
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8259 test: 0.7762 | best val epoch -- val: 0.8842 test: 0.7222

====epoch 70
Train Loss 5.324406380547031
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8273 test: 0.7711 | best val epoch -- val: 0.8842 test: 0.7222

====epoch 71
Train Loss 5.01384698497273
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8443 test: 0.7738 | best val epoch -- val: 0.8842 test: 0.7222

====epoch 72
Train Loss 4.767428695833083
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8414 test: 0.7738 | best val epoch -- val: 0.8842 test: 0.7222

====epoch 73
Train Loss 5.078276902312552
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8426 test: 0.7711 | best val epoch -- val: 0.8842 test: 0.7222

====epoch 74
Train Loss 5.361188889510893
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8487 test: 0.7831 | best val epoch -- val: 0.8842 test: 0.7222

====epoch 75
Train Loss 5.105499819397822
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8426 test: 0.7800 | best val epoch -- val: 0.8842 test: 0.7222

====epoch 76
Train Loss 5.1757524604499245
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8567 test: 0.7857 | best val epoch -- val: 0.8842 test: 0.7222

====epoch 77
Train Loss 5.316412711313495
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8256 test: 0.7795 | best val epoch -- val: 0.8842 test: 0.7222

====epoch 78
Train Loss 5.052935975411866
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8360 test: 0.7828 | best val epoch -- val: 0.8842 test: 0.7222

====epoch 79
Train Loss 5.031061866488359
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8455 test: 0.7813 | best val epoch -- val: 0.8842 test: 0.7222

====epoch 80
Train Loss 4.789296859910816
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8501 test: 0.7822 | best val epoch -- val: 0.8842 test: 0.7222

====epoch 81
Train Loss 5.224882967736336
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8566 test: 0.7872 | best val epoch -- val: 0.8842 test: 0.7222

====epoch 82
Train Loss 4.99695731002182
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8532 test: 0.7896 | best val epoch -- val: 0.8842 test: 0.7222

====epoch 83
Train Loss 4.732102480051529
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8513 test: 0.7682 | best val epoch -- val: 0.8842 test: 0.7222

====epoch 84
Train Loss 4.829829159344824
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8432 test: 0.7623 | best val epoch -- val: 0.8842 test: 0.7222

====epoch 85
Train Loss 5.054815615201667
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8255 test: 0.7690 | best val epoch -- val: 0.8842 test: 0.7222

====epoch 86
Train Loss 4.999862825430342
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8524 test: 0.7623 | best val epoch -- val: 0.8842 test: 0.7222

====epoch 87
Train Loss 4.680966416617578
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8502 test: 0.7665 | best val epoch -- val: 0.8842 test: 0.7222

====epoch 88
Train Loss 5.03309174572378
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8615 test: 0.7876 | best val epoch -- val: 0.8842 test: 0.7222

====epoch 89
Train Loss 4.869710611820777
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8632 test: 0.7678 | best val epoch -- val: 0.8842 test: 0.7222

====epoch 90
Train Loss 4.918012835042558
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8607 test: 0.7755 | best val epoch -- val: 0.8842 test: 0.7222

====epoch 91
Train Loss 4.470568257824862
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8674 test: 0.7843 | best val epoch -- val: 0.8842 test: 0.7222

====epoch 92
Train Loss 4.91363713951887
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8675 test: 0.7875 | best val epoch -- val: 0.8842 test: 0.7222

====epoch 93
Train Loss 4.708771970637977
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8583 test: 0.7870 | best val epoch -- val: 0.8842 test: 0.7222

====epoch 94
Train Loss 4.760783557273259
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8567 test: 0.7809 | best val epoch -- val: 0.8842 test: 0.7222

====epoch 95
Train Loss 4.831939776369642
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8673 test: 0.7836 | best val epoch -- val: 0.8842 test: 0.7222

====epoch 96
Train Loss 4.498237162334633
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8626 test: 0.7788 | best val epoch -- val: 0.8842 test: 0.7222

====epoch 97
Train Loss 4.913707595068389
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8783 test: 0.7837 | best val epoch -- val: 0.8842 test: 0.7222

====epoch 98
Train Loss 4.580376427937831
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8751 test: 0.7858 | best val epoch -- val: 0.8842 test: 0.7222

====epoch 99
Train Loss 4.508742957283776
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8557 test: 0.7814 | best val epoch -- val: 0.8842 test: 0.7222

====epoch 100
Train Loss 4.373158666424893
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8718 test: 0.7763 | best val epoch -- val: 0.8842 test: 0.7222

====epoch 101
Train Loss 4.780477600712563
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8703 test: 0.7783 | best val epoch -- val: 0.8842 test: 0.7222

====epoch 102
Train Loss 4.6721673542527755
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8628 test: 0.7952 | best val epoch -- val: 0.8842 test: 0.7222

====epoch 103
Train Loss 4.689850805739262
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8789 test: 0.7873 | best val epoch -- val: 0.8842 test: 0.7222

====epoch 104
Train Loss 4.817439054775145
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8661 test: 0.7957 | best val epoch -- val: 0.8842 test: 0.7222

====epoch 105
Train Loss 4.616788595016594
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8679 test: 0.7932 | best val epoch -- val: 0.8842 test: 0.7222

====epoch 106
Train Loss 4.343818825176117
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8694 test: 0.7924 | best val epoch -- val: 0.8842 test: 0.7222

====epoch 107
Train Loss 4.3791260010964415
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8642 test: 0.7813 | best val epoch -- val: 0.8842 test: 0.7222

====epoch 108
Train Loss 4.757114988096281
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8681 test: 0.7807 | best val epoch -- val: 0.8842 test: 0.7222

====epoch 109
Train Loss 4.389119598031318
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8756 test: 0.7746 | best val epoch -- val: 0.8842 test: 0.7222

====epoch 110
Train Loss 4.7955169437957474
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8685 test: 0.7803 | best val epoch -- val: 0.8842 test: 0.7222

====epoch 111
Train Loss 4.672856450085178
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8849 test: 0.7503 | best val epoch -- val: 0.8849 test: 0.7503

====epoch 112
Train Loss 4.405449951842475
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8842 test: 0.7563 | best val epoch -- val: 0.8849 test: 0.7503

====epoch 113
Train Loss 4.625030110858222
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8777 test: 0.7683 | best val epoch -- val: 0.8849 test: 0.7503

====epoch 114
Train Loss 4.633440064915109
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8829 test: 0.7645 | best val epoch -- val: 0.8849 test: 0.7503

====epoch 115
Train Loss 4.574660113445844
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8742 test: 0.7605 | best val epoch -- val: 0.8849 test: 0.7503

====epoch 116
Train Loss 4.442645099295877
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8746 test: 0.7616 | best val epoch -- val: 0.8849 test: 0.7503

====epoch 117
Train Loss 4.332218218895996
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8708 test: 0.7712 | best val epoch -- val: 0.8849 test: 0.7503

====epoch 118
Train Loss 4.633243746758103
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8689 test: 0.7672 | best val epoch -- val: 0.8849 test: 0.7503

====epoch 119
Train Loss 4.4330406502572055
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8647 test: 0.7633 | best val epoch -- val: 0.8849 test: 0.7503

====epoch 120
Train Loss 4.202241591578308
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8524 test: 0.7713 | best val epoch -- val: 0.8849 test: 0.7503

====epoch 121
Train Loss 4.142000139705448
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8551 test: 0.7596 | best val epoch -- val: 0.8849 test: 0.7503

====epoch 122
Train Loss 4.233920866263257
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8655 test: 0.7738 | best val epoch -- val: 0.8849 test: 0.7503

====epoch 123
Train Loss 4.194782218803731
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8477 test: 0.7569 | best val epoch -- val: 0.8849 test: 0.7503

====epoch 124
Train Loss 4.573801963803107
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8662 test: 0.7693 | best val epoch -- val: 0.8849 test: 0.7503

====epoch 125
Train Loss 4.128515464460636
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8673 test: 0.7634 | best val epoch -- val: 0.8849 test: 0.7503

====epoch 126
Train Loss 4.529870248411479
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8656 test: 0.7602 | best val epoch -- val: 0.8849 test: 0.7503

====epoch 127
Train Loss 4.265789985809418
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8717 test: 0.7630 | best val epoch -- val: 0.8849 test: 0.7503

====epoch 128
Train Loss 4.2460128045794425
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8653 test: 0.7726 | best val epoch -- val: 0.8849 test: 0.7503

====epoch 129
Train Loss 4.128589792584819
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8667 test: 0.7735 | best val epoch -- val: 0.8849 test: 0.7503

====epoch 130
Train Loss 4.299233560510347
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8601 test: 0.7694 | best val epoch -- val: 0.8849 test: 0.7503

====epoch 131
Train Loss 4.206122841953117
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8481 test: 0.7610 | best val epoch -- val: 0.8849 test: 0.7503

====epoch 132
Train Loss 4.208887696858875
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8592 test: 0.7680 | best val epoch -- val: 0.8849 test: 0.7503

====epoch 133
Train Loss 4.2084349473228
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8248 test: 0.7702 | best val epoch -- val: 0.8849 test: 0.7503

====epoch 134
Train Loss 4.460939465504197
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8409 test: 0.7759 | best val epoch -- val: 0.8849 test: 0.7503

====epoch 135
Train Loss 4.142516493115556
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8394 test: 0.7762 | best val epoch -- val: 0.8849 test: 0.7503

====epoch 136
Train Loss 3.8790674970796433
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8468 test: 0.7674 | best val epoch -- val: 0.8849 test: 0.7503

====epoch 137
Train Loss 4.308619020705273
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8490 test: 0.7711 | best val epoch -- val: 0.8849 test: 0.7503

====epoch 138
Train Loss 4.450415887655898
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8416 test: 0.7718 | best val epoch -- val: 0.8849 test: 0.7503

====epoch 139
Train Loss 4.178462887840739
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8560 test: 0.7670 | best val epoch -- val: 0.8849 test: 0.7503

====epoch 140
Train Loss 4.030055620295585
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8607 test: 0.7601 | best val epoch -- val: 0.8849 test: 0.7503

====epoch 141
Train Loss 4.456486729638904
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8415 test: 0.7586 | best val epoch -- val: 0.8849 test: 0.7503

====epoch 142
Train Loss 4.238932125006792
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8571 test: 0.7612 | best val epoch -- val: 0.8849 test: 0.7503

====epoch 143
Train Loss 4.052669699181605
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8467 test: 0.7621 | best val epoch -- val: 0.8849 test: 0.7503

====epoch 144
Train Loss 4.096265951500669
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8585 test: 0.7780 | best val epoch -- val: 0.8849 test: 0.7503

====epoch 145
Train Loss 4.41376843410621
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8439 test: 0.7729 | best val epoch -- val: 0.8849 test: 0.7503

====epoch 146
Train Loss 4.121066378209231
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8300 test: 0.7695 | best val epoch -- val: 0.8849 test: 0.7503

====epoch 147
Train Loss 4.29296445901945
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8330 test: 0.7795 | best val epoch -- val: 0.8849 test: 0.7503

====epoch 148
Train Loss 4.337784218146926
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8286 test: 0.7763 | best val epoch -- val: 0.8849 test: 0.7503

====epoch 149
Train Loss 4.239317915557579
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8717 test: 0.7756 | best val epoch -- val: 0.8849 test: 0.7503

====epoch 150
Train Loss 4.295302263392018
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8575 test: 0.7731 | best val epoch -- val: 0.8849 test: 0.7503

====epoch 151
Train Loss 4.187821632968133
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8624 test: 0.7591 | best val epoch -- val: 0.8849 test: 0.7503

====epoch 152
Train Loss 4.286106585483459
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8657 test: 0.7888 | best val epoch -- val: 0.8849 test: 0.7503

====epoch 153
Train Loss 3.9539822915559157
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8574 test: 0.7655 | best val epoch -- val: 0.8849 test: 0.7503

====epoch 154
Train Loss 4.149185696364216
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8659 test: 0.7670 | best val epoch -- val: 0.8849 test: 0.7503

====epoch 155
Train Loss 4.224923637222185
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8556 test: 0.7614 | best val epoch -- val: 0.8849 test: 0.7503

====epoch 156
Train Loss 3.9683824236434098
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8739 test: 0.7646 | best val epoch -- val: 0.8849 test: 0.7503

====epoch 157
Train Loss 3.8580548029898067
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8703 test: 0.7618 | best val epoch -- val: 0.8849 test: 0.7503

====epoch 158
Train Loss 4.273896443474394
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8623 test: 0.7688 | best val epoch -- val: 0.8849 test: 0.7503

====epoch 159
Train Loss 3.919744946147218
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8780 test: 0.7522 | best val epoch -- val: 0.8849 test: 0.7503

====epoch 160
Train Loss 3.6864606889958007
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8724 test: 0.7640 | best val epoch -- val: 0.8849 test: 0.7503

====epoch 161
Train Loss 4.0149534510411335
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8579 test: 0.7762 | best val epoch -- val: 0.8849 test: 0.7503

====epoch 162
Train Loss 4.133817334159738
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8453 test: 0.7673 | best val epoch -- val: 0.8849 test: 0.7503

====epoch 163
Train Loss 3.961059351124134
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8395 test: 0.7655 | best val epoch -- val: 0.8849 test: 0.7503

====epoch 164
Train Loss 3.9344307456998955
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8595 test: 0.7536 | best val epoch -- val: 0.8849 test: 0.7503

====epoch 165
Train Loss 4.033221970495896
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8688 test: 0.7636 | best val epoch -- val: 0.8849 test: 0.7503

====epoch 166
Train Loss 4.089978553195629
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8571 test: 0.7717 | best val epoch -- val: 0.8849 test: 0.7503

====epoch 167
Train Loss 3.9905553375953975
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8461 test: 0.7646 | best val epoch -- val: 0.8849 test: 0.7503

====epoch 168
Train Loss 3.9013167983221906
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8477 test: 0.7443 | best val epoch -- val: 0.8849 test: 0.7503

====epoch 169
Train Loss 4.115952296403195
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8709 test: 0.7716 | best val epoch -- val: 0.8849 test: 0.7503

====epoch 170
Train Loss 3.5637693960431034
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8740 test: 0.7663 | best val epoch -- val: 0.8849 test: 0.7503

====epoch 171
Train Loss 4.022296515130175
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8614 test: 0.7485 | best val epoch -- val: 0.8849 test: 0.7503

====epoch 172
Train Loss 4.0277835487003175
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8698 test: 0.7703 | best val epoch -- val: 0.8849 test: 0.7503

====epoch 173
Train Loss 3.875112206591756
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8680 test: 0.7560 | best val epoch -- val: 0.8849 test: 0.7503

====epoch 174
Train Loss 4.075243330731049
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8726 test: 0.7680 | best val epoch -- val: 0.8849 test: 0.7503

====epoch 175
Train Loss 4.092500994142245
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8779 test: 0.7703 | best val epoch -- val: 0.8849 test: 0.7503

====epoch 176
Train Loss 3.891862418596135
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8773 test: 0.7755 | best val epoch -- val: 0.8849 test: 0.7503

====epoch 177
Train Loss 3.691405355387769
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8876 test: 0.7905 | best val epoch -- val: 0.8876 test: 0.7905

====epoch 178
Train Loss 3.8625686281406164
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8775 test: 0.7762 | best val epoch -- val: 0.8876 test: 0.7905

====epoch 179
Train Loss 4.119037722252565
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8863 test: 0.7768 | best val epoch -- val: 0.8876 test: 0.7905

====epoch 180
Train Loss 3.9119241859976817
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8799 test: 0.7786 | best val epoch -- val: 0.8876 test: 0.7905

====epoch 181
Train Loss 3.7965171554535604
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8909 test: 0.7910 | best val epoch -- val: 0.8909 test: 0.7910

====epoch 182
Train Loss 3.7731885599122514
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8870 test: 0.7889 | best val epoch -- val: 0.8909 test: 0.7910

====epoch 183
Train Loss 3.756052752495468
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8940 test: 0.8337 | best val epoch -- val: 0.8940 test: 0.8337

====epoch 184
Train Loss 4.195825683374605
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8825 test: 0.7693 | best val epoch -- val: 0.8940 test: 0.8337

====epoch 185
Train Loss 3.4799465266412164
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8902 test: 0.7779 | best val epoch -- val: 0.8940 test: 0.8337

====epoch 186
Train Loss 3.724538714514044
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8929 test: 0.7781 | best val epoch -- val: 0.8940 test: 0.8337

====epoch 187
Train Loss 3.966810028420476
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8898 test: 0.7770 | best val epoch -- val: 0.8940 test: 0.8337

====epoch 188
Train Loss 3.764170179172675
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8737 test: 0.7797 | best val epoch -- val: 0.8940 test: 0.8337

====epoch 189
Train Loss 3.689239735699151
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8861 test: 0.7843 | best val epoch -- val: 0.8940 test: 0.8337

====epoch 190
Train Loss 3.362455188326889
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8908 test: 0.7853 | best val epoch -- val: 0.8940 test: 0.8337

====epoch 191
Train Loss 3.594141588451502
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8848 test: 0.7886 | best val epoch -- val: 0.8940 test: 0.8337

====epoch 192
Train Loss 3.7541155241645816
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8834 test: 0.7840 | best val epoch -- val: 0.8940 test: 0.8337

====epoch 193
Train Loss 3.7973535862695154
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8891 test: 0.7799 | best val epoch -- val: 0.8940 test: 0.8337

====epoch 194
Train Loss 3.692749700064794
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8807 test: 0.7825 | best val epoch -- val: 0.8940 test: 0.8337

====epoch 195
Train Loss 3.9321003268516295
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8819 test: 0.7704 | best val epoch -- val: 0.8940 test: 0.8337

====epoch 196
Train Loss 3.6979837579350963
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8871 test: 0.7737 | best val epoch -- val: 0.8940 test: 0.8337

====epoch 197
Train Loss 3.5706495294185467
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8893 test: 0.7720 | best val epoch -- val: 0.8940 test: 0.8337

====epoch 198
Train Loss 3.5447184704500265
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8921 test: 0.7783 | best val epoch -- val: 0.8940 test: 0.8337

====epoch 199
Train Loss 3.61610019491498
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8779 test: 0.7734 | best val epoch -- val: 0.8940 test: 0.8337

====epoch 200
Train Loss 3.652743200511845
====Evaluation
omit the training accuracy computation
train: 0.0000 val: 0.8763 test: 0.7849 | best val epoch -- val: 0.8940 test: 0.8337
